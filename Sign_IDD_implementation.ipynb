{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xgUlP1HqTfIuc4lPfjnfAJmUe0-D6XXQ",
      "authorship_tag": "ABX9TyOVMIOIdLU2NLekm3CgM+6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiranjan52/Sign-IDD-paper-implementation/blob/main/Sign_IDD_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python version needs to be changed to 3.9 for compatibility:\n",
        "\n",
        "to check current version:\n",
        "\n",
        "`!python--version`\n",
        "\n",
        "to get python3.9:\n",
        "\n",
        "`!sudo apt-get install python3.9`\n",
        "\n",
        "to change version to 3.9:\n",
        "\n",
        "`!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1`\n",
        "\n",
        "Finally after changing the version restart the runtime to apply changes"
      ],
      "metadata": {
        "id": "xOZGePn7RExZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "# coding: utf-8\n",
        "UNK_TOKEN = '<unk>'\n",
        "PAD_TOKEN = '<pad>'\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "TARGET_PAD = 0.0\n",
        "\n",
        "DEFAULT_UNK_ID = lambda: 0"
      ],
      "metadata": {
        "id": "9GSTmkIrljFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn.init import _calculate_fan_in_and_fan_out\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "4eINv1i3r-Pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d6e3c6a-6cc5-4ea1-bdaa-097fdd6ef553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xavier initializer for parameters that combine multiple matrices in one\n",
        "parameter for efficiency. This is e.g. used for GRU and LSTM parameters,\n",
        "where e.g. all gates are computed at the same time by 1 big matrix.\n",
        "\n",
        "    :param w: parameter\n",
        "    :param gain: default 1\n",
        "    :param n: default 4"
      ],
      "metadata": {
        "id": "NuBRY6HgsnXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xavier_uniform_n_(w: Tensor, gain: float = 1, n: int = 1) -> None:\n",
        "  with torch.no_grad():\n",
        "    fan_in, fan_out = _calculate_fan_in_and_fan_out(w)\n",
        "    assert fan_out % n == 0, \"fan_out should be divisible by n\"\n",
        "    fan_out //= n\n",
        "    std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n",
        "    a = math.sqrt(3.0) * std\n",
        "    nn.init.uniform(w, -a, a)"
      ],
      "metadata": {
        "id": "qIYgU3swsgkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initializes a model based on the provided config.\n",
        "\n",
        "All initializer configuration is part of the `model` section of the\n",
        "configuration file.\n",
        "\n",
        "The main initializer is set using the `initializer` key.\n",
        "Possible values are `xavier`, `uniform`, `normal` or `zeros`.\n",
        "(`xavier` is the default).\n",
        "\n",
        "When an initializer is set to `uniform`, then `init_weight` sets the\n",
        "range for the values (-init_weight, init_weight).\n",
        "\n",
        "When an initializer is set to `normal`, then `init_weight` sets the\n",
        "standard deviation for the weights (with mean 0).\n",
        "\n",
        "The word embedding initializer is set using `embed_initializer` and takes\n",
        "the same values. The default is `normal` with `embed_init_weight = 0.01`.\n",
        "\n",
        "Biases are initialized separately using `bias_initializer`.\n",
        "The default is `zeros`, but you can use the same initializers as\n",
        "the main initializer.\n",
        "\n",
        "    :param model: model to initialize\n",
        "    :param cfg: the model configuration\n",
        "    :param src_padding_idx: index of source padding token\n",
        "    :param trg_padding_idx: index of target padding token"
      ],
      "metadata": {
        "id": "WWskml2GudyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model: nn.Module, cfg: dict, src_padding_idx: int,\n",
        "                     trg_padding_idx: int) -> None:\n",
        "    # defaults: xavier, embeddings: normal 0.01, biases: zeros, no orthogonal\n",
        "    gain = float(cfg.get(\"init_gain\", 1.0))  # for xavier\n",
        "    init = cfg.get(\"initializer\", \"xavier\")\n",
        "    init_weight = float(cfg.get(\"init_weight\", 0.01))\n",
        "\n",
        "    embed_init = cfg.get(\"embed_initializer\", \"normal\")\n",
        "    embed_init_weight = float(cfg.get(\"embed_init_weight\", 0.01))\n",
        "    embed_gain = float(cfg.get(\"embed_init_gain\", 1.0))  # for xavier\n",
        "\n",
        "    bias_init = cfg.get(\"bias_initializer\", \"zeros\")\n",
        "    bias_init_weight = float(cfg.get(\"bias_init_weight\", 0.01))\n",
        "\n",
        "    def _parse_init(s, scale, _gain):\n",
        "        scale = float(scale)\n",
        "        assert scale > 0., \"incorrect init_weight\"\n",
        "        if s.lower() == \"xavier\":\n",
        "            return lambda p: nn.init.xavier_uniform_(p, gain=_gain)\n",
        "        elif s.lower() == \"uniform\":\n",
        "            return lambda p: nn.init.uniform_(p, a=-scale, b=scale)\n",
        "        elif s.lower() == \"normal\":\n",
        "            return lambda p: nn.init.normal_(p, mean=0., std=scale)\n",
        "        elif s.lower() == \"zeros\":\n",
        "            return lambda p: nn.init.zeros_(p)\n",
        "        else:\n",
        "            raise ValueError(\"unknown initializer\")\n",
        "\n",
        "    init_fn_ = _parse_init(init, init_weight, gain)\n",
        "    embed_init_fn_ = _parse_init(embed_init, embed_init_weight, embed_gain)\n",
        "    bias_init_fn_ = _parse_init(bias_init, bias_init_weight, gain)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for name, p in model.named_parameters():\n",
        "\n",
        "            if \"embed\" in name:\n",
        "                if \"bias\" in name:\n",
        "                    bias_init_fn_(p)\n",
        "                else:\n",
        "                    embed_init_fn_(p)\n",
        "\n",
        "            elif \"bias\" in name:\n",
        "                bias_init_fn_(p)\n",
        "\n",
        "            elif len(p.size()) > 1:\n",
        "\n",
        "                # RNNs combine multiple matrices is one, which messes up\n",
        "                # xavier initialization\n",
        "                if init == \"xavier\" and \"rnn\" in name:\n",
        "                    n = 1\n",
        "                    if \"encoder\" in name:\n",
        "                        n = 4 if isinstance(model.encoder.rnn, nn.LSTM) else 3\n",
        "                    elif \"decoder\" in name:\n",
        "                        n = 4 if isinstance(model.decoder.rnn, nn.LSTM) else 3\n",
        "                    xavier_uniform_n_(p.data, gain=gain, n=n)\n",
        "                else:\n",
        "                    init_fn_(p)\n",
        "\n",
        "        # zero out paddings\n",
        "        model.src_embed.lut.weight.data[src_padding_idx].zero_()"
      ],
      "metadata": {
        "id": "oDk9vTlNubg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Batch:\n",
        "    def __init__(self, torch_batch, pad_index, model):\n",
        "        self.src, self.src_lengths = torch_batch.src\n",
        "        self.src_mask = (self.src != pad_index).unsqueeze(1)\n",
        "        self.nseqs = self.src.size(0)\n",
        "        self.trg_input = None\n",
        "        self.trg = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        self.file_paths = torch_batch.file_paths\n",
        "        self.use_cuda = model.use_cuda\n",
        "        self.target_pad = TARGET_PAD\n",
        "\n",
        "        if hasattr(torch_batch, \"trg\"):\n",
        "            trg = torch_batch.trg\n",
        "            trg_lengths = torch_batch.trg.shape[1]\n",
        "            # trg_input is used for teacher forcing, last one is cut off\n",
        "            # Remove the last frame for target input, as inputs are only up to frame N-1\n",
        "            self.trg_input = trg.clone()\n",
        "\n",
        "            self.trg_lengths = trg_lengths\n",
        "            # trg is used for loss computation, shifted by one since BOS\n",
        "            self.trg = trg.clone()\n",
        "\n",
        "            # Target Pad is dynamic, so we exclude the padded areas from the loss computation\n",
        "            trg_mask = (self.trg_input != self.target_pad).unsqueeze(1)\n",
        "            # This increases the shape of the target mask to be even (16,1,120,120) -\n",
        "            # adding padding that replicates - so just continues the False's or True's\n",
        "            pad_amount = self.trg_input.shape[1] - self.trg_input.shape[2]\n",
        "            # Create the target mask the same size as target input\n",
        "            self.trg_mask = (torch.nn.functional.pad(input=trg_mask.double(), pad=(pad_amount, 0, 0, 0), mode='replicate') == 1.0)\n",
        "            self.ntokens = (self.trg != pad_index).data.sum().item()\n",
        "\n",
        "        if self.use_cuda:\n",
        "            self._make_cuda()\n",
        "\n",
        "    # If using Cuda\n",
        "    def _make_cuda(self):\n",
        "        \"\"\"\n",
        "        Move the batch to GPU\n",
        "\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.src = self.src.cuda()\n",
        "        self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "        if self.trg_input is not None:\n",
        "            self.trg_input = self.trg_input.cuda()\n",
        "            self.trg = self.trg.cuda()\n",
        "            self.trg_mask = self.trg_mask.cuda()"
      ],
      "metadata": {
        "id": "apOkHc82vtMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchtext --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luDuzCs3S1xS",
        "outputId": "c701a2b5-47f8-4723-828a-bc9d1b65f096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torchtext\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.17.0%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.16.2%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.16.1%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.16.0%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.1%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.0%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtext) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchtext)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchtext) (3.0.2)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List\n",
        "from torchtext.data import Dataset"
      ],
      "metadata": {
        "id": "xC5MH1erSlxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulary class represents a mapping between tokens and indices"
      ],
      "metadata": {
        "id": "P_1cqAq0FFZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, tokens: List[str] = None, file: str = None) -> None:\n",
        "\n",
        "        # don't rename stoi and itos since needed for torchtext\n",
        "        # warning: stoi grows with unknown tokens, don't use for saving or size\n",
        "\n",
        "        # special symbols\n",
        "        self.specials = [UNK_TOKEN, PAD_TOKEN, BOS_TOKEN, EOS_TOKEN]\n",
        "\n",
        "        self.stoi = defaultdict(DEFAULT_UNK_ID)\n",
        "        self.itos = []\n",
        "        if tokens is not None:\n",
        "            self._from_list(tokens)\n",
        "        elif file is not None:\n",
        "            self._from_file(file)\n",
        "\n",
        "\n",
        "    def _from_list(self, tokens: List[str] = None) -> None:\n",
        "        \"\"\"\n",
        "        Make vocabulary from list of tokens.\n",
        "        Tokens are assumed to be unique and pre-selected.\n",
        "        Special symbols are added if not in list.\n",
        "\n",
        "        :param tokens: list of tokens\n",
        "        \"\"\"\n",
        "        self.add_tokens(tokens=self.specials+tokens)\n",
        "        assert len(self.stoi) == len(self.itos)\n",
        "\n",
        "    def _from_file(self, file: str) -> None:\n",
        "        \"\"\"\n",
        "        Make vocabulary from contents of file.\n",
        "        File format: token with index i is in line i.\n",
        "\n",
        "        :param file: path to file where the vocabulary is loaded from\n",
        "        \"\"\"\n",
        "        tokens = []\n",
        "        with open(file, \"r\") as open_file:\n",
        "            for line in open_file:\n",
        "                tokens.append(line.strip(\"\\n\"))\n",
        "        self._from_list(tokens)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return self.stoi.__str__()\n",
        "\n",
        "    def to_file(self, file: str) -> None:\n",
        "        \"\"\"\n",
        "        Save the vocabulary to a file, by writing token with index i in line i.\n",
        "\n",
        "        :param file: path to file where the vocabulary is written\n",
        "        \"\"\"\n",
        "        with open(file, \"w\") as open_file:\n",
        "            for t in self.itos:\n",
        "                open_file.write(\"{}\\n\".format(t))\n",
        "\n",
        "    def add_tokens(self, tokens: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Add list of tokens to vocabulary\n",
        "\n",
        "        :param tokens: list of tokens to add to the vocabulary\n",
        "        \"\"\"\n",
        "        for t in tokens:\n",
        "            new_index = len(self.itos)\n",
        "            # add to vocab if not already there\n",
        "            if t not in self.itos:\n",
        "                self.itos.append(t)\n",
        "                self.stoi[t] = new_index\n",
        "\n",
        "    def is_unk(self, token: str) -> bool:\n",
        "        \"\"\"\n",
        "        Check whether a token is covered by the vocabulary\n",
        "\n",
        "        :param token:\n",
        "        :return: True if covered, False otherwise\n",
        "        \"\"\"\n",
        "        return self.stoi[token] == DEFAULT_UNK_ID()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.itos)\n",
        "\n",
        "    def array_to_sentence(self, array: np.array, cut_at_eos=True) -> List[str]:\n",
        "        \"\"\"\n",
        "        Converts an array of IDs to a sentence, optionally cutting the result\n",
        "        off at the end-of-sequence token.\n",
        "\n",
        "        :param array: 1D array containing indices\n",
        "        :param cut_at_eos: cut the decoded sentences at the first <eos>\n",
        "        :return: list of strings (tokens)\n",
        "        \"\"\"\n",
        "        sentence = []\n",
        "        for i in array:\n",
        "            s = self.itos[i]\n",
        "            if cut_at_eos and s == EOS_TOKEN:\n",
        "                break\n",
        "            sentence.append(s)\n",
        "        return sentence\n",
        "\n",
        "    def arrays_to_sentences(self, arrays: np.array, cut_at_eos=True) \\\n",
        "            -> List[List[str]]:\n",
        "        \"\"\"\n",
        "        Convert multiple arrays containing sequences of token IDs to their\n",
        "        sentences, optionally cutting them off at the end-of-sequence token.\n",
        "\n",
        "        :param arrays: 2D array containing indices\n",
        "        :param cut_at_eos: cut the decoded sentences at the first <eos>\n",
        "        :return: list of list of strings (tokens)\n",
        "        \"\"\"\n",
        "        sentences = []\n",
        "        for array in arrays:\n",
        "            sentences.append(\n",
        "                self.array_to_sentence(array=array, cut_at_eos=cut_at_eos))\n",
        "        return sentences"
      ],
      "metadata": {
        "id": "WteE4netE4i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function builds vocabulary for a torchtext `field` from given`dataset` or `vocab_file`.\n",
        "    \n",
        "    :param field: attribute e.g. \"src\"\n",
        "    :param max_size: maximum size of vocabulary\n",
        "    :param min_freq: minimum frequency for an item to be included\n",
        "    :param dataset: dataset to load data for field from\n",
        "    :param vocab_file: file to store the vocabulary,\n",
        "        if not None, load vocabulary from here\n",
        "    :return: Vocabulary created from either `dataset` or `vocab_file`"
      ],
      "metadata": {
        "id": "TDI4mkJ9Fun_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(field: str, max_size: int, min_freq: int, dataset: Dataset,\n",
        "                vocab_file: str = None) -> Vocabulary:\n",
        "    if vocab_file is not None:\n",
        "        # load it from file\n",
        "        vocab = Vocabulary(file=vocab_file)\n",
        "    else:\n",
        "        # create newly\n",
        "        def filter_min(counter: Counter, min_freq: int):\n",
        "            \"\"\" Filter counter by min frequency \"\"\"\n",
        "            filtered_counter = Counter({t: c for t, c in counter.items()\n",
        "                                        if c >= min_freq})\n",
        "            return filtered_counter\n",
        "\n",
        "        def sort_and_cut(counter: Counter, limit: int):\n",
        "            \"\"\" Cut counter to most frequent,\n",
        "            sorted numerically and alphabetically\"\"\"\n",
        "            # sort by frequency, then alphabetically\n",
        "            tokens_and_frequencies = sorted(counter.items(),\n",
        "                                            key=lambda tup: tup[0])\n",
        "            tokens_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
        "            vocab_tokens = [i[0] for i in tokens_and_frequencies[:limit]]\n",
        "            return vocab_tokens\n",
        "\n",
        "        tokens = []\n",
        "        for i in dataset.examples:\n",
        "            if field == \"src\":\n",
        "                tokens.extend(i.src)\n",
        "            elif field == \"trg\":\n",
        "                tokens.extend(i.trg)\n",
        "\n",
        "        counter = Counter(tokens)\n",
        "        if min_freq > -1:\n",
        "            counter = filter_min(counter, min_freq)\n",
        "        vocab_tokens = sort_and_cut(counter, max_size)\n",
        "        assert len(vocab_tokens) <= max_size\n",
        "\n",
        "        vocab = Vocabulary(tokens=vocab_tokens)\n",
        "        assert len(vocab) <= max_size + len(vocab.specials)\n",
        "        assert vocab.itos[DEFAULT_UNK_ID()] == UNK_TOKEN\n",
        "\n",
        "    # check for all except for UNK token whether they are OOVs\n",
        "    for s in vocab.specials[1:]:\n",
        "        assert not vocab.is_unk(s)\n",
        "\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "w64wdiBPGNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads: int, size: int, dropout: float = 0.1):\n",
        "\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "\n",
        "        assert size % num_heads == 0\n",
        "\n",
        "        self.head_size = head_size = size // num_heads\n",
        "        self.model_size = size\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.k_layer = nn.Linear(size, num_heads * head_size)\n",
        "        self.v_layer = nn.Linear(size, num_heads * head_size)\n",
        "        self.q_layer = nn.Linear(size, num_heads * head_size)\n",
        "\n",
        "        self.output_layer = nn.Linear(size, size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.target_pad = TARGET_PAD\n",
        "\n",
        "    def forward(self, k: Tensor, v: Tensor, q: Tensor, mask: Tensor = None, padding_mask: Tensor = None):\n",
        "\n",
        "        batch_size = k.size(0)\n",
        "        num_heads = self.num_heads\n",
        "\n",
        "        # project the queries (q), keys (k), and values (v)\n",
        "        k = self.k_layer(k)\n",
        "        v = self.v_layer(v)\n",
        "        q = self.q_layer(q)\n",
        "\n",
        "        # reshape q, k, v for our computation to [batch_size, num_heads, ..]\n",
        "        k = k.view(batch_size, -1, num_heads, self.head_size).transpose(1, 2)\n",
        "        v = v.view(batch_size, -1, num_heads, self.head_size).transpose(1, 2)\n",
        "        q = q.view(batch_size, -1, num_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "        # compute scores\n",
        "        q = q / math.sqrt(self.head_size)\n",
        "\n",
        "        # batch x num_heads x query_len x key_len\n",
        "        scores = torch.matmul(q, k.transpose(2, 3))\n",
        "\n",
        "        # apply the mask (if we have one)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(~mask.unsqueeze(1), float('-inf'))\n",
        "\n",
        "        # apply attention dropout and compute context vectors.\n",
        "        attention = self.softmax(scores)\n",
        "        attention = self.dropout(attention)\n",
        "\n",
        "        if padding_mask is not None:\n",
        "            # This masks out the attention of the padded end of sequences\n",
        "            attention = attention.masked_fill(~padding_mask, 0.0)\n",
        "\n",
        "        # get context vector (select values with attention) and reshape\n",
        "        context = torch.matmul(attention, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(\n",
        "            batch_size, -1, num_heads * self.head_size)\n",
        "\n",
        "        output = self.output_layer(context)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "QI_92ur9G312"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, ff_size, dropout=0.1):\n",
        "\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(input_size, eps=1e-6)\n",
        "        self.pwff_layer = nn.Sequential(\n",
        "            nn.Linear(input_size, ff_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(ff_size, input_size),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.layer_norm(x)\n",
        "        return self.pwff_layer(x_norm) + x"
      ],
      "metadata": {
        "id": "e60OSuZeHqjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 size: int = 0,\n",
        "                 ff_size: int = 0,\n",
        "                 num_heads: int = 0,\n",
        "                 dropout: float = 0.1):\n",
        "\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(size, eps=1e-6)\n",
        "        self.src_src_att = MultiHeadedAttention(num_heads, size,\n",
        "                                                dropout=dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(size, ff_size=ff_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.size = size\n",
        "\n",
        "    # pylint: disable=arguments-differ\n",
        "    def forward(self, x: Tensor, mask: Tensor) -> Tensor:\n",
        "\n",
        "        x_norm = self.layer_norm(x)\n",
        "\n",
        "        h = self.src_src_att(x_norm, x_norm, x_norm, mask=mask)\n",
        "\n",
        "        h = self.dropout(h) + x\n",
        "        o = self.feed_forward(h)\n",
        "        return o"
      ],
      "metadata": {
        "id": "GrsIKSj1H3sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "bzIe3PpLyKTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 size: int = 0,\n",
        "                 max_len: int = 200000, # Max length was too small for the required length\n",
        "                 mask_count=False):\n",
        "\n",
        "        if size % 2 != 0:\n",
        "            raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                             \"odd dim (got dim={:d})\".format(size))\n",
        "        pe = torch.zeros(max_len, size)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp((torch.arange(0, size, 2, dtype=torch.float) *\n",
        "                              -(math.log(10000.0) / size)))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        pe = pe.unsqueeze(0)  # shape: [1, size, max_len]\n",
        "\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.register_buffer('pe', pe)\n",
        "        self.dim = size\n",
        "        self.mask_count = mask_count\n",
        "\n",
        "    def forward(self, emb):\n",
        "        return emb + self.pe[:, :emb.size(1)]"
      ],
      "metadata": {
        "id": "A1qWfpMVyMXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 size: int = 0,\n",
        "                 ff_size: int = 0,\n",
        "                 num_heads: int = 0,\n",
        "                 dropout: float = 0.1,\n",
        "                 decoder_trg_trg: bool = True):\n",
        "\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "\n",
        "        self.trg_trg_att = MultiHeadedAttention(num_heads, size,\n",
        "                                                dropout=dropout)\n",
        "\n",
        "        self.src_trg_att = MultiHeadedAttention(num_heads, size,\n",
        "                                                dropout=dropout)\n",
        "\n",
        "        self.feed_forward = PositionwiseFeedForward(size, ff_size=ff_size)\n",
        "\n",
        "        self.x_layer_norm = nn.LayerNorm(size, eps=1e-6)\n",
        "        self.dec_layer_norm = nn.LayerNorm(size, eps=1e-6)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.decoder_trg_trg = decoder_trg_trg\n",
        "\n",
        "    # pylint: disable=arguments-differ\n",
        "    def forward(self,\n",
        "                x: Tensor = None,\n",
        "                memory: Tensor = None,\n",
        "                src_mask: Tensor = None,\n",
        "                trg_mask: Tensor = None,\n",
        "                padding_mask: Tensor = None) -> tuple[Tensor,Tensor]:\n",
        "\n",
        "        # decoder/target self-attention\n",
        "        h1 = self.x_layer_norm(x)\n",
        "\n",
        "        # Target-Target Self Attention\n",
        "        if self.decoder_trg_trg:\n",
        "            h1 = self.trg_trg_att(h1, h1, h1, mask=trg_mask, padding_mask=padding_mask)\n",
        "        h1 = self.dropout(h1) + x\n",
        "\n",
        "        # Source-Target Self Attention\n",
        "        h1_norm = self.dec_layer_norm(h1)\n",
        "        h2 = self.src_trg_att(memory, memory, h1_norm, mask=src_mask)\n",
        "\n",
        "        # final position-wise feed-forward layer\n",
        "        o = self.feed_forward(self.dropout(h2) + h1)\n",
        "\n",
        "        return o, h2"
      ],
      "metadata": {
        "id": "z3amt0iGH_Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic time warping (DTW) is used as a similarity measured between temporal sequences.\n",
        "\n",
        "The following function computes Dynamic Time Warping (DTW) of two sequences.\n",
        "\n",
        "    :param array x: N1*M array\n",
        "    :param array y: N2*M array\n",
        "    :param func dist: distance used as cost measure\n",
        "    :param int warp: how many shifts are computed.\n",
        "    :param int w: window size limiting the maximal distance between indices of matched entries |i,j|.\n",
        "    :param float s: weight applied on off-diagonal moves of the path. As s gets larger, the warping path is increasingly biased towards the diagonal\n",
        "    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path."
      ],
      "metadata": {
        "id": "4v2z2krwIvd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _traceback(D):\n",
        "    i, j = np.array(D.shape) - 2\n",
        "    p, q = [i], [j]\n",
        "    while (i > 0) or (j > 0):\n",
        "        tb = np.argmin((D[i, j], D[i, j + 1], D[i + 1, j]))\n",
        "        if tb == 0:\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif tb == 1:\n",
        "            i -= 1\n",
        "        else:  # (tb == 2):\n",
        "            j -= 1\n",
        "        p.insert(0, i)\n",
        "        q.insert(0, j)\n",
        "    return np.array(p), np.array(q)\n",
        "\n",
        "def dtw(x, y, dist, warp=1, w=np.inf, s=1.0):\n",
        "    assert len(x)\n",
        "    assert len(y)\n",
        "    assert np.isinf(w) or (w >= abs(len(x) - len(y)))\n",
        "    assert s > 0\n",
        "    r, c = len(x), len(y)\n",
        "    if not np.isinf(w):\n",
        "        D0 = np.full((r + 1, c + 1), np.inf)\n",
        "        for i in range(1, r + 1):\n",
        "            D0[i, max(1, i - w):min(c + 1, i + w + 1)] = 0\n",
        "        D0[0, 0] = 0\n",
        "    else:\n",
        "        D0 = np.zeros((r + 1, c + 1))\n",
        "        D0[0, 1:] = np.inf\n",
        "        D0[1:, 0] = np.inf\n",
        "    D1 = D0[1:, 1:]  # view\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            if (np.isinf(w) or (max(0, i - w) <= j <= min(c, i + w))):\n",
        "                D1[i, j] = dist(x[i], y[j])\n",
        "    C = D1.copy()\n",
        "    jrange = range(c)\n",
        "    for i in range(r):\n",
        "        if not np.isinf(w):\n",
        "            jrange = range(max(0, i - w), min(c, i + w + 1))\n",
        "        for j in jrange:\n",
        "            min_list = [D0[i, j]]\n",
        "            for k in range(1, warp + 1):\n",
        "                i_k = min(i + k, r)\n",
        "                j_k = min(j + k, c)\n",
        "                min_list += [D0[i_k, j] * s, D0[i, j_k] * s]\n",
        "            D1[i, j] += min(min_list)\n",
        "    if len(x) == 1:\n",
        "        path = np.zeros(len(y)), range(len(y))\n",
        "    elif len(y) == 1:\n",
        "        path = range(len(x)), np.zeros(len(x))\n",
        "    else:\n",
        "        path = _traceback(D0)\n",
        "    return D1[-1, -1], C, D1, path"
      ],
      "metadata": {
        "id": "gx8dnaoeIJcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import glob\n",
        "import os\n",
        "import os.path\n",
        "import errno\n",
        "import shutil\n",
        "import random\n",
        "import logging\n",
        "import yaml\n",
        "from logging import Logger\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "vxTzAXxyKfgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfigurationError(Exception):\n",
        "    \"\"\" Custom exception for misspecifications of configuration \"\"\""
      ],
      "metadata": {
        "id": "llKoTwBNN7dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function creates a new directory for the model.\n",
        "\n",
        "    :param model_dir: path to model directory\n",
        "    :param overwrite: whether to overwrite an existing directory\n",
        "    :param model_continue: whether to continue from a checkpoint\n",
        "    :return: path to model directory"
      ],
      "metadata": {
        "id": "UFiLfrkgOs6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model_dir(model_dir: str, overwrite=False, model_continue=False) -> str:\n",
        "    # If model already exists\n",
        "    if os.path.isdir(model_dir):\n",
        "\n",
        "        # If model continuing from checkpoint\n",
        "        if model_continue:\n",
        "            # Return the model_dir\n",
        "            return model_dir\n",
        "\n",
        "        # If set to not overwrite, this will error\n",
        "        if not overwrite:\n",
        "            raise FileExistsError(\n",
        "                \"Model directory exists and overwriting is disabled.\")\n",
        "\n",
        "        # If overwrite, recursively delete previous directory to start with empty dir again\n",
        "        for file in os.listdir(model_dir):\n",
        "            file_path = os.path.join(model_dir, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        shutil.rmtree(model_dir, ignore_errors=True)\n",
        "\n",
        "    # If model directly doesn't exist, make it and return\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    return model_dir"
      ],
      "metadata": {
        "id": "68qY2z77Okxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function creates a logger for logging the training process.\n",
        "\n",
        "    :param model_dir: path to logging directory\n",
        "    :param log_file: path to logging file\n",
        "    :return: logger object"
      ],
      "metadata": {
        "id": "DujPav-IPd0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_logger(model_dir: str, log_file: str = \"train.log\") -> Logger:\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.setLevel(level=logging.DEBUG)\n",
        "    fh = logging.FileHandler(\n",
        "        \"{}/{}\".format(model_dir, log_file))\n",
        "    fh.setLevel(level=logging.DEBUG)\n",
        "    logger.addHandler(fh)\n",
        "    sh = logging.StreamHandler()\n",
        "    sh.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    sh.setFormatter(formatter)\n",
        "    logging.getLogger(\"\").addHandler(sh)\n",
        "    logger.info(\"Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production\")\n",
        "    return logger"
      ],
      "metadata": {
        "id": "gGJVTr9uPWIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_cfg(cfg: dict, logger: Logger, prefix: str = \"cfg\") -> None:\n",
        "    \"\"\"\n",
        "    Write configuration to log.\n",
        "\n",
        "    :param cfg: configuration to log\n",
        "    :param logger: logger that defines where log is written to\n",
        "    :param prefix: prefix for logging\n",
        "    \"\"\"\n",
        "    for k, v in cfg.items():\n",
        "        if isinstance(v, dict):\n",
        "            p = '.'.join([prefix, k])\n",
        "            log_cfg(v, logger, prefix=p)\n",
        "        else:\n",
        "            p = '.'.join([prefix, k])\n",
        "            logger.info(\"{:34s} : {}\".format(p, v))"
      ],
      "metadata": {
        "id": "jUg2AUmSPs1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clones(module: nn.Module, n: int) -> nn.ModuleList:\n",
        "    \"\"\"\n",
        "    Produce N identical layers. Transformer helper function.\n",
        "\n",
        "    :param module: the module to clone\n",
        "    :param n: clone this many times\n",
        "    :return cloned modules\n",
        "    \"\"\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])"
      ],
      "metadata": {
        "id": "5jD4QNTYQGeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subsequent_mask(size: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Mask out subsequent positions (to prevent attending to future positions)\n",
        "    Transformer helper function.\n",
        "\n",
        "    :param size: size of mask (2nd and 3rd dim)\n",
        "    :return: Tensor with 0s and 1s of shape (1, size, size)\n",
        "    \"\"\"\n",
        "    mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
        "\n",
        "    return torch.from_numpy(mask) == 0 # Turns it into True and False's"
      ],
      "metadata": {
        "id": "9cjHTetIQMFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsequent mask of two sizes\n",
        "def uneven_subsequent_mask(x_size: int, y_size: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Mask out subsequent positions (to prevent attending to future positions)\n",
        "    Transformer helper function.\n",
        "\n",
        "    :param size: size of mask (2nd and 3rd dim)\n",
        "    :return: Tensor with 0s and 1s of shape (1, size, size)\n",
        "    \"\"\"\n",
        "    mask = np.triu(np.ones((1, x_size, y_size)), k=1).astype('uint8')\n",
        "    return torch.from_numpy(mask) == 0  # Turns it into True and False's"
      ],
      "metadata": {
        "id": "hrm4N26dQQRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Set the random seed for modules torch, numpy and random.\n",
        "\n",
        "    :param seed: random seed\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "_swW5iXVQX9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config(path=\"configs/default.yaml\") -> dict:\n",
        "    \"\"\"\n",
        "    Loads and parses a YAML configuration file.\n",
        "\n",
        "    :param path: path to YAML configuration file\n",
        "    :return: configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as ymlfile:\n",
        "        cfg = yaml.safe_load(ymlfile)\n",
        "    return cfg"
      ],
      "metadata": {
        "id": "Arja5AxFQdcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config(path=\"configs/default.yaml\") -> dict:\n",
        "    \"\"\"\n",
        "    Loads and parses a YAML configuration file.\n",
        "\n",
        "    :param path: path to YAML configuration file\n",
        "    :return: configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as ymlfile:\n",
        "        cfg = yaml.safe_load(ymlfile)\n",
        "    return cfg"
      ],
      "metadata": {
        "id": "uHdPTgHoQieD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bpe_postprocess(string) -> str:\n",
        "    \"\"\"\n",
        "    Post-processor for BPE output. Recombines BPE-split tokens.\n",
        "\n",
        "    :param string:\n",
        "    :return: post-processed string\n",
        "    \"\"\"\n",
        "    return string.replace(\"@@ \", \"\")"
      ],
      "metadata": {
        "id": "El6GY2AsQtXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_latest_checkpoint(ckpt_dir, post_fix=\"_every\" ) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Returns the latest checkpoint (by time) from the given directory, of either every validation step or best\n",
        "    If there is no checkpoint in this directory, returns None\n",
        "\n",
        "    :param ckpt_dir: directory of checkpoint\n",
        "    :param post_fixe: type of checkpoint, either \"_every\" or \"_best\"\n",
        "\n",
        "    :return: latest checkpoint file\n",
        "    \"\"\"\n",
        "    # Find all the every validation checkpoints\n",
        "    list_of_files = glob.glob(\"{}/*{}.ckpt\".format(ckpt_dir,post_fix))\n",
        "    latest_checkpoint = None\n",
        "    if list_of_files:\n",
        "        latest_checkpoint = max(list_of_files, key=os.path.getctime)\n",
        "    return latest_checkpoint"
      ],
      "metadata": {
        "id": "WutV9naQQ2uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(path: str, use_cuda: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Load model from saved checkpoint.\n",
        "\n",
        "    :param path: path to checkpoint\n",
        "    :param use_cuda: using cuda or not\n",
        "    :return: checkpoint (dict)\n",
        "    \"\"\"\n",
        "    assert os.path.isfile(path), \"Checkpoint %s not found\" % path\n",
        "    checkpoint = torch.load(path, map_location='cuda' if use_cuda else 'cpu', weights_only=False)\n",
        "    return checkpoint"
      ],
      "metadata": {
        "id": "mSWySYemQ4QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_params(module: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Freeze the parameters of this module,\n",
        "    i.e. do not update them during training\n",
        "\n",
        "    :param module: freeze parameters of this module\n",
        "    \"\"\"\n",
        "    for _, p in module.named_parameters():\n",
        "        p.requires_grad = False"
      ],
      "metadata": {
        "id": "U3wGiSkbQ9Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def symlink_update(target, link_name):\n",
        "    try:\n",
        "        os.symlink(target, link_name)\n",
        "    except FileExistsError as e:\n",
        "        if e.errno == errno.EEXIST:\n",
        "            os.remove(link_name)\n",
        "            os.symlink(target, link_name)\n",
        "        else:\n",
        "            raise e"
      ],
      "metadata": {
        "id": "SA6FnVvkREpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dtw(references, hypotheses):\n",
        "    \"\"\"\n",
        "    Calculate the DTW costs between a list of references and hypotheses\n",
        "\n",
        "    :param references: list of reference sequences to compare against\n",
        "    :param hypotheses: list of hypothesis sequences to fit onto the reference\n",
        "\n",
        "    :return: dtw_scores: list of DTW costs\n",
        "    \"\"\"\n",
        "    # Euclidean norm is the cost function, difference of coordinates\n",
        "    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n",
        "\n",
        "    dtw_scores = []\n",
        "\n",
        "    # Remove the BOS frame from the hypothesis\n",
        "    # hypotheses = hypotheses[:, 1:]    # Non-autoregressive annotation\n",
        "\n",
        "    # For each reference in the references list\n",
        "    for i, ref in enumerate(references):\n",
        "        # Cut the reference down to the max count value\n",
        "        _ , ref_max_idx = torch.max(ref[:, -1], 0)\n",
        "        if ref_max_idx == 0: ref_max_idx += 1\n",
        "        # Cut down frames by to the max counter value, and chop off counter from joints\n",
        "        ref_count = ref[:ref_max_idx,:-1].cpu().numpy()\n",
        "\n",
        "        # Cut the hypothesis down to the max count value\n",
        "        hyp = hypotheses[i]\n",
        "        _, hyp_max_idx = torch.max(hyp[:, -1], 0)\n",
        "        if hyp_max_idx == 0: hyp_max_idx += 1\n",
        "        # Cut down frames by to the max counter value, and chop off counter from joints\n",
        "        hyp_count = hyp[:hyp_max_idx,:-1].cpu().numpy()\n",
        "\n",
        "        # Calculate DTW of the reference and hypothesis, using euclidean norm\n",
        "        d, cost_matrix, acc_cost_matrix, path = dtw(ref_count, hyp_count, dist=euclidean_norm)\n",
        "\n",
        "        # Normalise the dtw cost by sequence length\n",
        "        d = d/acc_cost_matrix.shape[0]\n",
        "\n",
        "        dtw_scores.append(d)\n",
        "\n",
        "    # Return dtw scores and the hypothesis with altered timing\n",
        "    return dtw_scores"
      ],
      "metadata": {
        "id": "qhAYWSosR4Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSkeletalModelStructure():\n",
        "    return (\n",
        "        # head\n",
        "        (1, 0),\n",
        "        (1, 1),\n",
        "        (1, 2),\n",
        "        # left arm\n",
        "        (2, 3),\n",
        "        (3, 4),\n",
        "        (1, 5),\n",
        "        (5, 6),\n",
        "        (6, 7),\n",
        "        (7, 8),\n",
        "        (8, 9),\n",
        "        (9, 10),\n",
        "        (10, 11),\n",
        "        (11, 12),\n",
        "        (8, 13),\n",
        "        (13, 14),\n",
        "        (14, 15),\n",
        "        (15, 16),\n",
        "        (8, 17),\n",
        "        (17, 18),\n",
        "        (18, 19),\n",
        "        (19, 20),\n",
        "        (8, 21),\n",
        "        (21, 22),\n",
        "        (22, 23),\n",
        "        (23, 24),\n",
        "        (8, 25),\n",
        "        (25, 26),\n",
        "        (26, 27),\n",
        "        (27, 28),\n",
        "        (4, 29),\n",
        "        (29, 30),\n",
        "        (30, 31),\n",
        "        (31, 32),\n",
        "        (32, 33),\n",
        "        (29, 34),\n",
        "        (34, 35),\n",
        "        (35, 36),\n",
        "        (36, 37),\n",
        "        (29, 38),\n",
        "        (38, 39),\n",
        "        (39, 40),\n",
        "        (40, 41),\n",
        "        (29, 42),\n",
        "        (42, 43),\n",
        "        (43, 44),\n",
        "        (44, 45),\n",
        "        (29, 46),\n",
        "        (46, 47),\n",
        "        (47, 48),\n",
        "        (48, 49),\n",
        "    )"
      ],
      "metadata": {
        "id": "0lGsMHI_R-H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io\n",
        "from torchtext import data\n",
        "from torchtext.data import Iterator"
      ],
      "metadata": {
        "id": "GbrUjXzXSb0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Dataset Class\n",
        "class SignProdDataset(data.Dataset):\n",
        "    \"\"\"Defines a dataset for machine translation.\"\"\"\n",
        "\n",
        "    def __init__(self, path, exts, fields, trg_size, skip_frames=1, **kwargs):\n",
        "        \"\"\"Create a TranslationDataset given paths and fields.\n",
        "\n",
        "        Arguments:\n",
        "            path: Common prefix of paths to the data files for both languages.\n",
        "            exts: A tuple containing the extension to path for each language.\n",
        "            fields: A tuple containing the fields that will be used for data\n",
        "                in each language.\n",
        "            Remaining keyword arguments: Passed to the constructor of\n",
        "                data.Dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(fields[0], (tuple, list)):\n",
        "            fields = [('src', fields[0]), ('trg', fields[1]), ('file_paths', fields[2])]\n",
        "\n",
        "        src_path, trg_path, file_path = tuple(os.path.expanduser(path + x) for x in exts)\n",
        "\n",
        "        examples = []\n",
        "        # Extract the parallel src, trg and file files\n",
        "        with io.open(src_path, mode='r', encoding='utf-8') as src_file, \\\n",
        "                io.open(trg_path, mode='r', encoding='utf-8') as trg_file, \\\n",
        "                    io.open(file_path, mode='r', encoding='utf-8') as files_file:\n",
        "\n",
        "            i = 0\n",
        "            # For Source, Target and FilePath\n",
        "            for src_line, trg_line, files_line in zip(src_file, trg_file, files_file):\n",
        "                i+= 1\n",
        "\n",
        "                # Strip away the \"\\n\" at the end of the line\n",
        "                src_line, trg_line, files_line = src_line.strip(), trg_line.strip(), files_line.strip()\n",
        "\n",
        "                # Split target into joint coordinate values\n",
        "                trg_line = trg_line.split(\" \")\n",
        "                if len(trg_line) == 1:\n",
        "                    continue\n",
        "                # Turn each joint into a float value, with 1e-8 for numerical stability\n",
        "                trg_line = [(float(joint) + 1e-8) for joint in trg_line]\n",
        "                # Split up the joints into frames, using trg_size as the amount of coordinates in each frame\n",
        "                # If using skip frames, this just skips over every Nth frame\n",
        "                trg_frames = [trg_line[i:i + trg_size] for i in range(0, len(trg_line), trg_size*skip_frames)]\n",
        "\n",
        "                # Create a dataset examples out of the Source, Target Frames and FilesPath\n",
        "                if src_line != '' and trg_line != '':\n",
        "                    examples.append(data.Example.fromlist(\n",
        "                        [src_line, trg_frames, files_line], fields))\n",
        "\n",
        "        super(SignProdDataset, self).__init__(examples, fields, **kwargs)"
      ],
      "metadata": {
        "id": "WXgFdKE7sFeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(cfg: dict) -> (Dataset, Dataset, Optional[Dataset], Vocabulary, Vocabulary):\n",
        "    data_cfg = cfg[\"data\"]\n",
        "    # Source, Target and Files postfixes\n",
        "    src_lang = data_cfg[\"src\"]\n",
        "    trg_lang = data_cfg[\"trg\"]\n",
        "    files_lang = data_cfg.get(\"files\", \"files\")\n",
        "    # Train, Dev and Test Path\n",
        "    train_path = data_cfg[\"train\"]\n",
        "    dev_path = data_cfg[\"dev\"]\n",
        "    test_path = data_cfg[\"test\"]\n",
        "\n",
        "    level = \"word\"\n",
        "    lowercase = False\n",
        "    max_sent_length = data_cfg[\"max_sent_length\"]\n",
        "    # Target size is plus one due to the counter required for the model\n",
        "    trg_size = cfg[\"model\"][\"trg_size\"] + 1\n",
        "    # Skip frames is used to skip a set proportion of target frames, to simplify the model requirements\n",
        "    skip_frames = data_cfg.get(\"skip_frames\", 1)\n",
        "\n",
        "    EOS_TOKEN = '</s>'\n",
        "    tok_fun = lambda s: list(s) if level == \"char\" else s.split()\n",
        "\n",
        "    # Source field is a tokenised version of the source words\n",
        "    src_field = data.Field(init_token=None, eos_token=EOS_TOKEN,\n",
        "                           pad_token=PAD_TOKEN, tokenize=tok_fun,\n",
        "                           batch_first=True, lower=lowercase,\n",
        "                           unk_token=UNK_TOKEN,\n",
        "                           include_lengths=True)\n",
        "\n",
        "    # Files field is just a raw text field\n",
        "    files_field = data.RawField()\n",
        "\n",
        "    def tokenize_features(features):\n",
        "        features = torch.as_tensor(features)\n",
        "        ft_list = torch.split(features, 1, dim=0)\n",
        "        return [ft.squeeze() for ft in ft_list]\n",
        "\n",
        "    def stack_features(features, something):\n",
        "        return torch.stack([torch.stack(ft, dim=0) for ft in features], dim=0)\n",
        "\n",
        "    # Creating a regression target field\n",
        "    # Pad token is a vector of output size, containing the constant TARGET_PAD\n",
        "    reg_trg_field = data.Field(sequential=True,\n",
        "                               use_vocab=False,\n",
        "                               dtype=torch.float32,\n",
        "                               batch_first=True,\n",
        "                               include_lengths=False,\n",
        "                               pad_token=torch.ones((trg_size,))*TARGET_PAD,\n",
        "                               preprocessing=tokenize_features,\n",
        "                               postprocessing=stack_features,)\n",
        "\n",
        "    # Create the Training Data, using the SignProdDataset\n",
        "    train_data = SignProdDataset(path=train_path,\n",
        "                                 exts=(\".\" + src_lang, \".\" + trg_lang, \".\" + files_lang),\n",
        "                                 fields=(src_field, reg_trg_field, files_field),\n",
        "                                 trg_size=trg_size,\n",
        "                                 skip_frames=skip_frames,\n",
        "                                 filter_pred=\n",
        "                                 lambda x: len(vars(x)['src'])\n",
        "                                 <= max_sent_length\n",
        "                                 and len(vars(x)['trg'])\n",
        "                                 <= max_sent_length)\n",
        "\n",
        "    src_max_size = data_cfg.get(\"src_voc_limit\", sys.maxsize)\n",
        "    src_min_freq = data_cfg.get(\"src_voc_min_freq\", 1)\n",
        "    src_vocab_file = data_cfg.get(\"src_vocab\", None)\n",
        "    src_vocab = build_vocab(field=\"src\", min_freq=src_min_freq,\n",
        "                            max_size=src_max_size,\n",
        "                            dataset=train_data, vocab_file=src_vocab_file)\n",
        "\n",
        "    # Create a target vocab just as big as the required target vector size -\n",
        "    # So that len(trg_vocab) is # of joints + 1 (for the counter)\n",
        "    trg_vocab = [None]*trg_size\n",
        "\n",
        "    # Create the Validation Data\n",
        "    dev_data = SignProdDataset(path=dev_path,\n",
        "                               exts=(\".\" + src_lang, \".\" + trg_lang, \".\" + files_lang),\n",
        "                               trg_size=trg_size,\n",
        "                               fields=(src_field, reg_trg_field, files_field),\n",
        "                               skip_frames=skip_frames)\n",
        "\n",
        "    # Create the Testing Data\n",
        "    test_data = SignProdDataset(\n",
        "        path=test_path,\n",
        "        exts=(\".\" + src_lang, \".\" + trg_lang, \".\" + files_lang),\n",
        "        trg_size=trg_size,\n",
        "        fields=(src_field, reg_trg_field, files_field),\n",
        "        skip_frames=skip_frames)\n",
        "\n",
        "    src_field.vocab = src_vocab\n",
        "\n",
        "    return train_data, dev_data, test_data, src_vocab, trg_vocab"
      ],
      "metadata": {
        "id": "Z1wrSyZ3ru_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pylint: disable=global-at-module-level\n",
        "global max_src_in_batch, max_tgt_in_batch\n",
        "\n",
        "# pylint: disable=unused-argument,global-variable-undefined\n",
        "def token_batch_size_fn(new, count, sofar):\n",
        "    \"\"\"Compute batch size based on number of tokens (+padding).\"\"\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch, len(new.src))\n",
        "    src_elements = count * max_src_in_batch\n",
        "    if hasattr(new, 'trg'):  # for monolingual data sets (\"translate\" mode)\n",
        "        max_tgt_in_batch = max(max_tgt_in_batch, len(new.trg) + 2)\n",
        "        tgt_elements = count * max_tgt_in_batch\n",
        "    else:\n",
        "        tgt_elements = 0\n",
        "    return max(src_elements, tgt_elements)"
      ],
      "metadata": {
        "id": "LeqR75XWs0Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_data_iter(dataset: Dataset, batch_size: int, batch_type: str = \"sentence\", train: bool = False, shuffle: bool = False) -> Iterator:\n",
        "    \"\"\"\n",
        "    Returns a torchtext iterator for a torchtext dataset.\n",
        "\n",
        "    :param dataset: torchtext dataset containing src and optionally trg\n",
        "    :param batch_size: size of the batches the iterator prepares\n",
        "    :param batch_type: measure batch size by sentence count or by token count\n",
        "    :param train: whether it's training time, when turned off,\n",
        "        bucketing, sorting within batches and shuffling is disabled\n",
        "    :param shuffle: whether to shuffle the data before each epoch\n",
        "        (no effect if set to True for testing)\n",
        "    :return: torchtext iterator\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size_fn = token_batch_size_fn if batch_type == \"token\" else None\n",
        "\n",
        "    if train:\n",
        "        # optionally shuffle and sort during training\n",
        "        data_iter = data.BucketIterator(\n",
        "            repeat=False, sort=False, dataset=dataset,\n",
        "            batch_size=batch_size, batch_size_fn=batch_size_fn,\n",
        "            train=True, sort_within_batch=True,\n",
        "            sort_key=lambda x: len(x.src), shuffle=shuffle)\n",
        "    else:\n",
        "        # don't sort/shuffle for validation/inference\n",
        "        data_iter = data.BucketIterator(\n",
        "            repeat=False, dataset=dataset,\n",
        "            batch_size=batch_size, batch_size_fn=batch_size_fn,\n",
        "            train=False, sort=False)\n",
        "\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "2YX3mqjssjnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Generator\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import _LRScheduler, ReduceLROnPlateau, StepLR, ExponentialLR"
      ],
      "metadata": {
        "id": "Ph9i9vVZtoXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoamScheduler:\n",
        "    def __init__(self, hidden_size: int, optimizer: torch.optim.Optimizer,\n",
        "                 factor: float = 1, warmup: int = 4000):\n",
        "        \"\"\"\n",
        "        Warm-up, followed by learning rate decay.\n",
        "\n",
        "        :param hidden_size:\n",
        "        :param optimizer:\n",
        "        :param factor: decay factor\n",
        "        :param warmup: number of warmup steps\n",
        "        \"\"\"\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.hidden_size = hidden_size\n",
        "        self._rate = 0\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Update parameters and rate\"\"\"\n",
        "        self._step += 1\n",
        "        rate = self._compute_rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "\n",
        "    def _compute_rate(self):\n",
        "        \"\"\"Implement `lrate` above\"\"\"\n",
        "        step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.hidden_size ** (-0.5) *\n",
        "                min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "\n",
        "    #pylint: disable=no-self-use\n",
        "    def state_dict(self):\n",
        "        return None"
      ],
      "metadata": {
        "id": "N2wjIAq3t8U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the function for gradient clipping as specified in configuration. If not specified, returns None.\n",
        "\n",
        "    Current options:\n",
        "        - \"clip_grad_val\": clip the gradients if they exceed this value,\n",
        "            see `torch.nn.utils.clip_grad_value_`\n",
        "        - \"clip_grad_norm\": clip the gradients if their norm exceeds this value,\n",
        "            see `torch.nn.utils.clip_grad_norm_`\n",
        "\n",
        "    :param config: dictionary with training configurations\n",
        "    :return: clipping function (in-place) or None if no gradient clipping"
      ],
      "metadata": {
        "id": "1Hyylltsudwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gradient_clipper(config: dict) -> Optional[Callable]:\n",
        "    clip_grad_fun = None\n",
        "    if \"clip_grad_val\" in config.keys():\n",
        "        clip_value = config[\"clip_grad_val\"]\n",
        "        clip_grad_fun = lambda params: \\\n",
        "            nn.utils.clip_grad_value_(parameters=params,\n",
        "                                      clip_value=clip_value)\n",
        "    elif \"clip_grad_norm\" in config.keys():\n",
        "        max_norm = config[\"clip_grad_norm\"]\n",
        "        clip_grad_fun = lambda params: \\\n",
        "            nn.utils.clip_grad_norm_(parameters=params, max_norm=max_norm)\n",
        "\n",
        "    if \"clip_grad_val\" in config.keys() and \"clip_grad_norm\" in config.keys():\n",
        "        raise ConfigurationError(\n",
        "            \"You can only specify either clip_grad_val or clip_grad_norm.\")\n",
        "\n",
        "    return clip_grad_fun"
      ],
      "metadata": {
        "id": "n77s3sA3uXbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an optimizer for the given parameters as specified in config.\n",
        "\n",
        "Except for the weight decay and initial learning rate,\n",
        "default optimizer settings are used.\n",
        "\n",
        "Currently supported configuration settings for \"optimizer\":\n",
        "\n",
        "    - \"sgd\" (default): see `torch.optim.SGD`\n",
        "    - \"adam\": see `torch.optim.adam`\n",
        "    - \"adagrad\": see `torch.optim.adagrad`\n",
        "    - \"adadelta\": see `torch.optim.adadelta`\n",
        "    - \"rmsprop\": see `torch.optim.RMSprop`\n",
        "\n",
        "The initial learning rate is set according to \"learning_rate\" in the config.\n",
        "The weight decay is set according to \"weight_decay\" in the config.\n",
        "If they are not specified, the initial learning rate is set to 3.0e-4, the\n",
        "weight decay to 0.\n",
        "\n",
        "Note that the scheduler state is saved in the checkpoint, so if you load\n",
        "a model for further training you have to use the same type of scheduler.\n",
        "\n",
        "    :param config: configuration dictionary\n",
        "    :param parameters:\n",
        "    :return: optimizer"
      ],
      "metadata": {
        "id": "EEM1bZLWu4Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(config: dict, parameters: Generator) -> Optimizer:\n",
        "    optimizer_name = config.get(\"optimizer\", \"sgd\").lower()\n",
        "    learning_rate = config.get(\"learning_rate\", 3.0e-4)\n",
        "    weight_decay = config.get(\"weight_decay\", 0)\n",
        "\n",
        "    if optimizer_name == \"adam\":\n",
        "        adam_betas = config.get(\"adam_betas\", (0.9, 0.999))\n",
        "        optimizer = torch.optim.Adam(parameters, weight_decay=weight_decay,\n",
        "                                     lr=learning_rate, betas=adam_betas)\n",
        "    elif optimizer_name == \"adagrad\":\n",
        "        optimizer = torch.optim.Adagrad(parameters, weight_decay=weight_decay,\n",
        "                                        lr=learning_rate)\n",
        "    elif optimizer_name == \"adadelta\":\n",
        "        optimizer = torch.optim.Adadelta(parameters, weight_decay=weight_decay,\n",
        "                                         lr=learning_rate)\n",
        "    elif optimizer_name == \"rmsprop\":\n",
        "        optimizer = torch.optim.RMSprop(parameters, weight_decay=weight_decay,\n",
        "                                        lr=learning_rate)\n",
        "    elif optimizer_name == \"sgd\":\n",
        "        # default\n",
        "        optimizer = torch.optim.SGD(parameters, weight_decay=weight_decay,\n",
        "                                    lr=learning_rate)\n",
        "    else:\n",
        "        raise ConfigurationError(\"Invalid optimizer. Valid options: 'adam', \"\n",
        "                                 \"'adagrad', 'adadelta', 'rmsprop', 'sgd'.\")\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "UfLz7kLmusSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a learning rate scheduler if specified in config and\n",
        "determine when a scheduler step should be executed.\n",
        "\n",
        "Current options:\n",
        "\n",
        "    - \"plateau\": see `torch.optim.lr_scheduler.ReduceLROnPlateau`\n",
        "    - \"decaying\": see `torch.optim.lr_scheduler.StepLR`\n",
        "    - \"exponential\": see `torch.optim.lr_scheduler.ExponentialLR`\n",
        "    - \"noam\": see `SignProdJoey.transformer.NoamScheduler`\n",
        "\n",
        "If no scheduler is specified, returns (None, None) which will result in\n",
        "a constant learning rate.\n",
        "\n",
        "    :param config: training configuration\n",
        "    :param optimizer: optimizer for the scheduler, determines the set of\n",
        "        parameters which the scheduler sets the learning rate for\n",
        "    :param scheduler_mode: \"min\" or \"max\", depending on whether the validation\n",
        "        score should be minimized or maximized.\n",
        "        Only relevant for \"plateau\".\n",
        "    :param hidden_size: encoder hidden size (required for NoamScheduler)\n",
        "    :return:\n",
        "        - scheduler: scheduler object,\n",
        "        - scheduler_step_at: either \"validation\" or \"epoch\""
      ],
      "metadata": {
        "id": "PXFuAuSfwGyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_scheduler(config: dict, optimizer: Optimizer, scheduler_mode: str,\n",
        "                    hidden_size: int = 0) -> tuple[Optional[_LRScheduler], Optional[str]]:\n",
        "    scheduler, scheduler_step_at = None, None\n",
        "    if \"scheduling\" in config.keys() and config[\"scheduling\"]:\n",
        "        if config[\"scheduling\"].lower() == \"plateau\":\n",
        "            # learning rate scheduler\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer=optimizer,\n",
        "                mode=scheduler_mode,\n",
        "                verbose=False,\n",
        "                threshold_mode='abs',\n",
        "                threshold=1e-8,\n",
        "                factor=config.get(\"decrease_factor\", 0.1),\n",
        "                patience=config.get(\"patience\", 10))\n",
        "            # scheduler step is executed after every validation\n",
        "            scheduler_step_at = \"validation\"\n",
        "        elif config[\"scheduling\"].lower() == \"decaying\":\n",
        "            scheduler = StepLR(\n",
        "                optimizer=optimizer,\n",
        "                step_size=config.get(\"decaying_step_size\", 1))\n",
        "            # scheduler step is executed after every epoch\n",
        "            scheduler_step_at = \"epoch\"\n",
        "        elif config[\"scheduling\"].lower() == \"exponential\":\n",
        "            scheduler = ExponentialLR(\n",
        "                optimizer=optimizer,\n",
        "                gamma=config.get(\"decrease_factor\", 0.99))\n",
        "            # scheduler step is executed after every epoch\n",
        "            scheduler_step_at = \"epoch\"\n",
        "        elif config[\"scheduling\"].lower() == \"noam\":\n",
        "            factor = config.get(\"learning_rate_factor\", 1)\n",
        "            warmup = config.get(\"learning_rate_warmup\", 4000)\n",
        "            scheduler = NoamScheduler(hidden_size=hidden_size, factor=factor,\n",
        "                                      warmup=warmup, optimizer=optimizer)\n",
        "\n",
        "            scheduler_step_at = \"step\"\n",
        "    return scheduler, scheduler_step_at"
      ],
      "metadata": {
        "id": "ZeOqU9tKvLx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple embeddings class\n",
        "    \"\"\"\n",
        "    # pylint: disable=unused-argument\n",
        "    def __init__(self,\n",
        "                 embedding_dim: int = 64,\n",
        "                 scale: bool = False,\n",
        "                 vocab_size: int = 0,\n",
        "                 padding_idx: int = 1,\n",
        "                 freeze: bool = False,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Create new embeddings for the vocabulary.\n",
        "        Use scaling for the Transformer.\n",
        "\n",
        "        :param embedding_dim:\n",
        "        :param scale:\n",
        "        :param vocab_size:\n",
        "        :param padding_idx:\n",
        "        :param freeze: freeze the embeddings during training\n",
        "        \"\"\"\n",
        "        super(Embeddings, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.scale = scale\n",
        "        self.vocab_size = vocab_size\n",
        "        self.lut = nn.Embedding(vocab_size, self.embedding_dim, padding_idx=padding_idx)\n",
        "\n",
        "        if freeze:\n",
        "            freeze_params(self)\n",
        "\n",
        "    # pylint: disable=arguments-differ\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Perform lookup for input `x` in the embedding table.\n",
        "\n",
        "        :param x: index in the vocabulary\n",
        "        :return: embedded representation for `x`\n",
        "        \"\"\"\n",
        "        if self.scale:\n",
        "            return self.lut(x) * math.sqrt(self.embedding_dim)\n",
        "        return self.lut(x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"%s(embedding_dim=%d, vocab_size=%d)\" % (\n",
        "            self.__class__.__name__, self.embedding_dim, self.vocab_size)"
      ],
      "metadata": {
        "id": "ml7CaZFKwAY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size: int = 512,\n",
        "                 ff_size: int = 2048,\n",
        "                 num_layers: int = 2,\n",
        "                 num_heads: int = 4,\n",
        "                 dropout: float = 0.1,\n",
        "                 emb_dropout: float = 0.1,\n",
        "                 freeze: bool = False,\n",
        "                 **kwargs):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(size=hidden_size, ff_size=ff_size,\n",
        "                                    num_heads=num_heads, dropout=dropout)\n",
        "            for _ in range(num_layers)])\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
        "        self.pe = PositionalEncoding(hidden_size)\n",
        "        self.emb_dropout = nn.Dropout(p=emb_dropout)\n",
        "        self._output_size = hidden_size\n",
        "\n",
        "        if freeze:\n",
        "            freeze_params(self)\n",
        "\n",
        "    def forward(self,\n",
        "                embed_src: Tensor,\n",
        "                src_length: Tensor,\n",
        "                mask: Tensor):\n",
        "\n",
        "        x = embed_src\n",
        "\n",
        "        # Add position encoding to word embeddings\n",
        "        x = self.pe(x)\n",
        "        # Add Dropout\n",
        "        x = self.emb_dropout(x)\n",
        "\n",
        "        # Apply each layer to the input\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"%s(num_layers=%r, num_heads=%r)\" % (\n",
        "            self.__class__.__name__, len(self.layers),\n",
        "            self.layers[0].src_src_att.num_heads)"
      ],
      "metadata": {
        "id": "drmS-xKZxY5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_length_direct(trg):\n",
        "    trg_reshaped = trg.view(trg.shape[0], trg.shape[1], 50, 3)\n",
        "    trg_list = trg_reshaped.split(1, dim=2)\n",
        "    trg_list_squeeze = [t.squeeze(dim=2) for t in trg_list]\n",
        "    skeletons = getSkeletalModelStructure()\n",
        "\n",
        "    length = []\n",
        "    direct = []\n",
        "    for skeleton in skeletons:\n",
        "        result_length = Skeleton_length = torch.norm(trg_list_squeeze[skeleton[0]]-trg_list_squeeze[skeleton[1]], p=2, dim=2, keepdim=True)\n",
        "        result_direct = (trg_list_squeeze[skeleton[0]]-trg_list_squeeze[skeleton[1]]) / (Skeleton_length+torch.finfo(Skeleton_length.dtype).tiny)\n",
        "        direct.append(result_direct)\n",
        "        length.append(result_length)\n",
        "    lengths = torch.stack(length, dim=-1).squeeze()\n",
        "    directs = torch.stack(direct, dim=2).view(trg.shape[0], trg.shape[1], -1)\n",
        "\n",
        "    return lengths, directs"
      ],
      "metadata": {
        "id": "eDgqgrJ3yYCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg, target_pad=0.0):\n",
        "        super(Loss, self).__init__()\n",
        "\n",
        "        self.loss = cfg[\"training\"][\"loss\"].lower()\n",
        "        self.bone_loss = cfg[\"training\"][\"bone_loss\"].lower()\n",
        "\n",
        "        if self.loss == \"l1\":\n",
        "            self.criterion = nn.L1Loss()\n",
        "        elif self.loss == \"mse\":\n",
        "            self.criterion = nn.MSELoss()\n",
        "        else:\n",
        "            print(\"Loss not found - revert to default L1 loss\")\n",
        "            self.criterion = nn.L1Loss()\n",
        "\n",
        "        if self.bone_loss == \"l1\":\n",
        "            self.criterion_bone = nn.L1Loss()\n",
        "        elif self.bone_loss == \"mse\":\n",
        "            self.criterion_bone = nn.MSELoss()\n",
        "        else:\n",
        "            print(\"Loss not found - revert to default MSE loss\")\n",
        "            self.criterion_bone = nn.MSELoss()\n",
        "\n",
        "        model_cfg = cfg[\"model\"]\n",
        "\n",
        "        self.target_pad = target_pad\n",
        "        self.loss_scale = model_cfg.get(\"loss_scale\", 1.0)\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "\n",
        "        loss_mask = (targets != self.target_pad)\n",
        "\n",
        "        # Find the masked predictions and targets using loss mask\n",
        "        preds_masked = preds * loss_mask\n",
        "        targets_masked = targets * loss_mask\n",
        "\n",
        "        preds_masked_length, preds_masked_direct = get_length_direct(preds_masked)\n",
        "        targets_masked_length, targets_masked_direct = get_length_direct(targets_masked)\n",
        "\n",
        "        preds_masked_length = preds_masked_length * loss_mask[:, :, :50]\n",
        "        targets_masked_length = targets_masked_length * loss_mask[:, :, :50]\n",
        "        preds_masked_direct = preds_masked_direct * loss_mask[:, :, :150]\n",
        "        targets_masked_direct = targets_masked_direct * loss_mask[:, :, :150]\n",
        "\n",
        "        # Calculate loss just over the masked predictions\n",
        "        loss = self.criterion(preds_masked, targets_masked) + 0.1 * self.criterion_bone(preds_masked_direct, targets_masked_direct)\n",
        "\n",
        "        # Multiply loss by the loss scale\n",
        "        if self.loss_scale != 1.0:\n",
        "            loss = loss * self.loss_scale\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "dBsOCVIAzI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ID(trg):\n",
        "    trg_reshaped = trg.view(trg.shape[0], trg.shape[1], 50, 3)\n",
        "    trg_list = trg_reshaped.split(1, dim=2)\n",
        "    trg_list_squeeze = [t.squeeze(dim=2) for t in trg_list]\n",
        "    skeletons = getSkeletalModelStructure()\n",
        "    trg_reshaped_list = []\n",
        "    for skeleton in skeletons:\n",
        "        Skeleton_length = torch.norm(trg_list_squeeze[skeleton[0]]-trg_list_squeeze[skeleton[1]], p=2, dim=2, keepdim=True)\n",
        "        Skeleton_direct = (trg_list_squeeze[skeleton[0]]-trg_list_squeeze[skeleton[1]]) / (Skeleton_length+torch.finfo(Skeleton_length.dtype).tiny)\n",
        "        trg_reshaped_list.append(torch.cat((trg_list_squeeze[skeleton[1]], Skeleton_length, Skeleton_direct), dim=2))\n",
        "    trg_super = torch.stack(trg_reshaped_list, dim=-1).reshape(trg.shape[0],trg.shape[1],50*7)\n",
        "\n",
        "    return trg_super"
      ],
      "metadata": {
        "id": "vO47yrndzNRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "U802QSk-zc4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ACD_Denoiser(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int = 2,\n",
        "                 num_heads: int = 4,\n",
        "                 hidden_size: int = 512,\n",
        "                 ff_size: int = 2048,\n",
        "                 dropout: float = 0.1,\n",
        "                 emb_dropout: float = 0.1,\n",
        "                 vocab_size: int = 1,\n",
        "                 freeze: bool = False,\n",
        "                 trg_size: int = 150,\n",
        "                 decoder_trg_trg_: bool = True,\n",
        "                 **kwargs):\n",
        "        super(ACD_Denoiser, self).__init__()\n",
        "\n",
        "        self.in_feature_size = trg_size + (trg_size // 3) * 4\n",
        "        self.out_feature_size = trg_size\n",
        "\n",
        "        self.pos_drop = nn.Dropout(p=emb_dropout)\n",
        "        self.trg_embed = nn.Linear(self.in_feature_size, hidden_size)\n",
        "        self.pe = PositionalEncoding(hidden_size, mask_count=True)\n",
        "        self.emb_dropout = nn.Dropout(p=emb_dropout)\n",
        "\n",
        "        if num_layers == 2:\n",
        "\n",
        "            self.layers_pose_condition = TransformerDecoderLayer(\n",
        "                size=hidden_size, ff_size=ff_size, num_heads=num_heads,\n",
        "                dropout=dropout, decoder_trg_trg=decoder_trg_trg_)\n",
        "\n",
        "            self.layer_norm_mid = nn.LayerNorm(hidden_size, eps=1e-6)\n",
        "            self.output_layer_mid = nn.Linear(hidden_size, self.in_feature_size, bias=False)\n",
        "            self.o1_embed = nn.Linear(trg_size, hidden_size)\n",
        "            self.o2_embed = nn.Linear((trg_size // 3) * 4, hidden_size)\n",
        "\n",
        "            self.layers_mha_ac = TransformerDecoderLayer(\n",
        "                size=hidden_size, ff_size=ff_size, num_heads=num_heads,\n",
        "                dropout=dropout, decoder_trg_trg=decoder_trg_trg_)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(hidden_size),\n",
        "            nn.Linear(hidden_size, hidden_size * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "        )\n",
        "\n",
        "        # Output layer to be the size of joints vector + 1 for counter (total is trg_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, trg_size, bias=False)\n",
        "\n",
        "        if freeze:\n",
        "            freeze_params(self)\n",
        "\n",
        "    def forward(self,\n",
        "                t,\n",
        "                trg_embed: Tensor = None,\n",
        "                encoder_output: Tensor = None,\n",
        "                src_mask: Tensor = None,\n",
        "                trg_mask: Tensor = None,\n",
        "                **kwargs):\n",
        "\n",
        "        assert trg_mask is not None, \"trg_mask required for Transformer\"\n",
        "        time_embed = self.time_mlp(t)[:, None, :].repeat(1, encoder_output.shape[1], 1)\n",
        "        condition = encoder_output + time_embed\n",
        "        condition = self.pos_drop(condition)\n",
        "\n",
        "        trg_embed = self.trg_embed(trg_embed)\n",
        "        # add position encoding to word embedding\n",
        "        x = self.pe(trg_embed)\n",
        "        # Dropout if given\n",
        "        x = self.emb_dropout(x)\n",
        "\n",
        "        padding_mask = trg_mask\n",
        "        # Create subsequent mask for decoding\n",
        "        sub_mask = subsequent_mask(\n",
        "            trg_embed.size(1)).type_as(trg_mask)\n",
        "\n",
        "        x, h = self.layers_pose_condition(x=x, memory=condition,\n",
        "                             src_mask=src_mask, trg_mask=sub_mask, padding_mask=padding_mask)\n",
        "\n",
        "        x = self.layer_norm_mid(x)\n",
        "        x = self.output_layer_mid(x)\n",
        "        o_reshaped = x.view(x.shape[0], x.shape[1], 50, 7)\n",
        "        o_1, o_2 = torch.split(o_reshaped, [3, 4], dim=-1)\n",
        "        o_1 = o_1.reshape(o_1.shape[0], o_1.shape[1], 50 * 3)\n",
        "        o_2 = o_2.reshape(o_2.shape[0], o_2.shape[1], 50 * 4)\n",
        "        o_1 = self.o1_embed(o_1)\n",
        "        o_2 = self.o2_embed(o_2)\n",
        "\n",
        "        x, h = self.layers_mha_ac(x=o_1, memory=o_2,\n",
        "                     src_mask=sub_mask, trg_mask=sub_mask, padding_mask=padding_mask)\n",
        "\n",
        "        # Apply a layer normalisation\n",
        "        x = self.layer_norm(x)\n",
        "        # Output layer turns it back into vectors of size trg_size\n",
        "        output = self.output_layer(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"%s(num_layers=%r, num_heads=%r)\" % (\n",
        "            self.__class__.__name__, len(self.layers),\n",
        "            self.layers[0].trg_trg_att.num_heads)"
      ],
      "metadata": {
        "id": "IwynI-3PzxDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "__all__ = [\"ACD\"]\n",
        "\n",
        "ModelPrediction = namedtuple('ModelPrediction', ['pred_noise', 'pred_x_start'])"
      ],
      "metadata": {
        "id": "2d_jTB7ez4Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exists(x):\n",
        "    return x is not None\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if callable(d) else d\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    \"\"\"extract the appropriate  t  index for a batch of indices\"\"\"\n",
        "    batch_size = t.shape[0]\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps, dtype=torch.float64)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)"
      ],
      "metadata": {
        "id": "D7K-cJ2L2EKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ACD(nn.Module):\n",
        "    def __init__(self, args, trg_vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        timesteps = args[\"diffusion\"].get('timesteps', 1000)\n",
        "        sampling_timesteps = args[\"diffusion\"].get('sampling_timesteps', 5)\n",
        "\n",
        "        betas = cosine_beta_schedule(timesteps)\n",
        "        alphas = 1. - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "        alphas_cumprod_prev = torch.nn.functional.pad(alphas_cumprod[:-1], (1, 0), value=1.)\n",
        "        timesteps, = betas.shape\n",
        "\n",
        "        self.num_timesteps = int(timesteps)\n",
        "        self.sampling_timesteps = default(sampling_timesteps, timesteps)\n",
        "        assert self.sampling_timesteps <= timesteps\n",
        "        self.is_ddim_sampling = self.sampling_timesteps < timesteps\n",
        "        self.ddim_sampling_eta = 1.\n",
        "        self.self_condition = False\n",
        "        self.scale = args[\"diffusion\"].get('scale', 1.0)\n",
        "        self.box_renewal = True\n",
        "        self.use_ensemble = True\n",
        "\n",
        "        self.register_buffer('betas', betas)\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
        "\n",
        "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
        "        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
        "        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
        "        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
        "\n",
        "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "        # Above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
        "        self.register_buffer('posterior_variance', posterior_variance)\n",
        "\n",
        "        # Below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
        "        self.register_buffer('posterior_log_variance_clipped', torch.log(posterior_variance.clamp(min=1e-20)))\n",
        "        self.register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
        "        self.register_buffer('posterior_mean_coef2',\n",
        "                             (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n",
        "\n",
        "        self.ACD_Denoiser = ACD_Denoiser(num_layers=args[\"diffusion\"].get('num_layers', 2),\n",
        "                                         num_heads=args[\"diffusion\"].get('num_heads', 4),\n",
        "                                         hidden_size=args[\"diffusion\"].get('hidden_size', 512),\n",
        "                                         ff_size=args[\"diffusion\"].get('ff_size', 512),\n",
        "                                         dropout=args[\"diffusion\"].get('dropout', 0.1),\n",
        "                                         emb_dropout=args[\"diffusion\"][\"embeddings\"].get('dropout', 0.1),\n",
        "                                         vocab_size=len(trg_vocab),\n",
        "                                         freeze=False,\n",
        "                                         trg_size=args.get('trg_size', 150),\n",
        "                                         decoder_trg_trg_=True)\n",
        "\n",
        "    def predict_noise_from_start(self, x_t, t, x0):\n",
        "        return (\n",
        "                (extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0) /\n",
        "                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
        "        )\n",
        "\n",
        "    def model_predictions(self, x, encoder_output, t, src_mask, trg_mask):\n",
        "        x_t = ID(x)\n",
        "        x_t = x_t / self.scale\n",
        "\n",
        "        pred_pose = self.ACD_Denoiser(encoder_output=encoder_output,\n",
        "                                      trg_embed=x_t,\n",
        "                                      src_mask=src_mask,\n",
        "                                      trg_mask=trg_mask,\n",
        "                                      t=t)\n",
        "\n",
        "        x_start = pred_pose\n",
        "        x_start = x_start * self.scale\n",
        "        pred_noise = self.predict_noise_from_start(x, t, x_start)\n",
        "\n",
        "        return ModelPrediction(pred_noise, x_start)\n",
        "\n",
        "    def ddim_sample(self, encoder_output, input_3d, src_mask, trg_mask):\n",
        "        batch = encoder_output.shape[0]\n",
        "        shape = (batch, input_3d.shape[1], 150)\n",
        "        total_timesteps, sampling_timesteps, eta = self.num_timesteps, self.sampling_timesteps, self.ddim_sampling_eta\n",
        "\n",
        "        # [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps\n",
        "        times = torch.linspace(-1, total_timesteps - 1, steps=sampling_timesteps + 1)\n",
        "        times = list(reversed(times.int().tolist()))\n",
        "        time_pairs = list(zip(times[:-1], times[1:]))  # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]\n",
        "\n",
        "        img = torch.randn(shape, device='cuda:0')\n",
        "\n",
        "        ensemble_score, ensemble_label, ensemble_coord = [], [], []\n",
        "        x_start = None\n",
        "        preds_all=[]\n",
        "        for time, time_next in time_pairs:\n",
        "            time_cond = torch.full((batch,), time, device='cuda:0', dtype=torch.long)\n",
        "\n",
        "            preds = self.model_predictions(x=img, encoder_output=encoder_output, t=time_cond,src_mask=src_mask, trg_mask=trg_mask)\n",
        "            pred_noise, x_start = preds.pred_noise.float(), preds.pred_x_start\n",
        "            preds_all.append(x_start)\n",
        "\n",
        "            if time_next < 0:\n",
        "                img = x_start\n",
        "                continue\n",
        "\n",
        "            alpha = self.alphas_cumprod[time]\n",
        "            alpha_next = self.alphas_cumprod[time_next]\n",
        "\n",
        "            sigma = eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()\n",
        "            c = (1 - alpha_next - sigma ** 2).sqrt()\n",
        "\n",
        "            noise = torch.randn_like(img)\n",
        "\n",
        "            img = x_start * alpha_next.sqrt() + \\\n",
        "                  c * pred_noise + \\\n",
        "                  sigma * noise\n",
        "\n",
        "        return preds_all\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start)\n",
        "\n",
        "        sqrt_alphas_cumprod_t = extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
        "\n",
        "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "\n",
        "    def forward(self, encoder_output, input_3d, src_mask, trg_mask, is_train):\n",
        "\n",
        "        # Prepare Proposals.\n",
        "        if not is_train:\n",
        "            results = self.ddim_sample(encoder_output=encoder_output, input_3d=input_3d, src_mask=src_mask, trg_mask=trg_mask)\n",
        "            return results[self.sampling_timesteps-1]\n",
        "\n",
        "        if is_train:\n",
        "            x_poses, noises, t = self.prepare_targets(input_3d)\n",
        "            x_poses = x_poses.float()\n",
        "            x_poses = ID(x_poses)\n",
        "            t = t.squeeze(-1)\n",
        "            pred_pose = self.ACD_Denoiser(encoder_output=encoder_output,\n",
        "                                          trg_embed=x_poses,\n",
        "                                          src_mask=src_mask,\n",
        "                                          trg_mask=trg_mask,\n",
        "                                          t=t)\n",
        "            return pred_pose\n",
        "\n",
        "    def prepare_diffusion_concat(self, pose_3d):\n",
        "\n",
        "        t = torch.randint(0, self.num_timesteps, (1,), device='cuda').long()\n",
        "        noise = torch.randn(pose_3d.shape[0],150, device='cuda')\n",
        "\n",
        "        x_start = pose_3d\n",
        "\n",
        "        x_start = x_start * self.scale\n",
        "\n",
        "        # noise sample\n",
        "        x = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
        "\n",
        "        x = x / self.scale\n",
        "\n",
        "        return x, noise, t\n",
        "\n",
        "    def prepare_targets(self, targets):\n",
        "        diffused_poses = []\n",
        "        noises = []\n",
        "        ts = []\n",
        "        for i in range(0,targets.shape[0]):\n",
        "            targets_per_sample = targets[i]\n",
        "\n",
        "            d_poses, d_noise, d_t = self.prepare_diffusion_concat(targets_per_sample)\n",
        "            diffused_poses.append(d_poses)\n",
        "            noises.append(d_noise)\n",
        "            ts.append(d_t)\n",
        "\n",
        "        return torch.stack(diffused_poses), torch.stack(noises), torch.stack(ts)"
      ],
      "metadata": {
        "id": "CGEZxsnr2MtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,cfg: dict,\n",
        "                 encoder: Encoder,\n",
        "                 ACD: ACD,\n",
        "                 src_embed: Embeddings,\n",
        "                 src_vocab: Vocabulary,\n",
        "                 trg_vocab: Vocabulary,\n",
        "                 in_trg_size: int,\n",
        "                 out_trg_size: int):\n",
        "        \"\"\"\n",
        "        Create Sign-IDD\n",
        "\n",
        "        :param encoder: encoder\n",
        "        :param ACD: ACD\n",
        "        :param src_embed: source embedding\n",
        "        :param trg_embed: target embedding\n",
        "        :param src_vocab: source vocabulary\n",
        "        :param trg_vocab: target vocabulary\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        model_cfg = cfg[\"model\"]\n",
        "        self.src_embed = src_embed\n",
        "        self.encoder = encoder\n",
        "        self.ACD = ACD\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.bos_index = self.src_vocab.stoi[BOS_TOKEN]\n",
        "        self.pad_index = self.src_vocab.stoi[PAD_TOKEN]\n",
        "        self.eos_index = self.src_vocab.stoi[EOS_TOKEN]\n",
        "        self.target_pad = TARGET_PAD\n",
        "\n",
        "        self.use_cuda = cfg[\"training\"][\"use_cuda\"]\n",
        "\n",
        "        self.in_trg_size = in_trg_size\n",
        "        self.out_trg_size = out_trg_size\n",
        "\n",
        "    def forward(self, is_train: bool, src: Tensor, trg_input: Tensor, src_mask: Tensor, src_lengths: Tensor, trg_mask: Tensor):\n",
        "\n",
        "        \"\"\"\n",
        "        First encodes the source sentence.\n",
        "        Then produces the target one word at a time.\n",
        "\n",
        "        :param src: source input\n",
        "        :param trg_input: target input\n",
        "        :param src_mask: source mask\n",
        "        :param src_lengths: length of source inputs\n",
        "        :param trg_mask: target mask\n",
        "        :return: diffusion_output\n",
        "        \"\"\"\n",
        "\n",
        "        # Encode the source sequence\n",
        "        encoder_output = self.encode(src=src,\n",
        "                                     src_length=src_lengths,\n",
        "                                     src_mask=src_mask)\n",
        "\n",
        "        # Diffusion the target sequence\n",
        "        diffusion_output = self.diffusion(is_train=is_train,\n",
        "                                          encoder_output=encoder_output,\n",
        "                                          trg_input=trg_input,\n",
        "                                          src_mask=src_mask,\n",
        "                                          trg_mask=trg_mask)\n",
        "\n",
        "        return diffusion_output\n",
        "\n",
        "    def encode(self, src: Tensor, src_length: Tensor, src_mask: Tensor):\n",
        "\n",
        "        \"\"\"\n",
        "        Encodes the source sentence.\n",
        "\n",
        "        :param src:\n",
        "        :param src_length:\n",
        "        :param src_mask:\n",
        "        :return: encoder outputs\n",
        "        \"\"\"\n",
        "\n",
        "        # Encode an embedded source\n",
        "        encode_output = self.encoder(embed_src=self.src_embed(src),\n",
        "                                     src_length=src_length,\n",
        "                                     mask=src_mask)\n",
        "\n",
        "        return encode_output\n",
        "\n",
        "    def diffusion(self, is_train: bool, encoder_output: Tensor, src_mask: Tensor, trg_input: Tensor, trg_mask: Tensor):\n",
        "\n",
        "        \"\"\"\n",
        "        diffusion the target sentence.\n",
        "\n",
        "        :param src: param encoder_output: encoder states for attention computation\n",
        "        :param src_mask: source mask, 1 at valid tokens\n",
        "        :param trg_input: target inputs\n",
        "        :param trg_mask: mask for target steps\n",
        "        :return: diffusion outputs\n",
        "        \"\"\"\n",
        "\n",
        "        diffusion_output = self.ACD(is_train=is_train,\n",
        "                                    encoder_output=encoder_output,\n",
        "                                    input_3d=trg_input,\n",
        "                                    src_mask=src_mask,\n",
        "                                    trg_mask=trg_mask)\n",
        "\n",
        "        return diffusion_output\n",
        "\n",
        "    def get_loss_for_batch(self, is_train, batch: Batch, loss_function: nn.Module) -> Tensor:\n",
        "        \"\"\"\n",
        "        Compute non-normalized loss and number of tokens for a batch\n",
        "\n",
        "        :param batch: batch to compute loss for\n",
        "        :param loss_function: loss function, computes for input and target\n",
        "            a scalar loss for the complete batch\n",
        "        :return: batch_loss: sum of losses over non-pad elements in the batch\n",
        "        \"\"\"\n",
        "        # Forward through the batch input\n",
        "        skel_out = self.forward(src=batch.src,\n",
        "                                trg_input=batch.trg_input[:, :, :150],\n",
        "                                src_mask=batch.src_mask,\n",
        "                                src_lengths=batch.src_lengths,\n",
        "                                trg_mask=batch.trg_mask,\n",
        "                                is_train=is_train)\n",
        "\n",
        "        # compute batch loss using skel_out and the batch target\n",
        "        batch_loss = loss_function(skel_out, batch.trg_input[:, :, :150])\n",
        "\n",
        "        # return batch loss = sum over all elements in batch that are not pad\n",
        "        return batch_loss"
      ],
      "metadata": {
        "id": "-FSDwmTo2S7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(cfg: dict, src_vocab: Vocabulary, trg_vocab: Vocabulary):\n",
        "\n",
        "    \"\"\"\n",
        "    Build and initialize the model according to the configuration.\n",
        "\n",
        "    :param cfg: dictionary configuration containing model specifications\n",
        "    :param src_vocab: source vocabulary\n",
        "    :param trg_vocab: target vocabulary\n",
        "    :return: built and initialized model\n",
        "    \"\"\"\n",
        "    full_cfg = cfg\n",
        "    cfg = cfg[\"model\"]\n",
        "\n",
        "    src_padding_idx = src_vocab.stoi[PAD_TOKEN]\n",
        "    trg_padding_idx = 0\n",
        "\n",
        "    # Input target size is the joint vector length plus one for counter\n",
        "    in_trg_size = cfg[\"trg_size\"]\n",
        "    # Output target size is the joint vector length plus one for counter\n",
        "    out_trg_size = cfg[\"trg_size\"]\n",
        "\n",
        "    # Define source embedding\n",
        "    src_embed = Embeddings(\n",
        "        **cfg[\"encoder\"][\"embeddings\"], vocab_size=len(src_vocab),\n",
        "        padding_idx=src_padding_idx)\n",
        "\n",
        "    ## Encoder -------\n",
        "    enc_dropout = cfg[\"encoder\"].get(\"dropout\", 0.) # Dropout\n",
        "    enc_emb_dropout = cfg[\"encoder\"][\"embeddings\"].get(\"dropout\", enc_dropout)\n",
        "    assert cfg[\"encoder\"][\"embeddings\"][\"embedding_dim\"] == \\\n",
        "           cfg[\"encoder\"][\"hidden_size\"], \\\n",
        "           \"for transformer, emb_size must be hidden_size\"\n",
        "\n",
        "    # Transformer Encoder\n",
        "    encoder = Encoder(**cfg[\"encoder\"],\n",
        "                      emb_size=src_embed.embedding_dim,\n",
        "                      emb_dropout=enc_emb_dropout)\n",
        "\n",
        "    # ACD\n",
        "    diffusion = ACD(args=cfg,\n",
        "                    trg_vocab=trg_vocab)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(encoder=encoder,\n",
        "                  ACD=diffusion,\n",
        "                  src_embed=src_embed,\n",
        "                  src_vocab=src_vocab,\n",
        "                  trg_vocab=trg_vocab,\n",
        "                  cfg=full_cfg,\n",
        "                  in_trg_size=in_trg_size,\n",
        "                  out_trg_size=out_trg_size)\n",
        "\n",
        "    # Custom initialization of model parameters\n",
        "    initialize_model(model, cfg, src_padding_idx, trg_padding_idx)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fBDd_nnQ25Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate epoch given a dataset\n",
        "def validate_on_data(model: Model,\n",
        "                     data: Dataset,\n",
        "                     batch_size: int,\n",
        "                     max_output_length: int,\n",
        "                     eval_metric: str,\n",
        "                     loss_function: torch.nn.Module = None,\n",
        "                     batch_type: str = \"sentence\",\n",
        "                     type = \"val\",\n",
        "                     BT_model = None):\n",
        "\n",
        "    valid_iter = make_data_iter(\n",
        "        dataset=data, batch_size=batch_size, batch_type=batch_type,\n",
        "        shuffle=True, train=False)\n",
        "\n",
        "    pad_index = model.src_vocab.stoi[PAD_TOKEN]\n",
        "    # disable dropout\n",
        "    model.eval()\n",
        "    # don't track gradients during validation\n",
        "    with torch.no_grad():\n",
        "        valid_hypotheses = []\n",
        "        valid_references = []\n",
        "        valid_inputs = []\n",
        "        file_paths = []\n",
        "        all_dtw_scores = []\n",
        "\n",
        "        valid_loss = 0\n",
        "        total_ntokens = 0\n",
        "        total_nseqs = 0\n",
        "\n",
        "        batches = 0\n",
        "        for valid_batch in iter(valid_iter):\n",
        "            # Extract batch\n",
        "            batch = Batch(torch_batch=valid_batch,\n",
        "                          pad_index=pad_index,\n",
        "                          model=model)\n",
        "            targets = batch.trg_input\n",
        "\n",
        "            # run as during training with teacher forcing\n",
        "            if loss_function is not None and batch.trg is not None:\n",
        "                # Get the loss for this batch\n",
        "                batch_loss = model.get_loss_for_batch(is_train=True,\n",
        "                                                         batch=batch,\n",
        "                                                         loss_function=loss_function)\n",
        "\n",
        "                valid_loss += batch_loss\n",
        "                total_ntokens += batch.ntokens\n",
        "                total_nseqs += batch.nseqs\n",
        "\n",
        "            output = model.forward(src=batch.src,\n",
        "                                       trg_input=batch.trg_input[:, :, :150],\n",
        "                                       src_mask=batch.src_mask,\n",
        "                                       src_lengths=batch.src_lengths,\n",
        "                                       trg_mask=batch.trg_mask,\n",
        "                                       is_train=False)\n",
        "\n",
        "            output = torch.cat((output, batch.trg_input[:, :, 150:]), dim=-1)\n",
        "\n",
        "            # Add references, hypotheses and file paths to list\n",
        "            valid_references.extend(targets)\n",
        "            valid_hypotheses.extend(output)\n",
        "            file_paths.extend(batch.file_paths)\n",
        "            # Add the source sentences to list, by using the model source vocab and batch indices\n",
        "            valid_inputs.extend([[model.src_vocab.itos[batch.src[i][j]] for j in range(len(batch.src[i]))] for i in\n",
        "                                 range(len(batch.src))])\n",
        "\n",
        "            # Calculate the full Dynamic Time Warping score - for evaluation\n",
        "            dtw_score = calculate_dtw(targets, output)\n",
        "            all_dtw_scores.extend(dtw_score)\n",
        "\n",
        "            # Can set to only run a few batches\n",
        "            # if batches == math.ceil(20/batch_size):\n",
        "            #     break\n",
        "            batches += 1\n",
        "\n",
        "        # Dynamic Time Warping scores\n",
        "        current_valid_score = np.mean(all_dtw_scores)\n",
        "\n",
        "    return current_valid_score, valid_loss, valid_references, valid_hypotheses, \\\n",
        "           valid_inputs, all_dtw_scores, file_paths"
      ],
      "metadata": {
        "id": "1Yos86cU3ALU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "wzxcYRCG3O8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSkeletalModelStructure3D():\n",
        "    return (\n",
        "        # head\n",
        "        (0, 1, 0),\n",
        "\n",
        "        # left shoulder\n",
        "        (1, 2, 1),\n",
        "\n",
        "        # left arm\n",
        "        (2, 3, 2),\n",
        "        # (3, 4, 3),\n",
        "        # Changed to avoid wrist, go straight to hands\n",
        "        (3, 29, 3),\n",
        "\n",
        "        # right shoulder\n",
        "        (1, 5, 1),\n",
        "\n",
        "        # right arm\n",
        "        (5, 6, 2),\n",
        "        # (6, 7, 3),\n",
        "        # Changed to avoid wrist, go straight to hands\n",
        "        (6, 8, 3),\n",
        "\n",
        "        # left hand - wrist\n",
        "        # (7, 8, 4),\n",
        "\n",
        "        # left hand - palm\n",
        "        (8, 9, 5),\n",
        "        (8, 13, 9),\n",
        "        (8, 17, 13),\n",
        "        (8, 21, 17),\n",
        "        (8, 25, 21),\n",
        "\n",
        "        # left hand - 1st finger\n",
        "        (9, 10, 6),\n",
        "        (10, 11, 7),\n",
        "        (11, 12, 8),\n",
        "\n",
        "        # left hand - 2nd finger\n",
        "        (13, 14, 10),\n",
        "        (14, 15, 11),\n",
        "        (15, 16, 12),\n",
        "\n",
        "        # left hand - 3rd finger\n",
        "        (17, 18, 14),\n",
        "        (18, 19, 15),\n",
        "        (19, 20, 16),\n",
        "\n",
        "        # left hand - 4th finger\n",
        "        (21, 22, 18),\n",
        "        (22, 23, 19),\n",
        "        (23, 24, 20),\n",
        "\n",
        "        # left hand - 5th finger\n",
        "        (25, 26, 22),\n",
        "        (26, 27, 23),\n",
        "        (27, 28, 24),\n",
        "\n",
        "        # right hand - wrist\n",
        "        # (4, 29, 4),\n",
        "\n",
        "        # right hand - palm\n",
        "        (29, 30, 5),\n",
        "        (29, 34, 9),\n",
        "        (29, 38, 13),\n",
        "        (29, 42, 17),\n",
        "        (29, 46, 21),\n",
        "\n",
        "        # right hand - 1st finger\n",
        "        (30, 31, 6),\n",
        "        (31, 32, 7),\n",
        "        (32, 33, 8),\n",
        "\n",
        "        # right hand - 2nd finger\n",
        "        (34, 35, 10),\n",
        "        (35, 36, 11),\n",
        "        (36, 37, 12),\n",
        "\n",
        "        # right hand - 3rd finger\n",
        "        (38, 39, 14),\n",
        "        (39, 40, 15),\n",
        "        (40, 41, 16),\n",
        "\n",
        "        # right hand - 4th finger\n",
        "        (42, 43, 18),\n",
        "        (43, 44, 19),\n",
        "        (44, 45, 20),\n",
        "\n",
        "        # right hand - 5th finger\n",
        "        (46, 47, 22),\n",
        "        (47, 48, 23),\n",
        "        (48, 49, 24),\n",
        "    )"
      ],
      "metadata": {
        "id": "QoDcv43E4LwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw a line between two points, if they are positive points\n",
        "def draw_line(im, joint1, joint2, c=(0, 0, 255),t=1, width=3):\n",
        "    thresh = -100\n",
        "    if joint1[0] > thresh and  joint1[1] > thresh and joint2[0] > thresh and joint2[1] > thresh:\n",
        "\n",
        "        center = (int((joint1[0] + joint2[0]) / 2), int((joint1[1] + joint2[1]) / 2))\n",
        "\n",
        "        length = int(math.sqrt(((joint1[0] - joint2[0]) ** 2) + ((joint1[1] - joint2[1]) ** 2))/2)\n",
        "\n",
        "        angle = math.degrees(math.atan2((joint1[0] - joint2[0]),(joint1[1] - joint2[1])))\n",
        "\n",
        "        cv2.ellipse(im, center, (width,length), -angle,0.0,360.0, c, -1)"
      ],
      "metadata": {
        "id": "-q9xtG-U5iyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get bone colour given index\n",
        "def get_bone_colour(skeleton,j):\n",
        "    return (0, 0, 0)"
      ],
      "metadata": {
        "id": "b-i18va0551L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_frame_2D(frame, joints):\n",
        "    # Line to be between the stacked\n",
        "    draw_line(frame, [1, 650], [1, 1], c=(0,0,0), t=1, width=1)\n",
        "    # Give an offset to center the skeleton around\n",
        "    offset = [350, 250]\n",
        "\n",
        "    # Get the skeleton structure details of each bone, and size\n",
        "    skeleton = getSkeletalModelStructure3D()\n",
        "    skeleton = np.array(skeleton)\n",
        "\n",
        "    number = skeleton.shape[0]\n",
        "\n",
        "    # Increase the size and position of the joints\n",
        "    joints = joints * 10 * 12 * 2\n",
        "    joints = joints + np.ones((50, 2)) * offset\n",
        "\n",
        "    # Loop through each of the bone structures, and plot the bone\n",
        "    for j in range(number):\n",
        "\n",
        "        c = get_bone_colour(skeleton,j)\n",
        "\n",
        "        draw_line(frame, [joints[skeleton[j, 0]][0], joints[skeleton[j, 0]][1]],\n",
        "                  [joints[skeleton[j, 1]][0], joints[skeleton[j, 1]][1]], c=c, t=1, width=1)"
      ],
      "metadata": {
        "id": "i6qeQdxQ5xl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a video given a tensor of joints, a file path, video name and references/sequence ID\n",
        "def plot_video(joints,\n",
        "               file_path,\n",
        "               video_name,\n",
        "               references=None,\n",
        "               skip_frames=1,\n",
        "               sequence_ID=None):\n",
        "    # Create video template\n",
        "    FPS = (25 // skip_frames)\n",
        "    # ipdb.set_trace()\n",
        "    video_file = file_path + \"/{}.mp4\".format(sequence_ID.split(\".\")[0])\n",
        "    video_path, video_name = os.path.split(video_file)\n",
        "    if not os.path.exists(video_path):\n",
        "        os.mkdir(video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    if references is None:\n",
        "        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (650, 650), True)\n",
        "    elif references is not None:\n",
        "        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (1300, 650), True)  # Long\n",
        "\n",
        "    num_frames = 0\n",
        "\n",
        "    for (j, frame_joints) in enumerate(joints):\n",
        "\n",
        "        # Reached padding\n",
        "        if PAD_TOKEN in frame_joints.astype('str').tolist():\n",
        "            continue\n",
        "\n",
        "        # Initialise frame of white\n",
        "        frame = np.ones((650, 650, 3), np.uint8) * 255\n",
        "\n",
        "        # Cut off the percent_tok, multiply by 3 to restore joint size\n",
        "        # TODO - Remove the *3 if the joints weren't divided by 3 in data creation\n",
        "        frame_joints = frame_joints[:-1] * 3\n",
        "\n",
        "        # Reduce the frame joints down to 2D for visualisation - Frame joints 2d shape is (48,2)\n",
        "        frame_joints_2d = np.reshape(frame_joints, (50, 3))[:, :2]\n",
        "        # Draw the frame given 2D joints\n",
        "        draw_frame_2D(frame, frame_joints_2d)\n",
        "\n",
        "        cv2.putText(frame, \"Predicted Sign Pose\", (180, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                    (0, 0, 0), 2)\n",
        "\n",
        "        # If reference is provided, create and concatenate on the end\n",
        "        if references is not None:\n",
        "            # Extract the reference joints\n",
        "            ref_joints = references[j]\n",
        "            # Initialise frame of white\n",
        "            ref_frame = np.ones((650, 650, 3), np.uint8) * 255\n",
        "\n",
        "            # Cut off the percent_tok and multiply each joint by 3 (as was reduced in training files)\n",
        "            ref_joints = ref_joints[:-1] * 3\n",
        "\n",
        "            # Reduce the frame joints down to 2D- Frame joints 2d shape is (48,2)\n",
        "            ref_joints_2d = np.reshape(ref_joints, (50, 3))[:, :2]\n",
        "\n",
        "            # Draw these joints on the frame\n",
        "            draw_frame_2D(ref_frame, ref_joints_2d)\n",
        "\n",
        "            cv2.putText(ref_frame, \"Ground Truth Pose\", (190, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                        (0, 0, 0), 2)\n",
        "\n",
        "            frame = np.concatenate((frame, ref_frame), axis=1)\n",
        "\n",
        "            sequence_ID_write = \"Sequence ID: \" + sequence_ID.split(\"/\")[-1]\n",
        "            cv2.putText(frame, sequence_ID_write, (150, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                        (0, 0, 0), 2)\n",
        "        # Write the video frame\n",
        "        video.write(frame)\n",
        "        num_frames += 1\n",
        "    # Release the video\n",
        "    video.release()"
      ],
      "metadata": {
        "id": "nE38w56v4rqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average of the given frames\n",
        "def avg_frames(frames):\n",
        "    frames_sum = np.zeros_like(frames[0])\n",
        "    for frame in frames:\n",
        "        frames_sum += frame\n",
        "\n",
        "    avg_frame = frames_sum / len(frames)\n",
        "    return avg_frame"
      ],
      "metadata": {
        "id": "7YsxuCL16ArX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply DTW to the produced sequence, so it can be visually compared to the reference sequence\n",
        "def alter_DTW_timing(pred_seq,ref_seq):\n",
        "\n",
        "    # Define a cost function\n",
        "    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n",
        "\n",
        "    # Cut the reference down to the max count value\n",
        "    _ , ref_max_idx = torch.max(ref_seq[:, -1], 0)\n",
        "    if ref_max_idx == 0: ref_max_idx += 1\n",
        "    # Cut down frames by counter\n",
        "    ref_seq = ref_seq[:ref_max_idx,:].cpu().numpy()\n",
        "\n",
        "    # Cut the hypothesis down to the max count value\n",
        "    _, hyp_max_idx = torch.max(pred_seq[:, -1], 0)\n",
        "    if hyp_max_idx == 0: hyp_max_idx += 1\n",
        "    # Cut down frames by counter\n",
        "    pred_seq = pred_seq[:hyp_max_idx,:].cpu().numpy()\n",
        "    #pred_seq = pred_seq[:ref_max_idx, :].cpu().numpy()\n",
        "    # Run DTW on the reference and predicted sequence\n",
        "    d, cost_matrix, acc_cost_matrix, path = dtw(ref_seq[:,:-1], pred_seq[:,:-1], dist=euclidean_norm)\n",
        "\n",
        "    # Normalise the dtw cost by sequence length\n",
        "    d = d / acc_cost_matrix.shape[0]\n",
        "\n",
        "    # Initialise new sequence\n",
        "    new_pred_seq = np.zeros_like(ref_seq)\n",
        "    # j tracks the position in the reference sequence\n",
        "    j = 0\n",
        "    skips = 0\n",
        "    squeeze_frames = []\n",
        "    for (i, pred_num) in enumerate(path[0]):\n",
        "\n",
        "        if i == len(path[0]) - 1:\n",
        "            break\n",
        "\n",
        "        if path[1][i] == path[1][i + 1]:\n",
        "            skips += 1\n",
        "\n",
        "        # If a double coming up\n",
        "        if path[0][i] == path[0][i + 1]:\n",
        "            squeeze_frames.append(pred_seq[i - skips])\n",
        "            j += 1\n",
        "        # Just finished a double\n",
        "        elif path[0][i] == path[0][i - 1]:\n",
        "            new_pred_seq[pred_num] = avg_frames(squeeze_frames)\n",
        "            squeeze_frames = []\n",
        "        else:\n",
        "            new_pred_seq[pred_num] = pred_seq[i - skips]\n",
        "\n",
        "    return new_pred_seq, ref_seq, d"
      ],
      "metadata": {
        "id": "tzkQ_2W96Rvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "pC8HZvYD6YVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainManager:\n",
        "\n",
        "    def __init__(self, model: Model, config: dict, test=False):\n",
        "\n",
        "        train_config = config[\"training\"]\n",
        "        model_dir = train_config[\"model_dir\"]\n",
        "\n",
        "        # If model continue, continues model from the latest checkpoint\n",
        "        model_continue = train_config.get(\"continue\", True)\n",
        "\n",
        "        # If the directory has not been created, can't continue from anything\n",
        "        if not os.path.isdir(model_dir):\n",
        "            model_continue = False\n",
        "        if test:\n",
        "            model_continue = True\n",
        "\n",
        "        # files for logging and storing\n",
        "        self.model_dir = make_model_dir(train_config[\"model_dir\"],\n",
        "                                        overwrite=train_config.get(\"overwrite\", False),\n",
        "                                        model_continue=model_continue)\n",
        "\n",
        "        # Build logger\n",
        "        self.logger = make_logger(model_dir=self.model_dir)\n",
        "        self.logging_freq = train_config.get(\"logging_freq\", 100)\n",
        "        # Build validation files\n",
        "        self.valid_report_file = \"{}/validations.txt\".format(self.model_dir)\n",
        "        self.tb_writer = SummaryWriter(log_dir=self.model_dir+\"/tensorboard/\")\n",
        "\n",
        "        # model\n",
        "        self.model = model\n",
        "        self.pad_index = self.model.pad_index\n",
        "        self.bos_index = self.model.bos_index\n",
        "        self._log_parameters_list()\n",
        "        self.target_pad = TARGET_PAD\n",
        "\n",
        "        # New loss - depending on config\n",
        "        self.loss = Loss(cfg = config, target_pad=self.target_pad)\n",
        "\n",
        "        # normal\n",
        "        self.normalization = \"batch\"\n",
        "\n",
        "        # optimization\n",
        "        self.learning_rate_min = train_config.get(\"learning_rate_min\", 1.0e-8)\n",
        "        self.clip_grad_fun = build_gradient_clipper(config=train_config)\n",
        "        self.optimizer = build_optimizer(config=train_config, parameters=model.parameters())\n",
        "\n",
        "        # validation & early stopping\n",
        "        self.validation_freq = train_config.get(\"validation_freq\", 1000)\n",
        "        self.ckpt_best_queue = queue.Queue(maxsize=train_config.get(\"keep_last_ckpts\", 1))\n",
        "        self.ckpt_queue = queue.Queue(maxsize=1)\n",
        "\n",
        "        # TODO - Include Back Translation\n",
        "        self.eval_metric = train_config.get(\"eval_metric\", \"dtw\").lower()\n",
        "        if self.eval_metric not in ['bleu', 'chrf', \"dtw\"]:\n",
        "            raise ConfigurationError(\"Invalid setting for 'eval_metric', \"\n",
        "                                     \"valid options: 'bleu', 'chrf', 'DTW'\")\n",
        "        self.early_stopping_metric = train_config.get(\"early_stopping_metric\",\n",
        "                                                       \"eval_metric\")\n",
        "\n",
        "        # if we schedule after BLEU/chrf, we want to maximize it, else minimize\n",
        "        # early_stopping_metric decides on how to find the early stopping point:\n",
        "        # ckpts are written when there's a new high/low score for this metric\n",
        "        if self.early_stopping_metric in [\"loss\",\"dtw\"]:\n",
        "            self.minimize_metric = True\n",
        "        else:\n",
        "            raise ConfigurationError(\"Invalid setting for 'early_stopping_metric', \"\n",
        "                                    \"valid options: 'loss', 'dtw',.\")\n",
        "\n",
        "        # learning rate scheduling\n",
        "        self.scheduler, self.scheduler_step_at = build_scheduler(\n",
        "            config=train_config,\n",
        "            scheduler_mode=\"min\" if self.minimize_metric else \"max\",\n",
        "            optimizer=self.optimizer,\n",
        "            hidden_size=config[\"model\"][\"encoder\"][\"hidden_size\"])\n",
        "\n",
        "        # data & batch handling\n",
        "        self.level = \"word\"\n",
        "        self.shuffle = train_config.get(\"shuffle\", True)\n",
        "        self.epochs = train_config[\"epochs\"]\n",
        "        self.batch_size = train_config[\"batch_size\"]\n",
        "        self.batch_type = \"sentence\"\n",
        "        self.eval_batch_size = train_config.get(\"eval_batch_size\",self.batch_size)\n",
        "        self.eval_batch_type = train_config.get(\"eval_batch_type\",self.batch_type)\n",
        "        self.batch_multiplier = train_config.get(\"batch_multiplier\", 1)\n",
        "\n",
        "        # generation\n",
        "        self.max_output_length = train_config.get(\"max_output_length\", None)\n",
        "\n",
        "        # CPU / GPU\n",
        "        self.use_cuda = train_config[\"use_cuda\"]\n",
        "        if self.use_cuda:\n",
        "            self.model.cuda()\n",
        "            self.loss.cuda()\n",
        "\n",
        "        # initialize training statistics\n",
        "        self.steps = 0\n",
        "        # stop training if this flag is True by reaching learning rate minimum\n",
        "        self.stop = False\n",
        "        self.total_tokens = 0\n",
        "        self.best_ckpt_iteration = 0\n",
        "        # initial values for best scores\n",
        "        self.best_ckpt_score = np.inf if self.minimize_metric else -np.inf\n",
        "        # comparison function for scores\n",
        "        self.is_best = lambda score: score < self.best_ckpt_score \\\n",
        "            if self.minimize_metric else score > self.best_ckpt_score\n",
        "\n",
        "        ## Checkpoint restart\n",
        "        # If continuing\n",
        "        if model_continue:\n",
        "            # Get the latest checkpoint\n",
        "            ckpt = get_latest_checkpoint(model_dir)\n",
        "            if ckpt is None:\n",
        "                self.logger.info(\"Can't find checkpoint in directory %s\", ckpt)\n",
        "            else:\n",
        "                self.logger.info(\"Continuing model from %s\", ckpt)\n",
        "                self.init_from_checkpoint(ckpt)\n",
        "\n",
        "        # Skip frames\n",
        "        self.skip_frames = config[\"data\"].get(\"skip_frames\", 1)\n",
        "\n",
        "    # Save a checkpoint\n",
        "    def _save_checkpoint(self, type=\"every\") -> None:\n",
        "        # Define model path\n",
        "        model_path = \"{}/{}_{}.ckpt\".format(self.model_dir, self.steps, type)\n",
        "        # Define State\n",
        "        state = {\n",
        "            \"steps\": self.steps,\n",
        "            \"total_tokens\": self.total_tokens,\n",
        "            \"best_ckpt_score\": self.best_ckpt_score,\n",
        "            \"best_ckpt_iteration\": self.best_ckpt_iteration,\n",
        "            \"model_state\": self.model.state_dict(),\n",
        "            \"optimizer_state\": self.optimizer.state_dict(),\n",
        "            \"scheduler_state\": self.scheduler.state_dict() if \\\n",
        "            self.scheduler is not None else None,\n",
        "        }\n",
        "        torch.save(state, model_path)\n",
        "        # If this is the best checkpoint\n",
        "        if type == \"best\":\n",
        "            if self.ckpt_best_queue.full():\n",
        "                to_delete = self.ckpt_best_queue.get()  # delete oldest ckpt\n",
        "                try:\n",
        "                    os.remove(to_delete)\n",
        "                except FileNotFoundError:\n",
        "                    self.logger.warning(\"Wanted to delete old checkpoint %s but \"\n",
        "                                        \"file does not exist.\", to_delete)\n",
        "\n",
        "            self.ckpt_best_queue.put(model_path)\n",
        "\n",
        "            best_path = \"{}/best.ckpt\".format(self.model_dir)\n",
        "            try:\n",
        "                # create/modify symbolic link for best checkpoint\n",
        "                symlink_update(\"{}_best.ckpt\".format(self.steps), best_path)\n",
        "            except OSError:\n",
        "                # overwrite best.ckpt\n",
        "                torch.save(state, best_path)\n",
        "\n",
        "        # If this is just the checkpoint at every validation\n",
        "        elif type == \"every\":\n",
        "            if self.ckpt_queue.full():\n",
        "                to_delete = self.ckpt_queue.get()  # delete oldest ckpt\n",
        "                try:\n",
        "                    os.remove(to_delete)\n",
        "                except FileNotFoundError:\n",
        "                    self.logger.warning(\"Wanted to delete old checkpoint %s but \"\n",
        "                                        \"file does not exist.\", to_delete)\n",
        "\n",
        "            self.ckpt_queue.put(model_path)\n",
        "\n",
        "            every_path = \"{}/every.ckpt\".format(self.model_dir)\n",
        "            try:\n",
        "                # create/modify symbolic link for best checkpoint\n",
        "                symlink_update(\"{}_best.ckpt\".format(self.steps), every_path)\n",
        "            except OSError:\n",
        "                # overwrite every.ckpt\n",
        "                torch.save(state, every_path)\n",
        "\n",
        "    # Initialise from a checkpoint\n",
        "    def init_from_checkpoint(self, path: str) -> None:\n",
        "        # Find last checkpoint\n",
        "        model_checkpoint = load_checkpoint(path=path, use_cuda=self.use_cuda)\n",
        "\n",
        "        # restore model and optimizer parameters\n",
        "        self.model.load_state_dict(model_checkpoint[\"model_state\"])\n",
        "        self.optimizer.load_state_dict(model_checkpoint[\"optimizer_state\"])\n",
        "\n",
        "        if model_checkpoint[\"scheduler_state\"] is not None and \\\n",
        "                self.scheduler is not None:\n",
        "            # Load the scheduler state\n",
        "            self.scheduler.load_state_dict(model_checkpoint[\"scheduler_state\"])\n",
        "\n",
        "        # restore counts\n",
        "        self.steps = model_checkpoint[\"steps\"]\n",
        "        self.total_tokens = model_checkpoint[\"total_tokens\"]\n",
        "        self.best_ckpt_score = model_checkpoint[\"best_ckpt_score\"]\n",
        "        self.best_ckpt_iteration = model_checkpoint[\"best_ckpt_iteration\"]\n",
        "\n",
        "        # move parameters to cuda\n",
        "        if self.use_cuda:\n",
        "            self.model.cuda()\n",
        "\n",
        "    # Train and validate function\n",
        "    def train_and_validate(self, train_data: Dataset, valid_data: Dataset) -> None:\n",
        "\n",
        "        # Make training iterator\n",
        "        train_iter = make_data_iter(train_data,\n",
        "                                    batch_size=self.batch_size,\n",
        "                                    batch_type=self.batch_type,\n",
        "                                    train=True, shuffle=self.shuffle)\n",
        "\n",
        "        val_step = 0\n",
        "        # Loop through epochs\n",
        "        for epoch_no in range(self.epochs):\n",
        "            self.logger.info(\"EPOCH %d\", epoch_no + 1)\n",
        "\n",
        "            if self.scheduler is not None and self.scheduler_step_at == \"epoch\":\n",
        "                self.scheduler.step(epoch=epoch_no)\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            # Reset statistics for each epoch.\n",
        "            start = time.time()\n",
        "            total_valid_duration = 0\n",
        "            start_tokens = self.total_tokens\n",
        "            count = self.batch_multiplier - 1\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for batch in iter(train_iter):\n",
        "                # reactivate training\n",
        "                self.model.train()\n",
        "\n",
        "                # create a Batch object from torchtext batch\n",
        "                batch = Batch(torch_batch=batch,\n",
        "                              pad_index=self.pad_index,\n",
        "                              model=self.model)\n",
        "\n",
        "                update = count == 0\n",
        "\n",
        "                # Train the model on a batch\n",
        "                batch_loss = self._train_batch(batch, update=update)\n",
        "\n",
        "                self.tb_writer.add_scalar(\"train/train_batch_loss\", batch_loss,self.steps)\n",
        "                count = self.batch_multiplier if update else count\n",
        "                count -= 1\n",
        "                epoch_loss += batch_loss.detach().cpu().numpy()\n",
        "\n",
        "                if self.scheduler is not None and self.scheduler_step_at == \"step\" and update:\n",
        "                    self.scheduler.step()\n",
        "\n",
        "                # log learning progress\n",
        "                if self.steps % self.logging_freq == 0 and update:\n",
        "                    elapsed = time.time() - start - total_valid_duration\n",
        "                    elapsed_tokens = self.total_tokens - start_tokens\n",
        "                    self.logger.info(\n",
        "                        \"Epoch %3d Step: %8d Batch Loss: %12.6f \"\n",
        "                        \"Tokens per Sec: %8.0f, Lr: %.6f\",\n",
        "                        epoch_no + 1, self.steps, batch_loss,\n",
        "                        elapsed_tokens / elapsed,\n",
        "                        self.optimizer.param_groups[0][\"lr\"])\n",
        "                    start = time.time()\n",
        "                    total_valid_duration = 0\n",
        "                    start_tokens = self.total_tokens\n",
        "\n",
        "                # validate on the entire dev set\n",
        "                if self.steps % self.validation_freq == 0 and update:\n",
        "\n",
        "                    valid_start_time = time.time()\n",
        "\n",
        "                    valid_score, valid_loss, valid_references, valid_hypotheses, \\\n",
        "                        valid_inputs, all_dtw_scores, valid_file_paths = \\\n",
        "                        validate_on_data(\n",
        "                            batch_size=self.eval_batch_size,\n",
        "                            data=valid_data,\n",
        "                            eval_metric=self.eval_metric,\n",
        "                            model=self.model,\n",
        "                            max_output_length=self.max_output_length,\n",
        "                            loss_function=self.loss,\n",
        "                            batch_type=self.eval_batch_type,\n",
        "                            type=\"val\",\n",
        "                        )\n",
        "\n",
        "                    val_step += 1\n",
        "\n",
        "                    # Tensorboard writer\n",
        "                    self.tb_writer.add_scalar(\"valid/valid_loss\", valid_loss, self.steps)\n",
        "                    self.tb_writer.add_scalar(\"valid/valid_score\", valid_score, self.steps)\n",
        "\n",
        "                    if self.early_stopping_metric == \"loss\":\n",
        "                        ckpt_score = valid_loss\n",
        "                    elif self.early_stopping_metric == \"dtw\":\n",
        "                        ckpt_score = valid_score\n",
        "                    else:\n",
        "                        ckpt_score = valid_score\n",
        "\n",
        "                    new_best = False\n",
        "                    self.best = False\n",
        "                    if self.is_best(ckpt_score):\n",
        "                        self.best = True\n",
        "                        self.best_ckpt_score = ckpt_score\n",
        "                        self.best_ckpt_iteration = self.steps\n",
        "                        self.logger.info(\n",
        "                            'Hooray! New best validation result [%s]!',\n",
        "                            self.early_stopping_metric)\n",
        "                        if self.ckpt_queue.maxsize > 0:\n",
        "                            self.logger.info(\"Saving new checkpoint.\")\n",
        "                            new_best = True\n",
        "                            self._save_checkpoint(type=\"best\")\n",
        "\n",
        "                        # Display these sequences, in this index order\n",
        "                        display = list(range(0, len(valid_hypotheses), int(np.ceil(len(valid_hypotheses) / 13.15))))\n",
        "                        self.produce_validation_video(\n",
        "                            output_joints=valid_hypotheses,\n",
        "                            inputs=valid_inputs,\n",
        "                            references=valid_references,\n",
        "                            model_dir=self.model_dir,\n",
        "                            steps=self.steps,\n",
        "                            display=display,\n",
        "                            type=\"val_inf\",\n",
        "                            file_paths=valid_file_paths,\n",
        "                        )\n",
        "\n",
        "                    self._save_checkpoint(type=\"every\")\n",
        "\n",
        "                    if self.scheduler is not None and self.scheduler_step_at == \"validation\":\n",
        "                        self.scheduler.step(ckpt_score)\n",
        "\n",
        "                    # append to validation report\n",
        "                    self._add_report(\n",
        "                        valid_score=valid_score, valid_loss=valid_loss,\n",
        "                        eval_metric=self.eval_metric,\n",
        "                        new_best=new_best, report_type=\"val\",)\n",
        "\n",
        "                    valid_duration = time.time() - valid_start_time\n",
        "                    total_valid_duration += valid_duration\n",
        "                    self.logger.info(\n",
        "                        'Validation result at epoch %3d, step %8d: Val DTW Score: %6.2f, '\n",
        "                        'loss: %8.4f,  duration: %.4fs',\n",
        "                            epoch_no+1, self.steps, valid_score,\n",
        "                            valid_loss, valid_duration)\n",
        "\n",
        "                if self.stop:\n",
        "                    break\n",
        "            if self.stop:\n",
        "                self.logger.info(\n",
        "                    'Training ended since minimum lr %f was reached.',\n",
        "                     self.learning_rate_min)\n",
        "                break\n",
        "\n",
        "            self.logger.info('Epoch %3d: total training loss %.5f', epoch_no+1,\n",
        "                             epoch_loss)\n",
        "        else:\n",
        "            self.logger.info('Training ended after %3d epochs.', epoch_no+1)\n",
        "        self.logger.info('Best validation result at step %8d: %6.2f %s.',\n",
        "                         self.best_ckpt_iteration, self.best_ckpt_score,\n",
        "                         self.early_stopping_metric)\n",
        "\n",
        "        self.tb_writer.close()  # close Tensorboard writer\n",
        "\n",
        "\n",
        "    # Produce the video of Phoenix MTC joints\n",
        "    def produce_validation_video(self, output_joints, inputs, references, display, model_dir, type, steps=\"\", file_paths=None, dtw_file=None):\n",
        "\n",
        "        # If not at test\n",
        "        if type != \"test\":\n",
        "            dir_name = model_dir + \"/videos/Step_{}/\".format(steps)\n",
        "            if not os.path.exists(model_dir + \"/videos/\"):\n",
        "                os.mkdir(model_dir + \"/videos/\")\n",
        "\n",
        "        # If at test time\n",
        "        elif type == \"test\":\n",
        "            dir_name = model_dir + \"/test_videos/\"\n",
        "\n",
        "        # Create model video folder if not exist\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "\n",
        "        # For sequence to display\n",
        "        for i in display:\n",
        "\n",
        "            seq = output_joints[i]\n",
        "            ref_seq = references[i]\n",
        "            input = inputs[i]\n",
        "            # Write gloss label\n",
        "            gloss_label = input[0]\n",
        "            if input[1] is not \"</s>\":\n",
        "                gloss_label += \"_\" + input[1]\n",
        "            if input[2] is not \"</s>\":\n",
        "                gloss_label += \"_\" + input[2]\n",
        "\n",
        "            # Alter the dtw timing of the produced sequence, and collect the DTW score\n",
        "            timing_hyp_seq, ref_seq_count, dtw_score = alter_DTW_timing(seq, ref_seq)\n",
        "\n",
        "            video_ext = \"{}_{}.mp4\".format(gloss_label, \"{0:.2f}\".format(float(dtw_score)).replace(\".\", \"_\"))\n",
        "\n",
        "            if file_paths is not None:\n",
        "                sequence_ID = file_paths[i]\n",
        "            else:\n",
        "                sequence_ID = None\n",
        "\n",
        "            print(sequence_ID + '    dtw: ' + '{0:.2f}'.format(float(dtw_score)))\n",
        "\n",
        "            if dtw_file != None:\n",
        "                dtw_file.writelines(sequence_ID + ' ' + '{0:.2f}'.format(float(dtw_score)) + '\\n')\n",
        "\n",
        "            # Plot this sequences video\n",
        "            # if \"<\" not in video_ext:\n",
        "            plot_video(joints=timing_hyp_seq,\n",
        "                       file_path=dir_name,\n",
        "                       video_name=video_ext,\n",
        "                       references=ref_seq_count,\n",
        "                       skip_frames=self.skip_frames,\n",
        "                       sequence_ID=sequence_ID)\n",
        "\n",
        "\n",
        "    # Save the skeletons of Phoenix\n",
        "    def save_skels(self, output_joints, display, model_dir, type, file_paths=None):\n",
        "        # ipdb.set_trace()\n",
        "\n",
        "        picklefile = open(model_dir + \"/phoenix14t.skels.%s\" % type, \"wb\")\n",
        "\n",
        "        csvIn = pd.read_csv(model_dir + \"/csv/%s_phoenix2014t.csv\" % type, sep='|',encoding='utf-8')\n",
        "        pickle_list = []\n",
        "\n",
        "        for i in display:\n",
        "            name = file_paths[i]\n",
        "            video = name[len(os.path.dirname(name))+1:]\n",
        "            signer = csvIn[csvIn['id']==video]['signer'].item()\n",
        "            gloss = csvIn[csvIn['id']==video]['annotation'].item()\n",
        "            text = csvIn[csvIn['id']==video]['translation'].item()\n",
        "            seq = output_joints[i].cpu()[:,:-1]\n",
        "            sign = torch.tensor(seq, dtype = torch.float32)\n",
        "\n",
        "            dict_num = {'name': name, 'signer': signer, 'gloss': gloss, 'text': text, 'sign': sign}\n",
        "\n",
        "            pickle_list.append(dict_num)\n",
        "\n",
        "        pickle.dump(pickle_list, picklefile)\n",
        "        print(\"The skeletons of %s date have been save.\" % type)\n",
        "\n",
        "    # Train the batch\n",
        "    def _train_batch(self, batch: Batch, update: bool = True) -> Tensor:\n",
        "\n",
        "        # Get loss from this batch\n",
        "        batch_loss = self.model.get_loss_for_batch(is_train=True,\n",
        "                                                          batch=batch,\n",
        "                                                          loss_function=self.loss)\n",
        "\n",
        "        # normalize batch loss\n",
        "        if self.normalization == \"batch\":\n",
        "            normalizer = batch.nseqs\n",
        "        elif self.normalization == \"tokens\":\n",
        "            normalizer = batch.ntokens\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only normalize by 'batch' or 'tokens'\")\n",
        "\n",
        "        norm_batch_loss = batch_loss / normalizer\n",
        "        # division needed since loss.backward sums the gradients until updated\n",
        "        norm_batch_multiply = norm_batch_loss / self.batch_multiplier\n",
        "\n",
        "        # compute gradients\n",
        "        norm_batch_multiply.backward()\n",
        "\n",
        "        if self.clip_grad_fun is not None:\n",
        "            # clip gradients (in-place)\n",
        "            self.clip_grad_fun(params=self.model.parameters())\n",
        "\n",
        "        if update:\n",
        "            # make gradient step\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # increment step counter\n",
        "            self.steps += 1\n",
        "\n",
        "        # increment token counter\n",
        "        self.total_tokens += batch.ntokens\n",
        "\n",
        "        return norm_batch_loss\n",
        "\n",
        "    def _add_report(self, valid_score: float, valid_loss: float, eval_metric: str, new_best: bool = False, report_type: str = \"val\") -> None:\n",
        "\n",
        "        current_lr = -1\n",
        "        # ignores other param groups for now\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            current_lr = param_group['lr']\n",
        "\n",
        "        if current_lr < self.learning_rate_min:\n",
        "            self.stop = True\n",
        "\n",
        "        if report_type == \"val\":\n",
        "            with open(self.valid_report_file, 'a') as opened_file:\n",
        "                opened_file.write(\n",
        "                    \"Steps: {} Loss: {:.5f}| DTW: {:.3f}|\"\n",
        "                    \" LR: {:.6f} {}\\n\".format(\n",
        "                        self.steps, valid_loss, valid_score,\n",
        "                        current_lr, \"*\" if new_best else \"\"))\n",
        "\n",
        "\n",
        "    def _log_parameters_list(self) -> None:\n",
        "        \"\"\"\n",
        "        Write all model parameters (name, shape) to the log.\n",
        "        \"\"\"\n",
        "        model_parameters = filter(lambda p: p.requires_grad,\n",
        "                                  self.model.parameters())\n",
        "        n_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        self.logger.info(\"Total params: %d\", n_params)\n",
        "        trainable_params = [n for (n, p) in self.model.named_parameters()\n",
        "                            if p.requires_grad]\n",
        "        self.logger.info(\"Trainable parameters: %s\", sorted(trainable_params))\n",
        "        assert trainable_params\n",
        "\n",
        "\n",
        "def train(cfg_file: str, ckpt=None):\n",
        "\n",
        "    # Load the config file\n",
        "    cfg = load_config(cfg_file)\n",
        "\n",
        "    # Set the random seed\n",
        "    set_seed(seed=cfg[\"training\"].get(\"random_seed\", 42))\n",
        "\n",
        "    # Load the data - Trg as (batch, # of frames, joints + 1 )\n",
        "    train_data, dev_data, test_data, src_vocab, trg_vocab = load_data(cfg=cfg)\n",
        "\n",
        "    # Build the Sign-IDD model\n",
        "    model = build_model(cfg=cfg, src_vocab=src_vocab, trg_vocab=trg_vocab)\n",
        "\n",
        "    if ckpt is not None:\n",
        "        use_cuda = cfg[\"training\"].get(\"use_cuda\", True)\n",
        "        model_checkpoint = load_checkpoint(ckpt, use_cuda=use_cuda)\n",
        "        # Build model and load parameters from the checkpoint\n",
        "        model.load_state_dict(model_checkpoint[\"model_state\"])\n",
        "\n",
        "    # for training management, e.g. early stopping and model selection\n",
        "    trainer = TrainManager(config=cfg, model=model, test=False)\n",
        "\n",
        "    # Store copy of original training config in model dir\n",
        "    shutil.copy2(cfg_file, trainer.model_dir+\"/Sign-IDD.yaml\")\n",
        "    # Log all entries of config\n",
        "    log_cfg(cfg, trainer.logger)\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n",
        "\n",
        "def test(cfg_file, ckpt: str):\n",
        "\n",
        "    # Load the config file\n",
        "    cfg = load_config(cfg_file)\n",
        "\n",
        "    # Load the model directory and checkpoint\n",
        "    model_dir = cfg[\"training\"][\"model_dir\"]\n",
        "\n",
        "    # when checkpoint is not specified, take latest (best) from model dir\n",
        "    if ckpt is None:\n",
        "        ckpt = get_latest_checkpoint(model_dir,post_fix=\"_best\")\n",
        "        if ckpt is None:\n",
        "            raise FileNotFoundError(\"No checkpoint found in directory {}.\"\n",
        "                                    .format(model_dir))\n",
        "\n",
        "    batch_size = cfg[\"training\"].get(\"eval_batch_size\", cfg[\"training\"][\"batch_size\"])\n",
        "    batch_type = cfg[\"training\"].get(\"eval_batch_type\", cfg[\"training\"].get(\"batch_type\", \"sentence\"))\n",
        "    use_cuda = cfg[\"training\"].get(\"use_cuda\", True)\n",
        "    eval_metric = cfg[\"training\"][\"eval_metric\"]\n",
        "    max_output_length = cfg[\"training\"].get(\"max_output_length\", None)\n",
        "\n",
        "    # load the data\n",
        "    train_data, dev_data, test_data, src_vocab, trg_vocab = load_data(cfg=cfg)\n",
        "\n",
        "    # To produce testing results\n",
        "    # data_to_predict = {\"test\": test_data}\n",
        "    # To produce validation and testing results\n",
        "    data_to_predict = {\"dev\": dev_data, \"test\": test_data}\n",
        "\n",
        "    # Load model state from disk\n",
        "    model_checkpoint = load_checkpoint(ckpt, use_cuda=use_cuda)\n",
        "\n",
        "    # Build model and load parameters into it\n",
        "    model = build_model(cfg=cfg, src_vocab=src_vocab, trg_vocab=trg_vocab)\n",
        "    model.load_state_dict(model_checkpoint[\"model_state\"])\n",
        "\n",
        "    # If cuda, set model as cuda\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    # Set up trainer to produce videos\n",
        "    trainer = TrainManager(model=model, config=cfg, test=True)\n",
        "\n",
        "    # For each of the required data, produce results\n",
        "    for data_set_name, data_set in data_to_predict.items():\n",
        "\n",
        "        # Validate for this data set\n",
        "        score, loss, references, hypotheses, inputs, all_dtw_scores, file_paths = \\\n",
        "            validate_on_data(\n",
        "                model=model,\n",
        "                data=data_set,\n",
        "                batch_size=batch_size,\n",
        "                max_output_length=max_output_length,\n",
        "                eval_metric=eval_metric,\n",
        "                loss_function=None,\n",
        "                batch_type=batch_type,\n",
        "                type=\"val\" if not data_set_name is \"train\" else \"train_inf\"\n",
        "            )\n",
        "        if not os.path.exists(os.path.join(model_dir, 'test_videos')):\n",
        "            os.mkdir(os.path.join(model_dir, 'test_videos'))\n",
        "\n",
        "        dtw_file = open(os.path.join(model_dir, 'test_videos', data_set_name+'_dtw.txt'),'w')\n",
        "        dtw_file.writelines('DTW Score of %s set: %.3f\\n' %(data_set_name, score))\n",
        "\n",
        "        print('DTW Score of %s set: %.3f' %(data_set_name, score))\n",
        "        # Set which sequences to produce video for\n",
        "        display = list(range(len(hypotheses)))\n",
        "\n",
        "        trainer.save_skels(output_joints=hypotheses, display=display, model_dir=model_dir, type=data_set_name, file_paths=file_paths)\n",
        "\n",
        "        # Produce videos for the produced hypotheses\n",
        "        trainer.produce_validation_video(\n",
        "            output_joints=hypotheses,\n",
        "            inputs=inputs,\n",
        "            references=references,\n",
        "            model_dir=model_dir,\n",
        "            display=display,\n",
        "            type=\"test\",\n",
        "            file_paths=file_paths,\n",
        "            dtw_file=dtw_file,\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDfstR137kEL",
        "outputId": "d89b1e08-a483-4393-98f8-f44930cbfa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:384: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:386: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:599: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:384: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:386: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:599: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "/tmp/ipython-input-67-2907158123.py:384: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if input[1] is not \"</s>\":\n",
            "/tmp/ipython-input-67-2907158123.py:386: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if input[2] is not \"</s>\":\n",
            "/tmp/ipython-input-67-2907158123.py:599: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  type=\"val\" if not data_set_name is \"train\" else \"train_inf\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\"/content/drive/MyDrive/Colab Notebooks/Configs/Sign-IDD.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx1axbm78bhE",
        "outputId": "cc42137c-d80b-4a78-9c48-8462a5bbe269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 754\n",
            "2025-06-26 08:21:23,389 EPOCH 754\n",
            "INFO:__main__:Epoch 754: total training loss 0.01182\n",
            "2025-06-26 08:21:23,453 Epoch 754: total training loss 0.01182\n",
            "INFO:__main__:EPOCH 755\n",
            "2025-06-26 08:21:23,454 EPOCH 755\n",
            "INFO:__main__:Epoch 755: total training loss 0.01239\n",
            "2025-06-26 08:21:23,515 Epoch 755: total training loss 0.01239\n",
            "INFO:__main__:EPOCH 756\n",
            "2025-06-26 08:21:23,517 EPOCH 756\n",
            "INFO:__main__:Epoch 756: total training loss 0.01200\n",
            "2025-06-26 08:21:23,580 Epoch 756: total training loss 0.01200\n",
            "INFO:__main__:EPOCH 757\n",
            "2025-06-26 08:21:23,582 EPOCH 757\n",
            "INFO:__main__:Epoch 757: total training loss 0.01223\n",
            "2025-06-26 08:21:23,643 Epoch 757: total training loss 0.01223\n",
            "INFO:__main__:EPOCH 758\n",
            "2025-06-26 08:21:23,645 EPOCH 758\n",
            "INFO:__main__:Epoch 758: total training loss 0.01207\n",
            "2025-06-26 08:21:23,766 Epoch 758: total training loss 0.01207\n",
            "INFO:__main__:EPOCH 759\n",
            "2025-06-26 08:21:23,768 EPOCH 759\n",
            "INFO:__main__:Epoch 759: total training loss 0.01244\n",
            "2025-06-26 08:21:24,015 Epoch 759: total training loss 0.01244\n",
            "INFO:__main__:EPOCH 760\n",
            "2025-06-26 08:21:24,017 EPOCH 760\n",
            "INFO:__main__:Epoch 760: total training loss 0.01253\n",
            "2025-06-26 08:21:24,160 Epoch 760: total training loss 0.01253\n",
            "INFO:__main__:EPOCH 761\n",
            "2025-06-26 08:21:24,167 EPOCH 761\n",
            "INFO:__main__:Epoch 761: total training loss 0.01273\n",
            "2025-06-26 08:21:24,308 Epoch 761: total training loss 0.01273\n",
            "INFO:__main__:EPOCH 762\n",
            "2025-06-26 08:21:24,311 EPOCH 762\n",
            "INFO:__main__:Epoch 762: total training loss 0.01238\n",
            "2025-06-26 08:21:24,376 Epoch 762: total training loss 0.01238\n",
            "INFO:__main__:EPOCH 763\n",
            "2025-06-26 08:21:24,378 EPOCH 763\n",
            "INFO:__main__:Epoch 763: total training loss 0.01212\n",
            "2025-06-26 08:21:24,440 Epoch 763: total training loss 0.01212\n",
            "INFO:__main__:EPOCH 764\n",
            "2025-06-26 08:21:24,444 EPOCH 764\n",
            "INFO:__main__:Epoch 764: total training loss 0.01206\n",
            "2025-06-26 08:21:24,504 Epoch 764: total training loss 0.01206\n",
            "INFO:__main__:EPOCH 765\n",
            "2025-06-26 08:21:24,506 EPOCH 765\n",
            "INFO:__main__:Epoch 765: total training loss 0.01238\n",
            "2025-06-26 08:21:24,568 Epoch 765: total training loss 0.01238\n",
            "INFO:__main__:EPOCH 766\n",
            "2025-06-26 08:21:24,570 EPOCH 766\n",
            "INFO:__main__:Epoch 766: total training loss 0.01216\n",
            "2025-06-26 08:21:24,631 Epoch 766: total training loss 0.01216\n",
            "INFO:__main__:EPOCH 767\n",
            "2025-06-26 08:21:24,633 EPOCH 767\n",
            "INFO:__main__:Epoch 767: total training loss 0.01221\n",
            "2025-06-26 08:21:24,690 Epoch 767: total training loss 0.01221\n",
            "INFO:__main__:EPOCH 768\n",
            "2025-06-26 08:21:24,692 EPOCH 768\n",
            "INFO:__main__:Epoch 768: total training loss 0.01194\n",
            "2025-06-26 08:21:24,753 Epoch 768: total training loss 0.01194\n",
            "INFO:__main__:EPOCH 769\n",
            "2025-06-26 08:21:24,755 EPOCH 769\n",
            "INFO:__main__:Epoch 769: total training loss 0.01208\n",
            "2025-06-26 08:21:25,026 Epoch 769: total training loss 0.01208\n",
            "INFO:__main__:EPOCH 770\n",
            "2025-06-26 08:21:25,038 EPOCH 770\n",
            "INFO:__main__:Epoch 770: total training loss 0.01243\n",
            "2025-06-26 08:21:25,218 Epoch 770: total training loss 0.01243\n",
            "INFO:__main__:EPOCH 771\n",
            "2025-06-26 08:21:25,233 EPOCH 771\n",
            "INFO:__main__:Epoch 771: total training loss 0.01230\n",
            "2025-06-26 08:21:25,340 Epoch 771: total training loss 0.01230\n",
            "INFO:__main__:EPOCH 772\n",
            "2025-06-26 08:21:25,342 EPOCH 772\n",
            "INFO:__main__:Epoch 772: total training loss 0.01220\n",
            "2025-06-26 08:21:25,406 Epoch 772: total training loss 0.01220\n",
            "INFO:__main__:EPOCH 773\n",
            "2025-06-26 08:21:25,409 EPOCH 773\n",
            "INFO:__main__:Epoch 773: total training loss 0.01198\n",
            "2025-06-26 08:21:25,485 Epoch 773: total training loss 0.01198\n",
            "INFO:__main__:EPOCH 774\n",
            "2025-06-26 08:21:25,487 EPOCH 774\n",
            "INFO:__main__:Epoch 774: total training loss 0.01244\n",
            "2025-06-26 08:21:25,573 Epoch 774: total training loss 0.01244\n",
            "INFO:__main__:EPOCH 775\n",
            "2025-06-26 08:21:25,575 EPOCH 775\n",
            "INFO:__main__:Epoch 775: total training loss 0.01202\n",
            "2025-06-26 08:21:25,656 Epoch 775: total training loss 0.01202\n",
            "INFO:__main__:EPOCH 776\n",
            "2025-06-26 08:21:25,658 EPOCH 776\n",
            "INFO:__main__:Epoch 776: total training loss 0.01246\n",
            "2025-06-26 08:21:25,735 Epoch 776: total training loss 0.01246\n",
            "INFO:__main__:EPOCH 777\n",
            "2025-06-26 08:21:25,737 EPOCH 777\n",
            "INFO:__main__:Epoch 777: total training loss 0.01256\n",
            "2025-06-26 08:21:25,829 Epoch 777: total training loss 0.01256\n",
            "INFO:__main__:EPOCH 778\n",
            "2025-06-26 08:21:25,831 EPOCH 778\n",
            "INFO:__main__:Epoch 778: total training loss 0.01285\n",
            "2025-06-26 08:21:25,912 Epoch 778: total training loss 0.01285\n",
            "INFO:__main__:EPOCH 779\n",
            "2025-06-26 08:21:25,914 EPOCH 779\n",
            "INFO:__main__:Epoch 779: total training loss 0.01241\n",
            "2025-06-26 08:21:25,990 Epoch 779: total training loss 0.01241\n",
            "INFO:__main__:EPOCH 780\n",
            "2025-06-26 08:21:25,992 EPOCH 780\n",
            "INFO:__main__:Epoch 780: total training loss 0.01229\n",
            "2025-06-26 08:21:26,103 Epoch 780: total training loss 0.01229\n",
            "INFO:__main__:EPOCH 781\n",
            "2025-06-26 08:21:26,107 EPOCH 781\n",
            "INFO:__main__:Epoch 781: total training loss 0.01242\n",
            "2025-06-26 08:21:26,193 Epoch 781: total training loss 0.01242\n",
            "INFO:__main__:EPOCH 782\n",
            "2025-06-26 08:21:26,196 EPOCH 782\n",
            "INFO:__main__:Epoch 782: total training loss 0.01181\n",
            "2025-06-26 08:21:26,276 Epoch 782: total training loss 0.01181\n",
            "INFO:__main__:EPOCH 783\n",
            "2025-06-26 08:21:26,282 EPOCH 783\n",
            "INFO:__main__:Epoch 783: total training loss 0.01159\n",
            "2025-06-26 08:21:26,357 Epoch 783: total training loss 0.01159\n",
            "INFO:__main__:EPOCH 784\n",
            "2025-06-26 08:21:26,359 EPOCH 784\n",
            "INFO:__main__:Epoch 784: total training loss 0.01241\n",
            "2025-06-26 08:21:26,430 Epoch 784: total training loss 0.01241\n",
            "INFO:__main__:EPOCH 785\n",
            "2025-06-26 08:21:26,432 EPOCH 785\n",
            "INFO:__main__:Epoch 785: total training loss 0.01161\n",
            "2025-06-26 08:21:26,506 Epoch 785: total training loss 0.01161\n",
            "INFO:__main__:EPOCH 786\n",
            "2025-06-26 08:21:26,508 EPOCH 786\n",
            "INFO:__main__:Epoch 786: total training loss 0.01126\n",
            "2025-06-26 08:21:26,581 Epoch 786: total training loss 0.01126\n",
            "INFO:__main__:EPOCH 787\n",
            "2025-06-26 08:21:26,583 EPOCH 787\n",
            "INFO:__main__:Epoch 787: total training loss 0.01159\n",
            "2025-06-26 08:21:26,652 Epoch 787: total training loss 0.01159\n",
            "INFO:__main__:EPOCH 788\n",
            "2025-06-26 08:21:26,654 EPOCH 788\n",
            "INFO:__main__:Epoch 788: total training loss 0.01097\n",
            "2025-06-26 08:21:26,727 Epoch 788: total training loss 0.01097\n",
            "INFO:__main__:EPOCH 789\n",
            "2025-06-26 08:21:26,729 EPOCH 789\n",
            "INFO:__main__:Epoch 789: total training loss 0.01203\n",
            "2025-06-26 08:21:26,821 Epoch 789: total training loss 0.01203\n",
            "INFO:__main__:EPOCH 790\n",
            "2025-06-26 08:21:26,823 EPOCH 790\n",
            "INFO:__main__:Epoch 790: total training loss 0.01156\n",
            "2025-06-26 08:21:26,911 Epoch 790: total training loss 0.01156\n",
            "INFO:__main__:EPOCH 791\n",
            "2025-06-26 08:21:26,913 EPOCH 791\n",
            "INFO:__main__:Epoch 791: total training loss 0.01200\n",
            "2025-06-26 08:21:26,996 Epoch 791: total training loss 0.01200\n",
            "INFO:__main__:EPOCH 792\n",
            "2025-06-26 08:21:26,999 EPOCH 792\n",
            "INFO:__main__:Epoch 792: total training loss 0.01242\n",
            "2025-06-26 08:21:27,097 Epoch 792: total training loss 0.01242\n",
            "INFO:__main__:EPOCH 793\n",
            "2025-06-26 08:21:27,102 EPOCH 793\n",
            "INFO:__main__:Epoch 793: total training loss 0.01223\n",
            "2025-06-26 08:21:27,193 Epoch 793: total training loss 0.01223\n",
            "INFO:__main__:EPOCH 794\n",
            "2025-06-26 08:21:27,194 EPOCH 794\n",
            "INFO:__main__:Epoch 794: total training loss 0.01204\n",
            "2025-06-26 08:21:27,271 Epoch 794: total training loss 0.01204\n",
            "INFO:__main__:EPOCH 795\n",
            "2025-06-26 08:21:27,273 EPOCH 795\n",
            "INFO:__main__:Epoch 795: total training loss 0.01254\n",
            "2025-06-26 08:21:27,347 Epoch 795: total training loss 0.01254\n",
            "INFO:__main__:EPOCH 796\n",
            "2025-06-26 08:21:27,349 EPOCH 796\n",
            "INFO:__main__:Epoch 796: total training loss 0.01263\n",
            "2025-06-26 08:21:27,426 Epoch 796: total training loss 0.01263\n",
            "INFO:__main__:EPOCH 797\n",
            "2025-06-26 08:21:27,428 EPOCH 797\n",
            "INFO:__main__:Epoch 797: total training loss 0.01186\n",
            "2025-06-26 08:21:27,501 Epoch 797: total training loss 0.01186\n",
            "INFO:__main__:EPOCH 798\n",
            "2025-06-26 08:21:27,503 EPOCH 798\n",
            "INFO:__main__:Epoch 798: total training loss 0.01196\n",
            "2025-06-26 08:21:27,575 Epoch 798: total training loss 0.01196\n",
            "INFO:__main__:EPOCH 799\n",
            "2025-06-26 08:21:27,577 EPOCH 799\n",
            "INFO:__main__:Epoch 799: total training loss 0.01170\n",
            "2025-06-26 08:21:27,649 Epoch 799: total training loss 0.01170\n",
            "INFO:__main__:EPOCH 800\n",
            "2025-06-26 08:21:27,651 EPOCH 800\n",
            "INFO:__main__:Epoch 800: total training loss 0.01183\n",
            "2025-06-26 08:21:27,725 Epoch 800: total training loss 0.01183\n",
            "INFO:__main__:EPOCH 801\n",
            "2025-06-26 08:21:27,728 EPOCH 801\n",
            "INFO:__main__:Epoch 801: total training loss 0.01097\n",
            "2025-06-26 08:21:27,802 Epoch 801: total training loss 0.01097\n",
            "INFO:__main__:EPOCH 802\n",
            "2025-06-26 08:21:27,804 EPOCH 802\n",
            "INFO:__main__:Epoch 802: total training loss 0.01214\n",
            "2025-06-26 08:21:27,875 Epoch 802: total training loss 0.01214\n",
            "INFO:__main__:EPOCH 803\n",
            "2025-06-26 08:21:27,877 EPOCH 803\n",
            "INFO:__main__:Epoch 803: total training loss 0.01191\n",
            "2025-06-26 08:21:27,947 Epoch 803: total training loss 0.01191\n",
            "INFO:__main__:EPOCH 804\n",
            "2025-06-26 08:21:27,949 EPOCH 804\n",
            "INFO:__main__:Epoch 804: total training loss 0.01167\n",
            "2025-06-26 08:21:28,026 Epoch 804: total training loss 0.01167\n",
            "INFO:__main__:EPOCH 805\n",
            "2025-06-26 08:21:28,028 EPOCH 805\n",
            "INFO:__main__:Epoch 805: total training loss 0.01148\n",
            "2025-06-26 08:21:28,103 Epoch 805: total training loss 0.01148\n",
            "INFO:__main__:EPOCH 806\n",
            "2025-06-26 08:21:28,105 EPOCH 806\n",
            "INFO:__main__:Epoch 806: total training loss 0.01123\n",
            "2025-06-26 08:21:28,177 Epoch 806: total training loss 0.01123\n",
            "INFO:__main__:EPOCH 807\n",
            "2025-06-26 08:21:28,179 EPOCH 807\n",
            "INFO:__main__:Epoch 807: total training loss 0.01235\n",
            "2025-06-26 08:21:28,260 Epoch 807: total training loss 0.01235\n",
            "INFO:__main__:EPOCH 808\n",
            "2025-06-26 08:21:28,263 EPOCH 808\n",
            "INFO:__main__:Epoch 808: total training loss 0.01202\n",
            "2025-06-26 08:21:28,344 Epoch 808: total training loss 0.01202\n",
            "INFO:__main__:EPOCH 809\n",
            "2025-06-26 08:21:28,346 EPOCH 809\n",
            "INFO:__main__:Epoch 809: total training loss 0.01165\n",
            "2025-06-26 08:21:28,422 Epoch 809: total training loss 0.01165\n",
            "INFO:__main__:EPOCH 810\n",
            "2025-06-26 08:21:28,424 EPOCH 810\n",
            "INFO:__main__:Epoch 810: total training loss 0.01174\n",
            "2025-06-26 08:21:28,494 Epoch 810: total training loss 0.01174\n",
            "INFO:__main__:EPOCH 811\n",
            "2025-06-26 08:21:28,496 EPOCH 811\n",
            "INFO:__main__:Epoch 811: total training loss 0.01194\n",
            "2025-06-26 08:21:28,564 Epoch 811: total training loss 0.01194\n",
            "INFO:__main__:EPOCH 812\n",
            "2025-06-26 08:21:28,566 EPOCH 812\n",
            "INFO:__main__:Epoch 812: total training loss 0.01142\n",
            "2025-06-26 08:21:28,636 Epoch 812: total training loss 0.01142\n",
            "INFO:__main__:EPOCH 813\n",
            "2025-06-26 08:21:28,638 EPOCH 813\n",
            "INFO:__main__:Epoch 813: total training loss 0.01161\n",
            "2025-06-26 08:21:28,711 Epoch 813: total training loss 0.01161\n",
            "INFO:__main__:EPOCH 814\n",
            "2025-06-26 08:21:28,716 EPOCH 814\n",
            "INFO:__main__:Epoch 814: total training loss 0.01168\n",
            "2025-06-26 08:21:28,805 Epoch 814: total training loss 0.01168\n",
            "INFO:__main__:EPOCH 815\n",
            "2025-06-26 08:21:28,808 EPOCH 815\n",
            "INFO:__main__:Epoch 815: total training loss 0.01166\n",
            "2025-06-26 08:21:28,899 Epoch 815: total training loss 0.01166\n",
            "INFO:__main__:EPOCH 816\n",
            "2025-06-26 08:21:28,901 EPOCH 816\n",
            "INFO:__main__:Epoch 816: total training loss 0.01195\n",
            "2025-06-26 08:21:28,978 Epoch 816: total training loss 0.01195\n",
            "INFO:__main__:EPOCH 817\n",
            "2025-06-26 08:21:28,980 EPOCH 817\n",
            "INFO:__main__:Epoch 817: total training loss 0.01194\n",
            "2025-06-26 08:21:29,063 Epoch 817: total training loss 0.01194\n",
            "INFO:__main__:EPOCH 818\n",
            "2025-06-26 08:21:29,066 EPOCH 818\n",
            "INFO:__main__:Epoch 818: total training loss 0.01178\n",
            "2025-06-26 08:21:29,159 Epoch 818: total training loss 0.01178\n",
            "INFO:__main__:EPOCH 819\n",
            "2025-06-26 08:21:29,165 EPOCH 819\n",
            "INFO:__main__:Epoch 819: total training loss 0.01188\n",
            "2025-06-26 08:21:29,254 Epoch 819: total training loss 0.01188\n",
            "INFO:__main__:EPOCH 820\n",
            "2025-06-26 08:21:29,257 EPOCH 820\n",
            "INFO:__main__:Epoch 820: total training loss 0.01111\n",
            "2025-06-26 08:21:29,371 Epoch 820: total training loss 0.01111\n",
            "INFO:__main__:EPOCH 821\n",
            "2025-06-26 08:21:29,374 EPOCH 821\n",
            "INFO:__main__:Epoch 821: total training loss 0.01133\n",
            "2025-06-26 08:21:29,474 Epoch 821: total training loss 0.01133\n",
            "INFO:__main__:EPOCH 822\n",
            "2025-06-26 08:21:29,477 EPOCH 822\n",
            "INFO:__main__:Epoch 822: total training loss 0.01241\n",
            "2025-06-26 08:21:29,581 Epoch 822: total training loss 0.01241\n",
            "INFO:__main__:EPOCH 823\n",
            "2025-06-26 08:21:29,584 EPOCH 823\n",
            "INFO:__main__:Epoch 823: total training loss 0.01214\n",
            "2025-06-26 08:21:29,668 Epoch 823: total training loss 0.01214\n",
            "INFO:__main__:EPOCH 824\n",
            "2025-06-26 08:21:29,670 EPOCH 824\n",
            "INFO:__main__:Epoch 824: total training loss 0.01158\n",
            "2025-06-26 08:21:29,732 Epoch 824: total training loss 0.01158\n",
            "INFO:__main__:EPOCH 825\n",
            "2025-06-26 08:21:29,734 EPOCH 825\n",
            "INFO:__main__:Epoch 825: total training loss 0.01176\n",
            "2025-06-26 08:21:29,798 Epoch 825: total training loss 0.01176\n",
            "INFO:__main__:EPOCH 826\n",
            "2025-06-26 08:21:29,800 EPOCH 826\n",
            "INFO:__main__:Epoch 826: total training loss 0.01206\n",
            "2025-06-26 08:21:29,863 Epoch 826: total training loss 0.01206\n",
            "INFO:__main__:EPOCH 827\n",
            "2025-06-26 08:21:29,865 EPOCH 827\n",
            "INFO:__main__:Epoch 827: total training loss 0.01165\n",
            "2025-06-26 08:21:29,928 Epoch 827: total training loss 0.01165\n",
            "INFO:__main__:EPOCH 828\n",
            "2025-06-26 08:21:29,930 EPOCH 828\n",
            "INFO:__main__:Epoch 828: total training loss 0.01194\n",
            "2025-06-26 08:21:29,996 Epoch 828: total training loss 0.01194\n",
            "INFO:__main__:EPOCH 829\n",
            "2025-06-26 08:21:29,998 EPOCH 829\n",
            "INFO:__main__:Epoch 829: total training loss 0.01185\n",
            "2025-06-26 08:21:30,069 Epoch 829: total training loss 0.01185\n",
            "INFO:__main__:EPOCH 830\n",
            "2025-06-26 08:21:30,071 EPOCH 830\n",
            "INFO:__main__:Epoch 830: total training loss 0.01181\n",
            "2025-06-26 08:21:30,136 Epoch 830: total training loss 0.01181\n",
            "INFO:__main__:EPOCH 831\n",
            "2025-06-26 08:21:30,138 EPOCH 831\n",
            "INFO:__main__:Epoch 831: total training loss 0.01168\n",
            "2025-06-26 08:21:30,201 Epoch 831: total training loss 0.01168\n",
            "INFO:__main__:EPOCH 832\n",
            "2025-06-26 08:21:30,203 EPOCH 832\n",
            "INFO:__main__:Epoch 832: total training loss 0.01178\n",
            "2025-06-26 08:21:30,279 Epoch 832: total training loss 0.01178\n",
            "INFO:__main__:EPOCH 833\n",
            "2025-06-26 08:21:30,282 EPOCH 833\n",
            "INFO:__main__:Epoch 833: total training loss 0.01174\n",
            "2025-06-26 08:21:30,348 Epoch 833: total training loss 0.01174\n",
            "INFO:__main__:EPOCH 834\n",
            "2025-06-26 08:21:30,352 EPOCH 834\n",
            "INFO:__main__:Epoch 834: total training loss 0.01119\n",
            "2025-06-26 08:21:30,428 Epoch 834: total training loss 0.01119\n",
            "INFO:__main__:EPOCH 835\n",
            "2025-06-26 08:21:30,430 EPOCH 835\n",
            "INFO:__main__:Epoch 835: total training loss 0.01115\n",
            "2025-06-26 08:21:30,492 Epoch 835: total training loss 0.01115\n",
            "INFO:__main__:EPOCH 836\n",
            "2025-06-26 08:21:30,494 EPOCH 836\n",
            "INFO:__main__:Epoch 836: total training loss 0.01201\n",
            "2025-06-26 08:21:30,560 Epoch 836: total training loss 0.01201\n",
            "INFO:__main__:EPOCH 837\n",
            "2025-06-26 08:21:30,562 EPOCH 837\n",
            "INFO:__main__:Epoch 837: total training loss 0.01136\n",
            "2025-06-26 08:21:30,625 Epoch 837: total training loss 0.01136\n",
            "INFO:__main__:EPOCH 838\n",
            "2025-06-26 08:21:30,627 EPOCH 838\n",
            "INFO:__main__:Epoch 838: total training loss 0.01133\n",
            "2025-06-26 08:21:30,687 Epoch 838: total training loss 0.01133\n",
            "INFO:__main__:EPOCH 839\n",
            "2025-06-26 08:21:30,689 EPOCH 839\n",
            "INFO:__main__:Epoch 839: total training loss 0.01087\n",
            "2025-06-26 08:21:30,748 Epoch 839: total training loss 0.01087\n",
            "INFO:__main__:EPOCH 840\n",
            "2025-06-26 08:21:30,750 EPOCH 840\n",
            "INFO:__main__:Epoch 840: total training loss 0.01111\n",
            "2025-06-26 08:21:30,811 Epoch 840: total training loss 0.01111\n",
            "INFO:__main__:EPOCH 841\n",
            "2025-06-26 08:21:30,813 EPOCH 841\n",
            "INFO:__main__:Epoch 841: total training loss 0.01130\n",
            "2025-06-26 08:21:30,872 Epoch 841: total training loss 0.01130\n",
            "INFO:__main__:EPOCH 842\n",
            "2025-06-26 08:21:30,874 EPOCH 842\n",
            "INFO:__main__:Epoch 842: total training loss 0.01187\n",
            "2025-06-26 08:21:30,935 Epoch 842: total training loss 0.01187\n",
            "INFO:__main__:EPOCH 843\n",
            "2025-06-26 08:21:30,938 EPOCH 843\n",
            "INFO:__main__:Epoch 843: total training loss 0.01167\n",
            "2025-06-26 08:21:31,000 Epoch 843: total training loss 0.01167\n",
            "INFO:__main__:EPOCH 844\n",
            "2025-06-26 08:21:31,002 EPOCH 844\n",
            "INFO:__main__:Epoch 844: total training loss 0.01132\n",
            "2025-06-26 08:21:31,074 Epoch 844: total training loss 0.01132\n",
            "INFO:__main__:EPOCH 845\n",
            "2025-06-26 08:21:31,076 EPOCH 845\n",
            "INFO:__main__:Epoch 845: total training loss 0.01159\n",
            "2025-06-26 08:21:31,138 Epoch 845: total training loss 0.01159\n",
            "INFO:__main__:EPOCH 846\n",
            "2025-06-26 08:21:31,140 EPOCH 846\n",
            "INFO:__main__:Epoch 846: total training loss 0.01133\n",
            "2025-06-26 08:21:31,202 Epoch 846: total training loss 0.01133\n",
            "INFO:__main__:EPOCH 847\n",
            "2025-06-26 08:21:31,204 EPOCH 847\n",
            "INFO:__main__:Epoch 847: total training loss 0.01133\n",
            "2025-06-26 08:21:31,267 Epoch 847: total training loss 0.01133\n",
            "INFO:__main__:EPOCH 848\n",
            "2025-06-26 08:21:31,269 EPOCH 848\n",
            "INFO:__main__:Epoch 848: total training loss 0.01071\n",
            "2025-06-26 08:21:31,333 Epoch 848: total training loss 0.01071\n",
            "INFO:__main__:EPOCH 849\n",
            "2025-06-26 08:21:31,335 EPOCH 849\n",
            "INFO:__main__:Epoch 849: total training loss 0.01104\n",
            "2025-06-26 08:21:31,407 Epoch 849: total training loss 0.01104\n",
            "INFO:__main__:EPOCH 850\n",
            "2025-06-26 08:21:31,409 EPOCH 850\n",
            "INFO:__main__:Epoch 850: total training loss 0.01120\n",
            "2025-06-26 08:21:31,476 Epoch 850: total training loss 0.01120\n",
            "INFO:__main__:EPOCH 851\n",
            "2025-06-26 08:21:31,477 EPOCH 851\n",
            "INFO:__main__:Epoch 851: total training loss 0.01091\n",
            "2025-06-26 08:21:31,540 Epoch 851: total training loss 0.01091\n",
            "INFO:__main__:EPOCH 852\n",
            "2025-06-26 08:21:31,542 EPOCH 852\n",
            "INFO:__main__:Epoch 852: total training loss 0.01092\n",
            "2025-06-26 08:21:31,611 Epoch 852: total training loss 0.01092\n",
            "INFO:__main__:EPOCH 853\n",
            "2025-06-26 08:21:31,613 EPOCH 853\n",
            "INFO:__main__:Epoch 853: total training loss 0.01133\n",
            "2025-06-26 08:21:31,674 Epoch 853: total training loss 0.01133\n",
            "INFO:__main__:EPOCH 854\n",
            "2025-06-26 08:21:31,676 EPOCH 854\n",
            "INFO:__main__:Epoch 854: total training loss 0.01078\n",
            "2025-06-26 08:21:31,737 Epoch 854: total training loss 0.01078\n",
            "INFO:__main__:EPOCH 855\n",
            "2025-06-26 08:21:31,739 EPOCH 855\n",
            "INFO:__main__:Epoch 855: total training loss 0.01131\n",
            "2025-06-26 08:21:31,802 Epoch 855: total training loss 0.01131\n",
            "INFO:__main__:EPOCH 856\n",
            "2025-06-26 08:21:31,804 EPOCH 856\n",
            "INFO:__main__:Epoch 856: total training loss 0.01149\n",
            "2025-06-26 08:21:31,864 Epoch 856: total training loss 0.01149\n",
            "INFO:__main__:EPOCH 857\n",
            "2025-06-26 08:21:31,866 EPOCH 857\n",
            "INFO:__main__:Epoch 857: total training loss 0.01153\n",
            "2025-06-26 08:21:31,926 Epoch 857: total training loss 0.01153\n",
            "INFO:__main__:EPOCH 858\n",
            "2025-06-26 08:21:31,928 EPOCH 858\n",
            "INFO:__main__:Epoch 858: total training loss 0.01123\n",
            "2025-06-26 08:21:31,985 Epoch 858: total training loss 0.01123\n",
            "INFO:__main__:EPOCH 859\n",
            "2025-06-26 08:21:31,987 EPOCH 859\n",
            "INFO:__main__:Epoch 859: total training loss 0.01110\n",
            "2025-06-26 08:21:32,046 Epoch 859: total training loss 0.01110\n",
            "INFO:__main__:EPOCH 860\n",
            "2025-06-26 08:21:32,048 EPOCH 860\n",
            "INFO:__main__:Epoch 860: total training loss 0.01168\n",
            "2025-06-26 08:21:32,119 Epoch 860: total training loss 0.01168\n",
            "INFO:__main__:EPOCH 861\n",
            "2025-06-26 08:21:32,121 EPOCH 861\n",
            "INFO:__main__:Epoch 861: total training loss 0.01139\n",
            "2025-06-26 08:21:32,186 Epoch 861: total training loss 0.01139\n",
            "INFO:__main__:EPOCH 862\n",
            "2025-06-26 08:21:32,189 EPOCH 862\n",
            "INFO:__main__:Epoch 862: total training loss 0.01116\n",
            "2025-06-26 08:21:32,252 Epoch 862: total training loss 0.01116\n",
            "INFO:__main__:EPOCH 863\n",
            "2025-06-26 08:21:32,254 EPOCH 863\n",
            "INFO:__main__:Epoch 863: total training loss 0.01107\n",
            "2025-06-26 08:21:32,314 Epoch 863: total training loss 0.01107\n",
            "INFO:__main__:EPOCH 864\n",
            "2025-06-26 08:21:32,316 EPOCH 864\n",
            "INFO:__main__:Epoch 864: total training loss 0.01105\n",
            "2025-06-26 08:21:32,376 Epoch 864: total training loss 0.01105\n",
            "INFO:__main__:EPOCH 865\n",
            "2025-06-26 08:21:32,378 EPOCH 865\n",
            "INFO:__main__:Epoch 865: total training loss 0.01096\n",
            "2025-06-26 08:21:32,449 Epoch 865: total training loss 0.01096\n",
            "INFO:__main__:EPOCH 866\n",
            "2025-06-26 08:21:32,451 EPOCH 866\n",
            "INFO:__main__:Epoch 866: total training loss 0.01126\n",
            "2025-06-26 08:21:32,517 Epoch 866: total training loss 0.01126\n",
            "INFO:__main__:EPOCH 867\n",
            "2025-06-26 08:21:32,519 EPOCH 867\n",
            "INFO:__main__:Epoch 867: total training loss 0.01144\n",
            "2025-06-26 08:21:32,581 Epoch 867: total training loss 0.01144\n",
            "INFO:__main__:EPOCH 868\n",
            "2025-06-26 08:21:32,583 EPOCH 868\n",
            "INFO:__main__:Epoch 868: total training loss 0.01118\n",
            "2025-06-26 08:21:32,645 Epoch 868: total training loss 0.01118\n",
            "INFO:__main__:EPOCH 869\n",
            "2025-06-26 08:21:32,647 EPOCH 869\n",
            "INFO:__main__:Epoch 869: total training loss 0.01102\n",
            "2025-06-26 08:21:32,709 Epoch 869: total training loss 0.01102\n",
            "INFO:__main__:EPOCH 870\n",
            "2025-06-26 08:21:32,711 EPOCH 870\n",
            "INFO:__main__:Epoch 870: total training loss 0.01144\n",
            "2025-06-26 08:21:32,776 Epoch 870: total training loss 0.01144\n",
            "INFO:__main__:EPOCH 871\n",
            "2025-06-26 08:21:32,778 EPOCH 871\n",
            "INFO:__main__:Epoch 871: total training loss 0.01080\n",
            "2025-06-26 08:21:32,845 Epoch 871: total training loss 0.01080\n",
            "INFO:__main__:EPOCH 872\n",
            "2025-06-26 08:21:32,848 EPOCH 872\n",
            "INFO:__main__:Epoch 872: total training loss 0.01103\n",
            "2025-06-26 08:21:32,912 Epoch 872: total training loss 0.01103\n",
            "INFO:__main__:EPOCH 873\n",
            "2025-06-26 08:21:32,914 EPOCH 873\n",
            "INFO:__main__:Epoch 873: total training loss 0.01046\n",
            "2025-06-26 08:21:32,976 Epoch 873: total training loss 0.01046\n",
            "INFO:__main__:EPOCH 874\n",
            "2025-06-26 08:21:32,978 EPOCH 874\n",
            "INFO:__main__:Epoch 874: total training loss 0.01073\n",
            "2025-06-26 08:21:33,039 Epoch 874: total training loss 0.01073\n",
            "INFO:__main__:EPOCH 875\n",
            "2025-06-26 08:21:33,041 EPOCH 875\n",
            "INFO:__main__:Epoch 875: total training loss 0.01109\n",
            "2025-06-26 08:21:33,103 Epoch 875: total training loss 0.01109\n",
            "INFO:__main__:EPOCH 876\n",
            "2025-06-26 08:21:33,105 EPOCH 876\n",
            "INFO:__main__:Epoch 876: total training loss 0.01142\n",
            "2025-06-26 08:21:33,171 Epoch 876: total training loss 0.01142\n",
            "INFO:__main__:EPOCH 877\n",
            "2025-06-26 08:21:33,173 EPOCH 877\n",
            "INFO:__main__:Epoch 877: total training loss 0.01078\n",
            "2025-06-26 08:21:33,233 Epoch 877: total training loss 0.01078\n",
            "INFO:__main__:EPOCH 878\n",
            "2025-06-26 08:21:33,236 EPOCH 878\n",
            "INFO:__main__:Epoch 878: total training loss 0.01096\n",
            "2025-06-26 08:21:33,298 Epoch 878: total training loss 0.01096\n",
            "INFO:__main__:EPOCH 879\n",
            "2025-06-26 08:21:33,301 EPOCH 879\n",
            "INFO:__main__:Epoch 879: total training loss 0.01062\n",
            "2025-06-26 08:21:33,361 Epoch 879: total training loss 0.01062\n",
            "INFO:__main__:EPOCH 880\n",
            "2025-06-26 08:21:33,363 EPOCH 880\n",
            "INFO:__main__:Epoch 880: total training loss 0.01109\n",
            "2025-06-26 08:21:33,426 Epoch 880: total training loss 0.01109\n",
            "INFO:__main__:EPOCH 881\n",
            "2025-06-26 08:21:33,428 EPOCH 881\n",
            "INFO:__main__:Epoch 881: total training loss 0.01128\n",
            "2025-06-26 08:21:33,507 Epoch 881: total training loss 0.01128\n",
            "INFO:__main__:EPOCH 882\n",
            "2025-06-26 08:21:33,509 EPOCH 882\n",
            "INFO:__main__:Epoch 882: total training loss 0.01115\n",
            "2025-06-26 08:21:33,573 Epoch 882: total training loss 0.01115\n",
            "INFO:__main__:EPOCH 883\n",
            "2025-06-26 08:21:33,575 EPOCH 883\n",
            "INFO:__main__:Epoch 883: total training loss 0.01087\n",
            "2025-06-26 08:21:33,637 Epoch 883: total training loss 0.01087\n",
            "INFO:__main__:EPOCH 884\n",
            "2025-06-26 08:21:33,639 EPOCH 884\n",
            "INFO:__main__:Epoch 884: total training loss 0.01064\n",
            "2025-06-26 08:21:33,701 Epoch 884: total training loss 0.01064\n",
            "INFO:__main__:EPOCH 885\n",
            "2025-06-26 08:21:33,703 EPOCH 885\n",
            "INFO:__main__:Epoch 885: total training loss 0.01057\n",
            "2025-06-26 08:21:33,767 Epoch 885: total training loss 0.01057\n",
            "INFO:__main__:EPOCH 886\n",
            "2025-06-26 08:21:33,769 EPOCH 886\n",
            "INFO:__main__:Epoch 886: total training loss 0.01173\n",
            "2025-06-26 08:21:33,835 Epoch 886: total training loss 0.01173\n",
            "INFO:__main__:EPOCH 887\n",
            "2025-06-26 08:21:33,837 EPOCH 887\n",
            "INFO:__main__:Epoch 887: total training loss 0.01153\n",
            "2025-06-26 08:21:33,899 Epoch 887: total training loss 0.01153\n",
            "INFO:__main__:EPOCH 888\n",
            "2025-06-26 08:21:33,901 EPOCH 888\n",
            "INFO:__main__:Epoch 888: total training loss 0.01123\n",
            "2025-06-26 08:21:33,965 Epoch 888: total training loss 0.01123\n",
            "INFO:__main__:EPOCH 889\n",
            "2025-06-26 08:21:33,967 EPOCH 889\n",
            "INFO:__main__:Epoch 889: total training loss 0.01093\n",
            "2025-06-26 08:21:34,033 Epoch 889: total training loss 0.01093\n",
            "INFO:__main__:EPOCH 890\n",
            "2025-06-26 08:21:34,035 EPOCH 890\n",
            "INFO:__main__:Epoch 890: total training loss 0.01148\n",
            "2025-06-26 08:21:34,100 Epoch 890: total training loss 0.01148\n",
            "INFO:__main__:EPOCH 891\n",
            "2025-06-26 08:21:34,102 EPOCH 891\n",
            "INFO:__main__:Epoch 891: total training loss 0.01123\n",
            "2025-06-26 08:21:34,169 Epoch 891: total training loss 0.01123\n",
            "INFO:__main__:EPOCH 892\n",
            "2025-06-26 08:21:34,171 EPOCH 892\n",
            "INFO:__main__:Epoch 892: total training loss 0.01089\n",
            "2025-06-26 08:21:34,236 Epoch 892: total training loss 0.01089\n",
            "INFO:__main__:EPOCH 893\n",
            "2025-06-26 08:21:34,238 EPOCH 893\n",
            "INFO:__main__:Epoch 893: total training loss 0.01032\n",
            "2025-06-26 08:21:34,304 Epoch 893: total training loss 0.01032\n",
            "INFO:__main__:EPOCH 894\n",
            "2025-06-26 08:21:34,306 EPOCH 894\n",
            "INFO:__main__:Epoch 894: total training loss 0.01072\n",
            "2025-06-26 08:21:34,370 Epoch 894: total training loss 0.01072\n",
            "INFO:__main__:EPOCH 895\n",
            "2025-06-26 08:21:34,372 EPOCH 895\n",
            "INFO:__main__:Epoch 895: total training loss 0.00992\n",
            "2025-06-26 08:21:34,434 Epoch 895: total training loss 0.00992\n",
            "INFO:__main__:EPOCH 896\n",
            "2025-06-26 08:21:34,437 EPOCH 896\n",
            "INFO:__main__:Epoch 896: total training loss 0.01056\n",
            "2025-06-26 08:21:34,506 Epoch 896: total training loss 0.01056\n",
            "INFO:__main__:EPOCH 897\n",
            "2025-06-26 08:21:34,508 EPOCH 897\n",
            "INFO:__main__:Epoch 897: total training loss 0.01047\n",
            "2025-06-26 08:21:34,578 Epoch 897: total training loss 0.01047\n",
            "INFO:__main__:EPOCH 898\n",
            "2025-06-26 08:21:34,580 EPOCH 898\n",
            "INFO:__main__:Epoch 898: total training loss 0.01089\n",
            "2025-06-26 08:21:34,644 Epoch 898: total training loss 0.01089\n",
            "INFO:__main__:EPOCH 899\n",
            "2025-06-26 08:21:34,646 EPOCH 899\n",
            "INFO:__main__:Epoch 899: total training loss 0.01078\n",
            "2025-06-26 08:21:34,705 Epoch 899: total training loss 0.01078\n",
            "INFO:__main__:EPOCH 900\n",
            "2025-06-26 08:21:34,707 EPOCH 900\n",
            "INFO:__main__:Epoch 900: total training loss 0.01052\n",
            "2025-06-26 08:21:34,770 Epoch 900: total training loss 0.01052\n",
            "INFO:__main__:EPOCH 901\n",
            "2025-06-26 08:21:34,772 EPOCH 901\n",
            "INFO:__main__:Epoch 901: total training loss 0.01063\n",
            "2025-06-26 08:21:34,833 Epoch 901: total training loss 0.01063\n",
            "INFO:__main__:EPOCH 902\n",
            "2025-06-26 08:21:34,835 EPOCH 902\n",
            "INFO:__main__:Epoch 902: total training loss 0.01006\n",
            "2025-06-26 08:21:34,897 Epoch 902: total training loss 0.01006\n",
            "INFO:__main__:EPOCH 903\n",
            "2025-06-26 08:21:34,899 EPOCH 903\n",
            "INFO:__main__:Epoch 903: total training loss 0.01035\n",
            "2025-06-26 08:21:34,961 Epoch 903: total training loss 0.01035\n",
            "INFO:__main__:EPOCH 904\n",
            "2025-06-26 08:21:34,963 EPOCH 904\n",
            "INFO:__main__:Epoch 904: total training loss 0.01085\n",
            "2025-06-26 08:21:35,027 Epoch 904: total training loss 0.01085\n",
            "INFO:__main__:EPOCH 905\n",
            "2025-06-26 08:21:35,029 EPOCH 905\n",
            "INFO:__main__:Epoch 905: total training loss 0.01089\n",
            "2025-06-26 08:21:35,094 Epoch 905: total training loss 0.01089\n",
            "INFO:__main__:EPOCH 906\n",
            "2025-06-26 08:21:35,096 EPOCH 906\n",
            "INFO:__main__:Epoch 906: total training loss 0.01046\n",
            "2025-06-26 08:21:35,158 Epoch 906: total training loss 0.01046\n",
            "INFO:__main__:EPOCH 907\n",
            "2025-06-26 08:21:35,160 EPOCH 907\n",
            "INFO:__main__:Epoch 907: total training loss 0.01085\n",
            "2025-06-26 08:21:35,222 Epoch 907: total training loss 0.01085\n",
            "INFO:__main__:EPOCH 908\n",
            "2025-06-26 08:21:35,224 EPOCH 908\n",
            "INFO:__main__:Epoch 908: total training loss 0.01063\n",
            "2025-06-26 08:21:35,289 Epoch 908: total training loss 0.01063\n",
            "INFO:__main__:EPOCH 909\n",
            "2025-06-26 08:21:35,291 EPOCH 909\n",
            "INFO:__main__:Epoch 909: total training loss 0.01085\n",
            "2025-06-26 08:21:35,352 Epoch 909: total training loss 0.01085\n",
            "INFO:__main__:EPOCH 910\n",
            "2025-06-26 08:21:35,354 EPOCH 910\n",
            "INFO:__main__:Epoch 910: total training loss 0.01165\n",
            "2025-06-26 08:21:35,416 Epoch 910: total training loss 0.01165\n",
            "INFO:__main__:EPOCH 911\n",
            "2025-06-26 08:21:35,418 EPOCH 911\n",
            "INFO:__main__:Epoch 911: total training loss 0.01100\n",
            "2025-06-26 08:21:35,479 Epoch 911: total training loss 0.01100\n",
            "INFO:__main__:EPOCH 912\n",
            "2025-06-26 08:21:35,482 EPOCH 912\n",
            "INFO:__main__:Epoch 912: total training loss 0.01051\n",
            "2025-06-26 08:21:35,548 Epoch 912: total training loss 0.01051\n",
            "INFO:__main__:EPOCH 913\n",
            "2025-06-26 08:21:35,550 EPOCH 913\n",
            "INFO:__main__:Epoch 913: total training loss 0.01118\n",
            "2025-06-26 08:21:35,622 Epoch 913: total training loss 0.01118\n",
            "INFO:__main__:EPOCH 914\n",
            "2025-06-26 08:21:35,624 EPOCH 914\n",
            "INFO:__main__:Epoch 914: total training loss 0.01045\n",
            "2025-06-26 08:21:35,687 Epoch 914: total training loss 0.01045\n",
            "INFO:__main__:EPOCH 915\n",
            "2025-06-26 08:21:35,689 EPOCH 915\n",
            "INFO:__main__:Epoch 915: total training loss 0.01094\n",
            "2025-06-26 08:21:35,750 Epoch 915: total training loss 0.01094\n",
            "INFO:__main__:EPOCH 916\n",
            "2025-06-26 08:21:35,752 EPOCH 916\n",
            "INFO:__main__:Epoch 916: total training loss 0.01115\n",
            "2025-06-26 08:21:35,814 Epoch 916: total training loss 0.01115\n",
            "INFO:__main__:EPOCH 917\n",
            "2025-06-26 08:21:35,816 EPOCH 917\n",
            "INFO:__main__:Epoch 917: total training loss 0.01080\n",
            "2025-06-26 08:21:35,875 Epoch 917: total training loss 0.01080\n",
            "INFO:__main__:EPOCH 918\n",
            "2025-06-26 08:21:35,877 EPOCH 918\n",
            "INFO:__main__:Epoch 918: total training loss 0.01061\n",
            "2025-06-26 08:21:35,937 Epoch 918: total training loss 0.01061\n",
            "INFO:__main__:EPOCH 919\n",
            "2025-06-26 08:21:35,939 EPOCH 919\n",
            "INFO:__main__:Epoch 919: total training loss 0.01002\n",
            "2025-06-26 08:21:36,003 Epoch 919: total training loss 0.01002\n",
            "INFO:__main__:EPOCH 920\n",
            "2025-06-26 08:21:36,005 EPOCH 920\n",
            "INFO:__main__:Epoch 920: total training loss 0.01066\n",
            "2025-06-26 08:21:36,075 Epoch 920: total training loss 0.01066\n",
            "INFO:__main__:EPOCH 921\n",
            "2025-06-26 08:21:36,077 EPOCH 921\n",
            "INFO:__main__:Epoch 921: total training loss 0.01105\n",
            "2025-06-26 08:21:36,141 Epoch 921: total training loss 0.01105\n",
            "INFO:__main__:EPOCH 922\n",
            "2025-06-26 08:21:36,143 EPOCH 922\n",
            "INFO:__main__:Epoch 922: total training loss 0.01017\n",
            "2025-06-26 08:21:36,206 Epoch 922: total training loss 0.01017\n",
            "INFO:__main__:EPOCH 923\n",
            "2025-06-26 08:21:36,207 EPOCH 923\n",
            "INFO:__main__:Epoch 923: total training loss 0.01030\n",
            "2025-06-26 08:21:36,270 Epoch 923: total training loss 0.01030\n",
            "INFO:__main__:EPOCH 924\n",
            "2025-06-26 08:21:36,272 EPOCH 924\n",
            "INFO:__main__:Epoch 924: total training loss 0.01021\n",
            "2025-06-26 08:21:36,333 Epoch 924: total training loss 0.01021\n",
            "INFO:__main__:EPOCH 925\n",
            "2025-06-26 08:21:36,335 EPOCH 925\n",
            "INFO:__main__:Epoch 925: total training loss 0.01014\n",
            "2025-06-26 08:21:36,396 Epoch 925: total training loss 0.01014\n",
            "INFO:__main__:EPOCH 926\n",
            "2025-06-26 08:21:36,398 EPOCH 926\n",
            "INFO:__main__:Epoch 926: total training loss 0.00974\n",
            "2025-06-26 08:21:36,459 Epoch 926: total training loss 0.00974\n",
            "INFO:__main__:EPOCH 927\n",
            "2025-06-26 08:21:36,462 EPOCH 927\n",
            "INFO:__main__:Epoch 927: total training loss 0.00990\n",
            "2025-06-26 08:21:36,523 Epoch 927: total training loss 0.00990\n",
            "INFO:__main__:EPOCH 928\n",
            "2025-06-26 08:21:36,525 EPOCH 928\n",
            "INFO:__main__:Epoch 928: total training loss 0.00999\n",
            "2025-06-26 08:21:36,598 Epoch 928: total training loss 0.00999\n",
            "INFO:__main__:EPOCH 929\n",
            "2025-06-26 08:21:36,601 EPOCH 929\n",
            "INFO:__main__:Epoch 929: total training loss 0.01030\n",
            "2025-06-26 08:21:36,667 Epoch 929: total training loss 0.01030\n",
            "INFO:__main__:EPOCH 930\n",
            "2025-06-26 08:21:36,669 EPOCH 930\n",
            "INFO:__main__:Epoch 930: total training loss 0.00980\n",
            "2025-06-26 08:21:36,731 Epoch 930: total training loss 0.00980\n",
            "INFO:__main__:EPOCH 931\n",
            "2025-06-26 08:21:36,733 EPOCH 931\n",
            "INFO:__main__:Epoch 931: total training loss 0.01014\n",
            "2025-06-26 08:21:36,795 Epoch 931: total training loss 0.01014\n",
            "INFO:__main__:EPOCH 932\n",
            "2025-06-26 08:21:36,799 EPOCH 932\n",
            "INFO:__main__:Epoch 932: total training loss 0.01027\n",
            "2025-06-26 08:21:36,861 Epoch 932: total training loss 0.01027\n",
            "INFO:__main__:EPOCH 933\n",
            "2025-06-26 08:21:36,863 EPOCH 933\n",
            "INFO:__main__:Epoch 933: total training loss 0.00988\n",
            "2025-06-26 08:21:36,924 Epoch 933: total training loss 0.00988\n",
            "INFO:__main__:EPOCH 934\n",
            "2025-06-26 08:21:36,926 EPOCH 934\n",
            "INFO:__main__:Epoch 934: total training loss 0.01065\n",
            "2025-06-26 08:21:36,987 Epoch 934: total training loss 0.01065\n",
            "INFO:__main__:EPOCH 935\n",
            "2025-06-26 08:21:36,989 EPOCH 935\n",
            "INFO:__main__:Epoch 935: total training loss 0.01068\n",
            "2025-06-26 08:21:37,056 Epoch 935: total training loss 0.01068\n",
            "INFO:__main__:EPOCH 936\n",
            "2025-06-26 08:21:37,059 EPOCH 936\n",
            "INFO:__main__:Epoch 936: total training loss 0.01076\n",
            "2025-06-26 08:21:37,125 Epoch 936: total training loss 0.01076\n",
            "INFO:__main__:EPOCH 937\n",
            "2025-06-26 08:21:37,128 EPOCH 937\n",
            "INFO:__main__:Epoch 937: total training loss 0.01046\n",
            "2025-06-26 08:21:37,193 Epoch 937: total training loss 0.01046\n",
            "INFO:__main__:EPOCH 938\n",
            "2025-06-26 08:21:37,195 EPOCH 938\n",
            "INFO:__main__:Epoch 938: total training loss 0.01001\n",
            "2025-06-26 08:21:37,256 Epoch 938: total training loss 0.01001\n",
            "INFO:__main__:EPOCH 939\n",
            "2025-06-26 08:21:37,258 EPOCH 939\n",
            "INFO:__main__:Epoch 939: total training loss 0.01025\n",
            "2025-06-26 08:21:37,321 Epoch 939: total training loss 0.01025\n",
            "INFO:__main__:EPOCH 940\n",
            "2025-06-26 08:21:37,323 EPOCH 940\n",
            "INFO:__main__:Epoch 940: total training loss 0.01035\n",
            "2025-06-26 08:21:37,386 Epoch 940: total training loss 0.01035\n",
            "INFO:__main__:EPOCH 941\n",
            "2025-06-26 08:21:37,388 EPOCH 941\n",
            "INFO:__main__:Epoch 941: total training loss 0.01051\n",
            "2025-06-26 08:21:37,454 Epoch 941: total training loss 0.01051\n",
            "INFO:__main__:EPOCH 942\n",
            "2025-06-26 08:21:37,456 EPOCH 942\n",
            "INFO:__main__:Epoch 942: total training loss 0.00967\n",
            "2025-06-26 08:21:37,517 Epoch 942: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 943\n",
            "2025-06-26 08:21:37,522 EPOCH 943\n",
            "INFO:__main__:Epoch 943: total training loss 0.01010\n",
            "2025-06-26 08:21:37,583 Epoch 943: total training loss 0.01010\n",
            "INFO:__main__:EPOCH 944\n",
            "2025-06-26 08:21:37,586 EPOCH 944\n",
            "INFO:__main__:Epoch 944: total training loss 0.01068\n",
            "2025-06-26 08:21:37,664 Epoch 944: total training loss 0.01068\n",
            "INFO:__main__:EPOCH 945\n",
            "2025-06-26 08:21:37,667 EPOCH 945\n",
            "INFO:__main__:Epoch 945: total training loss 0.01011\n",
            "2025-06-26 08:21:37,728 Epoch 945: total training loss 0.01011\n",
            "INFO:__main__:EPOCH 946\n",
            "2025-06-26 08:21:37,730 EPOCH 946\n",
            "INFO:__main__:Epoch 946: total training loss 0.01018\n",
            "2025-06-26 08:21:37,797 Epoch 946: total training loss 0.01018\n",
            "INFO:__main__:EPOCH 947\n",
            "2025-06-26 08:21:37,799 EPOCH 947\n",
            "INFO:__main__:Epoch 947: total training loss 0.01044\n",
            "2025-06-26 08:21:37,863 Epoch 947: total training loss 0.01044\n",
            "INFO:__main__:EPOCH 948\n",
            "2025-06-26 08:21:37,865 EPOCH 948\n",
            "INFO:__main__:Epoch 948: total training loss 0.01056\n",
            "2025-06-26 08:21:37,931 Epoch 948: total training loss 0.01056\n",
            "INFO:__main__:EPOCH 949\n",
            "2025-06-26 08:21:37,934 EPOCH 949\n",
            "INFO:__main__:Epoch 949: total training loss 0.01077\n",
            "2025-06-26 08:21:37,994 Epoch 949: total training loss 0.01077\n",
            "INFO:__main__:EPOCH 950\n",
            "2025-06-26 08:21:37,996 EPOCH 950\n",
            "INFO:__main__:Epoch 950: total training loss 0.01059\n",
            "2025-06-26 08:21:38,055 Epoch 950: total training loss 0.01059\n",
            "INFO:__main__:EPOCH 951\n",
            "2025-06-26 08:21:38,057 EPOCH 951\n",
            "INFO:__main__:Epoch 951: total training loss 0.01119\n",
            "2025-06-26 08:21:38,126 Epoch 951: total training loss 0.01119\n",
            "INFO:__main__:EPOCH 952\n",
            "2025-06-26 08:21:38,128 EPOCH 952\n",
            "INFO:__main__:Epoch 952: total training loss 0.01111\n",
            "2025-06-26 08:21:38,196 Epoch 952: total training loss 0.01111\n",
            "INFO:__main__:EPOCH 953\n",
            "2025-06-26 08:21:38,199 EPOCH 953\n",
            "INFO:__main__:Epoch 953: total training loss 0.01104\n",
            "2025-06-26 08:21:38,260 Epoch 953: total training loss 0.01104\n",
            "INFO:__main__:EPOCH 954\n",
            "2025-06-26 08:21:38,262 EPOCH 954\n",
            "INFO:__main__:Epoch 954: total training loss 0.01063\n",
            "2025-06-26 08:21:38,323 Epoch 954: total training loss 0.01063\n",
            "INFO:__main__:EPOCH 955\n",
            "2025-06-26 08:21:38,325 EPOCH 955\n",
            "INFO:__main__:Epoch 955: total training loss 0.01065\n",
            "2025-06-26 08:21:38,390 Epoch 955: total training loss 0.01065\n",
            "INFO:__main__:EPOCH 956\n",
            "2025-06-26 08:21:38,392 EPOCH 956\n",
            "INFO:__main__:Epoch 956: total training loss 0.01046\n",
            "2025-06-26 08:21:38,456 Epoch 956: total training loss 0.01046\n",
            "INFO:__main__:EPOCH 957\n",
            "2025-06-26 08:21:38,458 EPOCH 957\n",
            "INFO:__main__:Epoch 957: total training loss 0.01082\n",
            "2025-06-26 08:21:38,525 Epoch 957: total training loss 0.01082\n",
            "INFO:__main__:EPOCH 958\n",
            "2025-06-26 08:21:38,527 EPOCH 958\n",
            "INFO:__main__:Epoch 958: total training loss 0.01058\n",
            "2025-06-26 08:21:38,592 Epoch 958: total training loss 0.01058\n",
            "INFO:__main__:EPOCH 959\n",
            "2025-06-26 08:21:38,594 EPOCH 959\n",
            "INFO:__main__:Epoch 959: total training loss 0.01033\n",
            "2025-06-26 08:21:38,658 Epoch 959: total training loss 0.01033\n",
            "INFO:__main__:EPOCH 960\n",
            "2025-06-26 08:21:38,660 EPOCH 960\n",
            "INFO:__main__:Epoch 960: total training loss 0.01050\n",
            "2025-06-26 08:21:38,738 Epoch 960: total training loss 0.01050\n",
            "INFO:__main__:EPOCH 961\n",
            "2025-06-26 08:21:38,740 EPOCH 961\n",
            "INFO:__main__:Epoch 961: total training loss 0.01022\n",
            "2025-06-26 08:21:38,803 Epoch 961: total training loss 0.01022\n",
            "INFO:__main__:EPOCH 962\n",
            "2025-06-26 08:21:38,806 EPOCH 962\n",
            "INFO:__main__:Epoch 962: total training loss 0.00960\n",
            "2025-06-26 08:21:38,869 Epoch 962: total training loss 0.00960\n",
            "INFO:__main__:EPOCH 963\n",
            "2025-06-26 08:21:38,871 EPOCH 963\n",
            "INFO:__main__:Epoch 963: total training loss 0.01028\n",
            "2025-06-26 08:21:38,934 Epoch 963: total training loss 0.01028\n",
            "INFO:__main__:EPOCH 964\n",
            "2025-06-26 08:21:38,936 EPOCH 964\n",
            "INFO:__main__:Epoch 964: total training loss 0.01068\n",
            "2025-06-26 08:21:39,002 Epoch 964: total training loss 0.01068\n",
            "INFO:__main__:EPOCH 965\n",
            "2025-06-26 08:21:39,004 EPOCH 965\n",
            "INFO:__main__:Epoch 965: total training loss 0.01020\n",
            "2025-06-26 08:21:39,068 Epoch 965: total training loss 0.01020\n",
            "INFO:__main__:EPOCH 966\n",
            "2025-06-26 08:21:39,070 EPOCH 966\n",
            "INFO:__main__:Epoch 966: total training loss 0.01032\n",
            "2025-06-26 08:21:39,135 Epoch 966: total training loss 0.01032\n",
            "INFO:__main__:EPOCH 967\n",
            "2025-06-26 08:21:39,138 EPOCH 967\n",
            "INFO:__main__:Epoch 967: total training loss 0.00981\n",
            "2025-06-26 08:21:39,201 Epoch 967: total training loss 0.00981\n",
            "INFO:__main__:EPOCH 968\n",
            "2025-06-26 08:21:39,203 EPOCH 968\n",
            "INFO:__main__:Epoch 968: total training loss 0.00954\n",
            "2025-06-26 08:21:39,268 Epoch 968: total training loss 0.00954\n",
            "INFO:__main__:EPOCH 969\n",
            "2025-06-26 08:21:39,271 EPOCH 969\n",
            "INFO:__main__:Epoch 969: total training loss 0.01006\n",
            "2025-06-26 08:21:39,332 Epoch 969: total training loss 0.01006\n",
            "INFO:__main__:EPOCH 970\n",
            "2025-06-26 08:21:39,334 EPOCH 970\n",
            "INFO:__main__:Epoch 970: total training loss 0.01028\n",
            "2025-06-26 08:21:39,398 Epoch 970: total training loss 0.01028\n",
            "INFO:__main__:EPOCH 971\n",
            "2025-06-26 08:21:39,400 EPOCH 971\n",
            "INFO:__main__:Epoch 971: total training loss 0.00947\n",
            "2025-06-26 08:21:39,462 Epoch 971: total training loss 0.00947\n",
            "INFO:__main__:EPOCH 972\n",
            "2025-06-26 08:21:39,464 EPOCH 972\n",
            "INFO:__main__:Epoch 972: total training loss 0.00959\n",
            "2025-06-26 08:21:39,528 Epoch 972: total training loss 0.00959\n",
            "INFO:__main__:EPOCH 973\n",
            "2025-06-26 08:21:39,530 EPOCH 973\n",
            "INFO:__main__:Epoch 973: total training loss 0.00992\n",
            "2025-06-26 08:21:39,593 Epoch 973: total training loss 0.00992\n",
            "INFO:__main__:EPOCH 974\n",
            "2025-06-26 08:21:39,595 EPOCH 974\n",
            "INFO:__main__:Epoch 974: total training loss 0.00952\n",
            "2025-06-26 08:21:39,655 Epoch 974: total training loss 0.00952\n",
            "INFO:__main__:EPOCH 975\n",
            "2025-06-26 08:21:39,657 EPOCH 975\n",
            "INFO:__main__:Epoch 975: total training loss 0.01052\n",
            "2025-06-26 08:21:39,756 Epoch 975: total training loss 0.01052\n",
            "INFO:__main__:EPOCH 976\n",
            "2025-06-26 08:21:39,758 EPOCH 976\n",
            "INFO:__main__:Epoch 976: total training loss 0.01024\n",
            "2025-06-26 08:21:39,852 Epoch 976: total training loss 0.01024\n",
            "INFO:__main__:EPOCH 977\n",
            "2025-06-26 08:21:39,854 EPOCH 977\n",
            "INFO:__main__:Epoch 977: total training loss 0.00999\n",
            "2025-06-26 08:21:39,937 Epoch 977: total training loss 0.00999\n",
            "INFO:__main__:EPOCH 978\n",
            "2025-06-26 08:21:39,939 EPOCH 978\n",
            "INFO:__main__:Epoch 978: total training loss 0.00977\n",
            "2025-06-26 08:21:40,015 Epoch 978: total training loss 0.00977\n",
            "INFO:__main__:EPOCH 979\n",
            "2025-06-26 08:21:40,019 EPOCH 979\n",
            "INFO:__main__:Epoch 979: total training loss 0.01007\n",
            "2025-06-26 08:21:40,114 Epoch 979: total training loss 0.01007\n",
            "INFO:__main__:EPOCH 980\n",
            "2025-06-26 08:21:40,116 EPOCH 980\n",
            "INFO:__main__:Epoch 980: total training loss 0.00990\n",
            "2025-06-26 08:21:40,206 Epoch 980: total training loss 0.00990\n",
            "INFO:__main__:EPOCH 981\n",
            "2025-06-26 08:21:40,208 EPOCH 981\n",
            "INFO:__main__:Epoch 981: total training loss 0.00975\n",
            "2025-06-26 08:21:40,287 Epoch 981: total training loss 0.00975\n",
            "INFO:__main__:EPOCH 982\n",
            "2025-06-26 08:21:40,289 EPOCH 982\n",
            "INFO:__main__:Epoch 982: total training loss 0.00999\n",
            "2025-06-26 08:21:40,380 Epoch 982: total training loss 0.00999\n",
            "INFO:__main__:EPOCH 983\n",
            "2025-06-26 08:21:40,381 EPOCH 983\n",
            "INFO:__main__:Epoch 983: total training loss 0.00982\n",
            "2025-06-26 08:21:40,462 Epoch 983: total training loss 0.00982\n",
            "INFO:__main__:EPOCH 984\n",
            "2025-06-26 08:21:40,463 EPOCH 984\n",
            "INFO:__main__:Epoch 984: total training loss 0.00958\n",
            "2025-06-26 08:21:40,542 Epoch 984: total training loss 0.00958\n",
            "INFO:__main__:EPOCH 985\n",
            "2025-06-26 08:21:40,547 EPOCH 985\n",
            "INFO:__main__:Epoch 985: total training loss 0.00936\n",
            "2025-06-26 08:21:40,623 Epoch 985: total training loss 0.00936\n",
            "INFO:__main__:EPOCH 986\n",
            "2025-06-26 08:21:40,625 EPOCH 986\n",
            "INFO:__main__:Epoch 986: total training loss 0.00991\n",
            "2025-06-26 08:21:40,695 Epoch 986: total training loss 0.00991\n",
            "INFO:__main__:EPOCH 987\n",
            "2025-06-26 08:21:40,697 EPOCH 987\n",
            "INFO:__main__:Epoch 987: total training loss 0.00984\n",
            "2025-06-26 08:21:40,767 Epoch 987: total training loss 0.00984\n",
            "INFO:__main__:EPOCH 988\n",
            "2025-06-26 08:21:40,769 EPOCH 988\n",
            "INFO:__main__:Epoch 988: total training loss 0.00994\n",
            "2025-06-26 08:21:40,851 Epoch 988: total training loss 0.00994\n",
            "INFO:__main__:EPOCH 989\n",
            "2025-06-26 08:21:40,853 EPOCH 989\n",
            "INFO:__main__:Epoch 989: total training loss 0.01010\n",
            "2025-06-26 08:21:40,939 Epoch 989: total training loss 0.01010\n",
            "INFO:__main__:EPOCH 990\n",
            "2025-06-26 08:21:40,941 EPOCH 990\n",
            "INFO:__main__:Epoch 990: total training loss 0.00951\n",
            "2025-06-26 08:21:41,009 Epoch 990: total training loss 0.00951\n",
            "INFO:__main__:EPOCH 991\n",
            "2025-06-26 08:21:41,011 EPOCH 991\n",
            "INFO:__main__:Epoch 991: total training loss 0.00990\n",
            "2025-06-26 08:21:41,084 Epoch 991: total training loss 0.00990\n",
            "INFO:__main__:EPOCH 992\n",
            "2025-06-26 08:21:41,086 EPOCH 992\n",
            "INFO:__main__:Epoch 992: total training loss 0.00994\n",
            "2025-06-26 08:21:41,187 Epoch 992: total training loss 0.00994\n",
            "INFO:__main__:EPOCH 993\n",
            "2025-06-26 08:21:41,189 EPOCH 993\n",
            "INFO:__main__:Epoch 993: total training loss 0.01006\n",
            "2025-06-26 08:21:41,282 Epoch 993: total training loss 0.01006\n",
            "INFO:__main__:EPOCH 994\n",
            "2025-06-26 08:21:41,285 EPOCH 994\n",
            "INFO:__main__:Epoch 994: total training loss 0.01009\n",
            "2025-06-26 08:21:41,385 Epoch 994: total training loss 0.01009\n",
            "INFO:__main__:EPOCH 995\n",
            "2025-06-26 08:21:41,387 EPOCH 995\n",
            "INFO:__main__:Epoch 995: total training loss 0.01037\n",
            "2025-06-26 08:21:41,465 Epoch 995: total training loss 0.01037\n",
            "INFO:__main__:EPOCH 996\n",
            "2025-06-26 08:21:41,467 EPOCH 996\n",
            "INFO:__main__:Epoch 996: total training loss 0.00964\n",
            "2025-06-26 08:21:41,547 Epoch 996: total training loss 0.00964\n",
            "INFO:__main__:EPOCH 997\n",
            "2025-06-26 08:21:41,549 EPOCH 997\n",
            "INFO:__main__:Epoch 997: total training loss 0.00994\n",
            "2025-06-26 08:21:41,626 Epoch 997: total training loss 0.00994\n",
            "INFO:__main__:EPOCH 998\n",
            "2025-06-26 08:21:41,628 EPOCH 998\n",
            "INFO:__main__:Epoch 998: total training loss 0.00989\n",
            "2025-06-26 08:21:41,715 Epoch 998: total training loss 0.00989\n",
            "INFO:__main__:EPOCH 999\n",
            "2025-06-26 08:21:41,717 EPOCH 999\n",
            "INFO:__main__:Epoch 999: total training loss 0.01018\n",
            "2025-06-26 08:21:41,792 Epoch 999: total training loss 0.01018\n",
            "INFO:__main__:EPOCH 1000\n",
            "2025-06-26 08:21:41,795 EPOCH 1000\n",
            "INFO:__main__:Epoch 1000 Step:     1000 Batch Loss:     0.009619 Tokens per Sec:  1937133, Lr: 0.001000\n",
            "2025-06-26 08:21:41,869 Epoch 1000 Step:     1000 Batch Loss:     0.009619 Tokens per Sec:  1937133, Lr: 0.001000\n",
            "INFO:__main__:Epoch 1000: total training loss 0.00962\n",
            "2025-06-26 08:21:41,872 Epoch 1000: total training loss 0.00962\n",
            "INFO:__main__:EPOCH 1001\n",
            "2025-06-26 08:21:41,873 EPOCH 1001\n",
            "INFO:__main__:Epoch 1001: total training loss 0.00986\n",
            "2025-06-26 08:21:41,957 Epoch 1001: total training loss 0.00986\n",
            "INFO:__main__:EPOCH 1002\n",
            "2025-06-26 08:21:41,959 EPOCH 1002\n",
            "INFO:__main__:Epoch 1002: total training loss 0.00981\n",
            "2025-06-26 08:21:42,043 Epoch 1002: total training loss 0.00981\n",
            "INFO:__main__:EPOCH 1003\n",
            "2025-06-26 08:21:42,045 EPOCH 1003\n",
            "INFO:__main__:Epoch 1003: total training loss 0.00966\n",
            "2025-06-26 08:21:42,139 Epoch 1003: total training loss 0.00966\n",
            "INFO:__main__:EPOCH 1004\n",
            "2025-06-26 08:21:42,141 EPOCH 1004\n",
            "INFO:__main__:Epoch 1004: total training loss 0.00950\n",
            "2025-06-26 08:21:42,241 Epoch 1004: total training loss 0.00950\n",
            "INFO:__main__:EPOCH 1005\n",
            "2025-06-26 08:21:42,244 EPOCH 1005\n",
            "INFO:__main__:Epoch 1005: total training loss 0.00971\n",
            "2025-06-26 08:21:42,331 Epoch 1005: total training loss 0.00971\n",
            "INFO:__main__:EPOCH 1006\n",
            "2025-06-26 08:21:42,333 EPOCH 1006\n",
            "INFO:__main__:Epoch 1006: total training loss 0.00943\n",
            "2025-06-26 08:21:42,415 Epoch 1006: total training loss 0.00943\n",
            "INFO:__main__:EPOCH 1007\n",
            "2025-06-26 08:21:42,417 EPOCH 1007\n",
            "INFO:__main__:Epoch 1007: total training loss 0.00967\n",
            "2025-06-26 08:21:42,509 Epoch 1007: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 1008\n",
            "2025-06-26 08:21:42,513 EPOCH 1008\n",
            "INFO:__main__:Epoch 1008: total training loss 0.00942\n",
            "2025-06-26 08:21:42,601 Epoch 1008: total training loss 0.00942\n",
            "INFO:__main__:EPOCH 1009\n",
            "2025-06-26 08:21:42,603 EPOCH 1009\n",
            "INFO:__main__:Epoch 1009: total training loss 0.00928\n",
            "2025-06-26 08:21:42,690 Epoch 1009: total training loss 0.00928\n",
            "INFO:__main__:EPOCH 1010\n",
            "2025-06-26 08:21:42,693 EPOCH 1010\n",
            "INFO:__main__:Epoch 1010: total training loss 0.00921\n",
            "2025-06-26 08:21:42,782 Epoch 1010: total training loss 0.00921\n",
            "INFO:__main__:EPOCH 1011\n",
            "2025-06-26 08:21:42,784 EPOCH 1011\n",
            "INFO:__main__:Epoch 1011: total training loss 0.00993\n",
            "2025-06-26 08:21:42,871 Epoch 1011: total training loss 0.00993\n",
            "INFO:__main__:EPOCH 1012\n",
            "2025-06-26 08:21:42,874 EPOCH 1012\n",
            "INFO:__main__:Epoch 1012: total training loss 0.00922\n",
            "2025-06-26 08:21:42,970 Epoch 1012: total training loss 0.00922\n",
            "INFO:__main__:EPOCH 1013\n",
            "2025-06-26 08:21:42,972 EPOCH 1013\n",
            "INFO:__main__:Epoch 1013: total training loss 0.00919\n",
            "2025-06-26 08:21:43,079 Epoch 1013: total training loss 0.00919\n",
            "INFO:__main__:EPOCH 1014\n",
            "2025-06-26 08:21:43,081 EPOCH 1014\n",
            "INFO:__main__:Epoch 1014: total training loss 0.00874\n",
            "2025-06-26 08:21:43,179 Epoch 1014: total training loss 0.00874\n",
            "INFO:__main__:EPOCH 1015\n",
            "2025-06-26 08:21:43,181 EPOCH 1015\n",
            "INFO:__main__:Epoch 1015: total training loss 0.00964\n",
            "2025-06-26 08:21:43,277 Epoch 1015: total training loss 0.00964\n",
            "INFO:__main__:EPOCH 1016\n",
            "2025-06-26 08:21:43,279 EPOCH 1016\n",
            "INFO:__main__:Epoch 1016: total training loss 0.00967\n",
            "2025-06-26 08:21:43,385 Epoch 1016: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 1017\n",
            "2025-06-26 08:21:43,387 EPOCH 1017\n",
            "INFO:__main__:Epoch 1017: total training loss 0.00912\n",
            "2025-06-26 08:21:43,479 Epoch 1017: total training loss 0.00912\n",
            "INFO:__main__:EPOCH 1018\n",
            "2025-06-26 08:21:43,481 EPOCH 1018\n",
            "INFO:__main__:Epoch 1018: total training loss 0.01009\n",
            "2025-06-26 08:21:43,576 Epoch 1018: total training loss 0.01009\n",
            "INFO:__main__:EPOCH 1019\n",
            "2025-06-26 08:21:43,579 EPOCH 1019\n",
            "INFO:__main__:Epoch 1019: total training loss 0.01046\n",
            "2025-06-26 08:21:43,689 Epoch 1019: total training loss 0.01046\n",
            "INFO:__main__:EPOCH 1020\n",
            "2025-06-26 08:21:43,691 EPOCH 1020\n",
            "INFO:__main__:Epoch 1020: total training loss 0.00973\n",
            "2025-06-26 08:21:43,785 Epoch 1020: total training loss 0.00973\n",
            "INFO:__main__:EPOCH 1021\n",
            "2025-06-26 08:21:43,787 EPOCH 1021\n",
            "INFO:__main__:Epoch 1021: total training loss 0.00941\n",
            "2025-06-26 08:21:43,853 Epoch 1021: total training loss 0.00941\n",
            "INFO:__main__:EPOCH 1022\n",
            "2025-06-26 08:21:43,856 EPOCH 1022\n",
            "INFO:__main__:Epoch 1022: total training loss 0.00979\n",
            "2025-06-26 08:21:43,923 Epoch 1022: total training loss 0.00979\n",
            "INFO:__main__:EPOCH 1023\n",
            "2025-06-26 08:21:43,926 EPOCH 1023\n",
            "INFO:__main__:Epoch 1023: total training loss 0.00967\n",
            "2025-06-26 08:21:43,993 Epoch 1023: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 1024\n",
            "2025-06-26 08:21:43,995 EPOCH 1024\n",
            "INFO:__main__:Epoch 1024: total training loss 0.00912\n",
            "2025-06-26 08:21:44,060 Epoch 1024: total training loss 0.00912\n",
            "INFO:__main__:EPOCH 1025\n",
            "2025-06-26 08:21:44,062 EPOCH 1025\n",
            "INFO:__main__:Epoch 1025: total training loss 0.01003\n",
            "2025-06-26 08:21:44,150 Epoch 1025: total training loss 0.01003\n",
            "INFO:__main__:EPOCH 1026\n",
            "2025-06-26 08:21:44,152 EPOCH 1026\n",
            "INFO:__main__:Epoch 1026: total training loss 0.01022\n",
            "2025-06-26 08:21:44,224 Epoch 1026: total training loss 0.01022\n",
            "INFO:__main__:EPOCH 1027\n",
            "2025-06-26 08:21:44,226 EPOCH 1027\n",
            "INFO:__main__:Epoch 1027: total training loss 0.00971\n",
            "2025-06-26 08:21:44,290 Epoch 1027: total training loss 0.00971\n",
            "INFO:__main__:EPOCH 1028\n",
            "2025-06-26 08:21:44,292 EPOCH 1028\n",
            "INFO:__main__:Epoch 1028: total training loss 0.00968\n",
            "2025-06-26 08:21:44,354 Epoch 1028: total training loss 0.00968\n",
            "INFO:__main__:EPOCH 1029\n",
            "2025-06-26 08:21:44,356 EPOCH 1029\n",
            "INFO:__main__:Epoch 1029: total training loss 0.00990\n",
            "2025-06-26 08:21:44,419 Epoch 1029: total training loss 0.00990\n",
            "INFO:__main__:EPOCH 1030\n",
            "2025-06-26 08:21:44,421 EPOCH 1030\n",
            "INFO:__main__:Epoch 1030: total training loss 0.00974\n",
            "2025-06-26 08:21:44,481 Epoch 1030: total training loss 0.00974\n",
            "INFO:__main__:EPOCH 1031\n",
            "2025-06-26 08:21:44,483 EPOCH 1031\n",
            "INFO:__main__:Epoch 1031: total training loss 0.00979\n",
            "2025-06-26 08:21:44,545 Epoch 1031: total training loss 0.00979\n",
            "INFO:__main__:EPOCH 1032\n",
            "2025-06-26 08:21:44,547 EPOCH 1032\n",
            "INFO:__main__:Epoch 1032: total training loss 0.01019\n",
            "2025-06-26 08:21:44,611 Epoch 1032: total training loss 0.01019\n",
            "INFO:__main__:EPOCH 1033\n",
            "2025-06-26 08:21:44,614 EPOCH 1033\n",
            "INFO:__main__:Epoch 1033: total training loss 0.01035\n",
            "2025-06-26 08:21:44,675 Epoch 1033: total training loss 0.01035\n",
            "INFO:__main__:EPOCH 1034\n",
            "2025-06-26 08:21:44,677 EPOCH 1034\n",
            "INFO:__main__:Epoch 1034: total training loss 0.00988\n",
            "2025-06-26 08:21:44,738 Epoch 1034: total training loss 0.00988\n",
            "INFO:__main__:EPOCH 1035\n",
            "2025-06-26 08:21:44,740 EPOCH 1035\n",
            "INFO:__main__:Epoch 1035: total training loss 0.00963\n",
            "2025-06-26 08:21:44,807 Epoch 1035: total training loss 0.00963\n",
            "INFO:__main__:EPOCH 1036\n",
            "2025-06-26 08:21:44,809 EPOCH 1036\n",
            "INFO:__main__:Epoch 1036: total training loss 0.00954\n",
            "2025-06-26 08:21:44,874 Epoch 1036: total training loss 0.00954\n",
            "INFO:__main__:EPOCH 1037\n",
            "2025-06-26 08:21:44,876 EPOCH 1037\n",
            "INFO:__main__:Epoch 1037: total training loss 0.00932\n",
            "2025-06-26 08:21:44,938 Epoch 1037: total training loss 0.00932\n",
            "INFO:__main__:EPOCH 1038\n",
            "2025-06-26 08:21:44,940 EPOCH 1038\n",
            "INFO:__main__:Epoch 1038: total training loss 0.00943\n",
            "2025-06-26 08:21:45,002 Epoch 1038: total training loss 0.00943\n",
            "INFO:__main__:EPOCH 1039\n",
            "2025-06-26 08:21:45,003 EPOCH 1039\n",
            "INFO:__main__:Epoch 1039: total training loss 0.00901\n",
            "2025-06-26 08:21:45,068 Epoch 1039: total training loss 0.00901\n",
            "INFO:__main__:EPOCH 1040\n",
            "2025-06-26 08:21:45,070 EPOCH 1040\n",
            "INFO:__main__:Epoch 1040: total training loss 0.00938\n",
            "2025-06-26 08:21:45,144 Epoch 1040: total training loss 0.00938\n",
            "INFO:__main__:EPOCH 1041\n",
            "2025-06-26 08:21:45,147 EPOCH 1041\n",
            "INFO:__main__:Epoch 1041: total training loss 0.00983\n",
            "2025-06-26 08:21:45,215 Epoch 1041: total training loss 0.00983\n",
            "INFO:__main__:EPOCH 1042\n",
            "2025-06-26 08:21:45,217 EPOCH 1042\n",
            "INFO:__main__:Epoch 1042: total training loss 0.00927\n",
            "2025-06-26 08:21:45,280 Epoch 1042: total training loss 0.00927\n",
            "INFO:__main__:EPOCH 1043\n",
            "2025-06-26 08:21:45,282 EPOCH 1043\n",
            "INFO:__main__:Epoch 1043: total training loss 0.00971\n",
            "2025-06-26 08:21:45,343 Epoch 1043: total training loss 0.00971\n",
            "INFO:__main__:EPOCH 1044\n",
            "2025-06-26 08:21:45,345 EPOCH 1044\n",
            "INFO:__main__:Epoch 1044: total training loss 0.00964\n",
            "2025-06-26 08:21:45,408 Epoch 1044: total training loss 0.00964\n",
            "INFO:__main__:EPOCH 1045\n",
            "2025-06-26 08:21:45,411 EPOCH 1045\n",
            "INFO:__main__:Epoch 1045: total training loss 0.00983\n",
            "2025-06-26 08:21:45,473 Epoch 1045: total training loss 0.00983\n",
            "INFO:__main__:EPOCH 1046\n",
            "2025-06-26 08:21:45,475 EPOCH 1046\n",
            "INFO:__main__:Epoch 1046: total training loss 0.00958\n",
            "2025-06-26 08:21:45,537 Epoch 1046: total training loss 0.00958\n",
            "INFO:__main__:EPOCH 1047\n",
            "2025-06-26 08:21:45,539 EPOCH 1047\n",
            "INFO:__main__:Epoch 1047: total training loss 0.00920\n",
            "2025-06-26 08:21:45,601 Epoch 1047: total training loss 0.00920\n",
            "INFO:__main__:EPOCH 1048\n",
            "2025-06-26 08:21:45,604 EPOCH 1048\n",
            "INFO:__main__:Epoch 1048: total training loss 0.00968\n",
            "2025-06-26 08:21:45,669 Epoch 1048: total training loss 0.00968\n",
            "INFO:__main__:EPOCH 1049\n",
            "2025-06-26 08:21:45,671 EPOCH 1049\n",
            "INFO:__main__:Epoch 1049: total training loss 0.01002\n",
            "2025-06-26 08:21:45,736 Epoch 1049: total training loss 0.01002\n",
            "INFO:__main__:EPOCH 1050\n",
            "2025-06-26 08:21:45,738 EPOCH 1050\n",
            "INFO:__main__:Epoch 1050: total training loss 0.00955\n",
            "2025-06-26 08:21:45,802 Epoch 1050: total training loss 0.00955\n",
            "INFO:__main__:EPOCH 1051\n",
            "2025-06-26 08:21:45,804 EPOCH 1051\n",
            "INFO:__main__:Epoch 1051: total training loss 0.00959\n",
            "2025-06-26 08:21:45,866 Epoch 1051: total training loss 0.00959\n",
            "INFO:__main__:EPOCH 1052\n",
            "2025-06-26 08:21:45,868 EPOCH 1052\n",
            "INFO:__main__:Epoch 1052: total training loss 0.00922\n",
            "2025-06-26 08:21:45,930 Epoch 1052: total training loss 0.00922\n",
            "INFO:__main__:EPOCH 1053\n",
            "2025-06-26 08:21:45,932 EPOCH 1053\n",
            "INFO:__main__:Epoch 1053: total training loss 0.00931\n",
            "2025-06-26 08:21:45,996 Epoch 1053: total training loss 0.00931\n",
            "INFO:__main__:EPOCH 1054\n",
            "2025-06-26 08:21:45,998 EPOCH 1054\n",
            "INFO:__main__:Epoch 1054: total training loss 0.01006\n",
            "2025-06-26 08:21:46,067 Epoch 1054: total training loss 0.01006\n",
            "INFO:__main__:EPOCH 1055\n",
            "2025-06-26 08:21:46,069 EPOCH 1055\n",
            "INFO:__main__:Epoch 1055: total training loss 0.00987\n",
            "2025-06-26 08:21:46,142 Epoch 1055: total training loss 0.00987\n",
            "INFO:__main__:EPOCH 1056\n",
            "2025-06-26 08:21:46,145 EPOCH 1056\n",
            "INFO:__main__:Epoch 1056: total training loss 0.00925\n",
            "2025-06-26 08:21:46,237 Epoch 1056: total training loss 0.00925\n",
            "INFO:__main__:EPOCH 1057\n",
            "2025-06-26 08:21:46,239 EPOCH 1057\n",
            "INFO:__main__:Epoch 1057: total training loss 0.00960\n",
            "2025-06-26 08:21:46,306 Epoch 1057: total training loss 0.00960\n",
            "INFO:__main__:EPOCH 1058\n",
            "2025-06-26 08:21:46,309 EPOCH 1058\n",
            "INFO:__main__:Epoch 1058: total training loss 0.00981\n",
            "2025-06-26 08:21:46,371 Epoch 1058: total training loss 0.00981\n",
            "INFO:__main__:EPOCH 1059\n",
            "2025-06-26 08:21:46,373 EPOCH 1059\n",
            "INFO:__main__:Epoch 1059: total training loss 0.00957\n",
            "2025-06-26 08:21:46,439 Epoch 1059: total training loss 0.00957\n",
            "INFO:__main__:EPOCH 1060\n",
            "2025-06-26 08:21:46,441 EPOCH 1060\n",
            "INFO:__main__:Epoch 1060: total training loss 0.00967\n",
            "2025-06-26 08:21:46,507 Epoch 1060: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 1061\n",
            "2025-06-26 08:21:46,509 EPOCH 1061\n",
            "INFO:__main__:Epoch 1061: total training loss 0.00972\n",
            "2025-06-26 08:21:46,572 Epoch 1061: total training loss 0.00972\n",
            "INFO:__main__:EPOCH 1062\n",
            "2025-06-26 08:21:46,574 EPOCH 1062\n",
            "INFO:__main__:Epoch 1062: total training loss 0.00930\n",
            "2025-06-26 08:21:46,635 Epoch 1062: total training loss 0.00930\n",
            "INFO:__main__:EPOCH 1063\n",
            "2025-06-26 08:21:46,638 EPOCH 1063\n",
            "INFO:__main__:Epoch 1063: total training loss 0.00934\n",
            "2025-06-26 08:21:46,700 Epoch 1063: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1064\n",
            "2025-06-26 08:21:46,702 EPOCH 1064\n",
            "INFO:__main__:Epoch 1064: total training loss 0.00911\n",
            "2025-06-26 08:21:46,767 Epoch 1064: total training loss 0.00911\n",
            "INFO:__main__:EPOCH 1065\n",
            "2025-06-26 08:21:46,769 EPOCH 1065\n",
            "INFO:__main__:Epoch 1065: total training loss 0.00916\n",
            "2025-06-26 08:21:46,834 Epoch 1065: total training loss 0.00916\n",
            "INFO:__main__:EPOCH 1066\n",
            "2025-06-26 08:21:46,836 EPOCH 1066\n",
            "INFO:__main__:Epoch 1066: total training loss 0.00986\n",
            "2025-06-26 08:21:46,896 Epoch 1066: total training loss 0.00986\n",
            "INFO:__main__:EPOCH 1067\n",
            "2025-06-26 08:21:46,898 EPOCH 1067\n",
            "INFO:__main__:Epoch 1067: total training loss 0.01004\n",
            "2025-06-26 08:21:46,962 Epoch 1067: total training loss 0.01004\n",
            "INFO:__main__:EPOCH 1068\n",
            "2025-06-26 08:21:46,964 EPOCH 1068\n",
            "INFO:__main__:Epoch 1068: total training loss 0.00952\n",
            "2025-06-26 08:21:47,032 Epoch 1068: total training loss 0.00952\n",
            "INFO:__main__:EPOCH 1069\n",
            "2025-06-26 08:21:47,033 EPOCH 1069\n",
            "INFO:__main__:Epoch 1069: total training loss 0.00950\n",
            "2025-06-26 08:21:47,095 Epoch 1069: total training loss 0.00950\n",
            "INFO:__main__:EPOCH 1070\n",
            "2025-06-26 08:21:47,097 EPOCH 1070\n",
            "INFO:__main__:Epoch 1070: total training loss 0.00950\n",
            "2025-06-26 08:21:47,156 Epoch 1070: total training loss 0.00950\n",
            "INFO:__main__:EPOCH 1071\n",
            "2025-06-26 08:21:47,158 EPOCH 1071\n",
            "INFO:__main__:Epoch 1071: total training loss 0.00985\n",
            "2025-06-26 08:21:47,238 Epoch 1071: total training loss 0.00985\n",
            "INFO:__main__:EPOCH 1072\n",
            "2025-06-26 08:21:47,241 EPOCH 1072\n",
            "INFO:__main__:Epoch 1072: total training loss 0.00985\n",
            "2025-06-26 08:21:47,308 Epoch 1072: total training loss 0.00985\n",
            "INFO:__main__:EPOCH 1073\n",
            "2025-06-26 08:21:47,310 EPOCH 1073\n",
            "INFO:__main__:Epoch 1073: total training loss 0.00935\n",
            "2025-06-26 08:21:47,370 Epoch 1073: total training loss 0.00935\n",
            "INFO:__main__:EPOCH 1074\n",
            "2025-06-26 08:21:47,372 EPOCH 1074\n",
            "INFO:__main__:Epoch 1074: total training loss 0.00922\n",
            "2025-06-26 08:21:47,432 Epoch 1074: total training loss 0.00922\n",
            "INFO:__main__:EPOCH 1075\n",
            "2025-06-26 08:21:47,435 EPOCH 1075\n",
            "INFO:__main__:Epoch 1075: total training loss 0.01009\n",
            "2025-06-26 08:21:47,497 Epoch 1075: total training loss 0.01009\n",
            "INFO:__main__:EPOCH 1076\n",
            "2025-06-26 08:21:47,499 EPOCH 1076\n",
            "INFO:__main__:Epoch 1076: total training loss 0.00977\n",
            "2025-06-26 08:21:47,566 Epoch 1076: total training loss 0.00977\n",
            "INFO:__main__:EPOCH 1077\n",
            "2025-06-26 08:21:47,568 EPOCH 1077\n",
            "INFO:__main__:Epoch 1077: total training loss 0.00973\n",
            "2025-06-26 08:21:47,633 Epoch 1077: total training loss 0.00973\n",
            "INFO:__main__:EPOCH 1078\n",
            "2025-06-26 08:21:47,635 EPOCH 1078\n",
            "INFO:__main__:Epoch 1078: total training loss 0.00940\n",
            "2025-06-26 08:21:47,695 Epoch 1078: total training loss 0.00940\n",
            "INFO:__main__:EPOCH 1079\n",
            "2025-06-26 08:21:47,698 EPOCH 1079\n",
            "INFO:__main__:Epoch 1079: total training loss 0.01006\n",
            "2025-06-26 08:21:47,764 Epoch 1079: total training loss 0.01006\n",
            "INFO:__main__:EPOCH 1080\n",
            "2025-06-26 08:21:47,766 EPOCH 1080\n",
            "INFO:__main__:Epoch 1080: total training loss 0.00894\n",
            "2025-06-26 08:21:47,830 Epoch 1080: total training loss 0.00894\n",
            "INFO:__main__:EPOCH 1081\n",
            "2025-06-26 08:21:47,832 EPOCH 1081\n",
            "INFO:__main__:Epoch 1081: total training loss 0.00936\n",
            "2025-06-26 08:21:47,895 Epoch 1081: total training loss 0.00936\n",
            "INFO:__main__:EPOCH 1082\n",
            "2025-06-26 08:21:47,897 EPOCH 1082\n",
            "INFO:__main__:Epoch 1082: total training loss 0.00986\n",
            "2025-06-26 08:21:47,957 Epoch 1082: total training loss 0.00986\n",
            "INFO:__main__:EPOCH 1083\n",
            "2025-06-26 08:21:47,959 EPOCH 1083\n",
            "INFO:__main__:Epoch 1083: total training loss 0.01001\n",
            "2025-06-26 08:21:48,021 Epoch 1083: total training loss 0.01001\n",
            "INFO:__main__:EPOCH 1084\n",
            "2025-06-26 08:21:48,023 EPOCH 1084\n",
            "INFO:__main__:Epoch 1084: total training loss 0.00927\n",
            "2025-06-26 08:21:48,089 Epoch 1084: total training loss 0.00927\n",
            "INFO:__main__:EPOCH 1085\n",
            "2025-06-26 08:21:48,091 EPOCH 1085\n",
            "INFO:__main__:Epoch 1085: total training loss 0.00915\n",
            "2025-06-26 08:21:48,153 Epoch 1085: total training loss 0.00915\n",
            "INFO:__main__:EPOCH 1086\n",
            "2025-06-26 08:21:48,156 EPOCH 1086\n",
            "INFO:__main__:Epoch 1086: total training loss 0.00948\n",
            "2025-06-26 08:21:48,223 Epoch 1086: total training loss 0.00948\n",
            "INFO:__main__:EPOCH 1087\n",
            "2025-06-26 08:21:48,225 EPOCH 1087\n",
            "INFO:__main__:Epoch 1087: total training loss 0.00900\n",
            "2025-06-26 08:21:48,309 Epoch 1087: total training loss 0.00900\n",
            "INFO:__main__:EPOCH 1088\n",
            "2025-06-26 08:21:48,311 EPOCH 1088\n",
            "INFO:__main__:Epoch 1088: total training loss 0.00907\n",
            "2025-06-26 08:21:48,372 Epoch 1088: total training loss 0.00907\n",
            "INFO:__main__:EPOCH 1089\n",
            "2025-06-26 08:21:48,374 EPOCH 1089\n",
            "INFO:__main__:Epoch 1089: total training loss 0.00958\n",
            "2025-06-26 08:21:48,439 Epoch 1089: total training loss 0.00958\n",
            "INFO:__main__:EPOCH 1090\n",
            "2025-06-26 08:21:48,441 EPOCH 1090\n",
            "INFO:__main__:Epoch 1090: total training loss 0.00885\n",
            "2025-06-26 08:21:48,508 Epoch 1090: total training loss 0.00885\n",
            "INFO:__main__:EPOCH 1091\n",
            "2025-06-26 08:21:48,510 EPOCH 1091\n",
            "INFO:__main__:Epoch 1091: total training loss 0.00986\n",
            "2025-06-26 08:21:48,573 Epoch 1091: total training loss 0.00986\n",
            "INFO:__main__:EPOCH 1092\n",
            "2025-06-26 08:21:48,575 EPOCH 1092\n",
            "INFO:__main__:Epoch 1092: total training loss 0.00985\n",
            "2025-06-26 08:21:48,638 Epoch 1092: total training loss 0.00985\n",
            "INFO:__main__:EPOCH 1093\n",
            "2025-06-26 08:21:48,640 EPOCH 1093\n",
            "INFO:__main__:Epoch 1093: total training loss 0.00934\n",
            "2025-06-26 08:21:48,700 Epoch 1093: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1094\n",
            "2025-06-26 08:21:48,702 EPOCH 1094\n",
            "INFO:__main__:Epoch 1094: total training loss 0.00933\n",
            "2025-06-26 08:21:48,769 Epoch 1094: total training loss 0.00933\n",
            "INFO:__main__:EPOCH 1095\n",
            "2025-06-26 08:21:48,772 EPOCH 1095\n",
            "INFO:__main__:Epoch 1095: total training loss 0.00962\n",
            "2025-06-26 08:21:48,834 Epoch 1095: total training loss 0.00962\n",
            "INFO:__main__:EPOCH 1096\n",
            "2025-06-26 08:21:48,836 EPOCH 1096\n",
            "INFO:__main__:Epoch 1096: total training loss 0.01014\n",
            "2025-06-26 08:21:48,900 Epoch 1096: total training loss 0.01014\n",
            "INFO:__main__:EPOCH 1097\n",
            "2025-06-26 08:21:48,903 EPOCH 1097\n",
            "INFO:__main__:Epoch 1097: total training loss 0.01020\n",
            "2025-06-26 08:21:48,966 Epoch 1097: total training loss 0.01020\n",
            "INFO:__main__:EPOCH 1098\n",
            "2025-06-26 08:21:48,968 EPOCH 1098\n",
            "INFO:__main__:Epoch 1098: total training loss 0.00994\n",
            "2025-06-26 08:21:49,037 Epoch 1098: total training loss 0.00994\n",
            "INFO:__main__:EPOCH 1099\n",
            "2025-06-26 08:21:49,040 EPOCH 1099\n",
            "INFO:__main__:Epoch 1099: total training loss 0.00935\n",
            "2025-06-26 08:21:49,122 Epoch 1099: total training loss 0.00935\n",
            "INFO:__main__:EPOCH 1100\n",
            "2025-06-26 08:21:49,125 EPOCH 1100\n",
            "INFO:__main__:Epoch 1100: total training loss 0.00968\n",
            "2025-06-26 08:21:49,195 Epoch 1100: total training loss 0.00968\n",
            "INFO:__main__:EPOCH 1101\n",
            "2025-06-26 08:21:49,197 EPOCH 1101\n",
            "INFO:__main__:Epoch 1101: total training loss 0.00962\n",
            "2025-06-26 08:21:49,258 Epoch 1101: total training loss 0.00962\n",
            "INFO:__main__:EPOCH 1102\n",
            "2025-06-26 08:21:49,263 EPOCH 1102\n",
            "INFO:__main__:Epoch 1102: total training loss 0.00992\n",
            "2025-06-26 08:21:49,342 Epoch 1102: total training loss 0.00992\n",
            "INFO:__main__:EPOCH 1103\n",
            "2025-06-26 08:21:49,344 EPOCH 1103\n",
            "INFO:__main__:Epoch 1103: total training loss 0.00935\n",
            "2025-06-26 08:21:49,407 Epoch 1103: total training loss 0.00935\n",
            "INFO:__main__:EPOCH 1104\n",
            "2025-06-26 08:21:49,409 EPOCH 1104\n",
            "INFO:__main__:Epoch 1104: total training loss 0.00946\n",
            "2025-06-26 08:21:49,470 Epoch 1104: total training loss 0.00946\n",
            "INFO:__main__:EPOCH 1105\n",
            "2025-06-26 08:21:49,472 EPOCH 1105\n",
            "INFO:__main__:Epoch 1105: total training loss 0.00962\n",
            "2025-06-26 08:21:49,533 Epoch 1105: total training loss 0.00962\n",
            "INFO:__main__:EPOCH 1106\n",
            "2025-06-26 08:21:49,535 EPOCH 1106\n",
            "INFO:__main__:Epoch 1106: total training loss 0.00936\n",
            "2025-06-26 08:21:49,598 Epoch 1106: total training loss 0.00936\n",
            "INFO:__main__:EPOCH 1107\n",
            "2025-06-26 08:21:49,600 EPOCH 1107\n",
            "INFO:__main__:Epoch 1107: total training loss 0.00939\n",
            "2025-06-26 08:21:49,662 Epoch 1107: total training loss 0.00939\n",
            "INFO:__main__:EPOCH 1108\n",
            "2025-06-26 08:21:49,665 EPOCH 1108\n",
            "INFO:__main__:Epoch 1108: total training loss 0.00924\n",
            "2025-06-26 08:21:49,726 Epoch 1108: total training loss 0.00924\n",
            "INFO:__main__:EPOCH 1109\n",
            "2025-06-26 08:21:49,728 EPOCH 1109\n",
            "INFO:__main__:Epoch 1109: total training loss 0.00925\n",
            "2025-06-26 08:21:49,796 Epoch 1109: total training loss 0.00925\n",
            "INFO:__main__:EPOCH 1110\n",
            "2025-06-26 08:21:49,799 EPOCH 1110\n",
            "INFO:__main__:Epoch 1110: total training loss 0.00964\n",
            "2025-06-26 08:21:49,859 Epoch 1110: total training loss 0.00964\n",
            "INFO:__main__:EPOCH 1111\n",
            "2025-06-26 08:21:49,861 EPOCH 1111\n",
            "INFO:__main__:Epoch 1111: total training loss 0.00944\n",
            "2025-06-26 08:21:49,925 Epoch 1111: total training loss 0.00944\n",
            "INFO:__main__:EPOCH 1112\n",
            "2025-06-26 08:21:49,928 EPOCH 1112\n",
            "INFO:__main__:Epoch 1112: total training loss 0.00852\n",
            "2025-06-26 08:21:49,994 Epoch 1112: total training loss 0.00852\n",
            "INFO:__main__:EPOCH 1113\n",
            "2025-06-26 08:21:49,996 EPOCH 1113\n",
            "INFO:__main__:Epoch 1113: total training loss 0.00975\n",
            "2025-06-26 08:21:50,056 Epoch 1113: total training loss 0.00975\n",
            "INFO:__main__:EPOCH 1114\n",
            "2025-06-26 08:21:50,058 EPOCH 1114\n",
            "INFO:__main__:Epoch 1114: total training loss 0.00918\n",
            "2025-06-26 08:21:50,118 Epoch 1114: total training loss 0.00918\n",
            "INFO:__main__:EPOCH 1115\n",
            "2025-06-26 08:21:50,120 EPOCH 1115\n",
            "INFO:__main__:Epoch 1115: total training loss 0.00964\n",
            "2025-06-26 08:21:50,182 Epoch 1115: total training loss 0.00964\n",
            "INFO:__main__:EPOCH 1116\n",
            "2025-06-26 08:21:50,187 EPOCH 1116\n",
            "INFO:__main__:Epoch 1116: total training loss 0.00916\n",
            "2025-06-26 08:21:50,253 Epoch 1116: total training loss 0.00916\n",
            "INFO:__main__:EPOCH 1117\n",
            "2025-06-26 08:21:50,256 EPOCH 1117\n",
            "INFO:__main__:Epoch 1117: total training loss 0.00919\n",
            "2025-06-26 08:21:50,318 Epoch 1117: total training loss 0.00919\n",
            "INFO:__main__:EPOCH 1118\n",
            "2025-06-26 08:21:50,321 EPOCH 1118\n",
            "INFO:__main__:Epoch 1118: total training loss 0.00920\n",
            "2025-06-26 08:21:50,405 Epoch 1118: total training loss 0.00920\n",
            "INFO:__main__:EPOCH 1119\n",
            "2025-06-26 08:21:50,407 EPOCH 1119\n",
            "INFO:__main__:Epoch 1119: total training loss 0.00934\n",
            "2025-06-26 08:21:50,469 Epoch 1119: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1120\n",
            "2025-06-26 08:21:50,471 EPOCH 1120\n",
            "INFO:__main__:Epoch 1120: total training loss 0.00892\n",
            "2025-06-26 08:21:50,535 Epoch 1120: total training loss 0.00892\n",
            "INFO:__main__:EPOCH 1121\n",
            "2025-06-26 08:21:50,537 EPOCH 1121\n",
            "INFO:__main__:Epoch 1121: total training loss 0.00883\n",
            "2025-06-26 08:21:50,600 Epoch 1121: total training loss 0.00883\n",
            "INFO:__main__:EPOCH 1122\n",
            "2025-06-26 08:21:50,602 EPOCH 1122\n",
            "INFO:__main__:Epoch 1122: total training loss 0.00934\n",
            "2025-06-26 08:21:50,665 Epoch 1122: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1123\n",
            "2025-06-26 08:21:50,667 EPOCH 1123\n",
            "INFO:__main__:Epoch 1123: total training loss 0.00858\n",
            "2025-06-26 08:21:50,728 Epoch 1123: total training loss 0.00858\n",
            "INFO:__main__:EPOCH 1124\n",
            "2025-06-26 08:21:50,730 EPOCH 1124\n",
            "INFO:__main__:Epoch 1124: total training loss 0.00934\n",
            "2025-06-26 08:21:50,797 Epoch 1124: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1125\n",
            "2025-06-26 08:21:50,799 EPOCH 1125\n",
            "INFO:__main__:Epoch 1125: total training loss 0.00914\n",
            "2025-06-26 08:21:50,863 Epoch 1125: total training loss 0.00914\n",
            "INFO:__main__:EPOCH 1126\n",
            "2025-06-26 08:21:50,865 EPOCH 1126\n",
            "INFO:__main__:Epoch 1126: total training loss 0.00884\n",
            "2025-06-26 08:21:50,930 Epoch 1126: total training loss 0.00884\n",
            "INFO:__main__:EPOCH 1127\n",
            "2025-06-26 08:21:50,932 EPOCH 1127\n",
            "INFO:__main__:Epoch 1127: total training loss 0.00867\n",
            "2025-06-26 08:21:50,993 Epoch 1127: total training loss 0.00867\n",
            "INFO:__main__:EPOCH 1128\n",
            "2025-06-26 08:21:50,995 EPOCH 1128\n",
            "INFO:__main__:Epoch 1128: total training loss 0.00967\n",
            "2025-06-26 08:21:51,060 Epoch 1128: total training loss 0.00967\n",
            "INFO:__main__:EPOCH 1129\n",
            "2025-06-26 08:21:51,062 EPOCH 1129\n",
            "INFO:__main__:Epoch 1129: total training loss 0.00930\n",
            "2025-06-26 08:21:51,125 Epoch 1129: total training loss 0.00930\n",
            "INFO:__main__:EPOCH 1130\n",
            "2025-06-26 08:21:51,127 EPOCH 1130\n",
            "INFO:__main__:Epoch 1130: total training loss 0.00912\n",
            "2025-06-26 08:21:51,191 Epoch 1130: total training loss 0.00912\n",
            "INFO:__main__:EPOCH 1131\n",
            "2025-06-26 08:21:51,193 EPOCH 1131\n",
            "INFO:__main__:Epoch 1131: total training loss 0.00920\n",
            "2025-06-26 08:21:51,258 Epoch 1131: total training loss 0.00920\n",
            "INFO:__main__:EPOCH 1132\n",
            "2025-06-26 08:21:51,260 EPOCH 1132\n",
            "INFO:__main__:Epoch 1132: total training loss 0.00936\n",
            "2025-06-26 08:21:51,326 Epoch 1132: total training loss 0.00936\n",
            "INFO:__main__:EPOCH 1133\n",
            "2025-06-26 08:21:51,328 EPOCH 1133\n",
            "INFO:__main__:Epoch 1133: total training loss 0.00918\n",
            "2025-06-26 08:21:51,391 Epoch 1133: total training loss 0.00918\n",
            "INFO:__main__:EPOCH 1134\n",
            "2025-06-26 08:21:51,394 EPOCH 1134\n",
            "INFO:__main__:Epoch 1134: total training loss 0.00957\n",
            "2025-06-26 08:21:51,471 Epoch 1134: total training loss 0.00957\n",
            "INFO:__main__:EPOCH 1135\n",
            "2025-06-26 08:21:51,473 EPOCH 1135\n",
            "INFO:__main__:Epoch 1135: total training loss 0.00923\n",
            "2025-06-26 08:21:51,537 Epoch 1135: total training loss 0.00923\n",
            "INFO:__main__:EPOCH 1136\n",
            "2025-06-26 08:21:51,539 EPOCH 1136\n",
            "INFO:__main__:Epoch 1136: total training loss 0.00929\n",
            "2025-06-26 08:21:51,602 Epoch 1136: total training loss 0.00929\n",
            "INFO:__main__:EPOCH 1137\n",
            "2025-06-26 08:21:51,604 EPOCH 1137\n",
            "INFO:__main__:Epoch 1137: total training loss 0.00984\n",
            "2025-06-26 08:21:51,665 Epoch 1137: total training loss 0.00984\n",
            "INFO:__main__:EPOCH 1138\n",
            "2025-06-26 08:21:51,667 EPOCH 1138\n",
            "INFO:__main__:Epoch 1138: total training loss 0.00968\n",
            "2025-06-26 08:21:51,730 Epoch 1138: total training loss 0.00968\n",
            "INFO:__main__:EPOCH 1139\n",
            "2025-06-26 08:21:51,732 EPOCH 1139\n",
            "INFO:__main__:Epoch 1139: total training loss 0.00883\n",
            "2025-06-26 08:21:51,797 Epoch 1139: total training loss 0.00883\n",
            "INFO:__main__:EPOCH 1140\n",
            "2025-06-26 08:21:51,799 EPOCH 1140\n",
            "INFO:__main__:Epoch 1140: total training loss 0.00937\n",
            "2025-06-26 08:21:51,863 Epoch 1140: total training loss 0.00937\n",
            "INFO:__main__:EPOCH 1141\n",
            "2025-06-26 08:21:51,865 EPOCH 1141\n",
            "INFO:__main__:Epoch 1141: total training loss 0.00939\n",
            "2025-06-26 08:21:51,929 Epoch 1141: total training loss 0.00939\n",
            "INFO:__main__:EPOCH 1142\n",
            "2025-06-26 08:21:51,931 EPOCH 1142\n",
            "INFO:__main__:Epoch 1142: total training loss 0.00991\n",
            "2025-06-26 08:21:51,992 Epoch 1142: total training loss 0.00991\n",
            "INFO:__main__:EPOCH 1143\n",
            "2025-06-26 08:21:51,994 EPOCH 1143\n",
            "INFO:__main__:Epoch 1143: total training loss 0.00965\n",
            "2025-06-26 08:21:52,057 Epoch 1143: total training loss 0.00965\n",
            "INFO:__main__:EPOCH 1144\n",
            "2025-06-26 08:21:52,059 EPOCH 1144\n",
            "INFO:__main__:Epoch 1144: total training loss 0.00923\n",
            "2025-06-26 08:21:52,126 Epoch 1144: total training loss 0.00923\n",
            "INFO:__main__:EPOCH 1145\n",
            "2025-06-26 08:21:52,128 EPOCH 1145\n",
            "INFO:__main__:Epoch 1145: total training loss 0.00941\n",
            "2025-06-26 08:21:52,197 Epoch 1145: total training loss 0.00941\n",
            "INFO:__main__:EPOCH 1146\n",
            "2025-06-26 08:21:52,200 EPOCH 1146\n",
            "INFO:__main__:Epoch 1146: total training loss 0.00849\n",
            "2025-06-26 08:21:52,265 Epoch 1146: total training loss 0.00849\n",
            "INFO:__main__:EPOCH 1147\n",
            "2025-06-26 08:21:52,267 EPOCH 1147\n",
            "INFO:__main__:Epoch 1147: total training loss 0.00898\n",
            "2025-06-26 08:21:52,331 Epoch 1147: total training loss 0.00898\n",
            "INFO:__main__:EPOCH 1148\n",
            "2025-06-26 08:21:52,333 EPOCH 1148\n",
            "INFO:__main__:Epoch 1148: total training loss 0.00888\n",
            "2025-06-26 08:21:52,395 Epoch 1148: total training loss 0.00888\n",
            "INFO:__main__:EPOCH 1149\n",
            "2025-06-26 08:21:52,397 EPOCH 1149\n",
            "INFO:__main__:Epoch 1149: total training loss 0.00902\n",
            "2025-06-26 08:21:52,480 Epoch 1149: total training loss 0.00902\n",
            "INFO:__main__:EPOCH 1150\n",
            "2025-06-26 08:21:52,482 EPOCH 1150\n",
            "INFO:__main__:Epoch 1150: total training loss 0.00896\n",
            "2025-06-26 08:21:52,547 Epoch 1150: total training loss 0.00896\n",
            "INFO:__main__:EPOCH 1151\n",
            "2025-06-26 08:21:52,549 EPOCH 1151\n",
            "INFO:__main__:Epoch 1151: total training loss 0.00915\n",
            "2025-06-26 08:21:52,612 Epoch 1151: total training loss 0.00915\n",
            "INFO:__main__:EPOCH 1152\n",
            "2025-06-26 08:21:52,614 EPOCH 1152\n",
            "INFO:__main__:Epoch 1152: total training loss 0.00911\n",
            "2025-06-26 08:21:52,675 Epoch 1152: total training loss 0.00911\n",
            "INFO:__main__:EPOCH 1153\n",
            "2025-06-26 08:21:52,677 EPOCH 1153\n",
            "INFO:__main__:Epoch 1153: total training loss 0.00905\n",
            "2025-06-26 08:21:52,740 Epoch 1153: total training loss 0.00905\n",
            "INFO:__main__:EPOCH 1154\n",
            "2025-06-26 08:21:52,742 EPOCH 1154\n",
            "INFO:__main__:Epoch 1154: total training loss 0.00838\n",
            "2025-06-26 08:21:52,806 Epoch 1154: total training loss 0.00838\n",
            "INFO:__main__:EPOCH 1155\n",
            "2025-06-26 08:21:52,808 EPOCH 1155\n",
            "INFO:__main__:Epoch 1155: total training loss 0.00922\n",
            "2025-06-26 08:21:52,872 Epoch 1155: total training loss 0.00922\n",
            "INFO:__main__:EPOCH 1156\n",
            "2025-06-26 08:21:52,874 EPOCH 1156\n",
            "INFO:__main__:Epoch 1156: total training loss 0.00934\n",
            "2025-06-26 08:21:52,939 Epoch 1156: total training loss 0.00934\n",
            "INFO:__main__:EPOCH 1157\n",
            "2025-06-26 08:21:52,941 EPOCH 1157\n",
            "INFO:__main__:Epoch 1157: total training loss 0.00881\n",
            "2025-06-26 08:21:53,006 Epoch 1157: total training loss 0.00881\n",
            "INFO:__main__:EPOCH 1158\n",
            "2025-06-26 08:21:53,009 EPOCH 1158\n",
            "INFO:__main__:Epoch 1158: total training loss 0.00867\n",
            "2025-06-26 08:21:53,076 Epoch 1158: total training loss 0.00867\n",
            "INFO:__main__:EPOCH 1159\n",
            "2025-06-26 08:21:53,078 EPOCH 1159\n",
            "INFO:__main__:Epoch 1159: total training loss 0.00842\n",
            "2025-06-26 08:21:53,144 Epoch 1159: total training loss 0.00842\n",
            "INFO:__main__:EPOCH 1160\n",
            "2025-06-26 08:21:53,146 EPOCH 1160\n",
            "INFO:__main__:Epoch 1160: total training loss 0.00894\n",
            "2025-06-26 08:21:53,219 Epoch 1160: total training loss 0.00894\n",
            "INFO:__main__:EPOCH 1161\n",
            "2025-06-26 08:21:53,221 EPOCH 1161\n",
            "INFO:__main__:Epoch 1161: total training loss 0.00898\n",
            "2025-06-26 08:21:53,287 Epoch 1161: total training loss 0.00898\n",
            "INFO:__main__:EPOCH 1162\n",
            "2025-06-26 08:21:53,289 EPOCH 1162\n",
            "INFO:__main__:Epoch 1162: total training loss 0.00890\n",
            "2025-06-26 08:21:53,352 Epoch 1162: total training loss 0.00890\n",
            "INFO:__main__:EPOCH 1163\n",
            "2025-06-26 08:21:53,354 EPOCH 1163\n",
            "INFO:__main__:Epoch 1163: total training loss 0.00844\n",
            "2025-06-26 08:21:53,416 Epoch 1163: total training loss 0.00844\n",
            "INFO:__main__:EPOCH 1164\n",
            "2025-06-26 08:21:53,418 EPOCH 1164\n",
            "INFO:__main__:Epoch 1164: total training loss 0.00793\n",
            "2025-06-26 08:21:53,483 Epoch 1164: total training loss 0.00793\n",
            "INFO:__main__:EPOCH 1165\n",
            "2025-06-26 08:21:53,488 EPOCH 1165\n",
            "INFO:__main__:Epoch 1165: total training loss 0.00938\n",
            "2025-06-26 08:21:53,566 Epoch 1165: total training loss 0.00938\n",
            "INFO:__main__:EPOCH 1166\n",
            "2025-06-26 08:21:53,568 EPOCH 1166\n",
            "INFO:__main__:Epoch 1166: total training loss 0.00926\n",
            "2025-06-26 08:21:53,631 Epoch 1166: total training loss 0.00926\n",
            "INFO:__main__:EPOCH 1167\n",
            "2025-06-26 08:21:53,634 EPOCH 1167\n",
            "INFO:__main__:Epoch 1167: total training loss 0.00898\n",
            "2025-06-26 08:21:53,700 Epoch 1167: total training loss 0.00898\n",
            "INFO:__main__:EPOCH 1168\n",
            "2025-06-26 08:21:53,701 EPOCH 1168\n",
            "INFO:__main__:Epoch 1168: total training loss 0.00893\n",
            "2025-06-26 08:21:53,766 Epoch 1168: total training loss 0.00893\n",
            "INFO:__main__:EPOCH 1169\n",
            "2025-06-26 08:21:53,768 EPOCH 1169\n",
            "INFO:__main__:Epoch 1169: total training loss 0.00890\n",
            "2025-06-26 08:21:53,844 Epoch 1169: total training loss 0.00890\n",
            "INFO:__main__:EPOCH 1170\n",
            "2025-06-26 08:21:53,846 EPOCH 1170\n",
            "INFO:__main__:Epoch 1170: total training loss 0.00840\n",
            "2025-06-26 08:21:53,930 Epoch 1170: total training loss 0.00840\n",
            "INFO:__main__:EPOCH 1171\n",
            "2025-06-26 08:21:53,931 EPOCH 1171\n",
            "INFO:__main__:Epoch 1171: total training loss 0.00861\n",
            "2025-06-26 08:21:54,018 Epoch 1171: total training loss 0.00861\n",
            "INFO:__main__:EPOCH 1172\n",
            "2025-06-26 08:21:54,020 EPOCH 1172\n",
            "INFO:__main__:Epoch 1172: total training loss 0.00878\n",
            "2025-06-26 08:21:54,105 Epoch 1172: total training loss 0.00878\n",
            "INFO:__main__:EPOCH 1173\n",
            "2025-06-26 08:21:54,107 EPOCH 1173\n",
            "INFO:__main__:Epoch 1173: total training loss 0.00893\n",
            "2025-06-26 08:21:54,187 Epoch 1173: total training loss 0.00893\n",
            "INFO:__main__:EPOCH 1174\n",
            "2025-06-26 08:21:54,190 EPOCH 1174\n",
            "INFO:__main__:Epoch 1174: total training loss 0.00910\n",
            "2025-06-26 08:21:54,280 Epoch 1174: total training loss 0.00910\n",
            "INFO:__main__:EPOCH 1175\n",
            "2025-06-26 08:21:54,282 EPOCH 1175\n",
            "INFO:__main__:Epoch 1175: total training loss 0.00895\n",
            "2025-06-26 08:21:54,370 Epoch 1175: total training loss 0.00895\n",
            "INFO:__main__:EPOCH 1176\n",
            "2025-06-26 08:21:54,372 EPOCH 1176\n",
            "INFO:__main__:Epoch 1176: total training loss 0.00863\n",
            "2025-06-26 08:21:54,462 Epoch 1176: total training loss 0.00863\n",
            "INFO:__main__:EPOCH 1177\n",
            "2025-06-26 08:21:54,469 EPOCH 1177\n",
            "INFO:__main__:Epoch 1177: total training loss 0.00910\n",
            "2025-06-26 08:21:54,581 Epoch 1177: total training loss 0.00910\n",
            "INFO:__main__:EPOCH 1178\n",
            "2025-06-26 08:21:54,583 EPOCH 1178\n",
            "INFO:__main__:Epoch 1178: total training loss 0.00798\n",
            "2025-06-26 08:21:54,673 Epoch 1178: total training loss 0.00798\n",
            "INFO:__main__:EPOCH 1179\n",
            "2025-06-26 08:21:54,676 EPOCH 1179\n",
            "INFO:__main__:Epoch 1179: total training loss 0.00862\n",
            "2025-06-26 08:21:54,775 Epoch 1179: total training loss 0.00862\n",
            "INFO:__main__:EPOCH 1180\n",
            "2025-06-26 08:21:54,777 EPOCH 1180\n",
            "INFO:__main__:Epoch 1180: total training loss 0.00910\n",
            "2025-06-26 08:21:54,861 Epoch 1180: total training loss 0.00910\n",
            "INFO:__main__:EPOCH 1181\n",
            "2025-06-26 08:21:54,863 EPOCH 1181\n",
            "INFO:__main__:Epoch 1181: total training loss 0.00919\n",
            "2025-06-26 08:21:54,955 Epoch 1181: total training loss 0.00919\n",
            "INFO:__main__:EPOCH 1182\n",
            "2025-06-26 08:21:54,957 EPOCH 1182\n",
            "INFO:__main__:Epoch 1182: total training loss 0.00801\n",
            "2025-06-26 08:21:55,042 Epoch 1182: total training loss 0.00801\n",
            "INFO:__main__:EPOCH 1183\n",
            "2025-06-26 08:21:55,044 EPOCH 1183\n",
            "INFO:__main__:Epoch 1183: total training loss 0.00900\n",
            "2025-06-26 08:21:55,127 Epoch 1183: total training loss 0.00900\n",
            "INFO:__main__:EPOCH 1184\n",
            "2025-06-26 08:21:55,131 EPOCH 1184\n",
            "INFO:__main__:Epoch 1184: total training loss 0.00886\n",
            "2025-06-26 08:21:55,238 Epoch 1184: total training loss 0.00886\n",
            "INFO:__main__:EPOCH 1185\n",
            "2025-06-26 08:21:55,241 EPOCH 1185\n",
            "INFO:__main__:Epoch 1185: total training loss 0.00915\n",
            "2025-06-26 08:21:55,346 Epoch 1185: total training loss 0.00915\n",
            "INFO:__main__:EPOCH 1186\n",
            "2025-06-26 08:21:55,348 EPOCH 1186\n",
            "INFO:__main__:Epoch 1186: total training loss 0.00883\n",
            "2025-06-26 08:21:55,429 Epoch 1186: total training loss 0.00883\n",
            "INFO:__main__:EPOCH 1187\n",
            "2025-06-26 08:21:55,432 EPOCH 1187\n",
            "INFO:__main__:Epoch 1187: total training loss 0.00852\n",
            "2025-06-26 08:21:55,522 Epoch 1187: total training loss 0.00852\n",
            "INFO:__main__:EPOCH 1188\n",
            "2025-06-26 08:21:55,523 EPOCH 1188\n",
            "INFO:__main__:Epoch 1188: total training loss 0.00860\n",
            "2025-06-26 08:21:55,629 Epoch 1188: total training loss 0.00860\n",
            "INFO:__main__:EPOCH 1189\n",
            "2025-06-26 08:21:55,631 EPOCH 1189\n",
            "INFO:__main__:Epoch 1189: total training loss 0.00867\n",
            "2025-06-26 08:21:55,714 Epoch 1189: total training loss 0.00867\n",
            "INFO:__main__:EPOCH 1190\n",
            "2025-06-26 08:21:55,716 EPOCH 1190\n",
            "INFO:__main__:Epoch 1190: total training loss 0.00876\n",
            "2025-06-26 08:21:55,805 Epoch 1190: total training loss 0.00876\n",
            "INFO:__main__:EPOCH 1191\n",
            "2025-06-26 08:21:55,809 EPOCH 1191\n",
            "INFO:__main__:Epoch 1191: total training loss 0.00856\n",
            "2025-06-26 08:21:55,880 Epoch 1191: total training loss 0.00856\n",
            "INFO:__main__:EPOCH 1192\n",
            "2025-06-26 08:21:55,882 EPOCH 1192\n",
            "INFO:__main__:Epoch 1192: total training loss 0.00858\n",
            "2025-06-26 08:21:55,961 Epoch 1192: total training loss 0.00858\n",
            "INFO:__main__:EPOCH 1193\n",
            "2025-06-26 08:21:55,964 EPOCH 1193\n",
            "INFO:__main__:Epoch 1193: total training loss 0.00862\n",
            "2025-06-26 08:21:56,040 Epoch 1193: total training loss 0.00862\n",
            "INFO:__main__:EPOCH 1194\n",
            "2025-06-26 08:21:56,043 EPOCH 1194\n",
            "INFO:__main__:Epoch 1194: total training loss 0.00952\n",
            "2025-06-26 08:21:56,116 Epoch 1194: total training loss 0.00952\n",
            "INFO:__main__:EPOCH 1195\n",
            "2025-06-26 08:21:56,118 EPOCH 1195\n",
            "INFO:__main__:Epoch 1195: total training loss 0.00862\n",
            "2025-06-26 08:21:56,194 Epoch 1195: total training loss 0.00862\n",
            "INFO:__main__:EPOCH 1196\n",
            "2025-06-26 08:21:56,196 EPOCH 1196\n",
            "INFO:__main__:Epoch 1196: total training loss 0.00914\n",
            "2025-06-26 08:21:56,278 Epoch 1196: total training loss 0.00914\n",
            "INFO:__main__:EPOCH 1197\n",
            "2025-06-26 08:21:56,282 EPOCH 1197\n",
            "INFO:__main__:Epoch 1197: total training loss 0.00924\n",
            "2025-06-26 08:21:56,368 Epoch 1197: total training loss 0.00924\n",
            "INFO:__main__:EPOCH 1198\n",
            "2025-06-26 08:21:56,373 EPOCH 1198\n",
            "INFO:__main__:Epoch 1198: total training loss 0.00886\n",
            "2025-06-26 08:21:56,451 Epoch 1198: total training loss 0.00886\n",
            "INFO:__main__:EPOCH 1199\n",
            "2025-06-26 08:21:56,453 EPOCH 1199\n",
            "INFO:__main__:Epoch 1199: total training loss 0.00868\n",
            "2025-06-26 08:21:56,533 Epoch 1199: total training loss 0.00868\n",
            "INFO:__main__:EPOCH 1200\n",
            "2025-06-26 08:21:56,536 EPOCH 1200\n",
            "INFO:__main__:Epoch 1200: total training loss 0.00898\n",
            "2025-06-26 08:21:56,627 Epoch 1200: total training loss 0.00898\n",
            "INFO:__main__:EPOCH 1201\n",
            "2025-06-26 08:21:56,629 EPOCH 1201\n",
            "INFO:__main__:Epoch 1201: total training loss 0.00821\n",
            "2025-06-26 08:21:56,743 Epoch 1201: total training loss 0.00821\n",
            "INFO:__main__:EPOCH 1202\n",
            "2025-06-26 08:21:56,745 EPOCH 1202\n",
            "INFO:__main__:Epoch 1202: total training loss 0.00895\n",
            "2025-06-26 08:21:56,829 Epoch 1202: total training loss 0.00895\n",
            "INFO:__main__:EPOCH 1203\n",
            "2025-06-26 08:21:56,839 EPOCH 1203\n",
            "INFO:__main__:Epoch 1203: total training loss 0.00835\n",
            "2025-06-26 08:21:56,920 Epoch 1203: total training loss 0.00835\n",
            "INFO:__main__:EPOCH 1204\n",
            "2025-06-26 08:21:56,922 EPOCH 1204\n",
            "INFO:__main__:Epoch 1204: total training loss 0.00906\n",
            "2025-06-26 08:21:57,016 Epoch 1204: total training loss 0.00906\n",
            "INFO:__main__:EPOCH 1205\n",
            "2025-06-26 08:21:57,018 EPOCH 1205\n",
            "INFO:__main__:Epoch 1205: total training loss 0.00834\n",
            "2025-06-26 08:21:57,111 Epoch 1205: total training loss 0.00834\n",
            "INFO:__main__:EPOCH 1206\n",
            "2025-06-26 08:21:57,113 EPOCH 1206\n",
            "INFO:__main__:Epoch 1206: total training loss 0.00870\n",
            "2025-06-26 08:21:57,208 Epoch 1206: total training loss 0.00870\n",
            "INFO:__main__:EPOCH 1207\n",
            "2025-06-26 08:21:57,210 EPOCH 1207\n",
            "INFO:__main__:Epoch 1207: total training loss 0.00860\n",
            "2025-06-26 08:21:57,310 Epoch 1207: total training loss 0.00860\n",
            "INFO:__main__:EPOCH 1208\n",
            "2025-06-26 08:21:57,313 EPOCH 1208\n",
            "INFO:__main__:Epoch 1208: total training loss 0.00877\n",
            "2025-06-26 08:21:57,410 Epoch 1208: total training loss 0.00877\n",
            "INFO:__main__:EPOCH 1209\n",
            "2025-06-26 08:21:57,413 EPOCH 1209\n",
            "INFO:__main__:Epoch 1209: total training loss 0.00889\n",
            "2025-06-26 08:21:57,504 Epoch 1209: total training loss 0.00889\n",
            "INFO:__main__:EPOCH 1210\n",
            "2025-06-26 08:21:57,506 EPOCH 1210\n",
            "INFO:__main__:Epoch 1210: total training loss 0.00886\n",
            "2025-06-26 08:21:57,582 Epoch 1210: total training loss 0.00886\n",
            "INFO:__main__:EPOCH 1211\n",
            "2025-06-26 08:21:57,585 EPOCH 1211\n",
            "INFO:__main__:Epoch 1211: total training loss 0.00861\n",
            "2025-06-26 08:21:57,665 Epoch 1211: total training loss 0.00861\n",
            "INFO:__main__:EPOCH 1212\n",
            "2025-06-26 08:21:57,668 EPOCH 1212\n",
            "INFO:__main__:Epoch 1212: total training loss 0.00954\n",
            "2025-06-26 08:21:57,765 Epoch 1212: total training loss 0.00954\n",
            "INFO:__main__:EPOCH 1213\n",
            "2025-06-26 08:21:57,771 EPOCH 1213\n",
            "INFO:__main__:Epoch 1213: total training loss 0.00913\n",
            "2025-06-26 08:21:57,885 Epoch 1213: total training loss 0.00913\n",
            "INFO:__main__:EPOCH 1214\n",
            "2025-06-26 08:21:57,890 EPOCH 1214\n",
            "INFO:__main__:Epoch 1214: total training loss 0.00892\n",
            "2025-06-26 08:21:57,979 Epoch 1214: total training loss 0.00892\n",
            "INFO:__main__:EPOCH 1215\n",
            "2025-06-26 08:21:57,981 EPOCH 1215\n",
            "INFO:__main__:Epoch 1215: total training loss 0.00865\n",
            "2025-06-26 08:21:58,057 Epoch 1215: total training loss 0.00865\n",
            "INFO:__main__:EPOCH 1216\n",
            "2025-06-26 08:21:58,059 EPOCH 1216\n",
            "INFO:__main__:Epoch 1216: total training loss 0.00834\n",
            "2025-06-26 08:21:58,123 Epoch 1216: total training loss 0.00834\n",
            "INFO:__main__:EPOCH 1217\n",
            "2025-06-26 08:21:58,125 EPOCH 1217\n",
            "INFO:__main__:Epoch 1217: total training loss 0.00842\n",
            "2025-06-26 08:21:58,191 Epoch 1217: total training loss 0.00842\n",
            "INFO:__main__:EPOCH 1218\n",
            "2025-06-26 08:21:58,193 EPOCH 1218\n",
            "INFO:__main__:Epoch 1218: total training loss 0.00878\n",
            "2025-06-26 08:21:58,263 Epoch 1218: total training loss 0.00878\n",
            "INFO:__main__:EPOCH 1219\n",
            "2025-06-26 08:21:58,267 EPOCH 1219\n",
            "INFO:__main__:Epoch 1219: total training loss 0.00877\n",
            "2025-06-26 08:21:58,334 Epoch 1219: total training loss 0.00877\n",
            "INFO:__main__:EPOCH 1220\n",
            "2025-06-26 08:21:58,336 EPOCH 1220\n",
            "INFO:__main__:Epoch 1220: total training loss 0.00864\n",
            "2025-06-26 08:21:58,401 Epoch 1220: total training loss 0.00864\n",
            "INFO:__main__:EPOCH 1221\n",
            "2025-06-26 08:21:58,404 EPOCH 1221\n",
            "INFO:__main__:Epoch 1221: total training loss 0.00867\n",
            "2025-06-26 08:21:58,468 Epoch 1221: total training loss 0.00867\n",
            "INFO:__main__:EPOCH 1222\n",
            "2025-06-26 08:21:58,470 EPOCH 1222\n",
            "INFO:__main__:Epoch 1222: total training loss 0.00873\n",
            "2025-06-26 08:21:58,531 Epoch 1222: total training loss 0.00873\n",
            "INFO:__main__:EPOCH 1223\n",
            "2025-06-26 08:21:58,533 EPOCH 1223\n",
            "INFO:__main__:Epoch 1223: total training loss 0.00828\n",
            "2025-06-26 08:21:58,598 Epoch 1223: total training loss 0.00828\n",
            "INFO:__main__:EPOCH 1224\n",
            "2025-06-26 08:21:58,600 EPOCH 1224\n",
            "INFO:__main__:Epoch 1224: total training loss 0.00818\n",
            "2025-06-26 08:21:58,665 Epoch 1224: total training loss 0.00818\n",
            "INFO:__main__:EPOCH 1225\n",
            "2025-06-26 08:21:58,667 EPOCH 1225\n",
            "INFO:__main__:Epoch 1225: total training loss 0.00824\n",
            "2025-06-26 08:21:58,729 Epoch 1225: total training loss 0.00824\n",
            "INFO:__main__:EPOCH 1226\n",
            "2025-06-26 08:21:58,731 EPOCH 1226\n",
            "INFO:__main__:Epoch 1226: total training loss 0.00783\n",
            "2025-06-26 08:21:58,797 Epoch 1226: total training loss 0.00783\n",
            "INFO:__main__:EPOCH 1227\n",
            "2025-06-26 08:21:58,801 EPOCH 1227\n",
            "INFO:__main__:Epoch 1227: total training loss 0.00877\n",
            "2025-06-26 08:21:58,877 Epoch 1227: total training loss 0.00877\n",
            "INFO:__main__:EPOCH 1228\n",
            "2025-06-26 08:21:58,879 EPOCH 1228\n",
            "INFO:__main__:Epoch 1228: total training loss 0.00815\n",
            "2025-06-26 08:21:58,941 Epoch 1228: total training loss 0.00815\n",
            "INFO:__main__:EPOCH 1229\n",
            "2025-06-26 08:21:58,944 EPOCH 1229\n",
            "INFO:__main__:Epoch 1229: total training loss 0.00825\n",
            "2025-06-26 08:21:59,007 Epoch 1229: total training loss 0.00825\n",
            "INFO:__main__:EPOCH 1230\n",
            "2025-06-26 08:21:59,010 EPOCH 1230\n",
            "INFO:__main__:Epoch 1230: total training loss 0.00865\n",
            "2025-06-26 08:21:59,070 Epoch 1230: total training loss 0.00865\n",
            "INFO:__main__:EPOCH 1231\n",
            "2025-06-26 08:21:59,074 EPOCH 1231\n",
            "INFO:__main__:Epoch 1231: total training loss 0.00828\n",
            "2025-06-26 08:21:59,138 Epoch 1231: total training loss 0.00828\n",
            "INFO:__main__:EPOCH 1232\n",
            "2025-06-26 08:21:59,140 EPOCH 1232\n",
            "INFO:__main__:Epoch 1232: total training loss 0.00826\n",
            "2025-06-26 08:21:59,208 Epoch 1232: total training loss 0.00826\n",
            "INFO:__main__:EPOCH 1233\n",
            "2025-06-26 08:21:59,210 EPOCH 1233\n",
            "INFO:__main__:Epoch 1233: total training loss 0.00816\n",
            "2025-06-26 08:21:59,276 Epoch 1233: total training loss 0.00816\n",
            "INFO:__main__:EPOCH 1234\n",
            "2025-06-26 08:21:59,277 EPOCH 1234\n",
            "INFO:__main__:Epoch 1234: total training loss 0.00853\n",
            "2025-06-26 08:21:59,339 Epoch 1234: total training loss 0.00853\n",
            "INFO:__main__:EPOCH 1235\n",
            "2025-06-26 08:21:59,341 EPOCH 1235\n",
            "INFO:__main__:Epoch 1235: total training loss 0.00843\n",
            "2025-06-26 08:21:59,405 Epoch 1235: total training loss 0.00843\n",
            "INFO:__main__:EPOCH 1236\n",
            "2025-06-26 08:21:59,407 EPOCH 1236\n",
            "INFO:__main__:Epoch 1236: total training loss 0.00896\n",
            "2025-06-26 08:21:59,470 Epoch 1236: total training loss 0.00896\n",
            "INFO:__main__:EPOCH 1237\n",
            "2025-06-26 08:21:59,472 EPOCH 1237\n",
            "INFO:__main__:Epoch 1237: total training loss 0.00856\n",
            "2025-06-26 08:21:59,536 Epoch 1237: total training loss 0.00856\n",
            "INFO:__main__:EPOCH 1238\n",
            "2025-06-26 08:21:59,538 EPOCH 1238\n",
            "INFO:__main__:Epoch 1238: total training loss 0.00803\n",
            "2025-06-26 08:21:59,603 Epoch 1238: total training loss 0.00803\n",
            "INFO:__main__:EPOCH 1239\n",
            "2025-06-26 08:21:59,605 EPOCH 1239\n",
            "INFO:__main__:Epoch 1239: total training loss 0.00856\n",
            "2025-06-26 08:21:59,669 Epoch 1239: total training loss 0.00856\n",
            "INFO:__main__:EPOCH 1240\n",
            "2025-06-26 08:21:59,671 EPOCH 1240\n",
            "INFO:__main__:Epoch 1240: total training loss 0.00889\n",
            "2025-06-26 08:21:59,735 Epoch 1240: total training loss 0.00889\n",
            "INFO:__main__:EPOCH 1241\n",
            "2025-06-26 08:21:59,737 EPOCH 1241\n",
            "INFO:__main__:Epoch 1241: total training loss 0.00872\n",
            "2025-06-26 08:21:59,800 Epoch 1241: total training loss 0.00872\n",
            "INFO:__main__:EPOCH 1242\n",
            "2025-06-26 08:21:59,802 EPOCH 1242\n",
            "INFO:__main__:Epoch 1242: total training loss 0.00872\n",
            "2025-06-26 08:21:59,866 Epoch 1242: total training loss 0.00872\n",
            "INFO:__main__:EPOCH 1243\n",
            "2025-06-26 08:21:59,868 EPOCH 1243\n",
            "INFO:__main__:Epoch 1243: total training loss 0.00870\n",
            "2025-06-26 08:21:59,951 Epoch 1243: total training loss 0.00870\n",
            "INFO:__main__:EPOCH 1244\n",
            "2025-06-26 08:21:59,953 EPOCH 1244\n",
            "INFO:__main__:Epoch 1244: total training loss 0.00907\n",
            "2025-06-26 08:22:00,018 Epoch 1244: total training loss 0.00907\n",
            "INFO:__main__:EPOCH 1245\n",
            "2025-06-26 08:22:00,020 EPOCH 1245\n",
            "INFO:__main__:Epoch 1245: total training loss 0.00881\n",
            "2025-06-26 08:22:00,084 Epoch 1245: total training loss 0.00881\n",
            "INFO:__main__:EPOCH 1246\n",
            "2025-06-26 08:22:00,089 EPOCH 1246\n",
            "INFO:__main__:Epoch 1246: total training loss 0.00842\n",
            "2025-06-26 08:22:00,155 Epoch 1246: total training loss 0.00842\n",
            "INFO:__main__:EPOCH 1247\n",
            "2025-06-26 08:22:00,157 EPOCH 1247\n",
            "INFO:__main__:Epoch 1247: total training loss 0.00857\n",
            "2025-06-26 08:22:00,225 Epoch 1247: total training loss 0.00857\n",
            "INFO:__main__:EPOCH 1248\n",
            "2025-06-26 08:22:00,227 EPOCH 1248\n",
            "INFO:__main__:Epoch 1248: total training loss 0.00825\n",
            "2025-06-26 08:22:00,286 Epoch 1248: total training loss 0.00825\n",
            "INFO:__main__:EPOCH 1249\n",
            "2025-06-26 08:22:00,288 EPOCH 1249\n",
            "INFO:__main__:Epoch 1249: total training loss 0.00861\n",
            "2025-06-26 08:22:00,349 Epoch 1249: total training loss 0.00861\n",
            "INFO:__main__:EPOCH 1250\n",
            "2025-06-26 08:22:00,351 EPOCH 1250\n",
            "INFO:__main__:Epoch 1250 Step:     1250 Batch Loss:     0.008272 Tokens per Sec:  2222262, Lr: 0.001000\n",
            "2025-06-26 08:22:00,416 Epoch 1250 Step:     1250 Batch Loss:     0.008272 Tokens per Sec:  2222262, Lr: 0.001000\n",
            "INFO:__main__:Epoch 1250: total training loss 0.00827\n",
            "2025-06-26 08:22:00,418 Epoch 1250: total training loss 0.00827\n",
            "INFO:__main__:EPOCH 1251\n",
            "2025-06-26 08:22:00,421 EPOCH 1251\n",
            "INFO:__main__:Epoch 1251: total training loss 0.00806\n",
            "2025-06-26 08:22:00,489 Epoch 1251: total training loss 0.00806\n",
            "INFO:__main__:EPOCH 1252\n",
            "2025-06-26 08:22:00,491 EPOCH 1252\n",
            "INFO:__main__:Epoch 1252: total training loss 0.00835\n",
            "2025-06-26 08:22:00,552 Epoch 1252: total training loss 0.00835\n",
            "INFO:__main__:EPOCH 1253\n",
            "2025-06-26 08:22:00,554 EPOCH 1253\n",
            "INFO:__main__:Epoch 1253: total training loss 0.00751\n",
            "2025-06-26 08:22:00,621 Epoch 1253: total training loss 0.00751\n",
            "INFO:__main__:EPOCH 1254\n",
            "2025-06-26 08:22:00,623 EPOCH 1254\n",
            "INFO:__main__:Epoch 1254: total training loss 0.00797\n",
            "2025-06-26 08:22:00,690 Epoch 1254: total training loss 0.00797\n",
            "INFO:__main__:EPOCH 1255\n",
            "2025-06-26 08:22:00,692 EPOCH 1255\n",
            "INFO:__main__:Epoch 1255: total training loss 0.00811\n",
            "2025-06-26 08:22:00,755 Epoch 1255: total training loss 0.00811\n",
            "INFO:__main__:EPOCH 1256\n",
            "2025-06-26 08:22:00,757 EPOCH 1256\n",
            "INFO:__main__:Epoch 1256: total training loss 0.00841\n",
            "2025-06-26 08:22:00,821 Epoch 1256: total training loss 0.00841\n",
            "INFO:__main__:EPOCH 1257\n",
            "2025-06-26 08:22:00,823 EPOCH 1257\n",
            "INFO:__main__:Epoch 1257: total training loss 0.00777\n",
            "2025-06-26 08:22:00,886 Epoch 1257: total training loss 0.00777\n",
            "INFO:__main__:EPOCH 1258\n",
            "2025-06-26 08:22:00,888 EPOCH 1258\n",
            "INFO:__main__:Epoch 1258: total training loss 0.00779\n",
            "2025-06-26 08:22:00,973 Epoch 1258: total training loss 0.00779\n",
            "INFO:__main__:EPOCH 1259\n",
            "2025-06-26 08:22:00,975 EPOCH 1259\n",
            "INFO:__main__:Epoch 1259: total training loss 0.00800\n",
            "2025-06-26 08:22:01,041 Epoch 1259: total training loss 0.00800\n",
            "INFO:__main__:EPOCH 1260\n",
            "2025-06-26 08:22:01,043 EPOCH 1260\n",
            "INFO:__main__:Epoch 1260: total training loss 0.00757\n",
            "2025-06-26 08:22:01,107 Epoch 1260: total training loss 0.00757\n",
            "INFO:__main__:EPOCH 1261\n",
            "2025-06-26 08:22:01,109 EPOCH 1261\n",
            "INFO:__main__:Epoch 1261: total training loss 0.00812\n",
            "2025-06-26 08:22:01,172 Epoch 1261: total training loss 0.00812\n",
            "INFO:__main__:EPOCH 1262\n",
            "2025-06-26 08:22:01,174 EPOCH 1262\n",
            "INFO:__main__:Epoch 1262: total training loss 0.00838\n",
            "2025-06-26 08:22:01,241 Epoch 1262: total training loss 0.00838\n",
            "INFO:__main__:EPOCH 1263\n",
            "2025-06-26 08:22:01,243 EPOCH 1263\n",
            "INFO:__main__:Epoch 1263: total training loss 0.00812\n",
            "2025-06-26 08:22:01,308 Epoch 1263: total training loss 0.00812\n",
            "INFO:__main__:EPOCH 1264\n",
            "2025-06-26 08:22:01,310 EPOCH 1264\n",
            "INFO:__main__:Epoch 1264: total training loss 0.00849\n",
            "2025-06-26 08:22:01,373 Epoch 1264: total training loss 0.00849\n",
            "INFO:__main__:EPOCH 1265\n",
            "2025-06-26 08:22:01,375 EPOCH 1265\n",
            "INFO:__main__:Epoch 1265: total training loss 0.00872\n",
            "2025-06-26 08:22:01,439 Epoch 1265: total training loss 0.00872\n",
            "INFO:__main__:EPOCH 1266\n",
            "2025-06-26 08:22:01,441 EPOCH 1266\n",
            "INFO:__main__:Epoch 1266: total training loss 0.00813\n",
            "2025-06-26 08:22:01,504 Epoch 1266: total training loss 0.00813\n",
            "INFO:__main__:EPOCH 1267\n",
            "2025-06-26 08:22:01,507 EPOCH 1267\n",
            "INFO:__main__:Epoch 1267: total training loss 0.00883\n",
            "2025-06-26 08:22:01,572 Epoch 1267: total training loss 0.00883\n",
            "INFO:__main__:EPOCH 1268\n",
            "2025-06-26 08:22:01,574 EPOCH 1268\n",
            "INFO:__main__:Epoch 1268: total training loss 0.00878\n",
            "2025-06-26 08:22:01,638 Epoch 1268: total training loss 0.00878\n",
            "INFO:__main__:EPOCH 1269\n",
            "2025-06-26 08:22:01,640 EPOCH 1269\n",
            "INFO:__main__:Epoch 1269: total training loss 0.00845\n",
            "2025-06-26 08:22:01,701 Epoch 1269: total training loss 0.00845\n",
            "INFO:__main__:EPOCH 1270\n",
            "2025-06-26 08:22:01,703 EPOCH 1270\n",
            "INFO:__main__:Epoch 1270: total training loss 0.00865\n",
            "2025-06-26 08:22:01,766 Epoch 1270: total training loss 0.00865\n",
            "INFO:__main__:EPOCH 1271\n",
            "2025-06-26 08:22:01,768 EPOCH 1271\n",
            "INFO:__main__:Epoch 1271: total training loss 0.00897\n",
            "2025-06-26 08:22:01,831 Epoch 1271: total training loss 0.00897\n",
            "INFO:__main__:EPOCH 1272\n",
            "2025-06-26 08:22:01,833 EPOCH 1272\n",
            "INFO:__main__:Epoch 1272: total training loss 0.00832\n",
            "2025-06-26 08:22:01,896 Epoch 1272: total training loss 0.00832\n",
            "INFO:__main__:EPOCH 1273\n",
            "2025-06-26 08:22:01,898 EPOCH 1273\n",
            "INFO:__main__:Epoch 1273: total training loss 0.00784\n",
            "2025-06-26 08:22:01,963 Epoch 1273: total training loss 0.00784\n",
            "INFO:__main__:EPOCH 1274\n",
            "2025-06-26 08:22:01,965 EPOCH 1274\n",
            "INFO:__main__:Epoch 1274: total training loss 0.00854\n",
            "2025-06-26 08:22:02,045 Epoch 1274: total training loss 0.00854\n",
            "INFO:__main__:EPOCH 1275\n",
            "2025-06-26 08:22:02,047 EPOCH 1275\n",
            "INFO:__main__:Epoch 1275: total training loss 0.00824\n",
            "2025-06-26 08:22:02,112 Epoch 1275: total training loss 0.00824\n",
            "INFO:__main__:EPOCH 1276\n",
            "2025-06-26 08:22:02,114 EPOCH 1276\n",
            "INFO:__main__:Epoch 1276: total training loss 0.00813\n",
            "2025-06-26 08:22:02,182 Epoch 1276: total training loss 0.00813\n",
            "INFO:__main__:EPOCH 1277\n",
            "2025-06-26 08:22:02,187 EPOCH 1277\n",
            "INFO:__main__:Epoch 1277: total training loss 0.00829\n",
            "2025-06-26 08:22:02,256 Epoch 1277: total training loss 0.00829\n",
            "INFO:__main__:EPOCH 1278\n",
            "2025-06-26 08:22:02,257 EPOCH 1278\n",
            "INFO:__main__:Epoch 1278: total training loss 0.00786\n",
            "2025-06-26 08:22:02,321 Epoch 1278: total training loss 0.00786\n",
            "INFO:__main__:EPOCH 1279\n",
            "2025-06-26 08:22:02,323 EPOCH 1279\n",
            "INFO:__main__:Epoch 1279: total training loss 0.00819\n",
            "2025-06-26 08:22:02,390 Epoch 1279: total training loss 0.00819\n",
            "INFO:__main__:EPOCH 1280\n",
            "2025-06-26 08:22:02,391 EPOCH 1280\n",
            "INFO:__main__:Epoch 1280: total training loss 0.00848\n",
            "2025-06-26 08:22:02,462 Epoch 1280: total training loss 0.00848\n",
            "INFO:__main__:EPOCH 1281\n",
            "2025-06-26 08:22:02,464 EPOCH 1281\n",
            "INFO:__main__:Epoch 1281: total training loss 0.00776\n",
            "2025-06-26 08:22:02,525 Epoch 1281: total training loss 0.00776\n",
            "INFO:__main__:EPOCH 1282\n",
            "2025-06-26 08:22:02,526 EPOCH 1282\n",
            "INFO:__main__:Epoch 1282: total training loss 0.00812\n",
            "2025-06-26 08:22:02,588 Epoch 1282: total training loss 0.00812\n",
            "INFO:__main__:EPOCH 1283\n",
            "2025-06-26 08:22:02,590 EPOCH 1283\n",
            "INFO:__main__:Epoch 1283: total training loss 0.00789\n",
            "2025-06-26 08:22:02,657 Epoch 1283: total training loss 0.00789\n",
            "INFO:__main__:EPOCH 1284\n",
            "2025-06-26 08:22:02,659 EPOCH 1284\n",
            "INFO:__main__:Epoch 1284: total training loss 0.00850\n",
            "2025-06-26 08:22:02,723 Epoch 1284: total training loss 0.00850\n",
            "INFO:__main__:EPOCH 1285\n",
            "2025-06-26 08:22:02,725 EPOCH 1285\n",
            "INFO:__main__:Epoch 1285: total training loss 0.00851\n",
            "2025-06-26 08:22:02,789 Epoch 1285: total training loss 0.00851\n",
            "INFO:__main__:EPOCH 1286\n",
            "2025-06-26 08:22:02,791 EPOCH 1286\n",
            "INFO:__main__:Epoch 1286: total training loss 0.00760\n",
            "2025-06-26 08:22:02,854 Epoch 1286: total training loss 0.00760\n",
            "INFO:__main__:EPOCH 1287\n",
            "2025-06-26 08:22:02,856 EPOCH 1287\n",
            "INFO:__main__:Epoch 1287: total training loss 0.00785\n",
            "2025-06-26 08:22:02,921 Epoch 1287: total training loss 0.00785\n",
            "INFO:__main__:EPOCH 1288\n",
            "2025-06-26 08:22:02,923 EPOCH 1288\n",
            "INFO:__main__:Epoch 1288: total training loss 0.00821\n",
            "2025-06-26 08:22:02,987 Epoch 1288: total training loss 0.00821\n",
            "INFO:__main__:EPOCH 1289\n",
            "2025-06-26 08:22:02,989 EPOCH 1289\n",
            "INFO:__main__:Epoch 1289: total training loss 0.00803\n",
            "2025-06-26 08:22:03,069 Epoch 1289: total training loss 0.00803\n",
            "INFO:__main__:EPOCH 1290\n",
            "2025-06-26 08:22:03,071 EPOCH 1290\n",
            "INFO:__main__:Epoch 1290: total training loss 0.00825\n",
            "2025-06-26 08:22:03,135 Epoch 1290: total training loss 0.00825\n",
            "INFO:__main__:EPOCH 1291\n",
            "2025-06-26 08:22:03,137 EPOCH 1291\n",
            "INFO:__main__:Epoch 1291: total training loss 0.00807\n",
            "2025-06-26 08:22:03,207 Epoch 1291: total training loss 0.00807\n",
            "INFO:__main__:EPOCH 1292\n",
            "2025-06-26 08:22:03,209 EPOCH 1292\n",
            "INFO:__main__:Epoch 1292: total training loss 0.00770\n",
            "2025-06-26 08:22:03,273 Epoch 1292: total training loss 0.00770\n",
            "INFO:__main__:EPOCH 1293\n",
            "2025-06-26 08:22:03,275 EPOCH 1293\n",
            "INFO:__main__:Epoch 1293: total training loss 0.00796\n",
            "2025-06-26 08:22:03,343 Epoch 1293: total training loss 0.00796\n",
            "INFO:__main__:EPOCH 1294\n",
            "2025-06-26 08:22:03,345 EPOCH 1294\n",
            "INFO:__main__:Epoch 1294: total training loss 0.00777\n",
            "2025-06-26 08:22:03,407 Epoch 1294: total training loss 0.00777\n",
            "INFO:__main__:EPOCH 1295\n",
            "2025-06-26 08:22:03,411 EPOCH 1295\n",
            "INFO:__main__:Epoch 1295: total training loss 0.00750\n",
            "2025-06-26 08:22:03,478 Epoch 1295: total training loss 0.00750\n",
            "INFO:__main__:EPOCH 1296\n",
            "2025-06-26 08:22:03,481 EPOCH 1296\n",
            "INFO:__main__:Epoch 1296: total training loss 0.00759\n",
            "2025-06-26 08:22:03,551 Epoch 1296: total training loss 0.00759\n",
            "INFO:__main__:EPOCH 1297\n",
            "2025-06-26 08:22:03,553 EPOCH 1297\n",
            "INFO:__main__:Epoch 1297: total training loss 0.00762\n",
            "2025-06-26 08:22:03,617 Epoch 1297: total training loss 0.00762\n",
            "INFO:__main__:EPOCH 1298\n",
            "2025-06-26 08:22:03,619 EPOCH 1298\n",
            "INFO:__main__:Epoch 1298: total training loss 0.00755\n",
            "2025-06-26 08:22:03,684 Epoch 1298: total training loss 0.00755\n",
            "INFO:__main__:EPOCH 1299\n",
            "2025-06-26 08:22:03,686 EPOCH 1299\n",
            "INFO:__main__:Epoch 1299: total training loss 0.00755\n",
            "2025-06-26 08:22:03,750 Epoch 1299: total training loss 0.00755\n",
            "INFO:__main__:EPOCH 1300\n",
            "2025-06-26 08:22:03,752 EPOCH 1300\n",
            "INFO:__main__:Epoch 1300: total training loss 0.00790\n",
            "2025-06-26 08:22:03,815 Epoch 1300: total training loss 0.00790\n",
            "INFO:__main__:EPOCH 1301\n",
            "2025-06-26 08:22:03,817 EPOCH 1301\n",
            "INFO:__main__:Epoch 1301: total training loss 0.00749\n",
            "2025-06-26 08:22:03,879 Epoch 1301: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1302\n",
            "2025-06-26 08:22:03,881 EPOCH 1302\n",
            "INFO:__main__:Epoch 1302: total training loss 0.00761\n",
            "2025-06-26 08:22:03,945 Epoch 1302: total training loss 0.00761\n",
            "INFO:__main__:EPOCH 1303\n",
            "2025-06-26 08:22:03,947 EPOCH 1303\n",
            "INFO:__main__:Epoch 1303: total training loss 0.00771\n",
            "2025-06-26 08:22:04,011 Epoch 1303: total training loss 0.00771\n",
            "INFO:__main__:EPOCH 1304\n",
            "2025-06-26 08:22:04,012 EPOCH 1304\n",
            "INFO:__main__:Epoch 1304: total training loss 0.00820\n",
            "2025-06-26 08:22:04,088 Epoch 1304: total training loss 0.00820\n",
            "INFO:__main__:EPOCH 1305\n",
            "2025-06-26 08:22:04,090 EPOCH 1305\n",
            "INFO:__main__:Epoch 1305: total training loss 0.00769\n",
            "2025-06-26 08:22:04,161 Epoch 1305: total training loss 0.00769\n",
            "INFO:__main__:EPOCH 1306\n",
            "2025-06-26 08:22:04,163 EPOCH 1306\n",
            "INFO:__main__:Epoch 1306: total training loss 0.00837\n",
            "2025-06-26 08:22:04,233 Epoch 1306: total training loss 0.00837\n",
            "INFO:__main__:EPOCH 1307\n",
            "2025-06-26 08:22:04,236 EPOCH 1307\n",
            "INFO:__main__:Epoch 1307: total training loss 0.00815\n",
            "2025-06-26 08:22:04,299 Epoch 1307: total training loss 0.00815\n",
            "INFO:__main__:EPOCH 1308\n",
            "2025-06-26 08:22:04,301 EPOCH 1308\n",
            "INFO:__main__:Epoch 1308: total training loss 0.00834\n",
            "2025-06-26 08:22:04,363 Epoch 1308: total training loss 0.00834\n",
            "INFO:__main__:EPOCH 1309\n",
            "2025-06-26 08:22:04,365 EPOCH 1309\n",
            "INFO:__main__:Epoch 1309: total training loss 0.00828\n",
            "2025-06-26 08:22:04,426 Epoch 1309: total training loss 0.00828\n",
            "INFO:__main__:EPOCH 1310\n",
            "2025-06-26 08:22:04,428 EPOCH 1310\n",
            "INFO:__main__:Epoch 1310: total training loss 0.00872\n",
            "2025-06-26 08:22:04,490 Epoch 1310: total training loss 0.00872\n",
            "INFO:__main__:EPOCH 1311\n",
            "2025-06-26 08:22:04,492 EPOCH 1311\n",
            "INFO:__main__:Epoch 1311: total training loss 0.00861\n",
            "2025-06-26 08:22:04,557 Epoch 1311: total training loss 0.00861\n",
            "INFO:__main__:EPOCH 1312\n",
            "2025-06-26 08:22:04,559 EPOCH 1312\n",
            "INFO:__main__:Epoch 1312: total training loss 0.00857\n",
            "2025-06-26 08:22:04,623 Epoch 1312: total training loss 0.00857\n",
            "INFO:__main__:EPOCH 1313\n",
            "2025-06-26 08:22:04,626 EPOCH 1313\n",
            "INFO:__main__:Epoch 1313: total training loss 0.00819\n",
            "2025-06-26 08:22:04,691 Epoch 1313: total training loss 0.00819\n",
            "INFO:__main__:EPOCH 1314\n",
            "2025-06-26 08:22:04,693 EPOCH 1314\n",
            "INFO:__main__:Epoch 1314: total training loss 0.00862\n",
            "2025-06-26 08:22:04,757 Epoch 1314: total training loss 0.00862\n",
            "INFO:__main__:EPOCH 1315\n",
            "2025-06-26 08:22:04,759 EPOCH 1315\n",
            "INFO:__main__:Epoch 1315: total training loss 0.00843\n",
            "2025-06-26 08:22:04,822 Epoch 1315: total training loss 0.00843\n",
            "INFO:__main__:EPOCH 1316\n",
            "2025-06-26 08:22:04,824 EPOCH 1316\n",
            "INFO:__main__:Epoch 1316: total training loss 0.00873\n",
            "2025-06-26 08:22:04,889 Epoch 1316: total training loss 0.00873\n",
            "INFO:__main__:EPOCH 1317\n",
            "2025-06-26 08:22:04,891 EPOCH 1317\n",
            "INFO:__main__:Epoch 1317: total training loss 0.00855\n",
            "2025-06-26 08:22:04,956 Epoch 1317: total training loss 0.00855\n",
            "INFO:__main__:EPOCH 1318\n",
            "2025-06-26 08:22:04,960 EPOCH 1318\n",
            "INFO:__main__:Epoch 1318: total training loss 0.00851\n",
            "2025-06-26 08:22:05,024 Epoch 1318: total training loss 0.00851\n",
            "INFO:__main__:EPOCH 1319\n",
            "2025-06-26 08:22:05,026 EPOCH 1319\n",
            "INFO:__main__:Epoch 1319: total training loss 0.00824\n",
            "2025-06-26 08:22:05,097 Epoch 1319: total training loss 0.00824\n",
            "INFO:__main__:EPOCH 1320\n",
            "2025-06-26 08:22:05,099 EPOCH 1320\n",
            "INFO:__main__:Epoch 1320: total training loss 0.00792\n",
            "2025-06-26 08:22:05,185 Epoch 1320: total training loss 0.00792\n",
            "INFO:__main__:EPOCH 1321\n",
            "2025-06-26 08:22:05,187 EPOCH 1321\n",
            "INFO:__main__:Epoch 1321: total training loss 0.00795\n",
            "2025-06-26 08:22:05,252 Epoch 1321: total training loss 0.00795\n",
            "INFO:__main__:EPOCH 1322\n",
            "2025-06-26 08:22:05,254 EPOCH 1322\n",
            "INFO:__main__:Epoch 1322: total training loss 0.00767\n",
            "2025-06-26 08:22:05,319 Epoch 1322: total training loss 0.00767\n",
            "INFO:__main__:EPOCH 1323\n",
            "2025-06-26 08:22:05,321 EPOCH 1323\n",
            "INFO:__main__:Epoch 1323: total training loss 0.00762\n",
            "2025-06-26 08:22:05,386 Epoch 1323: total training loss 0.00762\n",
            "INFO:__main__:EPOCH 1324\n",
            "2025-06-26 08:22:05,388 EPOCH 1324\n",
            "INFO:__main__:Epoch 1324: total training loss 0.00772\n",
            "2025-06-26 08:22:05,452 Epoch 1324: total training loss 0.00772\n",
            "INFO:__main__:EPOCH 1325\n",
            "2025-06-26 08:22:05,454 EPOCH 1325\n",
            "INFO:__main__:Epoch 1325: total training loss 0.00721\n",
            "2025-06-26 08:22:05,524 Epoch 1325: total training loss 0.00721\n",
            "INFO:__main__:EPOCH 1326\n",
            "2025-06-26 08:22:05,526 EPOCH 1326\n",
            "INFO:__main__:Epoch 1326: total training loss 0.00768\n",
            "2025-06-26 08:22:05,592 Epoch 1326: total training loss 0.00768\n",
            "INFO:__main__:EPOCH 1327\n",
            "2025-06-26 08:22:05,595 EPOCH 1327\n",
            "INFO:__main__:Epoch 1327: total training loss 0.00743\n",
            "2025-06-26 08:22:05,660 Epoch 1327: total training loss 0.00743\n",
            "INFO:__main__:EPOCH 1328\n",
            "2025-06-26 08:22:05,663 EPOCH 1328\n",
            "INFO:__main__:Epoch 1328: total training loss 0.00741\n",
            "2025-06-26 08:22:05,725 Epoch 1328: total training loss 0.00741\n",
            "INFO:__main__:EPOCH 1329\n",
            "2025-06-26 08:22:05,727 EPOCH 1329\n",
            "INFO:__main__:Epoch 1329: total training loss 0.00761\n",
            "2025-06-26 08:22:05,795 Epoch 1329: total training loss 0.00761\n",
            "INFO:__main__:EPOCH 1330\n",
            "2025-06-26 08:22:05,797 EPOCH 1330\n",
            "INFO:__main__:Epoch 1330: total training loss 0.00792\n",
            "2025-06-26 08:22:05,863 Epoch 1330: total training loss 0.00792\n",
            "INFO:__main__:EPOCH 1331\n",
            "2025-06-26 08:22:05,867 EPOCH 1331\n",
            "INFO:__main__:Epoch 1331: total training loss 0.00738\n",
            "2025-06-26 08:22:05,931 Epoch 1331: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1332\n",
            "2025-06-26 08:22:05,934 EPOCH 1332\n",
            "INFO:__main__:Epoch 1332: total training loss 0.00749\n",
            "2025-06-26 08:22:05,997 Epoch 1332: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1333\n",
            "2025-06-26 08:22:05,999 EPOCH 1333\n",
            "INFO:__main__:Epoch 1333: total training loss 0.00741\n",
            "2025-06-26 08:22:06,067 Epoch 1333: total training loss 0.00741\n",
            "INFO:__main__:EPOCH 1334\n",
            "2025-06-26 08:22:06,069 EPOCH 1334\n",
            "INFO:__main__:Epoch 1334: total training loss 0.00744\n",
            "2025-06-26 08:22:06,139 Epoch 1334: total training loss 0.00744\n",
            "INFO:__main__:EPOCH 1335\n",
            "2025-06-26 08:22:06,141 EPOCH 1335\n",
            "INFO:__main__:Epoch 1335: total training loss 0.00818\n",
            "2025-06-26 08:22:06,228 Epoch 1335: total training loss 0.00818\n",
            "INFO:__main__:EPOCH 1336\n",
            "2025-06-26 08:22:06,229 EPOCH 1336\n",
            "INFO:__main__:Epoch 1336: total training loss 0.00787\n",
            "2025-06-26 08:22:06,293 Epoch 1336: total training loss 0.00787\n",
            "INFO:__main__:EPOCH 1337\n",
            "2025-06-26 08:22:06,295 EPOCH 1337\n",
            "INFO:__main__:Epoch 1337: total training loss 0.00782\n",
            "2025-06-26 08:22:06,359 Epoch 1337: total training loss 0.00782\n",
            "INFO:__main__:EPOCH 1338\n",
            "2025-06-26 08:22:06,361 EPOCH 1338\n",
            "INFO:__main__:Epoch 1338: total training loss 0.00762\n",
            "2025-06-26 08:22:06,424 Epoch 1338: total training loss 0.00762\n",
            "INFO:__main__:EPOCH 1339\n",
            "2025-06-26 08:22:06,427 EPOCH 1339\n",
            "INFO:__main__:Epoch 1339: total training loss 0.00821\n",
            "2025-06-26 08:22:06,495 Epoch 1339: total training loss 0.00821\n",
            "INFO:__main__:EPOCH 1340\n",
            "2025-06-26 08:22:06,497 EPOCH 1340\n",
            "INFO:__main__:Epoch 1340: total training loss 0.00781\n",
            "2025-06-26 08:22:06,565 Epoch 1340: total training loss 0.00781\n",
            "INFO:__main__:EPOCH 1341\n",
            "2025-06-26 08:22:06,567 EPOCH 1341\n",
            "INFO:__main__:Epoch 1341: total training loss 0.00830\n",
            "2025-06-26 08:22:06,639 Epoch 1341: total training loss 0.00830\n",
            "INFO:__main__:EPOCH 1342\n",
            "2025-06-26 08:22:06,641 EPOCH 1342\n",
            "INFO:__main__:Epoch 1342: total training loss 0.00754\n",
            "2025-06-26 08:22:06,706 Epoch 1342: total training loss 0.00754\n",
            "INFO:__main__:EPOCH 1343\n",
            "2025-06-26 08:22:06,708 EPOCH 1343\n",
            "INFO:__main__:Epoch 1343: total training loss 0.00818\n",
            "2025-06-26 08:22:06,781 Epoch 1343: total training loss 0.00818\n",
            "INFO:__main__:EPOCH 1344\n",
            "2025-06-26 08:22:06,783 EPOCH 1344\n",
            "INFO:__main__:Epoch 1344: total training loss 0.00819\n",
            "2025-06-26 08:22:06,848 Epoch 1344: total training loss 0.00819\n",
            "INFO:__main__:EPOCH 1345\n",
            "2025-06-26 08:22:06,850 EPOCH 1345\n",
            "INFO:__main__:Epoch 1345: total training loss 0.00775\n",
            "2025-06-26 08:22:06,911 Epoch 1345: total training loss 0.00775\n",
            "INFO:__main__:EPOCH 1346\n",
            "2025-06-26 08:22:06,914 EPOCH 1346\n",
            "INFO:__main__:Epoch 1346: total training loss 0.00841\n",
            "2025-06-26 08:22:06,976 Epoch 1346: total training loss 0.00841\n",
            "INFO:__main__:EPOCH 1347\n",
            "2025-06-26 08:22:06,981 EPOCH 1347\n",
            "INFO:__main__:Epoch 1347: total training loss 0.00794\n",
            "2025-06-26 08:22:07,046 Epoch 1347: total training loss 0.00794\n",
            "INFO:__main__:EPOCH 1348\n",
            "2025-06-26 08:22:07,048 EPOCH 1348\n",
            "INFO:__main__:Epoch 1348: total training loss 0.00764\n",
            "2025-06-26 08:22:07,110 Epoch 1348: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1349\n",
            "2025-06-26 08:22:07,112 EPOCH 1349\n",
            "INFO:__main__:Epoch 1349: total training loss 0.00764\n",
            "2025-06-26 08:22:07,181 Epoch 1349: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1350\n",
            "2025-06-26 08:22:07,183 EPOCH 1350\n",
            "INFO:__main__:Epoch 1350: total training loss 0.00765\n",
            "2025-06-26 08:22:07,267 Epoch 1350: total training loss 0.00765\n",
            "INFO:__main__:EPOCH 1351\n",
            "2025-06-26 08:22:07,269 EPOCH 1351\n",
            "INFO:__main__:Epoch 1351: total training loss 0.00802\n",
            "2025-06-26 08:22:07,339 Epoch 1351: total training loss 0.00802\n",
            "INFO:__main__:EPOCH 1352\n",
            "2025-06-26 08:22:07,341 EPOCH 1352\n",
            "INFO:__main__:Epoch 1352: total training loss 0.00768\n",
            "2025-06-26 08:22:07,404 Epoch 1352: total training loss 0.00768\n",
            "INFO:__main__:EPOCH 1353\n",
            "2025-06-26 08:22:07,406 EPOCH 1353\n",
            "INFO:__main__:Epoch 1353: total training loss 0.00748\n",
            "2025-06-26 08:22:07,468 Epoch 1353: total training loss 0.00748\n",
            "INFO:__main__:EPOCH 1354\n",
            "2025-06-26 08:22:07,470 EPOCH 1354\n",
            "INFO:__main__:Epoch 1354: total training loss 0.00783\n",
            "2025-06-26 08:22:07,536 Epoch 1354: total training loss 0.00783\n",
            "INFO:__main__:EPOCH 1355\n",
            "2025-06-26 08:22:07,538 EPOCH 1355\n",
            "INFO:__main__:Epoch 1355: total training loss 0.00802\n",
            "2025-06-26 08:22:07,601 Epoch 1355: total training loss 0.00802\n",
            "INFO:__main__:EPOCH 1356\n",
            "2025-06-26 08:22:07,603 EPOCH 1356\n",
            "INFO:__main__:Epoch 1356: total training loss 0.00743\n",
            "2025-06-26 08:22:07,665 Epoch 1356: total training loss 0.00743\n",
            "INFO:__main__:EPOCH 1357\n",
            "2025-06-26 08:22:07,668 EPOCH 1357\n",
            "INFO:__main__:Epoch 1357: total training loss 0.00729\n",
            "2025-06-26 08:22:07,729 Epoch 1357: total training loss 0.00729\n",
            "INFO:__main__:EPOCH 1358\n",
            "2025-06-26 08:22:07,732 EPOCH 1358\n",
            "INFO:__main__:Epoch 1358: total training loss 0.00814\n",
            "2025-06-26 08:22:07,797 Epoch 1358: total training loss 0.00814\n",
            "INFO:__main__:EPOCH 1359\n",
            "2025-06-26 08:22:07,801 EPOCH 1359\n",
            "INFO:__main__:Epoch 1359: total training loss 0.00828\n",
            "2025-06-26 08:22:07,863 Epoch 1359: total training loss 0.00828\n",
            "INFO:__main__:EPOCH 1360\n",
            "2025-06-26 08:22:07,865 EPOCH 1360\n",
            "INFO:__main__:Epoch 1360: total training loss 0.00733\n",
            "2025-06-26 08:22:07,930 Epoch 1360: total training loss 0.00733\n",
            "INFO:__main__:EPOCH 1361\n",
            "2025-06-26 08:22:07,931 EPOCH 1361\n",
            "INFO:__main__:Epoch 1361: total training loss 0.00805\n",
            "2025-06-26 08:22:07,997 Epoch 1361: total training loss 0.00805\n",
            "INFO:__main__:EPOCH 1362\n",
            "2025-06-26 08:22:08,000 EPOCH 1362\n",
            "INFO:__main__:Epoch 1362: total training loss 0.00780\n",
            "2025-06-26 08:22:08,078 Epoch 1362: total training loss 0.00780\n",
            "INFO:__main__:EPOCH 1363\n",
            "2025-06-26 08:22:08,081 EPOCH 1363\n",
            "INFO:__main__:Epoch 1363: total training loss 0.00765\n",
            "2025-06-26 08:22:08,162 Epoch 1363: total training loss 0.00765\n",
            "INFO:__main__:EPOCH 1364\n",
            "2025-06-26 08:22:08,164 EPOCH 1364\n",
            "INFO:__main__:Epoch 1364: total training loss 0.00820\n",
            "2025-06-26 08:22:08,245 Epoch 1364: total training loss 0.00820\n",
            "INFO:__main__:EPOCH 1365\n",
            "2025-06-26 08:22:08,248 EPOCH 1365\n",
            "INFO:__main__:Epoch 1365: total training loss 0.00783\n",
            "2025-06-26 08:22:08,343 Epoch 1365: total training loss 0.00783\n",
            "INFO:__main__:EPOCH 1366\n",
            "2025-06-26 08:22:08,346 EPOCH 1366\n",
            "INFO:__main__:Epoch 1366: total training loss 0.00758\n",
            "2025-06-26 08:22:08,426 Epoch 1366: total training loss 0.00758\n",
            "INFO:__main__:EPOCH 1367\n",
            "2025-06-26 08:22:08,428 EPOCH 1367\n",
            "INFO:__main__:Epoch 1367: total training loss 0.00750\n",
            "2025-06-26 08:22:08,515 Epoch 1367: total training loss 0.00750\n",
            "INFO:__main__:EPOCH 1368\n",
            "2025-06-26 08:22:08,517 EPOCH 1368\n",
            "INFO:__main__:Epoch 1368: total training loss 0.00771\n",
            "2025-06-26 08:22:08,607 Epoch 1368: total training loss 0.00771\n",
            "INFO:__main__:EPOCH 1369\n",
            "2025-06-26 08:22:08,609 EPOCH 1369\n",
            "INFO:__main__:Epoch 1369: total training loss 0.00786\n",
            "2025-06-26 08:22:08,682 Epoch 1369: total training loss 0.00786\n",
            "INFO:__main__:EPOCH 1370\n",
            "2025-06-26 08:22:08,684 EPOCH 1370\n",
            "INFO:__main__:Epoch 1370: total training loss 0.00796\n",
            "2025-06-26 08:22:08,754 Epoch 1370: total training loss 0.00796\n",
            "INFO:__main__:EPOCH 1371\n",
            "2025-06-26 08:22:08,757 EPOCH 1371\n",
            "INFO:__main__:Epoch 1371: total training loss 0.00715\n",
            "2025-06-26 08:22:08,829 Epoch 1371: total training loss 0.00715\n",
            "INFO:__main__:EPOCH 1372\n",
            "2025-06-26 08:22:08,831 EPOCH 1372\n",
            "INFO:__main__:Epoch 1372: total training loss 0.00777\n",
            "2025-06-26 08:22:08,907 Epoch 1372: total training loss 0.00777\n",
            "INFO:__main__:EPOCH 1373\n",
            "2025-06-26 08:22:08,909 EPOCH 1373\n",
            "INFO:__main__:Epoch 1373: total training loss 0.00776\n",
            "2025-06-26 08:22:09,000 Epoch 1373: total training loss 0.00776\n",
            "INFO:__main__:EPOCH 1374\n",
            "2025-06-26 08:22:09,002 EPOCH 1374\n",
            "INFO:__main__:Epoch 1374: total training loss 0.00748\n",
            "2025-06-26 08:22:09,081 Epoch 1374: total training loss 0.00748\n",
            "INFO:__main__:EPOCH 1375\n",
            "2025-06-26 08:22:09,084 EPOCH 1375\n",
            "INFO:__main__:Epoch 1375: total training loss 0.00768\n",
            "2025-06-26 08:22:09,166 Epoch 1375: total training loss 0.00768\n",
            "INFO:__main__:EPOCH 1376\n",
            "2025-06-26 08:22:09,168 EPOCH 1376\n",
            "INFO:__main__:Epoch 1376: total training loss 0.00740\n",
            "2025-06-26 08:22:09,262 Epoch 1376: total training loss 0.00740\n",
            "INFO:__main__:EPOCH 1377\n",
            "2025-06-26 08:22:09,264 EPOCH 1377\n",
            "INFO:__main__:Epoch 1377: total training loss 0.00811\n",
            "2025-06-26 08:22:09,345 Epoch 1377: total training loss 0.00811\n",
            "INFO:__main__:EPOCH 1378\n",
            "2025-06-26 08:22:09,347 EPOCH 1378\n",
            "INFO:__main__:Epoch 1378: total training loss 0.00744\n",
            "2025-06-26 08:22:09,442 Epoch 1378: total training loss 0.00744\n",
            "INFO:__main__:EPOCH 1379\n",
            "2025-06-26 08:22:09,444 EPOCH 1379\n",
            "INFO:__main__:Epoch 1379: total training loss 0.00743\n",
            "2025-06-26 08:22:09,525 Epoch 1379: total training loss 0.00743\n",
            "INFO:__main__:EPOCH 1380\n",
            "2025-06-26 08:22:09,527 EPOCH 1380\n",
            "INFO:__main__:Epoch 1380: total training loss 0.00775\n",
            "2025-06-26 08:22:09,623 Epoch 1380: total training loss 0.00775\n",
            "INFO:__main__:EPOCH 1381\n",
            "2025-06-26 08:22:09,625 EPOCH 1381\n",
            "INFO:__main__:Epoch 1381: total training loss 0.00768\n",
            "2025-06-26 08:22:09,715 Epoch 1381: total training loss 0.00768\n",
            "INFO:__main__:EPOCH 1382\n",
            "2025-06-26 08:22:09,717 EPOCH 1382\n",
            "INFO:__main__:Epoch 1382: total training loss 0.00738\n",
            "2025-06-26 08:22:09,801 Epoch 1382: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1383\n",
            "2025-06-26 08:22:09,803 EPOCH 1383\n",
            "INFO:__main__:Epoch 1383: total training loss 0.00755\n",
            "2025-06-26 08:22:09,891 Epoch 1383: total training loss 0.00755\n",
            "INFO:__main__:EPOCH 1384\n",
            "2025-06-26 08:22:09,896 EPOCH 1384\n",
            "INFO:__main__:Epoch 1384: total training loss 0.00722\n",
            "2025-06-26 08:22:09,981 Epoch 1384: total training loss 0.00722\n",
            "INFO:__main__:EPOCH 1385\n",
            "2025-06-26 08:22:09,983 EPOCH 1385\n",
            "INFO:__main__:Epoch 1385: total training loss 0.00779\n",
            "2025-06-26 08:22:10,070 Epoch 1385: total training loss 0.00779\n",
            "INFO:__main__:EPOCH 1386\n",
            "2025-06-26 08:22:10,072 EPOCH 1386\n",
            "INFO:__main__:Epoch 1386: total training loss 0.00839\n",
            "2025-06-26 08:22:10,161 Epoch 1386: total training loss 0.00839\n",
            "INFO:__main__:EPOCH 1387\n",
            "2025-06-26 08:22:10,167 EPOCH 1387\n",
            "INFO:__main__:Epoch 1387: total training loss 0.00736\n",
            "2025-06-26 08:22:10,260 Epoch 1387: total training loss 0.00736\n",
            "INFO:__main__:EPOCH 1388\n",
            "2025-06-26 08:22:10,262 EPOCH 1388\n",
            "INFO:__main__:Epoch 1388: total training loss 0.00749\n",
            "2025-06-26 08:22:10,368 Epoch 1388: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1389\n",
            "2025-06-26 08:22:10,371 EPOCH 1389\n",
            "INFO:__main__:Epoch 1389: total training loss 0.00751\n",
            "2025-06-26 08:22:10,460 Epoch 1389: total training loss 0.00751\n",
            "INFO:__main__:EPOCH 1390\n",
            "2025-06-26 08:22:10,465 EPOCH 1390\n",
            "INFO:__main__:Epoch 1390: total training loss 0.00713\n",
            "2025-06-26 08:22:10,545 Epoch 1390: total training loss 0.00713\n",
            "INFO:__main__:EPOCH 1391\n",
            "2025-06-26 08:22:10,548 EPOCH 1391\n",
            "INFO:__main__:Epoch 1391: total training loss 0.00706\n",
            "2025-06-26 08:22:10,627 Epoch 1391: total training loss 0.00706\n",
            "INFO:__main__:EPOCH 1392\n",
            "2025-06-26 08:22:10,629 EPOCH 1392\n",
            "INFO:__main__:Epoch 1392: total training loss 0.00733\n",
            "2025-06-26 08:22:10,702 Epoch 1392: total training loss 0.00733\n",
            "INFO:__main__:EPOCH 1393\n",
            "2025-06-26 08:22:10,704 EPOCH 1393\n",
            "INFO:__main__:Epoch 1393: total training loss 0.00741\n",
            "2025-06-26 08:22:10,778 Epoch 1393: total training loss 0.00741\n",
            "INFO:__main__:EPOCH 1394\n",
            "2025-06-26 08:22:10,780 EPOCH 1394\n",
            "INFO:__main__:Epoch 1394: total training loss 0.00757\n",
            "2025-06-26 08:22:10,852 Epoch 1394: total training loss 0.00757\n",
            "INFO:__main__:EPOCH 1395\n",
            "2025-06-26 08:22:10,854 EPOCH 1395\n",
            "INFO:__main__:Epoch 1395: total training loss 0.00733\n",
            "2025-06-26 08:22:10,924 Epoch 1395: total training loss 0.00733\n",
            "INFO:__main__:EPOCH 1396\n",
            "2025-06-26 08:22:10,926 EPOCH 1396\n",
            "INFO:__main__:Epoch 1396: total training loss 0.00736\n",
            "2025-06-26 08:22:10,998 Epoch 1396: total training loss 0.00736\n",
            "INFO:__main__:EPOCH 1397\n",
            "2025-06-26 08:22:11,000 EPOCH 1397\n",
            "INFO:__main__:Epoch 1397: total training loss 0.00738\n",
            "2025-06-26 08:22:11,078 Epoch 1397: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1398\n",
            "2025-06-26 08:22:11,081 EPOCH 1398\n",
            "INFO:__main__:Epoch 1398: total training loss 0.00735\n",
            "2025-06-26 08:22:11,170 Epoch 1398: total training loss 0.00735\n",
            "INFO:__main__:EPOCH 1399\n",
            "2025-06-26 08:22:11,172 EPOCH 1399\n",
            "INFO:__main__:Epoch 1399: total training loss 0.00764\n",
            "2025-06-26 08:22:11,257 Epoch 1399: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1400\n",
            "2025-06-26 08:22:11,259 EPOCH 1400\n",
            "INFO:__main__:Epoch 1400: total training loss 0.00727\n",
            "2025-06-26 08:22:11,338 Epoch 1400: total training loss 0.00727\n",
            "INFO:__main__:EPOCH 1401\n",
            "2025-06-26 08:22:11,341 EPOCH 1401\n",
            "INFO:__main__:Epoch 1401: total training loss 0.00733\n",
            "2025-06-26 08:22:11,422 Epoch 1401: total training loss 0.00733\n",
            "INFO:__main__:EPOCH 1402\n",
            "2025-06-26 08:22:11,428 EPOCH 1402\n",
            "INFO:__main__:Epoch 1402: total training loss 0.00820\n",
            "2025-06-26 08:22:11,519 Epoch 1402: total training loss 0.00820\n",
            "INFO:__main__:EPOCH 1403\n",
            "2025-06-26 08:22:11,521 EPOCH 1403\n",
            "INFO:__main__:Epoch 1403: total training loss 0.00782\n",
            "2025-06-26 08:22:11,616 Epoch 1403: total training loss 0.00782\n",
            "INFO:__main__:EPOCH 1404\n",
            "2025-06-26 08:22:11,619 EPOCH 1404\n",
            "INFO:__main__:Epoch 1404: total training loss 0.00738\n",
            "2025-06-26 08:22:11,708 Epoch 1404: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1405\n",
            "2025-06-26 08:22:11,710 EPOCH 1405\n",
            "INFO:__main__:Epoch 1405: total training loss 0.00797\n",
            "2025-06-26 08:22:11,786 Epoch 1405: total training loss 0.00797\n",
            "INFO:__main__:EPOCH 1406\n",
            "2025-06-26 08:22:11,788 EPOCH 1406\n",
            "INFO:__main__:Epoch 1406: total training loss 0.00812\n",
            "2025-06-26 08:22:11,866 Epoch 1406: total training loss 0.00812\n",
            "INFO:__main__:EPOCH 1407\n",
            "2025-06-26 08:22:11,868 EPOCH 1407\n",
            "INFO:__main__:Epoch 1407: total training loss 0.00777\n",
            "2025-06-26 08:22:11,962 Epoch 1407: total training loss 0.00777\n",
            "INFO:__main__:EPOCH 1408\n",
            "2025-06-26 08:22:11,964 EPOCH 1408\n",
            "INFO:__main__:Epoch 1408: total training loss 0.00792\n",
            "2025-06-26 08:22:12,048 Epoch 1408: total training loss 0.00792\n",
            "INFO:__main__:EPOCH 1409\n",
            "2025-06-26 08:22:12,051 EPOCH 1409\n",
            "INFO:__main__:Epoch 1409: total training loss 0.00785\n",
            "2025-06-26 08:22:12,145 Epoch 1409: total training loss 0.00785\n",
            "INFO:__main__:EPOCH 1410\n",
            "2025-06-26 08:22:12,149 EPOCH 1410\n",
            "INFO:__main__:Epoch 1410: total training loss 0.00716\n",
            "2025-06-26 08:22:12,240 Epoch 1410: total training loss 0.00716\n",
            "INFO:__main__:EPOCH 1411\n",
            "2025-06-26 08:22:12,242 EPOCH 1411\n",
            "INFO:__main__:Epoch 1411: total training loss 0.00748\n",
            "2025-06-26 08:22:12,337 Epoch 1411: total training loss 0.00748\n",
            "INFO:__main__:EPOCH 1412\n",
            "2025-06-26 08:22:12,340 EPOCH 1412\n",
            "INFO:__main__:Epoch 1412: total training loss 0.00771\n",
            "2025-06-26 08:22:12,430 Epoch 1412: total training loss 0.00771\n",
            "INFO:__main__:EPOCH 1413\n",
            "2025-06-26 08:22:12,433 EPOCH 1413\n",
            "INFO:__main__:Epoch 1413: total training loss 0.00691\n",
            "2025-06-26 08:22:12,523 Epoch 1413: total training loss 0.00691\n",
            "INFO:__main__:EPOCH 1414\n",
            "2025-06-26 08:22:12,525 EPOCH 1414\n",
            "INFO:__main__:Epoch 1414: total training loss 0.00755\n",
            "2025-06-26 08:22:12,590 Epoch 1414: total training loss 0.00755\n",
            "INFO:__main__:EPOCH 1415\n",
            "2025-06-26 08:22:12,592 EPOCH 1415\n",
            "INFO:__main__:Epoch 1415: total training loss 0.00758\n",
            "2025-06-26 08:22:12,659 Epoch 1415: total training loss 0.00758\n",
            "INFO:__main__:EPOCH 1416\n",
            "2025-06-26 08:22:12,668 EPOCH 1416\n",
            "INFO:__main__:Epoch 1416: total training loss 0.00748\n",
            "2025-06-26 08:22:12,743 Epoch 1416: total training loss 0.00748\n",
            "INFO:__main__:EPOCH 1417\n",
            "2025-06-26 08:22:12,745 EPOCH 1417\n",
            "INFO:__main__:Epoch 1417: total training loss 0.00771\n",
            "2025-06-26 08:22:12,809 Epoch 1417: total training loss 0.00771\n",
            "INFO:__main__:EPOCH 1418\n",
            "2025-06-26 08:22:12,814 EPOCH 1418\n",
            "INFO:__main__:Epoch 1418: total training loss 0.00729\n",
            "2025-06-26 08:22:12,881 Epoch 1418: total training loss 0.00729\n",
            "INFO:__main__:EPOCH 1419\n",
            "2025-06-26 08:22:12,883 EPOCH 1419\n",
            "INFO:__main__:Epoch 1419: total training loss 0.00720\n",
            "2025-06-26 08:22:12,948 Epoch 1419: total training loss 0.00720\n",
            "INFO:__main__:EPOCH 1420\n",
            "2025-06-26 08:22:12,951 EPOCH 1420\n",
            "INFO:__main__:Epoch 1420: total training loss 0.00736\n",
            "2025-06-26 08:22:13,014 Epoch 1420: total training loss 0.00736\n",
            "INFO:__main__:EPOCH 1421\n",
            "2025-06-26 08:22:13,016 EPOCH 1421\n",
            "INFO:__main__:Epoch 1421: total training loss 0.00780\n",
            "2025-06-26 08:22:13,084 Epoch 1421: total training loss 0.00780\n",
            "INFO:__main__:EPOCH 1422\n",
            "2025-06-26 08:22:13,086 EPOCH 1422\n",
            "INFO:__main__:Epoch 1422: total training loss 0.00759\n",
            "2025-06-26 08:22:13,152 Epoch 1422: total training loss 0.00759\n",
            "INFO:__main__:EPOCH 1423\n",
            "2025-06-26 08:22:13,154 EPOCH 1423\n",
            "INFO:__main__:Epoch 1423: total training loss 0.00782\n",
            "2025-06-26 08:22:13,219 Epoch 1423: total training loss 0.00782\n",
            "INFO:__main__:EPOCH 1424\n",
            "2025-06-26 08:22:13,221 EPOCH 1424\n",
            "INFO:__main__:Epoch 1424: total training loss 0.00744\n",
            "2025-06-26 08:22:13,288 Epoch 1424: total training loss 0.00744\n",
            "INFO:__main__:EPOCH 1425\n",
            "2025-06-26 08:22:13,290 EPOCH 1425\n",
            "INFO:__main__:Epoch 1425: total training loss 0.00783\n",
            "2025-06-26 08:22:13,353 Epoch 1425: total training loss 0.00783\n",
            "INFO:__main__:EPOCH 1426\n",
            "2025-06-26 08:22:13,355 EPOCH 1426\n",
            "INFO:__main__:Epoch 1426: total training loss 0.00792\n",
            "2025-06-26 08:22:13,421 Epoch 1426: total training loss 0.00792\n",
            "INFO:__main__:EPOCH 1427\n",
            "2025-06-26 08:22:13,424 EPOCH 1427\n",
            "INFO:__main__:Epoch 1427: total training loss 0.00799\n",
            "2025-06-26 08:22:13,486 Epoch 1427: total training loss 0.00799\n",
            "INFO:__main__:EPOCH 1428\n",
            "2025-06-26 08:22:13,487 EPOCH 1428\n",
            "INFO:__main__:Epoch 1428: total training loss 0.00827\n",
            "2025-06-26 08:22:13,553 Epoch 1428: total training loss 0.00827\n",
            "INFO:__main__:EPOCH 1429\n",
            "2025-06-26 08:22:13,555 EPOCH 1429\n",
            "INFO:__main__:Epoch 1429: total training loss 0.00747\n",
            "2025-06-26 08:22:13,618 Epoch 1429: total training loss 0.00747\n",
            "INFO:__main__:EPOCH 1430\n",
            "2025-06-26 08:22:13,620 EPOCH 1430\n",
            "INFO:__main__:Epoch 1430: total training loss 0.00749\n",
            "2025-06-26 08:22:13,686 Epoch 1430: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1431\n",
            "2025-06-26 08:22:13,688 EPOCH 1431\n",
            "INFO:__main__:Epoch 1431: total training loss 0.00723\n",
            "2025-06-26 08:22:13,773 Epoch 1431: total training loss 0.00723\n",
            "INFO:__main__:EPOCH 1432\n",
            "2025-06-26 08:22:13,776 EPOCH 1432\n",
            "INFO:__main__:Epoch 1432: total training loss 0.00764\n",
            "2025-06-26 08:22:13,838 Epoch 1432: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1433\n",
            "2025-06-26 08:22:13,840 EPOCH 1433\n",
            "INFO:__main__:Epoch 1433: total training loss 0.00738\n",
            "2025-06-26 08:22:13,902 Epoch 1433: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1434\n",
            "2025-06-26 08:22:13,904 EPOCH 1434\n",
            "INFO:__main__:Epoch 1434: total training loss 0.00759\n",
            "2025-06-26 08:22:13,970 Epoch 1434: total training loss 0.00759\n",
            "INFO:__main__:EPOCH 1435\n",
            "2025-06-26 08:22:13,971 EPOCH 1435\n",
            "INFO:__main__:Epoch 1435: total training loss 0.00730\n",
            "2025-06-26 08:22:14,034 Epoch 1435: total training loss 0.00730\n",
            "INFO:__main__:EPOCH 1436\n",
            "2025-06-26 08:22:14,037 EPOCH 1436\n",
            "INFO:__main__:Epoch 1436: total training loss 0.00785\n",
            "2025-06-26 08:22:14,098 Epoch 1436: total training loss 0.00785\n",
            "INFO:__main__:EPOCH 1437\n",
            "2025-06-26 08:22:14,101 EPOCH 1437\n",
            "INFO:__main__:Epoch 1437: total training loss 0.00791\n",
            "2025-06-26 08:22:14,162 Epoch 1437: total training loss 0.00791\n",
            "INFO:__main__:EPOCH 1438\n",
            "2025-06-26 08:22:14,164 EPOCH 1438\n",
            "INFO:__main__:Epoch 1438: total training loss 0.00775\n",
            "2025-06-26 08:22:14,231 Epoch 1438: total training loss 0.00775\n",
            "INFO:__main__:EPOCH 1439\n",
            "2025-06-26 08:22:14,233 EPOCH 1439\n",
            "INFO:__main__:Epoch 1439: total training loss 0.00763\n",
            "2025-06-26 08:22:14,296 Epoch 1439: total training loss 0.00763\n",
            "INFO:__main__:EPOCH 1440\n",
            "2025-06-26 08:22:14,298 EPOCH 1440\n",
            "INFO:__main__:Epoch 1440: total training loss 0.00786\n",
            "2025-06-26 08:22:14,360 Epoch 1440: total training loss 0.00786\n",
            "INFO:__main__:EPOCH 1441\n",
            "2025-06-26 08:22:14,363 EPOCH 1441\n",
            "INFO:__main__:Epoch 1441: total training loss 0.00796\n",
            "2025-06-26 08:22:14,428 Epoch 1441: total training loss 0.00796\n",
            "INFO:__main__:EPOCH 1442\n",
            "2025-06-26 08:22:14,430 EPOCH 1442\n",
            "INFO:__main__:Epoch 1442: total training loss 0.00749\n",
            "2025-06-26 08:22:14,493 Epoch 1442: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1443\n",
            "2025-06-26 08:22:14,495 EPOCH 1443\n",
            "INFO:__main__:Epoch 1443: total training loss 0.00764\n",
            "2025-06-26 08:22:14,558 Epoch 1443: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1444\n",
            "2025-06-26 08:22:14,561 EPOCH 1444\n",
            "INFO:__main__:Epoch 1444: total training loss 0.00816\n",
            "2025-06-26 08:22:14,626 Epoch 1444: total training loss 0.00816\n",
            "INFO:__main__:EPOCH 1445\n",
            "2025-06-26 08:22:14,628 EPOCH 1445\n",
            "INFO:__main__:Epoch 1445: total training loss 0.00730\n",
            "2025-06-26 08:22:14,692 Epoch 1445: total training loss 0.00730\n",
            "INFO:__main__:EPOCH 1446\n",
            "2025-06-26 08:22:14,694 EPOCH 1446\n",
            "INFO:__main__:Epoch 1446: total training loss 0.00752\n",
            "2025-06-26 08:22:14,763 Epoch 1446: total training loss 0.00752\n",
            "INFO:__main__:EPOCH 1447\n",
            "2025-06-26 08:22:14,766 EPOCH 1447\n",
            "INFO:__main__:Epoch 1447: total training loss 0.00781\n",
            "2025-06-26 08:22:14,840 Epoch 1447: total training loss 0.00781\n",
            "INFO:__main__:EPOCH 1448\n",
            "2025-06-26 08:22:14,842 EPOCH 1448\n",
            "INFO:__main__:Epoch 1448: total training loss 0.00759\n",
            "2025-06-26 08:22:14,910 Epoch 1448: total training loss 0.00759\n",
            "INFO:__main__:EPOCH 1449\n",
            "2025-06-26 08:22:14,912 EPOCH 1449\n",
            "INFO:__main__:Epoch 1449: total training loss 0.00740\n",
            "2025-06-26 08:22:14,977 Epoch 1449: total training loss 0.00740\n",
            "INFO:__main__:EPOCH 1450\n",
            "2025-06-26 08:22:14,979 EPOCH 1450\n",
            "INFO:__main__:Epoch 1450: total training loss 0.00778\n",
            "2025-06-26 08:22:15,042 Epoch 1450: total training loss 0.00778\n",
            "INFO:__main__:EPOCH 1451\n",
            "2025-06-26 08:22:15,044 EPOCH 1451\n",
            "INFO:__main__:Epoch 1451: total training loss 0.00705\n",
            "2025-06-26 08:22:15,106 Epoch 1451: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1452\n",
            "2025-06-26 08:22:15,108 EPOCH 1452\n",
            "INFO:__main__:Epoch 1452: total training loss 0.00727\n",
            "2025-06-26 08:22:15,173 Epoch 1452: total training loss 0.00727\n",
            "INFO:__main__:EPOCH 1453\n",
            "2025-06-26 08:22:15,175 EPOCH 1453\n",
            "INFO:__main__:Epoch 1453: total training loss 0.00746\n",
            "2025-06-26 08:22:15,240 Epoch 1453: total training loss 0.00746\n",
            "INFO:__main__:EPOCH 1454\n",
            "2025-06-26 08:22:15,242 EPOCH 1454\n",
            "INFO:__main__:Epoch 1454: total training loss 0.00705\n",
            "2025-06-26 08:22:15,310 Epoch 1454: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1455\n",
            "2025-06-26 08:22:15,312 EPOCH 1455\n",
            "INFO:__main__:Epoch 1455: total training loss 0.00730\n",
            "2025-06-26 08:22:15,372 Epoch 1455: total training loss 0.00730\n",
            "INFO:__main__:EPOCH 1456\n",
            "2025-06-26 08:22:15,374 EPOCH 1456\n",
            "INFO:__main__:Epoch 1456: total training loss 0.00715\n",
            "2025-06-26 08:22:15,434 Epoch 1456: total training loss 0.00715\n",
            "INFO:__main__:EPOCH 1457\n",
            "2025-06-26 08:22:15,435 EPOCH 1457\n",
            "INFO:__main__:Epoch 1457: total training loss 0.00730\n",
            "2025-06-26 08:22:15,497 Epoch 1457: total training loss 0.00730\n",
            "INFO:__main__:EPOCH 1458\n",
            "2025-06-26 08:22:15,499 EPOCH 1458\n",
            "INFO:__main__:Epoch 1458: total training loss 0.00709\n",
            "2025-06-26 08:22:15,565 Epoch 1458: total training loss 0.00709\n",
            "INFO:__main__:EPOCH 1459\n",
            "2025-06-26 08:22:15,567 EPOCH 1459\n",
            "INFO:__main__:Epoch 1459: total training loss 0.00708\n",
            "2025-06-26 08:22:15,631 Epoch 1459: total training loss 0.00708\n",
            "INFO:__main__:EPOCH 1460\n",
            "2025-06-26 08:22:15,633 EPOCH 1460\n",
            "INFO:__main__:Epoch 1460: total training loss 0.00721\n",
            "2025-06-26 08:22:15,698 Epoch 1460: total training loss 0.00721\n",
            "INFO:__main__:EPOCH 1461\n",
            "2025-06-26 08:22:15,700 EPOCH 1461\n",
            "INFO:__main__:Epoch 1461: total training loss 0.00737\n",
            "2025-06-26 08:22:15,764 Epoch 1461: total training loss 0.00737\n",
            "INFO:__main__:EPOCH 1462\n",
            "2025-06-26 08:22:15,766 EPOCH 1462\n",
            "INFO:__main__:Epoch 1462: total training loss 0.00687\n",
            "2025-06-26 08:22:15,851 Epoch 1462: total training loss 0.00687\n",
            "INFO:__main__:EPOCH 1463\n",
            "2025-06-26 08:22:15,852 EPOCH 1463\n",
            "INFO:__main__:Epoch 1463: total training loss 0.00684\n",
            "2025-06-26 08:22:15,917 Epoch 1463: total training loss 0.00684\n",
            "INFO:__main__:EPOCH 1464\n",
            "2025-06-26 08:22:15,919 EPOCH 1464\n",
            "INFO:__main__:Epoch 1464: total training loss 0.00684\n",
            "2025-06-26 08:22:15,984 Epoch 1464: total training loss 0.00684\n",
            "INFO:__main__:EPOCH 1465\n",
            "2025-06-26 08:22:15,986 EPOCH 1465\n",
            "INFO:__main__:Epoch 1465: total training loss 0.00678\n",
            "2025-06-26 08:22:16,049 Epoch 1465: total training loss 0.00678\n",
            "INFO:__main__:EPOCH 1466\n",
            "2025-06-26 08:22:16,051 EPOCH 1466\n",
            "INFO:__main__:Epoch 1466: total training loss 0.00671\n",
            "2025-06-26 08:22:16,116 Epoch 1466: total training loss 0.00671\n",
            "INFO:__main__:EPOCH 1467\n",
            "2025-06-26 08:22:16,118 EPOCH 1467\n",
            "INFO:__main__:Epoch 1467: total training loss 0.00674\n",
            "2025-06-26 08:22:16,181 Epoch 1467: total training loss 0.00674\n",
            "INFO:__main__:EPOCH 1468\n",
            "2025-06-26 08:22:16,183 EPOCH 1468\n",
            "INFO:__main__:Epoch 1468: total training loss 0.00607\n",
            "2025-06-26 08:22:16,248 Epoch 1468: total training loss 0.00607\n",
            "INFO:__main__:EPOCH 1469\n",
            "2025-06-26 08:22:16,251 EPOCH 1469\n",
            "INFO:__main__:Epoch 1469: total training loss 0.00690\n",
            "2025-06-26 08:22:16,314 Epoch 1469: total training loss 0.00690\n",
            "INFO:__main__:EPOCH 1470\n",
            "2025-06-26 08:22:16,316 EPOCH 1470\n",
            "INFO:__main__:Epoch 1470: total training loss 0.00643\n",
            "2025-06-26 08:22:16,379 Epoch 1470: total training loss 0.00643\n",
            "INFO:__main__:EPOCH 1471\n",
            "2025-06-26 08:22:16,381 EPOCH 1471\n",
            "INFO:__main__:Epoch 1471: total training loss 0.00669\n",
            "2025-06-26 08:22:16,445 Epoch 1471: total training loss 0.00669\n",
            "INFO:__main__:EPOCH 1472\n",
            "2025-06-26 08:22:16,448 EPOCH 1472\n",
            "INFO:__main__:Epoch 1472: total training loss 0.00687\n",
            "2025-06-26 08:22:16,512 Epoch 1472: total training loss 0.00687\n",
            "INFO:__main__:EPOCH 1473\n",
            "2025-06-26 08:22:16,514 EPOCH 1473\n",
            "INFO:__main__:Epoch 1473: total training loss 0.00695\n",
            "2025-06-26 08:22:16,577 Epoch 1473: total training loss 0.00695\n",
            "INFO:__main__:EPOCH 1474\n",
            "2025-06-26 08:22:16,580 EPOCH 1474\n",
            "INFO:__main__:Epoch 1474: total training loss 0.00718\n",
            "2025-06-26 08:22:16,645 Epoch 1474: total training loss 0.00718\n",
            "INFO:__main__:EPOCH 1475\n",
            "2025-06-26 08:22:16,648 EPOCH 1475\n",
            "INFO:__main__:Epoch 1475: total training loss 0.00706\n",
            "2025-06-26 08:22:16,714 Epoch 1475: total training loss 0.00706\n",
            "INFO:__main__:EPOCH 1476\n",
            "2025-06-26 08:22:16,717 EPOCH 1476\n",
            "INFO:__main__:Epoch 1476: total training loss 0.00705\n",
            "2025-06-26 08:22:16,779 Epoch 1476: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1477\n",
            "2025-06-26 08:22:16,781 EPOCH 1477\n",
            "INFO:__main__:Epoch 1477: total training loss 0.00686\n",
            "2025-06-26 08:22:16,846 Epoch 1477: total training loss 0.00686\n",
            "INFO:__main__:EPOCH 1478\n",
            "2025-06-26 08:22:16,852 EPOCH 1478\n",
            "INFO:__main__:Epoch 1478: total training loss 0.00677\n",
            "2025-06-26 08:22:16,926 Epoch 1478: total training loss 0.00677\n",
            "INFO:__main__:EPOCH 1479\n",
            "2025-06-26 08:22:16,928 EPOCH 1479\n",
            "INFO:__main__:Epoch 1479: total training loss 0.00742\n",
            "2025-06-26 08:22:16,992 Epoch 1479: total training loss 0.00742\n",
            "INFO:__main__:EPOCH 1480\n",
            "2025-06-26 08:22:16,994 EPOCH 1480\n",
            "INFO:__main__:Epoch 1480: total training loss 0.00663\n",
            "2025-06-26 08:22:17,062 Epoch 1480: total training loss 0.00663\n",
            "INFO:__main__:EPOCH 1481\n",
            "2025-06-26 08:22:17,064 EPOCH 1481\n",
            "INFO:__main__:Epoch 1481: total training loss 0.00715\n",
            "2025-06-26 08:22:17,131 Epoch 1481: total training loss 0.00715\n",
            "INFO:__main__:EPOCH 1482\n",
            "2025-06-26 08:22:17,133 EPOCH 1482\n",
            "INFO:__main__:Epoch 1482: total training loss 0.00708\n",
            "2025-06-26 08:22:17,202 Epoch 1482: total training loss 0.00708\n",
            "INFO:__main__:EPOCH 1483\n",
            "2025-06-26 08:22:17,204 EPOCH 1483\n",
            "INFO:__main__:Epoch 1483: total training loss 0.00707\n",
            "2025-06-26 08:22:17,269 Epoch 1483: total training loss 0.00707\n",
            "INFO:__main__:EPOCH 1484\n",
            "2025-06-26 08:22:17,271 EPOCH 1484\n",
            "INFO:__main__:Epoch 1484: total training loss 0.00728\n",
            "2025-06-26 08:22:17,335 Epoch 1484: total training loss 0.00728\n",
            "INFO:__main__:EPOCH 1485\n",
            "2025-06-26 08:22:17,337 EPOCH 1485\n",
            "INFO:__main__:Epoch 1485: total training loss 0.00700\n",
            "2025-06-26 08:22:17,398 Epoch 1485: total training loss 0.00700\n",
            "INFO:__main__:EPOCH 1486\n",
            "2025-06-26 08:22:17,399 EPOCH 1486\n",
            "INFO:__main__:Epoch 1486: total training loss 0.00727\n",
            "2025-06-26 08:22:17,464 Epoch 1486: total training loss 0.00727\n",
            "INFO:__main__:EPOCH 1487\n",
            "2025-06-26 08:22:17,465 EPOCH 1487\n",
            "INFO:__main__:Epoch 1487: total training loss 0.00663\n",
            "2025-06-26 08:22:17,529 Epoch 1487: total training loss 0.00663\n",
            "INFO:__main__:EPOCH 1488\n",
            "2025-06-26 08:22:17,531 EPOCH 1488\n",
            "INFO:__main__:Epoch 1488: total training loss 0.00703\n",
            "2025-06-26 08:22:17,596 Epoch 1488: total training loss 0.00703\n",
            "INFO:__main__:EPOCH 1489\n",
            "2025-06-26 08:22:17,598 EPOCH 1489\n",
            "INFO:__main__:Epoch 1489: total training loss 0.00716\n",
            "2025-06-26 08:22:17,662 Epoch 1489: total training loss 0.00716\n",
            "INFO:__main__:EPOCH 1490\n",
            "2025-06-26 08:22:17,665 EPOCH 1490\n",
            "INFO:__main__:Epoch 1490: total training loss 0.00718\n",
            "2025-06-26 08:22:17,730 Epoch 1490: total training loss 0.00718\n",
            "INFO:__main__:EPOCH 1491\n",
            "2025-06-26 08:22:17,732 EPOCH 1491\n",
            "INFO:__main__:Epoch 1491: total training loss 0.00693\n",
            "2025-06-26 08:22:17,800 Epoch 1491: total training loss 0.00693\n",
            "INFO:__main__:EPOCH 1492\n",
            "2025-06-26 08:22:17,802 EPOCH 1492\n",
            "INFO:__main__:Epoch 1492: total training loss 0.00668\n",
            "2025-06-26 08:22:17,865 Epoch 1492: total training loss 0.00668\n",
            "INFO:__main__:EPOCH 1493\n",
            "2025-06-26 08:22:17,867 EPOCH 1493\n",
            "INFO:__main__:Epoch 1493: total training loss 0.00699\n",
            "2025-06-26 08:22:17,947 Epoch 1493: total training loss 0.00699\n",
            "INFO:__main__:EPOCH 1494\n",
            "2025-06-26 08:22:17,949 EPOCH 1494\n",
            "INFO:__main__:Epoch 1494: total training loss 0.00733\n",
            "2025-06-26 08:22:18,013 Epoch 1494: total training loss 0.00733\n",
            "INFO:__main__:EPOCH 1495\n",
            "2025-06-26 08:22:18,015 EPOCH 1495\n",
            "INFO:__main__:Epoch 1495: total training loss 0.00716\n",
            "2025-06-26 08:22:18,093 Epoch 1495: total training loss 0.00716\n",
            "INFO:__main__:EPOCH 1496\n",
            "2025-06-26 08:22:18,095 EPOCH 1496\n",
            "INFO:__main__:Epoch 1496: total training loss 0.00714\n",
            "2025-06-26 08:22:18,160 Epoch 1496: total training loss 0.00714\n",
            "INFO:__main__:EPOCH 1497\n",
            "2025-06-26 08:22:18,162 EPOCH 1497\n",
            "INFO:__main__:Epoch 1497: total training loss 0.00786\n",
            "2025-06-26 08:22:18,226 Epoch 1497: total training loss 0.00786\n",
            "INFO:__main__:EPOCH 1498\n",
            "2025-06-26 08:22:18,228 EPOCH 1498\n",
            "INFO:__main__:Epoch 1498: total training loss 0.00723\n",
            "2025-06-26 08:22:18,298 Epoch 1498: total training loss 0.00723\n",
            "INFO:__main__:EPOCH 1499\n",
            "2025-06-26 08:22:18,301 EPOCH 1499\n",
            "INFO:__main__:Epoch 1499: total training loss 0.00771\n",
            "2025-06-26 08:22:18,364 Epoch 1499: total training loss 0.00771\n",
            "INFO:__main__:EPOCH 1500\n",
            "2025-06-26 08:22:18,366 EPOCH 1500\n",
            "INFO:__main__:Epoch 1500 Step:     1500 Batch Loss:     0.007183 Tokens per Sec:  2339586, Lr: 0.001000\n",
            "2025-06-26 08:22:18,429 Epoch 1500 Step:     1500 Batch Loss:     0.007183 Tokens per Sec:  2339586, Lr: 0.001000\n",
            "INFO:__main__:Epoch 1500: total training loss 0.00718\n",
            "2025-06-26 08:22:18,431 Epoch 1500: total training loss 0.00718\n",
            "INFO:__main__:EPOCH 1501\n",
            "2025-06-26 08:22:18,434 EPOCH 1501\n",
            "INFO:__main__:Epoch 1501: total training loss 0.00764\n",
            "2025-06-26 08:22:18,500 Epoch 1501: total training loss 0.00764\n",
            "INFO:__main__:EPOCH 1502\n",
            "2025-06-26 08:22:18,502 EPOCH 1502\n",
            "INFO:__main__:Epoch 1502: total training loss 0.00713\n",
            "2025-06-26 08:22:18,571 Epoch 1502: total training loss 0.00713\n",
            "INFO:__main__:EPOCH 1503\n",
            "2025-06-26 08:22:18,573 EPOCH 1503\n",
            "INFO:__main__:Epoch 1503: total training loss 0.00663\n",
            "2025-06-26 08:22:18,637 Epoch 1503: total training loss 0.00663\n",
            "INFO:__main__:EPOCH 1504\n",
            "2025-06-26 08:22:18,639 EPOCH 1504\n",
            "INFO:__main__:Epoch 1504: total training loss 0.00703\n",
            "2025-06-26 08:22:18,704 Epoch 1504: total training loss 0.00703\n",
            "INFO:__main__:EPOCH 1505\n",
            "2025-06-26 08:22:18,706 EPOCH 1505\n",
            "INFO:__main__:Epoch 1505: total training loss 0.00736\n",
            "2025-06-26 08:22:18,773 Epoch 1505: total training loss 0.00736\n",
            "INFO:__main__:EPOCH 1506\n",
            "2025-06-26 08:22:18,775 EPOCH 1506\n",
            "INFO:__main__:Epoch 1506: total training loss 0.00779\n",
            "2025-06-26 08:22:18,842 Epoch 1506: total training loss 0.00779\n",
            "INFO:__main__:EPOCH 1507\n",
            "2025-06-26 08:22:18,844 EPOCH 1507\n",
            "INFO:__main__:Epoch 1507: total training loss 0.00683\n",
            "2025-06-26 08:22:18,907 Epoch 1507: total training loss 0.00683\n",
            "INFO:__main__:EPOCH 1508\n",
            "2025-06-26 08:22:18,908 EPOCH 1508\n",
            "INFO:__main__:Epoch 1508: total training loss 0.00743\n",
            "2025-06-26 08:22:18,989 Epoch 1508: total training loss 0.00743\n",
            "INFO:__main__:EPOCH 1509\n",
            "2025-06-26 08:22:18,992 EPOCH 1509\n",
            "INFO:__main__:Epoch 1509: total training loss 0.00725\n",
            "2025-06-26 08:22:19,065 Epoch 1509: total training loss 0.00725\n",
            "INFO:__main__:EPOCH 1510\n",
            "2025-06-26 08:22:19,068 EPOCH 1510\n",
            "INFO:__main__:Epoch 1510: total training loss 0.00738\n",
            "2025-06-26 08:22:19,134 Epoch 1510: total training loss 0.00738\n",
            "INFO:__main__:EPOCH 1511\n",
            "2025-06-26 08:22:19,138 EPOCH 1511\n",
            "INFO:__main__:Epoch 1511: total training loss 0.00767\n",
            "2025-06-26 08:22:19,201 Epoch 1511: total training loss 0.00767\n",
            "INFO:__main__:EPOCH 1512\n",
            "2025-06-26 08:22:19,203 EPOCH 1512\n",
            "INFO:__main__:Epoch 1512: total training loss 0.00751\n",
            "2025-06-26 08:22:19,267 Epoch 1512: total training loss 0.00751\n",
            "INFO:__main__:EPOCH 1513\n",
            "2025-06-26 08:22:19,269 EPOCH 1513\n",
            "INFO:__main__:Epoch 1513: total training loss 0.00722\n",
            "2025-06-26 08:22:19,348 Epoch 1513: total training loss 0.00722\n",
            "INFO:__main__:EPOCH 1514\n",
            "2025-06-26 08:22:19,350 EPOCH 1514\n",
            "INFO:__main__:Epoch 1514: total training loss 0.00743\n",
            "2025-06-26 08:22:19,427 Epoch 1514: total training loss 0.00743\n",
            "INFO:__main__:EPOCH 1515\n",
            "2025-06-26 08:22:19,429 EPOCH 1515\n",
            "INFO:__main__:Epoch 1515: total training loss 0.00747\n",
            "2025-06-26 08:22:19,493 Epoch 1515: total training loss 0.00747\n",
            "INFO:__main__:EPOCH 1516\n",
            "2025-06-26 08:22:19,495 EPOCH 1516\n",
            "INFO:__main__:Epoch 1516: total training loss 0.00708\n",
            "2025-06-26 08:22:19,556 Epoch 1516: total training loss 0.00708\n",
            "INFO:__main__:EPOCH 1517\n",
            "2025-06-26 08:22:19,558 EPOCH 1517\n",
            "INFO:__main__:Epoch 1517: total training loss 0.00741\n",
            "2025-06-26 08:22:19,621 Epoch 1517: total training loss 0.00741\n",
            "INFO:__main__:EPOCH 1518\n",
            "2025-06-26 08:22:19,623 EPOCH 1518\n",
            "INFO:__main__:Epoch 1518: total training loss 0.00708\n",
            "2025-06-26 08:22:19,687 Epoch 1518: total training loss 0.00708\n",
            "INFO:__main__:EPOCH 1519\n",
            "2025-06-26 08:22:19,689 EPOCH 1519\n",
            "INFO:__main__:Epoch 1519: total training loss 0.00673\n",
            "2025-06-26 08:22:19,761 Epoch 1519: total training loss 0.00673\n",
            "INFO:__main__:EPOCH 1520\n",
            "2025-06-26 08:22:19,763 EPOCH 1520\n",
            "INFO:__main__:Epoch 1520: total training loss 0.00686\n",
            "2025-06-26 08:22:19,828 Epoch 1520: total training loss 0.00686\n",
            "INFO:__main__:EPOCH 1521\n",
            "2025-06-26 08:22:19,830 EPOCH 1521\n",
            "INFO:__main__:Epoch 1521: total training loss 0.00722\n",
            "2025-06-26 08:22:19,892 Epoch 1521: total training loss 0.00722\n",
            "INFO:__main__:EPOCH 1522\n",
            "2025-06-26 08:22:19,894 EPOCH 1522\n",
            "INFO:__main__:Epoch 1522: total training loss 0.00670\n",
            "2025-06-26 08:22:19,962 Epoch 1522: total training loss 0.00670\n",
            "INFO:__main__:EPOCH 1523\n",
            "2025-06-26 08:22:19,964 EPOCH 1523\n",
            "INFO:__main__:Epoch 1523: total training loss 0.00709\n",
            "2025-06-26 08:22:20,044 Epoch 1523: total training loss 0.00709\n",
            "INFO:__main__:EPOCH 1524\n",
            "2025-06-26 08:22:20,046 EPOCH 1524\n",
            "INFO:__main__:Epoch 1524: total training loss 0.00706\n",
            "2025-06-26 08:22:20,112 Epoch 1524: total training loss 0.00706\n",
            "INFO:__main__:EPOCH 1525\n",
            "2025-06-26 08:22:20,114 EPOCH 1525\n",
            "INFO:__main__:Epoch 1525: total training loss 0.00735\n",
            "2025-06-26 08:22:20,177 Epoch 1525: total training loss 0.00735\n",
            "INFO:__main__:EPOCH 1526\n",
            "2025-06-26 08:22:20,180 EPOCH 1526\n",
            "INFO:__main__:Epoch 1526: total training loss 0.00666\n",
            "2025-06-26 08:22:20,253 Epoch 1526: total training loss 0.00666\n",
            "INFO:__main__:EPOCH 1527\n",
            "2025-06-26 08:22:20,255 EPOCH 1527\n",
            "INFO:__main__:Epoch 1527: total training loss 0.00756\n",
            "2025-06-26 08:22:20,321 Epoch 1527: total training loss 0.00756\n",
            "INFO:__main__:EPOCH 1528\n",
            "2025-06-26 08:22:20,323 EPOCH 1528\n",
            "INFO:__main__:Epoch 1528: total training loss 0.00754\n",
            "2025-06-26 08:22:20,386 Epoch 1528: total training loss 0.00754\n",
            "INFO:__main__:EPOCH 1529\n",
            "2025-06-26 08:22:20,389 EPOCH 1529\n",
            "INFO:__main__:Epoch 1529: total training loss 0.00759\n",
            "2025-06-26 08:22:20,454 Epoch 1529: total training loss 0.00759\n",
            "INFO:__main__:EPOCH 1530\n",
            "2025-06-26 08:22:20,456 EPOCH 1530\n",
            "INFO:__main__:Epoch 1530: total training loss 0.00749\n",
            "2025-06-26 08:22:20,519 Epoch 1530: total training loss 0.00749\n",
            "INFO:__main__:EPOCH 1531\n",
            "2025-06-26 08:22:20,521 EPOCH 1531\n",
            "INFO:__main__:Epoch 1531: total training loss 0.00732\n",
            "2025-06-26 08:22:20,586 Epoch 1531: total training loss 0.00732\n",
            "INFO:__main__:EPOCH 1532\n",
            "2025-06-26 08:22:20,588 EPOCH 1532\n",
            "INFO:__main__:Epoch 1532: total training loss 0.00735\n",
            "2025-06-26 08:22:20,652 Epoch 1532: total training loss 0.00735\n",
            "INFO:__main__:EPOCH 1533\n",
            "2025-06-26 08:22:20,654 EPOCH 1533\n",
            "INFO:__main__:Epoch 1533: total training loss 0.00728\n",
            "2025-06-26 08:22:20,719 Epoch 1533: total training loss 0.00728\n",
            "INFO:__main__:EPOCH 1534\n",
            "2025-06-26 08:22:20,721 EPOCH 1534\n",
            "INFO:__main__:Epoch 1534: total training loss 0.00672\n",
            "2025-06-26 08:22:20,794 Epoch 1534: total training loss 0.00672\n",
            "INFO:__main__:EPOCH 1535\n",
            "2025-06-26 08:22:20,796 EPOCH 1535\n",
            "INFO:__main__:Epoch 1535: total training loss 0.00754\n",
            "2025-06-26 08:22:20,861 Epoch 1535: total training loss 0.00754\n",
            "INFO:__main__:EPOCH 1536\n",
            "2025-06-26 08:22:20,863 EPOCH 1536\n",
            "INFO:__main__:Epoch 1536: total training loss 0.00720\n",
            "2025-06-26 08:22:20,928 Epoch 1536: total training loss 0.00720\n",
            "INFO:__main__:EPOCH 1537\n",
            "2025-06-26 08:22:20,930 EPOCH 1537\n",
            "INFO:__main__:Epoch 1537: total training loss 0.00681\n",
            "2025-06-26 08:22:20,997 Epoch 1537: total training loss 0.00681\n",
            "INFO:__main__:EPOCH 1538\n",
            "2025-06-26 08:22:20,999 EPOCH 1538\n",
            "INFO:__main__:Epoch 1538: total training loss 0.00690\n",
            "2025-06-26 08:22:21,085 Epoch 1538: total training loss 0.00690\n",
            "INFO:__main__:EPOCH 1539\n",
            "2025-06-26 08:22:21,087 EPOCH 1539\n",
            "INFO:__main__:Epoch 1539: total training loss 0.00697\n",
            "2025-06-26 08:22:21,148 Epoch 1539: total training loss 0.00697\n",
            "INFO:__main__:EPOCH 1540\n",
            "2025-06-26 08:22:21,150 EPOCH 1540\n",
            "INFO:__main__:Epoch 1540: total training loss 0.00704\n",
            "2025-06-26 08:22:21,214 Epoch 1540: total training loss 0.00704\n",
            "INFO:__main__:EPOCH 1541\n",
            "2025-06-26 08:22:21,216 EPOCH 1541\n",
            "INFO:__main__:Epoch 1541: total training loss 0.00690\n",
            "2025-06-26 08:22:21,278 Epoch 1541: total training loss 0.00690\n",
            "INFO:__main__:EPOCH 1542\n",
            "2025-06-26 08:22:21,280 EPOCH 1542\n",
            "INFO:__main__:Epoch 1542: total training loss 0.00667\n",
            "2025-06-26 08:22:21,345 Epoch 1542: total training loss 0.00667\n",
            "INFO:__main__:EPOCH 1543\n",
            "2025-06-26 08:22:21,347 EPOCH 1543\n",
            "INFO:__main__:Epoch 1543: total training loss 0.00673\n",
            "2025-06-26 08:22:21,409 Epoch 1543: total training loss 0.00673\n",
            "INFO:__main__:EPOCH 1544\n",
            "2025-06-26 08:22:21,411 EPOCH 1544\n",
            "INFO:__main__:Epoch 1544: total training loss 0.00651\n",
            "2025-06-26 08:22:21,472 Epoch 1544: total training loss 0.00651\n",
            "INFO:__main__:EPOCH 1545\n",
            "2025-06-26 08:22:21,474 EPOCH 1545\n",
            "INFO:__main__:Epoch 1545: total training loss 0.00657\n",
            "2025-06-26 08:22:21,538 Epoch 1545: total training loss 0.00657\n",
            "INFO:__main__:EPOCH 1546\n",
            "2025-06-26 08:22:21,540 EPOCH 1546\n",
            "INFO:__main__:Epoch 1546: total training loss 0.00676\n",
            "2025-06-26 08:22:21,604 Epoch 1546: total training loss 0.00676\n",
            "INFO:__main__:EPOCH 1547\n",
            "2025-06-26 08:22:21,606 EPOCH 1547\n",
            "INFO:__main__:Epoch 1547: total training loss 0.00633\n",
            "2025-06-26 08:22:21,669 Epoch 1547: total training loss 0.00633\n",
            "INFO:__main__:EPOCH 1548\n",
            "2025-06-26 08:22:21,671 EPOCH 1548\n",
            "INFO:__main__:Epoch 1548: total training loss 0.00674\n",
            "2025-06-26 08:22:21,733 Epoch 1548: total training loss 0.00674\n",
            "INFO:__main__:EPOCH 1549\n",
            "2025-06-26 08:22:21,735 EPOCH 1549\n",
            "INFO:__main__:Epoch 1549: total training loss 0.00676\n",
            "2025-06-26 08:22:21,797 Epoch 1549: total training loss 0.00676\n",
            "INFO:__main__:EPOCH 1550\n",
            "2025-06-26 08:22:21,799 EPOCH 1550\n",
            "INFO:__main__:Epoch 1550: total training loss 0.00619\n",
            "2025-06-26 08:22:21,867 Epoch 1550: total training loss 0.00619\n",
            "INFO:__main__:EPOCH 1551\n",
            "2025-06-26 08:22:21,870 EPOCH 1551\n",
            "INFO:__main__:Epoch 1551: total training loss 0.00663\n",
            "2025-06-26 08:22:21,932 Epoch 1551: total training loss 0.00663\n",
            "INFO:__main__:EPOCH 1552\n",
            "2025-06-26 08:22:21,934 EPOCH 1552\n",
            "INFO:__main__:Epoch 1552: total training loss 0.00645\n",
            "2025-06-26 08:22:21,996 Epoch 1552: total training loss 0.00645\n",
            "INFO:__main__:EPOCH 1553\n",
            "2025-06-26 08:22:21,998 EPOCH 1553\n",
            "INFO:__main__:Epoch 1553: total training loss 0.00671\n",
            "2025-06-26 08:22:22,060 Epoch 1553: total training loss 0.00671\n",
            "INFO:__main__:EPOCH 1554\n",
            "2025-06-26 08:22:22,062 EPOCH 1554\n",
            "INFO:__main__:Epoch 1554: total training loss 0.00670\n",
            "2025-06-26 08:22:22,147 Epoch 1554: total training loss 0.00670\n",
            "INFO:__main__:EPOCH 1555\n",
            "2025-06-26 08:22:22,149 EPOCH 1555\n",
            "INFO:__main__:Epoch 1555: total training loss 0.00705\n",
            "2025-06-26 08:22:22,214 Epoch 1555: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1556\n",
            "2025-06-26 08:22:22,216 EPOCH 1556\n",
            "INFO:__main__:Epoch 1556: total training loss 0.00716\n",
            "2025-06-26 08:22:22,280 Epoch 1556: total training loss 0.00716\n",
            "INFO:__main__:EPOCH 1557\n",
            "2025-06-26 08:22:22,282 EPOCH 1557\n",
            "INFO:__main__:Epoch 1557: total training loss 0.00693\n",
            "2025-06-26 08:22:22,348 Epoch 1557: total training loss 0.00693\n",
            "INFO:__main__:EPOCH 1558\n",
            "2025-06-26 08:22:22,350 EPOCH 1558\n",
            "INFO:__main__:Epoch 1558: total training loss 0.00627\n",
            "2025-06-26 08:22:22,414 Epoch 1558: total training loss 0.00627\n",
            "INFO:__main__:EPOCH 1559\n",
            "2025-06-26 08:22:22,416 EPOCH 1559\n",
            "INFO:__main__:Epoch 1559: total training loss 0.00726\n",
            "2025-06-26 08:22:22,478 Epoch 1559: total training loss 0.00726\n",
            "INFO:__main__:EPOCH 1560\n",
            "2025-06-26 08:22:22,480 EPOCH 1560\n",
            "INFO:__main__:Epoch 1560: total training loss 0.00681\n",
            "2025-06-26 08:22:22,572 Epoch 1560: total training loss 0.00681\n",
            "INFO:__main__:EPOCH 1561\n",
            "2025-06-26 08:22:22,575 EPOCH 1561\n",
            "INFO:__main__:Epoch 1561: total training loss 0.00664\n",
            "2025-06-26 08:22:22,665 Epoch 1561: total training loss 0.00664\n",
            "INFO:__main__:EPOCH 1562\n",
            "2025-06-26 08:22:22,667 EPOCH 1562\n",
            "INFO:__main__:Epoch 1562: total training loss 0.00673\n",
            "2025-06-26 08:22:22,756 Epoch 1562: total training loss 0.00673\n",
            "INFO:__main__:EPOCH 1563\n",
            "2025-06-26 08:22:22,758 EPOCH 1563\n",
            "INFO:__main__:Epoch 1563: total training loss 0.00652\n",
            "2025-06-26 08:22:22,843 Epoch 1563: total training loss 0.00652\n",
            "INFO:__main__:EPOCH 1564\n",
            "2025-06-26 08:22:22,845 EPOCH 1564\n",
            "INFO:__main__:Epoch 1564: total training loss 0.00682\n",
            "2025-06-26 08:22:22,926 Epoch 1564: total training loss 0.00682\n",
            "INFO:__main__:EPOCH 1565\n",
            "2025-06-26 08:22:22,928 EPOCH 1565\n",
            "INFO:__main__:Epoch 1565: total training loss 0.00670\n",
            "2025-06-26 08:22:23,010 Epoch 1565: total training loss 0.00670\n",
            "INFO:__main__:EPOCH 1566\n",
            "2025-06-26 08:22:23,012 EPOCH 1566\n",
            "INFO:__main__:Epoch 1566: total training loss 0.00720\n",
            "2025-06-26 08:22:23,086 Epoch 1566: total training loss 0.00720\n",
            "INFO:__main__:EPOCH 1567\n",
            "2025-06-26 08:22:23,088 EPOCH 1567\n",
            "INFO:__main__:Epoch 1567: total training loss 0.00692\n",
            "2025-06-26 08:22:23,173 Epoch 1567: total training loss 0.00692\n",
            "INFO:__main__:EPOCH 1568\n",
            "2025-06-26 08:22:23,175 EPOCH 1568\n",
            "INFO:__main__:Epoch 1568: total training loss 0.00719\n",
            "2025-06-26 08:22:23,257 Epoch 1568: total training loss 0.00719\n",
            "INFO:__main__:EPOCH 1569\n",
            "2025-06-26 08:22:23,259 EPOCH 1569\n",
            "INFO:__main__:Epoch 1569: total training loss 0.00694\n",
            "2025-06-26 08:22:23,340 Epoch 1569: total training loss 0.00694\n",
            "INFO:__main__:EPOCH 1570\n",
            "2025-06-26 08:22:23,342 EPOCH 1570\n",
            "INFO:__main__:Epoch 1570: total training loss 0.00704\n",
            "2025-06-26 08:22:23,418 Epoch 1570: total training loss 0.00704\n",
            "INFO:__main__:EPOCH 1571\n",
            "2025-06-26 08:22:23,420 EPOCH 1571\n",
            "INFO:__main__:Epoch 1571: total training loss 0.00725\n",
            "2025-06-26 08:22:23,491 Epoch 1571: total training loss 0.00725\n",
            "INFO:__main__:EPOCH 1572\n",
            "2025-06-26 08:22:23,493 EPOCH 1572\n",
            "INFO:__main__:Epoch 1572: total training loss 0.00707\n",
            "2025-06-26 08:22:23,571 Epoch 1572: total training loss 0.00707\n",
            "INFO:__main__:EPOCH 1573\n",
            "2025-06-26 08:22:23,573 EPOCH 1573\n",
            "INFO:__main__:Epoch 1573: total training loss 0.00657\n",
            "2025-06-26 08:22:23,648 Epoch 1573: total training loss 0.00657\n",
            "INFO:__main__:EPOCH 1574\n",
            "2025-06-26 08:22:23,650 EPOCH 1574\n",
            "INFO:__main__:Epoch 1574: total training loss 0.00686\n",
            "2025-06-26 08:22:23,719 Epoch 1574: total training loss 0.00686\n",
            "INFO:__main__:EPOCH 1575\n",
            "2025-06-26 08:22:23,721 EPOCH 1575\n",
            "INFO:__main__:Epoch 1575: total training loss 0.00677\n",
            "2025-06-26 08:22:23,796 Epoch 1575: total training loss 0.00677\n",
            "INFO:__main__:EPOCH 1576\n",
            "2025-06-26 08:22:23,798 EPOCH 1576\n",
            "INFO:__main__:Epoch 1576: total training loss 0.00662\n",
            "2025-06-26 08:22:23,867 Epoch 1576: total training loss 0.00662\n",
            "INFO:__main__:EPOCH 1577\n",
            "2025-06-26 08:22:23,869 EPOCH 1577\n",
            "INFO:__main__:Epoch 1577: total training loss 0.00691\n",
            "2025-06-26 08:22:23,946 Epoch 1577: total training loss 0.00691\n",
            "INFO:__main__:EPOCH 1578\n",
            "2025-06-26 08:22:23,948 EPOCH 1578\n",
            "INFO:__main__:Epoch 1578: total training loss 0.00648\n",
            "2025-06-26 08:22:24,016 Epoch 1578: total training loss 0.00648\n",
            "INFO:__main__:EPOCH 1579\n",
            "2025-06-26 08:22:24,018 EPOCH 1579\n",
            "INFO:__main__:Epoch 1579: total training loss 0.00655\n",
            "2025-06-26 08:22:24,089 Epoch 1579: total training loss 0.00655\n",
            "INFO:__main__:EPOCH 1580\n",
            "2025-06-26 08:22:24,091 EPOCH 1580\n",
            "INFO:__main__:Epoch 1580: total training loss 0.00717\n",
            "2025-06-26 08:22:24,168 Epoch 1580: total training loss 0.00717\n",
            "INFO:__main__:EPOCH 1581\n",
            "2025-06-26 08:22:24,170 EPOCH 1581\n",
            "INFO:__main__:Epoch 1581: total training loss 0.00649\n",
            "2025-06-26 08:22:24,275 Epoch 1581: total training loss 0.00649\n",
            "INFO:__main__:EPOCH 1582\n",
            "2025-06-26 08:22:24,277 EPOCH 1582\n",
            "INFO:__main__:Epoch 1582: total training loss 0.00703\n",
            "2025-06-26 08:22:24,369 Epoch 1582: total training loss 0.00703\n",
            "INFO:__main__:EPOCH 1583\n",
            "2025-06-26 08:22:24,370 EPOCH 1583\n",
            "INFO:__main__:Epoch 1583: total training loss 0.00730\n",
            "2025-06-26 08:22:24,458 Epoch 1583: total training loss 0.00730\n",
            "INFO:__main__:EPOCH 1584\n",
            "2025-06-26 08:22:24,462 EPOCH 1584\n",
            "INFO:__main__:Epoch 1584: total training loss 0.00705\n",
            "2025-06-26 08:22:24,550 Epoch 1584: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1585\n",
            "2025-06-26 08:22:24,552 EPOCH 1585\n",
            "INFO:__main__:Epoch 1585: total training loss 0.00728\n",
            "2025-06-26 08:22:24,627 Epoch 1585: total training loss 0.00728\n",
            "INFO:__main__:EPOCH 1586\n",
            "2025-06-26 08:22:24,629 EPOCH 1586\n",
            "INFO:__main__:Epoch 1586: total training loss 0.00672\n",
            "2025-06-26 08:22:24,705 Epoch 1586: total training loss 0.00672\n",
            "INFO:__main__:EPOCH 1587\n",
            "2025-06-26 08:22:24,707 EPOCH 1587\n",
            "INFO:__main__:Epoch 1587: total training loss 0.00704\n",
            "2025-06-26 08:22:24,793 Epoch 1587: total training loss 0.00704\n",
            "INFO:__main__:EPOCH 1588\n",
            "2025-06-26 08:22:24,796 EPOCH 1588\n",
            "INFO:__main__:Epoch 1588: total training loss 0.00704\n",
            "2025-06-26 08:22:24,888 Epoch 1588: total training loss 0.00704\n",
            "INFO:__main__:EPOCH 1589\n",
            "2025-06-26 08:22:24,890 EPOCH 1589\n",
            "INFO:__main__:Epoch 1589: total training loss 0.00682\n",
            "2025-06-26 08:22:24,961 Epoch 1589: total training loss 0.00682\n",
            "INFO:__main__:EPOCH 1590\n",
            "2025-06-26 08:22:24,963 EPOCH 1590\n",
            "INFO:__main__:Epoch 1590: total training loss 0.00674\n",
            "2025-06-26 08:22:25,033 Epoch 1590: total training loss 0.00674\n",
            "INFO:__main__:EPOCH 1591\n",
            "2025-06-26 08:22:25,035 EPOCH 1591\n",
            "INFO:__main__:Epoch 1591: total training loss 0.00687\n",
            "2025-06-26 08:22:25,107 Epoch 1591: total training loss 0.00687\n",
            "INFO:__main__:EPOCH 1592\n",
            "2025-06-26 08:22:25,109 EPOCH 1592\n",
            "INFO:__main__:Epoch 1592: total training loss 0.00706\n",
            "2025-06-26 08:22:25,181 Epoch 1592: total training loss 0.00706\n",
            "INFO:__main__:EPOCH 1593\n",
            "2025-06-26 08:22:25,183 EPOCH 1593\n",
            "INFO:__main__:Epoch 1593: total training loss 0.00623\n",
            "2025-06-26 08:22:25,260 Epoch 1593: total training loss 0.00623\n",
            "INFO:__main__:EPOCH 1594\n",
            "2025-06-26 08:22:25,262 EPOCH 1594\n",
            "INFO:__main__:Epoch 1594: total training loss 0.00683\n",
            "2025-06-26 08:22:25,340 Epoch 1594: total training loss 0.00683\n",
            "INFO:__main__:EPOCH 1595\n",
            "2025-06-26 08:22:25,342 EPOCH 1595\n",
            "INFO:__main__:Epoch 1595: total training loss 0.00698\n",
            "2025-06-26 08:22:25,440 Epoch 1595: total training loss 0.00698\n",
            "INFO:__main__:EPOCH 1596\n",
            "2025-06-26 08:22:25,442 EPOCH 1596\n",
            "INFO:__main__:Epoch 1596: total training loss 0.00717\n",
            "2025-06-26 08:22:25,530 Epoch 1596: total training loss 0.00717\n",
            "INFO:__main__:EPOCH 1597\n",
            "2025-06-26 08:22:25,532 EPOCH 1597\n",
            "INFO:__main__:Epoch 1597: total training loss 0.00634\n",
            "2025-06-26 08:22:25,619 Epoch 1597: total training loss 0.00634\n",
            "INFO:__main__:EPOCH 1598\n",
            "2025-06-26 08:22:25,621 EPOCH 1598\n",
            "INFO:__main__:Epoch 1598: total training loss 0.00675\n",
            "2025-06-26 08:22:25,692 Epoch 1598: total training loss 0.00675\n",
            "INFO:__main__:EPOCH 1599\n",
            "2025-06-26 08:22:25,694 EPOCH 1599\n",
            "INFO:__main__:Epoch 1599: total training loss 0.00653\n",
            "2025-06-26 08:22:25,768 Epoch 1599: total training loss 0.00653\n",
            "INFO:__main__:EPOCH 1600\n",
            "2025-06-26 08:22:25,771 EPOCH 1600\n",
            "INFO:__main__:Epoch 1600: total training loss 0.00620\n",
            "2025-06-26 08:22:25,842 Epoch 1600: total training loss 0.00620\n",
            "INFO:__main__:EPOCH 1601\n",
            "2025-06-26 08:22:25,844 EPOCH 1601\n",
            "INFO:__main__:Epoch 1601: total training loss 0.00626\n",
            "2025-06-26 08:22:25,912 Epoch 1601: total training loss 0.00626\n",
            "INFO:__main__:EPOCH 1602\n",
            "2025-06-26 08:22:25,914 EPOCH 1602\n",
            "INFO:__main__:Epoch 1602: total training loss 0.00645\n",
            "2025-06-26 08:22:25,985 Epoch 1602: total training loss 0.00645\n",
            "INFO:__main__:EPOCH 1603\n",
            "2025-06-26 08:22:25,987 EPOCH 1603\n",
            "INFO:__main__:Epoch 1603: total training loss 0.00610\n",
            "2025-06-26 08:22:26,065 Epoch 1603: total training loss 0.00610\n",
            "INFO:__main__:EPOCH 1604\n",
            "2025-06-26 08:22:26,067 EPOCH 1604\n",
            "INFO:__main__:Epoch 1604: total training loss 0.00627\n",
            "2025-06-26 08:22:26,135 Epoch 1604: total training loss 0.00627\n",
            "INFO:__main__:EPOCH 1605\n",
            "2025-06-26 08:22:26,137 EPOCH 1605\n",
            "INFO:__main__:Epoch 1605: total training loss 0.00594\n",
            "2025-06-26 08:22:26,217 Epoch 1605: total training loss 0.00594\n",
            "INFO:__main__:EPOCH 1606\n",
            "2025-06-26 08:22:26,219 EPOCH 1606\n",
            "INFO:__main__:Epoch 1606: total training loss 0.00635\n",
            "2025-06-26 08:22:26,296 Epoch 1606: total training loss 0.00635\n",
            "INFO:__main__:EPOCH 1607\n",
            "2025-06-26 08:22:26,298 EPOCH 1607\n",
            "INFO:__main__:Epoch 1607: total training loss 0.00686\n",
            "2025-06-26 08:22:26,390 Epoch 1607: total training loss 0.00686\n",
            "INFO:__main__:EPOCH 1608\n",
            "2025-06-26 08:22:26,393 EPOCH 1608\n",
            "INFO:__main__:Epoch 1608: total training loss 0.00681\n",
            "2025-06-26 08:22:26,493 Epoch 1608: total training loss 0.00681\n",
            "INFO:__main__:EPOCH 1609\n",
            "2025-06-26 08:22:26,499 EPOCH 1609\n",
            "INFO:__main__:Epoch 1609: total training loss 0.00613\n",
            "2025-06-26 08:22:26,597 Epoch 1609: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1610\n",
            "2025-06-26 08:22:26,605 EPOCH 1610\n",
            "INFO:__main__:Epoch 1610: total training loss 0.00676\n",
            "2025-06-26 08:22:26,692 Epoch 1610: total training loss 0.00676\n",
            "INFO:__main__:EPOCH 1611\n",
            "2025-06-26 08:22:26,695 EPOCH 1611\n",
            "INFO:__main__:Epoch 1611: total training loss 0.00679\n",
            "2025-06-26 08:22:26,786 Epoch 1611: total training loss 0.00679\n",
            "INFO:__main__:EPOCH 1612\n",
            "2025-06-26 08:22:26,791 EPOCH 1612\n",
            "INFO:__main__:Epoch 1612: total training loss 0.00645\n",
            "2025-06-26 08:22:26,871 Epoch 1612: total training loss 0.00645\n",
            "INFO:__main__:EPOCH 1613\n",
            "2025-06-26 08:22:26,875 EPOCH 1613\n",
            "INFO:__main__:Epoch 1613: total training loss 0.00669\n",
            "2025-06-26 08:22:26,968 Epoch 1613: total training loss 0.00669\n",
            "INFO:__main__:EPOCH 1614\n",
            "2025-06-26 08:22:26,971 EPOCH 1614\n",
            "INFO:__main__:Epoch 1614: total training loss 0.00705\n",
            "2025-06-26 08:22:27,079 Epoch 1614: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1615\n",
            "2025-06-26 08:22:27,081 EPOCH 1615\n",
            "INFO:__main__:Epoch 1615: total training loss 0.00690\n",
            "2025-06-26 08:22:27,173 Epoch 1615: total training loss 0.00690\n",
            "INFO:__main__:EPOCH 1616\n",
            "2025-06-26 08:22:27,175 EPOCH 1616\n",
            "INFO:__main__:Epoch 1616: total training loss 0.00654\n",
            "2025-06-26 08:22:27,262 Epoch 1616: total training loss 0.00654\n",
            "INFO:__main__:EPOCH 1617\n",
            "2025-06-26 08:22:27,264 EPOCH 1617\n",
            "INFO:__main__:Epoch 1617: total training loss 0.00653\n",
            "2025-06-26 08:22:27,332 Epoch 1617: total training loss 0.00653\n",
            "INFO:__main__:EPOCH 1618\n",
            "2025-06-26 08:22:27,334 EPOCH 1618\n",
            "INFO:__main__:Epoch 1618: total training loss 0.00650\n",
            "2025-06-26 08:22:27,398 Epoch 1618: total training loss 0.00650\n",
            "INFO:__main__:EPOCH 1619\n",
            "2025-06-26 08:22:27,401 EPOCH 1619\n",
            "INFO:__main__:Epoch 1619: total training loss 0.00696\n",
            "2025-06-26 08:22:27,468 Epoch 1619: total training loss 0.00696\n",
            "INFO:__main__:EPOCH 1620\n",
            "2025-06-26 08:22:27,471 EPOCH 1620\n",
            "INFO:__main__:Epoch 1620: total training loss 0.00699\n",
            "2025-06-26 08:22:27,536 Epoch 1620: total training loss 0.00699\n",
            "INFO:__main__:EPOCH 1621\n",
            "2025-06-26 08:22:27,538 EPOCH 1621\n",
            "INFO:__main__:Epoch 1621: total training loss 0.00657\n",
            "2025-06-26 08:22:27,618 Epoch 1621: total training loss 0.00657\n",
            "INFO:__main__:EPOCH 1622\n",
            "2025-06-26 08:22:27,620 EPOCH 1622\n",
            "INFO:__main__:Epoch 1622: total training loss 0.00677\n",
            "2025-06-26 08:22:27,683 Epoch 1622: total training loss 0.00677\n",
            "INFO:__main__:EPOCH 1623\n",
            "2025-06-26 08:22:27,685 EPOCH 1623\n",
            "INFO:__main__:Epoch 1623: total training loss 0.00688\n",
            "2025-06-26 08:22:27,748 Epoch 1623: total training loss 0.00688\n",
            "INFO:__main__:EPOCH 1624\n",
            "2025-06-26 08:22:27,751 EPOCH 1624\n",
            "INFO:__main__:Epoch 1624: total training loss 0.00659\n",
            "2025-06-26 08:22:27,816 Epoch 1624: total training loss 0.00659\n",
            "INFO:__main__:EPOCH 1625\n",
            "2025-06-26 08:22:27,820 EPOCH 1625\n",
            "INFO:__main__:Epoch 1625: total training loss 0.00646\n",
            "2025-06-26 08:22:27,887 Epoch 1625: total training loss 0.00646\n",
            "INFO:__main__:EPOCH 1626\n",
            "2025-06-26 08:22:27,889 EPOCH 1626\n",
            "INFO:__main__:Epoch 1626: total training loss 0.00662\n",
            "2025-06-26 08:22:27,952 Epoch 1626: total training loss 0.00662\n",
            "INFO:__main__:EPOCH 1627\n",
            "2025-06-26 08:22:27,954 EPOCH 1627\n",
            "INFO:__main__:Epoch 1627: total training loss 0.00626\n",
            "2025-06-26 08:22:28,014 Epoch 1627: total training loss 0.00626\n",
            "INFO:__main__:EPOCH 1628\n",
            "2025-06-26 08:22:28,017 EPOCH 1628\n",
            "INFO:__main__:Epoch 1628: total training loss 0.00647\n",
            "2025-06-26 08:22:28,085 Epoch 1628: total training loss 0.00647\n",
            "INFO:__main__:EPOCH 1629\n",
            "2025-06-26 08:22:28,087 EPOCH 1629\n",
            "INFO:__main__:Epoch 1629: total training loss 0.00635\n",
            "2025-06-26 08:22:28,150 Epoch 1629: total training loss 0.00635\n",
            "INFO:__main__:EPOCH 1630\n",
            "2025-06-26 08:22:28,152 EPOCH 1630\n",
            "INFO:__main__:Epoch 1630: total training loss 0.00647\n",
            "2025-06-26 08:22:28,215 Epoch 1630: total training loss 0.00647\n",
            "INFO:__main__:EPOCH 1631\n",
            "2025-06-26 08:22:28,217 EPOCH 1631\n",
            "INFO:__main__:Epoch 1631: total training loss 0.00644\n",
            "2025-06-26 08:22:28,283 Epoch 1631: total training loss 0.00644\n",
            "INFO:__main__:EPOCH 1632\n",
            "2025-06-26 08:22:28,285 EPOCH 1632\n",
            "INFO:__main__:Epoch 1632: total training loss 0.00629\n",
            "2025-06-26 08:22:28,354 Epoch 1632: total training loss 0.00629\n",
            "INFO:__main__:EPOCH 1633\n",
            "2025-06-26 08:22:28,355 EPOCH 1633\n",
            "INFO:__main__:Epoch 1633: total training loss 0.00656\n",
            "2025-06-26 08:22:28,420 Epoch 1633: total training loss 0.00656\n",
            "INFO:__main__:EPOCH 1634\n",
            "2025-06-26 08:22:28,422 EPOCH 1634\n",
            "INFO:__main__:Epoch 1634: total training loss 0.00601\n",
            "2025-06-26 08:22:28,482 Epoch 1634: total training loss 0.00601\n",
            "INFO:__main__:EPOCH 1635\n",
            "2025-06-26 08:22:28,484 EPOCH 1635\n",
            "INFO:__main__:Epoch 1635: total training loss 0.00631\n",
            "2025-06-26 08:22:28,545 Epoch 1635: total training loss 0.00631\n",
            "INFO:__main__:EPOCH 1636\n",
            "2025-06-26 08:22:28,547 EPOCH 1636\n",
            "INFO:__main__:Epoch 1636: total training loss 0.00596\n",
            "2025-06-26 08:22:28,621 Epoch 1636: total training loss 0.00596\n",
            "INFO:__main__:EPOCH 1637\n",
            "2025-06-26 08:22:28,623 EPOCH 1637\n",
            "INFO:__main__:Epoch 1637: total training loss 0.00626\n",
            "2025-06-26 08:22:28,686 Epoch 1637: total training loss 0.00626\n",
            "INFO:__main__:EPOCH 1638\n",
            "2025-06-26 08:22:28,687 EPOCH 1638\n",
            "INFO:__main__:Epoch 1638: total training loss 0.00642\n",
            "2025-06-26 08:22:28,751 Epoch 1638: total training loss 0.00642\n",
            "INFO:__main__:EPOCH 1639\n",
            "2025-06-26 08:22:28,753 EPOCH 1639\n",
            "INFO:__main__:Epoch 1639: total training loss 0.00589\n",
            "2025-06-26 08:22:28,816 Epoch 1639: total training loss 0.00589\n",
            "INFO:__main__:EPOCH 1640\n",
            "2025-06-26 08:22:28,819 EPOCH 1640\n",
            "INFO:__main__:Epoch 1640: total training loss 0.00654\n",
            "2025-06-26 08:22:28,885 Epoch 1640: total training loss 0.00654\n",
            "INFO:__main__:EPOCH 1641\n",
            "2025-06-26 08:22:28,887 EPOCH 1641\n",
            "INFO:__main__:Epoch 1641: total training loss 0.00623\n",
            "2025-06-26 08:22:28,952 Epoch 1641: total training loss 0.00623\n",
            "INFO:__main__:EPOCH 1642\n",
            "2025-06-26 08:22:28,954 EPOCH 1642\n",
            "INFO:__main__:Epoch 1642: total training loss 0.00688\n",
            "2025-06-26 08:22:29,020 Epoch 1642: total training loss 0.00688\n",
            "INFO:__main__:EPOCH 1643\n",
            "2025-06-26 08:22:29,022 EPOCH 1643\n",
            "INFO:__main__:Epoch 1643: total training loss 0.00662\n",
            "2025-06-26 08:22:29,085 Epoch 1643: total training loss 0.00662\n",
            "INFO:__main__:EPOCH 1644\n",
            "2025-06-26 08:22:29,087 EPOCH 1644\n",
            "INFO:__main__:Epoch 1644: total training loss 0.00682\n",
            "2025-06-26 08:22:29,157 Epoch 1644: total training loss 0.00682\n",
            "INFO:__main__:EPOCH 1645\n",
            "2025-06-26 08:22:29,159 EPOCH 1645\n",
            "INFO:__main__:Epoch 1645: total training loss 0.00643\n",
            "2025-06-26 08:22:29,222 Epoch 1645: total training loss 0.00643\n",
            "INFO:__main__:EPOCH 1646\n",
            "2025-06-26 08:22:29,225 EPOCH 1646\n",
            "INFO:__main__:Epoch 1646: total training loss 0.00618\n",
            "2025-06-26 08:22:29,288 Epoch 1646: total training loss 0.00618\n",
            "INFO:__main__:EPOCH 1647\n",
            "2025-06-26 08:22:29,290 EPOCH 1647\n",
            "INFO:__main__:Epoch 1647: total training loss 0.00688\n",
            "2025-06-26 08:22:29,357 Epoch 1647: total training loss 0.00688\n",
            "INFO:__main__:EPOCH 1648\n",
            "2025-06-26 08:22:29,359 EPOCH 1648\n",
            "INFO:__main__:Epoch 1648: total training loss 0.00656\n",
            "2025-06-26 08:22:29,424 Epoch 1648: total training loss 0.00656\n",
            "INFO:__main__:EPOCH 1649\n",
            "2025-06-26 08:22:29,426 EPOCH 1649\n",
            "INFO:__main__:Epoch 1649: total training loss 0.00649\n",
            "2025-06-26 08:22:29,487 Epoch 1649: total training loss 0.00649\n",
            "INFO:__main__:EPOCH 1650\n",
            "2025-06-26 08:22:29,489 EPOCH 1650\n",
            "INFO:__main__:Epoch 1650: total training loss 0.00656\n",
            "2025-06-26 08:22:29,555 Epoch 1650: total training loss 0.00656\n",
            "INFO:__main__:EPOCH 1651\n",
            "2025-06-26 08:22:29,557 EPOCH 1651\n",
            "INFO:__main__:Epoch 1651: total training loss 0.00682\n",
            "2025-06-26 08:22:29,624 Epoch 1651: total training loss 0.00682\n",
            "INFO:__main__:EPOCH 1652\n",
            "2025-06-26 08:22:29,626 EPOCH 1652\n",
            "INFO:__main__:Epoch 1652: total training loss 0.00592\n",
            "2025-06-26 08:22:29,713 Epoch 1652: total training loss 0.00592\n",
            "INFO:__main__:EPOCH 1653\n",
            "2025-06-26 08:22:29,715 EPOCH 1653\n",
            "INFO:__main__:Epoch 1653: total training loss 0.00660\n",
            "2025-06-26 08:22:29,780 Epoch 1653: total training loss 0.00660\n",
            "INFO:__main__:EPOCH 1654\n",
            "2025-06-26 08:22:29,782 EPOCH 1654\n",
            "INFO:__main__:Epoch 1654: total training loss 0.00666\n",
            "2025-06-26 08:22:29,845 Epoch 1654: total training loss 0.00666\n",
            "INFO:__main__:EPOCH 1655\n",
            "2025-06-26 08:22:29,847 EPOCH 1655\n",
            "INFO:__main__:Epoch 1655: total training loss 0.00655\n",
            "2025-06-26 08:22:29,913 Epoch 1655: total training loss 0.00655\n",
            "INFO:__main__:EPOCH 1656\n",
            "2025-06-26 08:22:29,915 EPOCH 1656\n",
            "INFO:__main__:Epoch 1656: total training loss 0.00664\n",
            "2025-06-26 08:22:29,982 Epoch 1656: total training loss 0.00664\n",
            "INFO:__main__:EPOCH 1657\n",
            "2025-06-26 08:22:29,985 EPOCH 1657\n",
            "INFO:__main__:Epoch 1657: total training loss 0.00734\n",
            "2025-06-26 08:22:30,051 Epoch 1657: total training loss 0.00734\n",
            "INFO:__main__:EPOCH 1658\n",
            "2025-06-26 08:22:30,052 EPOCH 1658\n",
            "INFO:__main__:Epoch 1658: total training loss 0.00645\n",
            "2025-06-26 08:22:30,117 Epoch 1658: total training loss 0.00645\n",
            "INFO:__main__:EPOCH 1659\n",
            "2025-06-26 08:22:30,119 EPOCH 1659\n",
            "INFO:__main__:Epoch 1659: total training loss 0.00696\n",
            "2025-06-26 08:22:30,184 Epoch 1659: total training loss 0.00696\n",
            "INFO:__main__:EPOCH 1660\n",
            "2025-06-26 08:22:30,186 EPOCH 1660\n",
            "INFO:__main__:Epoch 1660: total training loss 0.00667\n",
            "2025-06-26 08:22:30,251 Epoch 1660: total training loss 0.00667\n",
            "INFO:__main__:EPOCH 1661\n",
            "2025-06-26 08:22:30,254 EPOCH 1661\n",
            "INFO:__main__:Epoch 1661: total training loss 0.00712\n",
            "2025-06-26 08:22:30,318 Epoch 1661: total training loss 0.00712\n",
            "INFO:__main__:EPOCH 1662\n",
            "2025-06-26 08:22:30,320 EPOCH 1662\n",
            "INFO:__main__:Epoch 1662: total training loss 0.00695\n",
            "2025-06-26 08:22:30,383 Epoch 1662: total training loss 0.00695\n",
            "INFO:__main__:EPOCH 1663\n",
            "2025-06-26 08:22:30,385 EPOCH 1663\n",
            "INFO:__main__:Epoch 1663: total training loss 0.00727\n",
            "2025-06-26 08:22:30,450 Epoch 1663: total training loss 0.00727\n",
            "INFO:__main__:EPOCH 1664\n",
            "2025-06-26 08:22:30,453 EPOCH 1664\n",
            "INFO:__main__:Epoch 1664: total training loss 0.00754\n",
            "2025-06-26 08:22:30,519 Epoch 1664: total training loss 0.00754\n",
            "INFO:__main__:EPOCH 1665\n",
            "2025-06-26 08:22:30,521 EPOCH 1665\n",
            "INFO:__main__:Epoch 1665: total training loss 0.00691\n",
            "2025-06-26 08:22:30,586 Epoch 1665: total training loss 0.00691\n",
            "INFO:__main__:EPOCH 1666\n",
            "2025-06-26 08:22:30,588 EPOCH 1666\n",
            "INFO:__main__:Epoch 1666: total training loss 0.00628\n",
            "2025-06-26 08:22:30,651 Epoch 1666: total training loss 0.00628\n",
            "INFO:__main__:EPOCH 1667\n",
            "2025-06-26 08:22:30,653 EPOCH 1667\n",
            "INFO:__main__:Epoch 1667: total training loss 0.00664\n",
            "2025-06-26 08:22:30,732 Epoch 1667: total training loss 0.00664\n",
            "INFO:__main__:EPOCH 1668\n",
            "2025-06-26 08:22:30,735 EPOCH 1668\n",
            "INFO:__main__:Epoch 1668: total training loss 0.00669\n",
            "2025-06-26 08:22:30,799 Epoch 1668: total training loss 0.00669\n",
            "INFO:__main__:EPOCH 1669\n",
            "2025-06-26 08:22:30,801 EPOCH 1669\n",
            "INFO:__main__:Epoch 1669: total training loss 0.00617\n",
            "2025-06-26 08:22:30,864 Epoch 1669: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1670\n",
            "2025-06-26 08:22:30,866 EPOCH 1670\n",
            "INFO:__main__:Epoch 1670: total training loss 0.00630\n",
            "2025-06-26 08:22:30,929 Epoch 1670: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1671\n",
            "2025-06-26 08:22:30,931 EPOCH 1671\n",
            "INFO:__main__:Epoch 1671: total training loss 0.00624\n",
            "2025-06-26 08:22:30,994 Epoch 1671: total training loss 0.00624\n",
            "INFO:__main__:EPOCH 1672\n",
            "2025-06-26 08:22:30,996 EPOCH 1672\n",
            "INFO:__main__:Epoch 1672: total training loss 0.00616\n",
            "2025-06-26 08:22:31,063 Epoch 1672: total training loss 0.00616\n",
            "INFO:__main__:EPOCH 1673\n",
            "2025-06-26 08:22:31,065 EPOCH 1673\n",
            "INFO:__main__:Epoch 1673: total training loss 0.00625\n",
            "2025-06-26 08:22:31,128 Epoch 1673: total training loss 0.00625\n",
            "INFO:__main__:EPOCH 1674\n",
            "2025-06-26 08:22:31,131 EPOCH 1674\n",
            "INFO:__main__:Epoch 1674: total training loss 0.00605\n",
            "2025-06-26 08:22:31,197 Epoch 1674: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1675\n",
            "2025-06-26 08:22:31,200 EPOCH 1675\n",
            "INFO:__main__:Epoch 1675: total training loss 0.00632\n",
            "2025-06-26 08:22:31,264 Epoch 1675: total training loss 0.00632\n",
            "INFO:__main__:EPOCH 1676\n",
            "2025-06-26 08:22:31,268 EPOCH 1676\n",
            "INFO:__main__:Epoch 1676: total training loss 0.00613\n",
            "2025-06-26 08:22:31,333 Epoch 1676: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1677\n",
            "2025-06-26 08:22:31,335 EPOCH 1677\n",
            "INFO:__main__:Epoch 1677: total training loss 0.00617\n",
            "2025-06-26 08:22:31,399 Epoch 1677: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1678\n",
            "2025-06-26 08:22:31,401 EPOCH 1678\n",
            "INFO:__main__:Epoch 1678: total training loss 0.00705\n",
            "2025-06-26 08:22:31,465 Epoch 1678: total training loss 0.00705\n",
            "INFO:__main__:EPOCH 1679\n",
            "2025-06-26 08:22:31,467 EPOCH 1679\n",
            "INFO:__main__:Epoch 1679: total training loss 0.00649\n",
            "2025-06-26 08:22:31,530 Epoch 1679: total training loss 0.00649\n",
            "INFO:__main__:EPOCH 1680\n",
            "2025-06-26 08:22:31,532 EPOCH 1680\n",
            "INFO:__main__:Epoch 1680: total training loss 0.00631\n",
            "2025-06-26 08:22:31,597 Epoch 1680: total training loss 0.00631\n",
            "INFO:__main__:EPOCH 1681\n",
            "2025-06-26 08:22:31,599 EPOCH 1681\n",
            "INFO:__main__:Epoch 1681: total training loss 0.00633\n",
            "2025-06-26 08:22:31,663 Epoch 1681: total training loss 0.00633\n",
            "INFO:__main__:EPOCH 1682\n",
            "2025-06-26 08:22:31,665 EPOCH 1682\n",
            "INFO:__main__:Epoch 1682: total training loss 0.00661\n",
            "2025-06-26 08:22:31,727 Epoch 1682: total training loss 0.00661\n",
            "INFO:__main__:EPOCH 1683\n",
            "2025-06-26 08:22:31,729 EPOCH 1683\n",
            "INFO:__main__:Epoch 1683: total training loss 0.00634\n",
            "2025-06-26 08:22:31,810 Epoch 1683: total training loss 0.00634\n",
            "INFO:__main__:EPOCH 1684\n",
            "2025-06-26 08:22:31,812 EPOCH 1684\n",
            "INFO:__main__:Epoch 1684: total training loss 0.00646\n",
            "2025-06-26 08:22:31,880 Epoch 1684: total training loss 0.00646\n",
            "INFO:__main__:EPOCH 1685\n",
            "2025-06-26 08:22:31,882 EPOCH 1685\n",
            "INFO:__main__:Epoch 1685: total training loss 0.00659\n",
            "2025-06-26 08:22:31,945 Epoch 1685: total training loss 0.00659\n",
            "INFO:__main__:EPOCH 1686\n",
            "2025-06-26 08:22:31,947 EPOCH 1686\n",
            "INFO:__main__:Epoch 1686: total training loss 0.00610\n",
            "2025-06-26 08:22:32,010 Epoch 1686: total training loss 0.00610\n",
            "INFO:__main__:EPOCH 1687\n",
            "2025-06-26 08:22:32,013 EPOCH 1687\n",
            "INFO:__main__:Epoch 1687: total training loss 0.00595\n",
            "2025-06-26 08:22:32,079 Epoch 1687: total training loss 0.00595\n",
            "INFO:__main__:EPOCH 1688\n",
            "2025-06-26 08:22:32,081 EPOCH 1688\n",
            "INFO:__main__:Epoch 1688: total training loss 0.00581\n",
            "2025-06-26 08:22:32,147 Epoch 1688: total training loss 0.00581\n",
            "INFO:__main__:EPOCH 1689\n",
            "2025-06-26 08:22:32,149 EPOCH 1689\n",
            "INFO:__main__:Epoch 1689: total training loss 0.00586\n",
            "2025-06-26 08:22:32,213 Epoch 1689: total training loss 0.00586\n",
            "INFO:__main__:EPOCH 1690\n",
            "2025-06-26 08:22:32,216 EPOCH 1690\n",
            "INFO:__main__:Epoch 1690: total training loss 0.00592\n",
            "2025-06-26 08:22:32,279 Epoch 1690: total training loss 0.00592\n",
            "INFO:__main__:EPOCH 1691\n",
            "2025-06-26 08:22:32,282 EPOCH 1691\n",
            "INFO:__main__:Epoch 1691: total training loss 0.00637\n",
            "2025-06-26 08:22:32,349 Epoch 1691: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1692\n",
            "2025-06-26 08:22:32,351 EPOCH 1692\n",
            "INFO:__main__:Epoch 1692: total training loss 0.00575\n",
            "2025-06-26 08:22:32,416 Epoch 1692: total training loss 0.00575\n",
            "INFO:__main__:EPOCH 1693\n",
            "2025-06-26 08:22:32,418 EPOCH 1693\n",
            "INFO:__main__:Epoch 1693: total training loss 0.00676\n",
            "2025-06-26 08:22:32,482 Epoch 1693: total training loss 0.00676\n",
            "INFO:__main__:EPOCH 1694\n",
            "2025-06-26 08:22:32,484 EPOCH 1694\n",
            "INFO:__main__:Epoch 1694: total training loss 0.00620\n",
            "2025-06-26 08:22:32,547 Epoch 1694: total training loss 0.00620\n",
            "INFO:__main__:EPOCH 1695\n",
            "2025-06-26 08:22:32,549 EPOCH 1695\n",
            "INFO:__main__:Epoch 1695: total training loss 0.00622\n",
            "2025-06-26 08:22:32,613 Epoch 1695: total training loss 0.00622\n",
            "INFO:__main__:EPOCH 1696\n",
            "2025-06-26 08:22:32,616 EPOCH 1696\n",
            "INFO:__main__:Epoch 1696: total training loss 0.00675\n",
            "2025-06-26 08:22:32,678 Epoch 1696: total training loss 0.00675\n",
            "INFO:__main__:EPOCH 1697\n",
            "2025-06-26 08:22:32,680 EPOCH 1697\n",
            "INFO:__main__:Epoch 1697: total training loss 0.00619\n",
            "2025-06-26 08:22:32,742 Epoch 1697: total training loss 0.00619\n",
            "INFO:__main__:EPOCH 1698\n",
            "2025-06-26 08:22:32,744 EPOCH 1698\n",
            "INFO:__main__:Epoch 1698: total training loss 0.00638\n",
            "2025-06-26 08:22:32,823 Epoch 1698: total training loss 0.00638\n",
            "INFO:__main__:EPOCH 1699\n",
            "2025-06-26 08:22:32,825 EPOCH 1699\n",
            "INFO:__main__:Epoch 1699: total training loss 0.00572\n",
            "2025-06-26 08:22:32,894 Epoch 1699: total training loss 0.00572\n",
            "INFO:__main__:EPOCH 1700\n",
            "2025-06-26 08:22:32,896 EPOCH 1700\n",
            "INFO:__main__:Epoch 1700: total training loss 0.00612\n",
            "2025-06-26 08:22:32,962 Epoch 1700: total training loss 0.00612\n",
            "INFO:__main__:EPOCH 1701\n",
            "2025-06-26 08:22:32,964 EPOCH 1701\n",
            "INFO:__main__:Epoch 1701: total training loss 0.00632\n",
            "2025-06-26 08:22:33,026 Epoch 1701: total training loss 0.00632\n",
            "INFO:__main__:EPOCH 1702\n",
            "2025-06-26 08:22:33,028 EPOCH 1702\n",
            "INFO:__main__:Epoch 1702: total training loss 0.00624\n",
            "2025-06-26 08:22:33,096 Epoch 1702: total training loss 0.00624\n",
            "INFO:__main__:EPOCH 1703\n",
            "2025-06-26 08:22:33,098 EPOCH 1703\n",
            "INFO:__main__:Epoch 1703: total training loss 0.00628\n",
            "2025-06-26 08:22:33,169 Epoch 1703: total training loss 0.00628\n",
            "INFO:__main__:EPOCH 1704\n",
            "2025-06-26 08:22:33,171 EPOCH 1704\n",
            "INFO:__main__:Epoch 1704: total training loss 0.00613\n",
            "2025-06-26 08:22:33,238 Epoch 1704: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1705\n",
            "2025-06-26 08:22:33,240 EPOCH 1705\n",
            "INFO:__main__:Epoch 1705: total training loss 0.00637\n",
            "2025-06-26 08:22:33,304 Epoch 1705: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1706\n",
            "2025-06-26 08:22:33,306 EPOCH 1706\n",
            "INFO:__main__:Epoch 1706: total training loss 0.00614\n",
            "2025-06-26 08:22:33,371 Epoch 1706: total training loss 0.00614\n",
            "INFO:__main__:EPOCH 1707\n",
            "2025-06-26 08:22:33,374 EPOCH 1707\n",
            "INFO:__main__:Epoch 1707: total training loss 0.00658\n",
            "2025-06-26 08:22:33,440 Epoch 1707: total training loss 0.00658\n",
            "INFO:__main__:EPOCH 1708\n",
            "2025-06-26 08:22:33,442 EPOCH 1708\n",
            "INFO:__main__:Epoch 1708: total training loss 0.00616\n",
            "2025-06-26 08:22:33,505 Epoch 1708: total training loss 0.00616\n",
            "INFO:__main__:EPOCH 1709\n",
            "2025-06-26 08:22:33,507 EPOCH 1709\n",
            "INFO:__main__:Epoch 1709: total training loss 0.00639\n",
            "2025-06-26 08:22:33,570 Epoch 1709: total training loss 0.00639\n",
            "INFO:__main__:EPOCH 1710\n",
            "2025-06-26 08:22:33,573 EPOCH 1710\n",
            "INFO:__main__:Epoch 1710: total training loss 0.00587\n",
            "2025-06-26 08:22:33,635 Epoch 1710: total training loss 0.00587\n",
            "INFO:__main__:EPOCH 1711\n",
            "2025-06-26 08:22:33,637 EPOCH 1711\n",
            "INFO:__main__:Epoch 1711: total training loss 0.00636\n",
            "2025-06-26 08:22:33,700 Epoch 1711: total training loss 0.00636\n",
            "INFO:__main__:EPOCH 1712\n",
            "2025-06-26 08:22:33,703 EPOCH 1712\n",
            "INFO:__main__:Epoch 1712: total training loss 0.00613\n",
            "2025-06-26 08:22:33,769 Epoch 1712: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1713\n",
            "2025-06-26 08:22:33,771 EPOCH 1713\n",
            "INFO:__main__:Epoch 1713: total training loss 0.00614\n",
            "2025-06-26 08:22:33,846 Epoch 1713: total training loss 0.00614\n",
            "INFO:__main__:EPOCH 1714\n",
            "2025-06-26 08:22:33,852 EPOCH 1714\n",
            "INFO:__main__:Epoch 1714: total training loss 0.00650\n",
            "2025-06-26 08:22:33,921 Epoch 1714: total training loss 0.00650\n",
            "INFO:__main__:EPOCH 1715\n",
            "2025-06-26 08:22:33,923 EPOCH 1715\n",
            "INFO:__main__:Epoch 1715: total training loss 0.00611\n",
            "2025-06-26 08:22:33,990 Epoch 1715: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1716\n",
            "2025-06-26 08:22:33,992 EPOCH 1716\n",
            "INFO:__main__:Epoch 1716: total training loss 0.00601\n",
            "2025-06-26 08:22:34,054 Epoch 1716: total training loss 0.00601\n",
            "INFO:__main__:EPOCH 1717\n",
            "2025-06-26 08:22:34,056 EPOCH 1717\n",
            "INFO:__main__:Epoch 1717: total training loss 0.00643\n",
            "2025-06-26 08:22:34,118 Epoch 1717: total training loss 0.00643\n",
            "INFO:__main__:EPOCH 1718\n",
            "2025-06-26 08:22:34,120 EPOCH 1718\n",
            "INFO:__main__:Epoch 1718: total training loss 0.00638\n",
            "2025-06-26 08:22:34,187 Epoch 1718: total training loss 0.00638\n",
            "INFO:__main__:EPOCH 1719\n",
            "2025-06-26 08:22:34,189 EPOCH 1719\n",
            "INFO:__main__:Epoch 1719: total training loss 0.00593\n",
            "2025-06-26 08:22:34,252 Epoch 1719: total training loss 0.00593\n",
            "INFO:__main__:EPOCH 1720\n",
            "2025-06-26 08:22:34,254 EPOCH 1720\n",
            "INFO:__main__:Epoch 1720: total training loss 0.00644\n",
            "2025-06-26 08:22:34,323 Epoch 1720: total training loss 0.00644\n",
            "INFO:__main__:EPOCH 1721\n",
            "2025-06-26 08:22:34,325 EPOCH 1721\n",
            "INFO:__main__:Epoch 1721: total training loss 0.00593\n",
            "2025-06-26 08:22:34,391 Epoch 1721: total training loss 0.00593\n",
            "INFO:__main__:EPOCH 1722\n",
            "2025-06-26 08:22:34,393 EPOCH 1722\n",
            "INFO:__main__:Epoch 1722: total training loss 0.00621\n",
            "2025-06-26 08:22:34,459 Epoch 1722: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1723\n",
            "2025-06-26 08:22:34,461 EPOCH 1723\n",
            "INFO:__main__:Epoch 1723: total training loss 0.00661\n",
            "2025-06-26 08:22:34,522 Epoch 1723: total training loss 0.00661\n",
            "INFO:__main__:EPOCH 1724\n",
            "2025-06-26 08:22:34,524 EPOCH 1724\n",
            "INFO:__main__:Epoch 1724: total training loss 0.00568\n",
            "2025-06-26 08:22:34,591 Epoch 1724: total training loss 0.00568\n",
            "INFO:__main__:EPOCH 1725\n",
            "2025-06-26 08:22:34,593 EPOCH 1725\n",
            "INFO:__main__:Epoch 1725: total training loss 0.00614\n",
            "2025-06-26 08:22:34,657 Epoch 1725: total training loss 0.00614\n",
            "INFO:__main__:EPOCH 1726\n",
            "2025-06-26 08:22:34,659 EPOCH 1726\n",
            "INFO:__main__:Epoch 1726: total training loss 0.00585\n",
            "2025-06-26 08:22:34,724 Epoch 1726: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1727\n",
            "2025-06-26 08:22:34,726 EPOCH 1727\n",
            "INFO:__main__:Epoch 1727: total training loss 0.00600\n",
            "2025-06-26 08:22:34,793 Epoch 1727: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1728\n",
            "2025-06-26 08:22:34,797 EPOCH 1728\n",
            "INFO:__main__:Epoch 1728: total training loss 0.00576\n",
            "2025-06-26 08:22:34,868 Epoch 1728: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1729\n",
            "2025-06-26 08:22:34,870 EPOCH 1729\n",
            "INFO:__main__:Epoch 1729: total training loss 0.00621\n",
            "2025-06-26 08:22:34,942 Epoch 1729: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1730\n",
            "2025-06-26 08:22:34,944 EPOCH 1730\n",
            "INFO:__main__:Epoch 1730: total training loss 0.00623\n",
            "2025-06-26 08:22:35,009 Epoch 1730: total training loss 0.00623\n",
            "INFO:__main__:EPOCH 1731\n",
            "2025-06-26 08:22:35,012 EPOCH 1731\n",
            "INFO:__main__:Epoch 1731: total training loss 0.00607\n",
            "2025-06-26 08:22:35,078 Epoch 1731: total training loss 0.00607\n",
            "INFO:__main__:EPOCH 1732\n",
            "2025-06-26 08:22:35,080 EPOCH 1732\n",
            "INFO:__main__:Epoch 1732: total training loss 0.00652\n",
            "2025-06-26 08:22:35,144 Epoch 1732: total training loss 0.00652\n",
            "INFO:__main__:EPOCH 1733\n",
            "2025-06-26 08:22:35,147 EPOCH 1733\n",
            "INFO:__main__:Epoch 1733: total training loss 0.00637\n",
            "2025-06-26 08:22:35,211 Epoch 1733: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1734\n",
            "2025-06-26 08:22:35,213 EPOCH 1734\n",
            "INFO:__main__:Epoch 1734: total training loss 0.00600\n",
            "2025-06-26 08:22:35,283 Epoch 1734: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1735\n",
            "2025-06-26 08:22:35,285 EPOCH 1735\n",
            "INFO:__main__:Epoch 1735: total training loss 0.00609\n",
            "2025-06-26 08:22:35,360 Epoch 1735: total training loss 0.00609\n",
            "INFO:__main__:EPOCH 1736\n",
            "2025-06-26 08:22:35,362 EPOCH 1736\n",
            "INFO:__main__:Epoch 1736: total training loss 0.00646\n",
            "2025-06-26 08:22:35,432 Epoch 1736: total training loss 0.00646\n",
            "INFO:__main__:EPOCH 1737\n",
            "2025-06-26 08:22:35,434 EPOCH 1737\n",
            "INFO:__main__:Epoch 1737: total training loss 0.00653\n",
            "2025-06-26 08:22:35,505 Epoch 1737: total training loss 0.00653\n",
            "INFO:__main__:EPOCH 1738\n",
            "2025-06-26 08:22:35,507 EPOCH 1738\n",
            "INFO:__main__:Epoch 1738: total training loss 0.00611\n",
            "2025-06-26 08:22:35,571 Epoch 1738: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1739\n",
            "2025-06-26 08:22:35,572 EPOCH 1739\n",
            "INFO:__main__:Epoch 1739: total training loss 0.00673\n",
            "2025-06-26 08:22:35,634 Epoch 1739: total training loss 0.00673\n",
            "INFO:__main__:EPOCH 1740\n",
            "2025-06-26 08:22:35,637 EPOCH 1740\n",
            "INFO:__main__:Epoch 1740: total training loss 0.00596\n",
            "2025-06-26 08:22:35,699 Epoch 1740: total training loss 0.00596\n",
            "INFO:__main__:EPOCH 1741\n",
            "2025-06-26 08:22:35,701 EPOCH 1741\n",
            "INFO:__main__:Epoch 1741: total training loss 0.00595\n",
            "2025-06-26 08:22:35,765 Epoch 1741: total training loss 0.00595\n",
            "INFO:__main__:EPOCH 1742\n",
            "2025-06-26 08:22:35,767 EPOCH 1742\n",
            "INFO:__main__:Epoch 1742: total training loss 0.00583\n",
            "2025-06-26 08:22:35,832 Epoch 1742: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1743\n",
            "2025-06-26 08:22:35,834 EPOCH 1743\n",
            "INFO:__main__:Epoch 1743: total training loss 0.00605\n",
            "2025-06-26 08:22:35,898 Epoch 1743: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1744\n",
            "2025-06-26 08:22:35,900 EPOCH 1744\n",
            "INFO:__main__:Epoch 1744: total training loss 0.00627\n",
            "2025-06-26 08:22:35,980 Epoch 1744: total training loss 0.00627\n",
            "INFO:__main__:EPOCH 1745\n",
            "2025-06-26 08:22:35,982 EPOCH 1745\n",
            "INFO:__main__:Epoch 1745: total training loss 0.00630\n",
            "2025-06-26 08:22:36,048 Epoch 1745: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1746\n",
            "2025-06-26 08:22:36,050 EPOCH 1746\n",
            "INFO:__main__:Epoch 1746: total training loss 0.00586\n",
            "2025-06-26 08:22:36,113 Epoch 1746: total training loss 0.00586\n",
            "INFO:__main__:EPOCH 1747\n",
            "2025-06-26 08:22:36,115 EPOCH 1747\n",
            "INFO:__main__:Epoch 1747: total training loss 0.00638\n",
            "2025-06-26 08:22:36,178 Epoch 1747: total training loss 0.00638\n",
            "INFO:__main__:EPOCH 1748\n",
            "2025-06-26 08:22:36,180 EPOCH 1748\n",
            "INFO:__main__:Epoch 1748: total training loss 0.00635\n",
            "2025-06-26 08:22:36,249 Epoch 1748: total training loss 0.00635\n",
            "INFO:__main__:EPOCH 1749\n",
            "2025-06-26 08:22:36,252 EPOCH 1749\n",
            "INFO:__main__:Epoch 1749: total training loss 0.00622\n",
            "2025-06-26 08:22:36,315 Epoch 1749: total training loss 0.00622\n",
            "INFO:__main__:EPOCH 1750\n",
            "2025-06-26 08:22:36,317 EPOCH 1750\n",
            "INFO:__main__:Epoch 1750 Step:     1750 Batch Loss:     0.006295 Tokens per Sec:  2384776, Lr: 0.001000\n",
            "2025-06-26 08:22:36,382 Epoch 1750 Step:     1750 Batch Loss:     0.006295 Tokens per Sec:  2384776, Lr: 0.001000\n",
            "INFO:__main__:Epoch 1750: total training loss 0.00629\n",
            "2025-06-26 08:22:36,384 Epoch 1750: total training loss 0.00629\n",
            "INFO:__main__:EPOCH 1751\n",
            "2025-06-26 08:22:36,386 EPOCH 1751\n",
            "INFO:__main__:Epoch 1751: total training loss 0.00573\n",
            "2025-06-26 08:22:36,455 Epoch 1751: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1752\n",
            "2025-06-26 08:22:36,457 EPOCH 1752\n",
            "INFO:__main__:Epoch 1752: total training loss 0.00657\n",
            "2025-06-26 08:22:36,527 Epoch 1752: total training loss 0.00657\n",
            "INFO:__main__:EPOCH 1753\n",
            "2025-06-26 08:22:36,529 EPOCH 1753\n",
            "INFO:__main__:Epoch 1753: total training loss 0.00683\n",
            "2025-06-26 08:22:36,591 Epoch 1753: total training loss 0.00683\n",
            "INFO:__main__:EPOCH 1754\n",
            "2025-06-26 08:22:36,593 EPOCH 1754\n",
            "INFO:__main__:Epoch 1754: total training loss 0.00611\n",
            "2025-06-26 08:22:36,658 Epoch 1754: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1755\n",
            "2025-06-26 08:22:36,660 EPOCH 1755\n",
            "INFO:__main__:Epoch 1755: total training loss 0.00615\n",
            "2025-06-26 08:22:36,720 Epoch 1755: total training loss 0.00615\n",
            "INFO:__main__:EPOCH 1756\n",
            "2025-06-26 08:22:36,722 EPOCH 1756\n",
            "INFO:__main__:Epoch 1756: total training loss 0.00617\n",
            "2025-06-26 08:22:36,786 Epoch 1756: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1757\n",
            "2025-06-26 08:22:36,788 EPOCH 1757\n",
            "INFO:__main__:Epoch 1757: total training loss 0.00592\n",
            "2025-06-26 08:22:36,852 Epoch 1757: total training loss 0.00592\n",
            "INFO:__main__:EPOCH 1758\n",
            "2025-06-26 08:22:36,855 EPOCH 1758\n",
            "INFO:__main__:Epoch 1758: total training loss 0.00573\n",
            "2025-06-26 08:22:36,921 Epoch 1758: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1759\n",
            "2025-06-26 08:22:36,923 EPOCH 1759\n",
            "INFO:__main__:Epoch 1759: total training loss 0.00621\n",
            "2025-06-26 08:22:37,005 Epoch 1759: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1760\n",
            "2025-06-26 08:22:37,007 EPOCH 1760\n",
            "INFO:__main__:Epoch 1760: total training loss 0.00548\n",
            "2025-06-26 08:22:37,076 Epoch 1760: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1761\n",
            "2025-06-26 08:22:37,078 EPOCH 1761\n",
            "INFO:__main__:Epoch 1761: total training loss 0.00611\n",
            "2025-06-26 08:22:37,142 Epoch 1761: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1762\n",
            "2025-06-26 08:22:37,144 EPOCH 1762\n",
            "INFO:__main__:Epoch 1762: total training loss 0.00579\n",
            "2025-06-26 08:22:37,209 Epoch 1762: total training loss 0.00579\n",
            "INFO:__main__:EPOCH 1763\n",
            "2025-06-26 08:22:37,211 EPOCH 1763\n",
            "INFO:__main__:Epoch 1763: total training loss 0.00614\n",
            "2025-06-26 08:22:37,286 Epoch 1763: total training loss 0.00614\n",
            "INFO:__main__:EPOCH 1764\n",
            "2025-06-26 08:22:37,289 EPOCH 1764\n",
            "INFO:__main__:Epoch 1764: total training loss 0.00591\n",
            "2025-06-26 08:22:37,380 Epoch 1764: total training loss 0.00591\n",
            "INFO:__main__:EPOCH 1765\n",
            "2025-06-26 08:22:37,382 EPOCH 1765\n",
            "INFO:__main__:Epoch 1765: total training loss 0.00620\n",
            "2025-06-26 08:22:37,467 Epoch 1765: total training loss 0.00620\n",
            "INFO:__main__:EPOCH 1766\n",
            "2025-06-26 08:22:37,469 EPOCH 1766\n",
            "INFO:__main__:Epoch 1766: total training loss 0.00605\n",
            "2025-06-26 08:22:37,546 Epoch 1766: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1767\n",
            "2025-06-26 08:22:37,548 EPOCH 1767\n",
            "INFO:__main__:Epoch 1767: total training loss 0.00641\n",
            "2025-06-26 08:22:37,641 Epoch 1767: total training loss 0.00641\n",
            "INFO:__main__:EPOCH 1768\n",
            "2025-06-26 08:22:37,644 EPOCH 1768\n",
            "INFO:__main__:Epoch 1768: total training loss 0.00600\n",
            "2025-06-26 08:22:37,727 Epoch 1768: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1769\n",
            "2025-06-26 08:22:37,729 EPOCH 1769\n",
            "INFO:__main__:Epoch 1769: total training loss 0.00606\n",
            "2025-06-26 08:22:37,804 Epoch 1769: total training loss 0.00606\n",
            "INFO:__main__:EPOCH 1770\n",
            "2025-06-26 08:22:37,806 EPOCH 1770\n",
            "INFO:__main__:Epoch 1770: total training loss 0.00658\n",
            "2025-06-26 08:22:37,878 Epoch 1770: total training loss 0.00658\n",
            "INFO:__main__:EPOCH 1771\n",
            "2025-06-26 08:22:37,880 EPOCH 1771\n",
            "INFO:__main__:Epoch 1771: total training loss 0.00580\n",
            "2025-06-26 08:22:37,954 Epoch 1771: total training loss 0.00580\n",
            "INFO:__main__:EPOCH 1772\n",
            "2025-06-26 08:22:37,957 EPOCH 1772\n",
            "INFO:__main__:Epoch 1772: total training loss 0.00640\n",
            "2025-06-26 08:22:38,044 Epoch 1772: total training loss 0.00640\n",
            "INFO:__main__:EPOCH 1773\n",
            "2025-06-26 08:22:38,046 EPOCH 1773\n",
            "INFO:__main__:Epoch 1773: total training loss 0.00598\n",
            "2025-06-26 08:22:38,150 Epoch 1773: total training loss 0.00598\n",
            "INFO:__main__:EPOCH 1774\n",
            "2025-06-26 08:22:38,152 EPOCH 1774\n",
            "INFO:__main__:Epoch 1774: total training loss 0.00613\n",
            "2025-06-26 08:22:38,240 Epoch 1774: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1775\n",
            "2025-06-26 08:22:38,242 EPOCH 1775\n",
            "INFO:__main__:Epoch 1775: total training loss 0.00633\n",
            "2025-06-26 08:22:38,330 Epoch 1775: total training loss 0.00633\n",
            "INFO:__main__:EPOCH 1776\n",
            "2025-06-26 08:22:38,332 EPOCH 1776\n",
            "INFO:__main__:Epoch 1776: total training loss 0.00621\n",
            "2025-06-26 08:22:38,410 Epoch 1776: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1777\n",
            "2025-06-26 08:22:38,413 EPOCH 1777\n",
            "INFO:__main__:Epoch 1777: total training loss 0.00668\n",
            "2025-06-26 08:22:38,485 Epoch 1777: total training loss 0.00668\n",
            "INFO:__main__:EPOCH 1778\n",
            "2025-06-26 08:22:38,487 EPOCH 1778\n",
            "INFO:__main__:Epoch 1778: total training loss 0.00605\n",
            "2025-06-26 08:22:38,563 Epoch 1778: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1779\n",
            "2025-06-26 08:22:38,565 EPOCH 1779\n",
            "INFO:__main__:Epoch 1779: total training loss 0.00637\n",
            "2025-06-26 08:22:38,635 Epoch 1779: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1780\n",
            "2025-06-26 08:22:38,637 EPOCH 1780\n",
            "INFO:__main__:Epoch 1780: total training loss 0.00608\n",
            "2025-06-26 08:22:38,707 Epoch 1780: total training loss 0.00608\n",
            "INFO:__main__:EPOCH 1781\n",
            "2025-06-26 08:22:38,709 EPOCH 1781\n",
            "INFO:__main__:Epoch 1781: total training loss 0.00674\n",
            "2025-06-26 08:22:38,793 Epoch 1781: total training loss 0.00674\n",
            "INFO:__main__:EPOCH 1782\n",
            "2025-06-26 08:22:38,795 EPOCH 1782\n",
            "INFO:__main__:Epoch 1782: total training loss 0.00673\n",
            "2025-06-26 08:22:38,886 Epoch 1782: total training loss 0.00673\n",
            "INFO:__main__:EPOCH 1783\n",
            "2025-06-26 08:22:38,889 EPOCH 1783\n",
            "INFO:__main__:Epoch 1783: total training loss 0.00604\n",
            "2025-06-26 08:22:38,972 Epoch 1783: total training loss 0.00604\n",
            "INFO:__main__:EPOCH 1784\n",
            "2025-06-26 08:22:38,974 EPOCH 1784\n",
            "INFO:__main__:Epoch 1784: total training loss 0.00615\n",
            "2025-06-26 08:22:39,062 Epoch 1784: total training loss 0.00615\n",
            "INFO:__main__:EPOCH 1785\n",
            "2025-06-26 08:22:39,065 EPOCH 1785\n",
            "INFO:__main__:Epoch 1785: total training loss 0.00630\n",
            "2025-06-26 08:22:39,154 Epoch 1785: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1786\n",
            "2025-06-26 08:22:39,160 EPOCH 1786\n",
            "INFO:__main__:Epoch 1786: total training loss 0.00558\n",
            "2025-06-26 08:22:39,249 Epoch 1786: total training loss 0.00558\n",
            "INFO:__main__:EPOCH 1787\n",
            "2025-06-26 08:22:39,251 EPOCH 1787\n",
            "INFO:__main__:Epoch 1787: total training loss 0.00629\n",
            "2025-06-26 08:22:39,327 Epoch 1787: total training loss 0.00629\n",
            "INFO:__main__:EPOCH 1788\n",
            "2025-06-26 08:22:39,329 EPOCH 1788\n",
            "INFO:__main__:Epoch 1788: total training loss 0.00617\n",
            "2025-06-26 08:22:39,411 Epoch 1788: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1789\n",
            "2025-06-26 08:22:39,413 EPOCH 1789\n",
            "INFO:__main__:Epoch 1789: total training loss 0.00580\n",
            "2025-06-26 08:22:39,497 Epoch 1789: total training loss 0.00580\n",
            "INFO:__main__:EPOCH 1790\n",
            "2025-06-26 08:22:39,504 EPOCH 1790\n",
            "INFO:__main__:Epoch 1790: total training loss 0.00612\n",
            "2025-06-26 08:22:39,595 Epoch 1790: total training loss 0.00612\n",
            "INFO:__main__:EPOCH 1791\n",
            "2025-06-26 08:22:39,597 EPOCH 1791\n",
            "INFO:__main__:Epoch 1791: total training loss 0.00605\n",
            "2025-06-26 08:22:39,667 Epoch 1791: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1792\n",
            "2025-06-26 08:22:39,669 EPOCH 1792\n",
            "INFO:__main__:Epoch 1792: total training loss 0.00618\n",
            "2025-06-26 08:22:39,738 Epoch 1792: total training loss 0.00618\n",
            "INFO:__main__:EPOCH 1793\n",
            "2025-06-26 08:22:39,740 EPOCH 1793\n",
            "INFO:__main__:Epoch 1793: total training loss 0.00576\n",
            "2025-06-26 08:22:39,811 Epoch 1793: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1794\n",
            "2025-06-26 08:22:39,813 EPOCH 1794\n",
            "INFO:__main__:Epoch 1794: total training loss 0.00583\n",
            "2025-06-26 08:22:39,885 Epoch 1794: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1795\n",
            "2025-06-26 08:22:39,887 EPOCH 1795\n",
            "INFO:__main__:Epoch 1795: total training loss 0.00605\n",
            "2025-06-26 08:22:39,957 Epoch 1795: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1796\n",
            "2025-06-26 08:22:39,959 EPOCH 1796\n",
            "INFO:__main__:Epoch 1796: total training loss 0.00580\n",
            "2025-06-26 08:22:40,031 Epoch 1796: total training loss 0.00580\n",
            "INFO:__main__:EPOCH 1797\n",
            "2025-06-26 08:22:40,033 EPOCH 1797\n",
            "INFO:__main__:Epoch 1797: total training loss 0.00598\n",
            "2025-06-26 08:22:40,111 Epoch 1797: total training loss 0.00598\n",
            "INFO:__main__:EPOCH 1798\n",
            "2025-06-26 08:22:40,113 EPOCH 1798\n",
            "INFO:__main__:Epoch 1798: total training loss 0.00579\n",
            "2025-06-26 08:22:40,196 Epoch 1798: total training loss 0.00579\n",
            "INFO:__main__:EPOCH 1799\n",
            "2025-06-26 08:22:40,200 EPOCH 1799\n",
            "INFO:__main__:Epoch 1799: total training loss 0.00598\n",
            "2025-06-26 08:22:40,285 Epoch 1799: total training loss 0.00598\n",
            "INFO:__main__:EPOCH 1800\n",
            "2025-06-26 08:22:40,289 EPOCH 1800\n",
            "INFO:__main__:Epoch 1800: total training loss 0.00621\n",
            "2025-06-26 08:22:40,366 Epoch 1800: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1801\n",
            "2025-06-26 08:22:40,367 EPOCH 1801\n",
            "INFO:__main__:Epoch 1801: total training loss 0.00586\n",
            "2025-06-26 08:22:40,462 Epoch 1801: total training loss 0.00586\n",
            "INFO:__main__:EPOCH 1802\n",
            "2025-06-26 08:22:40,464 EPOCH 1802\n",
            "INFO:__main__:Epoch 1802: total training loss 0.00631\n",
            "2025-06-26 08:22:40,536 Epoch 1802: total training loss 0.00631\n",
            "INFO:__main__:EPOCH 1803\n",
            "2025-06-26 08:22:40,541 EPOCH 1803\n",
            "INFO:__main__:Epoch 1803: total training loss 0.00600\n",
            "2025-06-26 08:22:40,613 Epoch 1803: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1804\n",
            "2025-06-26 08:22:40,615 EPOCH 1804\n",
            "INFO:__main__:Epoch 1804: total training loss 0.00597\n",
            "2025-06-26 08:22:40,690 Epoch 1804: total training loss 0.00597\n",
            "INFO:__main__:EPOCH 1805\n",
            "2025-06-26 08:22:40,692 EPOCH 1805\n",
            "INFO:__main__:Epoch 1805: total training loss 0.00606\n",
            "2025-06-26 08:22:40,773 Epoch 1805: total training loss 0.00606\n",
            "INFO:__main__:EPOCH 1806\n",
            "2025-06-26 08:22:40,780 EPOCH 1806\n",
            "INFO:__main__:Epoch 1806: total training loss 0.00592\n",
            "2025-06-26 08:22:40,897 Epoch 1806: total training loss 0.00592\n",
            "INFO:__main__:EPOCH 1807\n",
            "2025-06-26 08:22:40,901 EPOCH 1807\n",
            "INFO:__main__:Epoch 1807: total training loss 0.00633\n",
            "2025-06-26 08:22:40,989 Epoch 1807: total training loss 0.00633\n",
            "INFO:__main__:EPOCH 1808\n",
            "2025-06-26 08:22:40,991 EPOCH 1808\n",
            "INFO:__main__:Epoch 1808: total training loss 0.00587\n",
            "2025-06-26 08:22:41,090 Epoch 1808: total training loss 0.00587\n",
            "INFO:__main__:EPOCH 1809\n",
            "2025-06-26 08:22:41,092 EPOCH 1809\n",
            "INFO:__main__:Epoch 1809: total training loss 0.00576\n",
            "2025-06-26 08:22:41,198 Epoch 1809: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1810\n",
            "2025-06-26 08:22:41,200 EPOCH 1810\n",
            "INFO:__main__:Epoch 1810: total training loss 0.00640\n",
            "2025-06-26 08:22:41,305 Epoch 1810: total training loss 0.00640\n",
            "INFO:__main__:EPOCH 1811\n",
            "2025-06-26 08:22:41,307 EPOCH 1811\n",
            "INFO:__main__:Epoch 1811: total training loss 0.00616\n",
            "2025-06-26 08:22:41,417 Epoch 1811: total training loss 0.00616\n",
            "INFO:__main__:EPOCH 1812\n",
            "2025-06-26 08:22:41,420 EPOCH 1812\n",
            "INFO:__main__:Epoch 1812: total training loss 0.00603\n",
            "2025-06-26 08:22:41,500 Epoch 1812: total training loss 0.00603\n",
            "INFO:__main__:EPOCH 1813\n",
            "2025-06-26 08:22:41,502 EPOCH 1813\n",
            "INFO:__main__:Epoch 1813: total training loss 0.00670\n",
            "2025-06-26 08:22:41,598 Epoch 1813: total training loss 0.00670\n",
            "INFO:__main__:EPOCH 1814\n",
            "2025-06-26 08:22:41,600 EPOCH 1814\n",
            "INFO:__main__:Epoch 1814: total training loss 0.00650\n",
            "2025-06-26 08:22:41,698 Epoch 1814: total training loss 0.00650\n",
            "INFO:__main__:EPOCH 1815\n",
            "2025-06-26 08:22:41,702 EPOCH 1815\n",
            "INFO:__main__:Epoch 1815: total training loss 0.00630\n",
            "2025-06-26 08:22:41,781 Epoch 1815: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1816\n",
            "2025-06-26 08:22:41,783 EPOCH 1816\n",
            "INFO:__main__:Epoch 1816: total training loss 0.00605\n",
            "2025-06-26 08:22:41,848 Epoch 1816: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1817\n",
            "2025-06-26 08:22:41,850 EPOCH 1817\n",
            "INFO:__main__:Epoch 1817: total training loss 0.00633\n",
            "2025-06-26 08:22:41,915 Epoch 1817: total training loss 0.00633\n",
            "INFO:__main__:EPOCH 1818\n",
            "2025-06-26 08:22:41,918 EPOCH 1818\n",
            "INFO:__main__:Epoch 1818: total training loss 0.00603\n",
            "2025-06-26 08:22:41,982 Epoch 1818: total training loss 0.00603\n",
            "INFO:__main__:EPOCH 1819\n",
            "2025-06-26 08:22:41,984 EPOCH 1819\n",
            "INFO:__main__:Epoch 1819: total training loss 0.00656\n",
            "2025-06-26 08:22:42,049 Epoch 1819: total training loss 0.00656\n",
            "INFO:__main__:EPOCH 1820\n",
            "2025-06-26 08:22:42,051 EPOCH 1820\n",
            "INFO:__main__:Epoch 1820: total training loss 0.00669\n",
            "2025-06-26 08:22:42,116 Epoch 1820: total training loss 0.00669\n",
            "INFO:__main__:EPOCH 1821\n",
            "2025-06-26 08:22:42,118 EPOCH 1821\n",
            "INFO:__main__:Epoch 1821: total training loss 0.00645\n",
            "2025-06-26 08:22:42,185 Epoch 1821: total training loss 0.00645\n",
            "INFO:__main__:EPOCH 1822\n",
            "2025-06-26 08:22:42,188 EPOCH 1822\n",
            "INFO:__main__:Epoch 1822: total training loss 0.00624\n",
            "2025-06-26 08:22:42,253 Epoch 1822: total training loss 0.00624\n",
            "INFO:__main__:EPOCH 1823\n",
            "2025-06-26 08:22:42,255 EPOCH 1823\n",
            "INFO:__main__:Epoch 1823: total training loss 0.00616\n",
            "2025-06-26 08:22:42,322 Epoch 1823: total training loss 0.00616\n",
            "INFO:__main__:EPOCH 1824\n",
            "2025-06-26 08:22:42,324 EPOCH 1824\n",
            "INFO:__main__:Epoch 1824: total training loss 0.00582\n",
            "2025-06-26 08:22:42,398 Epoch 1824: total training loss 0.00582\n",
            "INFO:__main__:EPOCH 1825\n",
            "2025-06-26 08:22:42,400 EPOCH 1825\n",
            "INFO:__main__:Epoch 1825: total training loss 0.00641\n",
            "2025-06-26 08:22:42,477 Epoch 1825: total training loss 0.00641\n",
            "INFO:__main__:EPOCH 1826\n",
            "2025-06-26 08:22:42,479 EPOCH 1826\n",
            "INFO:__main__:Epoch 1826: total training loss 0.00605\n",
            "2025-06-26 08:22:42,541 Epoch 1826: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1827\n",
            "2025-06-26 08:22:42,543 EPOCH 1827\n",
            "INFO:__main__:Epoch 1827: total training loss 0.00641\n",
            "2025-06-26 08:22:42,609 Epoch 1827: total training loss 0.00641\n",
            "INFO:__main__:EPOCH 1828\n",
            "2025-06-26 08:22:42,612 EPOCH 1828\n",
            "INFO:__main__:Epoch 1828: total training loss 0.00624\n",
            "2025-06-26 08:22:42,677 Epoch 1828: total training loss 0.00624\n",
            "INFO:__main__:EPOCH 1829\n",
            "2025-06-26 08:22:42,679 EPOCH 1829\n",
            "INFO:__main__:Epoch 1829: total training loss 0.00617\n",
            "2025-06-26 08:22:42,746 Epoch 1829: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1830\n",
            "2025-06-26 08:22:42,748 EPOCH 1830\n",
            "INFO:__main__:Epoch 1830: total training loss 0.00565\n",
            "2025-06-26 08:22:42,813 Epoch 1830: total training loss 0.00565\n",
            "INFO:__main__:EPOCH 1831\n",
            "2025-06-26 08:22:42,815 EPOCH 1831\n",
            "INFO:__main__:Epoch 1831: total training loss 0.00644\n",
            "2025-06-26 08:22:42,878 Epoch 1831: total training loss 0.00644\n",
            "INFO:__main__:EPOCH 1832\n",
            "2025-06-26 08:22:42,882 EPOCH 1832\n",
            "INFO:__main__:Epoch 1832: total training loss 0.00585\n",
            "2025-06-26 08:22:42,947 Epoch 1832: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1833\n",
            "2025-06-26 08:22:42,949 EPOCH 1833\n",
            "INFO:__main__:Epoch 1833: total training loss 0.00605\n",
            "2025-06-26 08:22:43,013 Epoch 1833: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1834\n",
            "2025-06-26 08:22:43,015 EPOCH 1834\n",
            "INFO:__main__:Epoch 1834: total training loss 0.00594\n",
            "2025-06-26 08:22:43,079 Epoch 1834: total training loss 0.00594\n",
            "INFO:__main__:EPOCH 1835\n",
            "2025-06-26 08:22:43,081 EPOCH 1835\n",
            "INFO:__main__:Epoch 1835: total training loss 0.00630\n",
            "2025-06-26 08:22:43,142 Epoch 1835: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1836\n",
            "2025-06-26 08:22:43,144 EPOCH 1836\n",
            "INFO:__main__:Epoch 1836: total training loss 0.00577\n",
            "2025-06-26 08:22:43,211 Epoch 1836: total training loss 0.00577\n",
            "INFO:__main__:EPOCH 1837\n",
            "2025-06-26 08:22:43,213 EPOCH 1837\n",
            "INFO:__main__:Epoch 1837: total training loss 0.00587\n",
            "2025-06-26 08:22:43,279 Epoch 1837: total training loss 0.00587\n",
            "INFO:__main__:EPOCH 1838\n",
            "2025-06-26 08:22:43,281 EPOCH 1838\n",
            "INFO:__main__:Epoch 1838: total training loss 0.00595\n",
            "2025-06-26 08:22:43,346 Epoch 1838: total training loss 0.00595\n",
            "INFO:__main__:EPOCH 1839\n",
            "2025-06-26 08:22:43,348 EPOCH 1839\n",
            "INFO:__main__:Epoch 1839: total training loss 0.00540\n",
            "2025-06-26 08:22:43,414 Epoch 1839: total training loss 0.00540\n",
            "INFO:__main__:EPOCH 1840\n",
            "2025-06-26 08:22:43,416 EPOCH 1840\n",
            "INFO:__main__:Epoch 1840: total training loss 0.00604\n",
            "2025-06-26 08:22:43,499 Epoch 1840: total training loss 0.00604\n",
            "INFO:__main__:EPOCH 1841\n",
            "2025-06-26 08:22:43,502 EPOCH 1841\n",
            "INFO:__main__:Epoch 1841: total training loss 0.00595\n",
            "2025-06-26 08:22:43,569 Epoch 1841: total training loss 0.00595\n",
            "INFO:__main__:EPOCH 1842\n",
            "2025-06-26 08:22:43,571 EPOCH 1842\n",
            "INFO:__main__:Epoch 1842: total training loss 0.00559\n",
            "2025-06-26 08:22:43,636 Epoch 1842: total training loss 0.00559\n",
            "INFO:__main__:EPOCH 1843\n",
            "2025-06-26 08:22:43,639 EPOCH 1843\n",
            "INFO:__main__:Epoch 1843: total training loss 0.00599\n",
            "2025-06-26 08:22:43,703 Epoch 1843: total training loss 0.00599\n",
            "INFO:__main__:EPOCH 1844\n",
            "2025-06-26 08:22:43,705 EPOCH 1844\n",
            "INFO:__main__:Epoch 1844: total training loss 0.00632\n",
            "2025-06-26 08:22:43,773 Epoch 1844: total training loss 0.00632\n",
            "INFO:__main__:EPOCH 1845\n",
            "2025-06-26 08:22:43,775 EPOCH 1845\n",
            "INFO:__main__:Epoch 1845: total training loss 0.00567\n",
            "2025-06-26 08:22:43,846 Epoch 1845: total training loss 0.00567\n",
            "INFO:__main__:EPOCH 1846\n",
            "2025-06-26 08:22:43,849 EPOCH 1846\n",
            "INFO:__main__:Epoch 1846: total training loss 0.00613\n",
            "2025-06-26 08:22:43,915 Epoch 1846: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1847\n",
            "2025-06-26 08:22:43,917 EPOCH 1847\n",
            "INFO:__main__:Epoch 1847: total training loss 0.00623\n",
            "2025-06-26 08:22:43,982 Epoch 1847: total training loss 0.00623\n",
            "INFO:__main__:EPOCH 1848\n",
            "2025-06-26 08:22:43,985 EPOCH 1848\n",
            "INFO:__main__:Epoch 1848: total training loss 0.00585\n",
            "2025-06-26 08:22:44,049 Epoch 1848: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1849\n",
            "2025-06-26 08:22:44,052 EPOCH 1849\n",
            "INFO:__main__:Epoch 1849: total training loss 0.00646\n",
            "2025-06-26 08:22:44,118 Epoch 1849: total training loss 0.00646\n",
            "INFO:__main__:EPOCH 1850\n",
            "2025-06-26 08:22:44,121 EPOCH 1850\n",
            "INFO:__main__:Epoch 1850: total training loss 0.00617\n",
            "2025-06-26 08:22:44,185 Epoch 1850: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1851\n",
            "2025-06-26 08:22:44,187 EPOCH 1851\n",
            "INFO:__main__:Epoch 1851: total training loss 0.00665\n",
            "2025-06-26 08:22:44,247 Epoch 1851: total training loss 0.00665\n",
            "INFO:__main__:EPOCH 1852\n",
            "2025-06-26 08:22:44,249 EPOCH 1852\n",
            "INFO:__main__:Epoch 1852: total training loss 0.00597\n",
            "2025-06-26 08:22:44,310 Epoch 1852: total training loss 0.00597\n",
            "INFO:__main__:EPOCH 1853\n",
            "2025-06-26 08:22:44,311 EPOCH 1853\n",
            "INFO:__main__:Epoch 1853: total training loss 0.00634\n",
            "2025-06-26 08:22:44,377 Epoch 1853: total training loss 0.00634\n",
            "INFO:__main__:EPOCH 1854\n",
            "2025-06-26 08:22:44,379 EPOCH 1854\n",
            "INFO:__main__:Epoch 1854: total training loss 0.00613\n",
            "2025-06-26 08:22:44,445 Epoch 1854: total training loss 0.00613\n",
            "INFO:__main__:EPOCH 1855\n",
            "2025-06-26 08:22:44,447 EPOCH 1855\n",
            "INFO:__main__:Epoch 1855: total training loss 0.00601\n",
            "2025-06-26 08:22:44,526 Epoch 1855: total training loss 0.00601\n",
            "INFO:__main__:EPOCH 1856\n",
            "2025-06-26 08:22:44,528 EPOCH 1856\n",
            "INFO:__main__:Epoch 1856: total training loss 0.00640\n",
            "2025-06-26 08:22:44,592 Epoch 1856: total training loss 0.00640\n",
            "INFO:__main__:EPOCH 1857\n",
            "2025-06-26 08:22:44,594 EPOCH 1857\n",
            "INFO:__main__:Epoch 1857: total training loss 0.00625\n",
            "2025-06-26 08:22:44,656 Epoch 1857: total training loss 0.00625\n",
            "INFO:__main__:EPOCH 1858\n",
            "2025-06-26 08:22:44,658 EPOCH 1858\n",
            "INFO:__main__:Epoch 1858: total training loss 0.00636\n",
            "2025-06-26 08:22:44,724 Epoch 1858: total training loss 0.00636\n",
            "INFO:__main__:EPOCH 1859\n",
            "2025-06-26 08:22:44,726 EPOCH 1859\n",
            "INFO:__main__:Epoch 1859: total training loss 0.00590\n",
            "2025-06-26 08:22:44,793 Epoch 1859: total training loss 0.00590\n",
            "INFO:__main__:EPOCH 1860\n",
            "2025-06-26 08:22:44,795 EPOCH 1860\n",
            "INFO:__main__:Epoch 1860: total training loss 0.00607\n",
            "2025-06-26 08:22:44,859 Epoch 1860: total training loss 0.00607\n",
            "INFO:__main__:EPOCH 1861\n",
            "2025-06-26 08:22:44,861 EPOCH 1861\n",
            "INFO:__main__:Epoch 1861: total training loss 0.00606\n",
            "2025-06-26 08:22:44,925 Epoch 1861: total training loss 0.00606\n",
            "INFO:__main__:EPOCH 1862\n",
            "2025-06-26 08:22:44,927 EPOCH 1862\n",
            "INFO:__main__:Epoch 1862: total training loss 0.00555\n",
            "2025-06-26 08:22:44,993 Epoch 1862: total training loss 0.00555\n",
            "INFO:__main__:EPOCH 1863\n",
            "2025-06-26 08:22:44,995 EPOCH 1863\n",
            "INFO:__main__:Epoch 1863: total training loss 0.00614\n",
            "2025-06-26 08:22:45,059 Epoch 1863: total training loss 0.00614\n",
            "INFO:__main__:EPOCH 1864\n",
            "2025-06-26 08:22:45,062 EPOCH 1864\n",
            "INFO:__main__:Epoch 1864: total training loss 0.00573\n",
            "2025-06-26 08:22:45,128 Epoch 1864: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1865\n",
            "2025-06-26 08:22:45,131 EPOCH 1865\n",
            "INFO:__main__:Epoch 1865: total training loss 0.00606\n",
            "2025-06-26 08:22:45,196 Epoch 1865: total training loss 0.00606\n",
            "INFO:__main__:EPOCH 1866\n",
            "2025-06-26 08:22:45,198 EPOCH 1866\n",
            "INFO:__main__:Epoch 1866: total training loss 0.00600\n",
            "2025-06-26 08:22:45,257 Epoch 1866: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1867\n",
            "2025-06-26 08:22:45,259 EPOCH 1867\n",
            "INFO:__main__:Epoch 1867: total training loss 0.00551\n",
            "2025-06-26 08:22:45,321 Epoch 1867: total training loss 0.00551\n",
            "INFO:__main__:EPOCH 1868\n",
            "2025-06-26 08:22:45,323 EPOCH 1868\n",
            "INFO:__main__:Epoch 1868: total training loss 0.00582\n",
            "2025-06-26 08:22:45,387 Epoch 1868: total training loss 0.00582\n",
            "INFO:__main__:EPOCH 1869\n",
            "2025-06-26 08:22:45,389 EPOCH 1869\n",
            "INFO:__main__:Epoch 1869: total training loss 0.00553\n",
            "2025-06-26 08:22:45,453 Epoch 1869: total training loss 0.00553\n",
            "INFO:__main__:EPOCH 1870\n",
            "2025-06-26 08:22:45,455 EPOCH 1870\n",
            "INFO:__main__:Epoch 1870: total training loss 0.00581\n",
            "2025-06-26 08:22:45,518 Epoch 1870: total training loss 0.00581\n",
            "INFO:__main__:EPOCH 1871\n",
            "2025-06-26 08:22:45,522 EPOCH 1871\n",
            "INFO:__main__:Epoch 1871: total training loss 0.00594\n",
            "2025-06-26 08:22:45,606 Epoch 1871: total training loss 0.00594\n",
            "INFO:__main__:EPOCH 1872\n",
            "2025-06-26 08:22:45,609 EPOCH 1872\n",
            "INFO:__main__:Epoch 1872: total training loss 0.00543\n",
            "2025-06-26 08:22:45,671 Epoch 1872: total training loss 0.00543\n",
            "INFO:__main__:EPOCH 1873\n",
            "2025-06-26 08:22:45,674 EPOCH 1873\n",
            "INFO:__main__:Epoch 1873: total training loss 0.00595\n",
            "2025-06-26 08:22:45,739 Epoch 1873: total training loss 0.00595\n",
            "INFO:__main__:EPOCH 1874\n",
            "2025-06-26 08:22:45,741 EPOCH 1874\n",
            "INFO:__main__:Epoch 1874: total training loss 0.00579\n",
            "2025-06-26 08:22:45,806 Epoch 1874: total training loss 0.00579\n",
            "INFO:__main__:EPOCH 1875\n",
            "2025-06-26 08:22:45,808 EPOCH 1875\n",
            "INFO:__main__:Epoch 1875: total training loss 0.00591\n",
            "2025-06-26 08:22:45,871 Epoch 1875: total training loss 0.00591\n",
            "INFO:__main__:EPOCH 1876\n",
            "2025-06-26 08:22:45,873 EPOCH 1876\n",
            "INFO:__main__:Epoch 1876: total training loss 0.00629\n",
            "2025-06-26 08:22:45,939 Epoch 1876: total training loss 0.00629\n",
            "INFO:__main__:EPOCH 1877\n",
            "2025-06-26 08:22:45,941 EPOCH 1877\n",
            "INFO:__main__:Epoch 1877: total training loss 0.00576\n",
            "2025-06-26 08:22:46,006 Epoch 1877: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1878\n",
            "2025-06-26 08:22:46,008 EPOCH 1878\n",
            "INFO:__main__:Epoch 1878: total training loss 0.00615\n",
            "2025-06-26 08:22:46,071 Epoch 1878: total training loss 0.00615\n",
            "INFO:__main__:EPOCH 1879\n",
            "2025-06-26 08:22:46,073 EPOCH 1879\n",
            "INFO:__main__:Epoch 1879: total training loss 0.00624\n",
            "2025-06-26 08:22:46,139 Epoch 1879: total training loss 0.00624\n",
            "INFO:__main__:EPOCH 1880\n",
            "2025-06-26 08:22:46,141 EPOCH 1880\n",
            "INFO:__main__:Epoch 1880: total training loss 0.00637\n",
            "2025-06-26 08:22:46,206 Epoch 1880: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1881\n",
            "2025-06-26 08:22:46,208 EPOCH 1881\n",
            "INFO:__main__:Epoch 1881: total training loss 0.00574\n",
            "2025-06-26 08:22:46,274 Epoch 1881: total training loss 0.00574\n",
            "INFO:__main__:EPOCH 1882\n",
            "2025-06-26 08:22:46,276 EPOCH 1882\n",
            "INFO:__main__:Epoch 1882: total training loss 0.00531\n",
            "2025-06-26 08:22:46,339 Epoch 1882: total training loss 0.00531\n",
            "INFO:__main__:EPOCH 1883\n",
            "2025-06-26 08:22:46,341 EPOCH 1883\n",
            "INFO:__main__:Epoch 1883: total training loss 0.00583\n",
            "2025-06-26 08:22:46,411 Epoch 1883: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1884\n",
            "2025-06-26 08:22:46,413 EPOCH 1884\n",
            "INFO:__main__:Epoch 1884: total training loss 0.00620\n",
            "2025-06-26 08:22:46,479 Epoch 1884: total training loss 0.00620\n",
            "INFO:__main__:EPOCH 1885\n",
            "2025-06-26 08:22:46,481 EPOCH 1885\n",
            "INFO:__main__:Epoch 1885: total training loss 0.00583\n",
            "2025-06-26 08:22:46,544 Epoch 1885: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1886\n",
            "2025-06-26 08:22:46,546 EPOCH 1886\n",
            "INFO:__main__:Epoch 1886: total training loss 0.00604\n",
            "2025-06-26 08:22:46,629 Epoch 1886: total training loss 0.00604\n",
            "INFO:__main__:EPOCH 1887\n",
            "2025-06-26 08:22:46,631 EPOCH 1887\n",
            "INFO:__main__:Epoch 1887: total training loss 0.00605\n",
            "2025-06-26 08:22:46,695 Epoch 1887: total training loss 0.00605\n",
            "INFO:__main__:EPOCH 1888\n",
            "2025-06-26 08:22:46,697 EPOCH 1888\n",
            "INFO:__main__:Epoch 1888: total training loss 0.00617\n",
            "2025-06-26 08:22:46,762 Epoch 1888: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1889\n",
            "2025-06-26 08:22:46,764 EPOCH 1889\n",
            "INFO:__main__:Epoch 1889: total training loss 0.00637\n",
            "2025-06-26 08:22:46,830 Epoch 1889: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1890\n",
            "2025-06-26 08:22:46,832 EPOCH 1890\n",
            "INFO:__main__:Epoch 1890: total training loss 0.00616\n",
            "2025-06-26 08:22:46,894 Epoch 1890: total training loss 0.00616\n",
            "INFO:__main__:EPOCH 1891\n",
            "2025-06-26 08:22:46,896 EPOCH 1891\n",
            "INFO:__main__:Epoch 1891: total training loss 0.00579\n",
            "2025-06-26 08:22:46,960 Epoch 1891: total training loss 0.00579\n",
            "INFO:__main__:EPOCH 1892\n",
            "2025-06-26 08:22:46,962 EPOCH 1892\n",
            "INFO:__main__:Epoch 1892: total training loss 0.00603\n",
            "2025-06-26 08:22:47,026 Epoch 1892: total training loss 0.00603\n",
            "INFO:__main__:EPOCH 1893\n",
            "2025-06-26 08:22:47,028 EPOCH 1893\n",
            "INFO:__main__:Epoch 1893: total training loss 0.00615\n",
            "2025-06-26 08:22:47,093 Epoch 1893: total training loss 0.00615\n",
            "INFO:__main__:EPOCH 1894\n",
            "2025-06-26 08:22:47,095 EPOCH 1894\n",
            "INFO:__main__:Epoch 1894: total training loss 0.00625\n",
            "2025-06-26 08:22:47,160 Epoch 1894: total training loss 0.00625\n",
            "INFO:__main__:EPOCH 1895\n",
            "2025-06-26 08:22:47,163 EPOCH 1895\n",
            "INFO:__main__:Epoch 1895: total training loss 0.00601\n",
            "2025-06-26 08:22:47,226 Epoch 1895: total training loss 0.00601\n",
            "INFO:__main__:EPOCH 1896\n",
            "2025-06-26 08:22:47,228 EPOCH 1896\n",
            "INFO:__main__:Epoch 1896: total training loss 0.00552\n",
            "2025-06-26 08:22:47,292 Epoch 1896: total training loss 0.00552\n",
            "INFO:__main__:EPOCH 1897\n",
            "2025-06-26 08:22:47,294 EPOCH 1897\n",
            "INFO:__main__:Epoch 1897: total training loss 0.00630\n",
            "2025-06-26 08:22:47,359 Epoch 1897: total training loss 0.00630\n",
            "INFO:__main__:EPOCH 1898\n",
            "2025-06-26 08:22:47,361 EPOCH 1898\n",
            "INFO:__main__:Epoch 1898: total training loss 0.00621\n",
            "2025-06-26 08:22:47,426 Epoch 1898: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1899\n",
            "2025-06-26 08:22:47,428 EPOCH 1899\n",
            "INFO:__main__:Epoch 1899: total training loss 0.00592\n",
            "2025-06-26 08:22:47,491 Epoch 1899: total training loss 0.00592\n",
            "INFO:__main__:EPOCH 1900\n",
            "2025-06-26 08:22:47,493 EPOCH 1900\n",
            "INFO:__main__:Epoch 1900: total training loss 0.00596\n",
            "2025-06-26 08:22:47,554 Epoch 1900: total training loss 0.00596\n",
            "INFO:__main__:EPOCH 1901\n",
            "2025-06-26 08:22:47,556 EPOCH 1901\n",
            "INFO:__main__:Epoch 1901: total training loss 0.00565\n",
            "2025-06-26 08:22:47,626 Epoch 1901: total training loss 0.00565\n",
            "INFO:__main__:EPOCH 1902\n",
            "2025-06-26 08:22:47,628 EPOCH 1902\n",
            "INFO:__main__:Epoch 1902: total training loss 0.00569\n",
            "2025-06-26 08:22:47,697 Epoch 1902: total training loss 0.00569\n",
            "INFO:__main__:EPOCH 1903\n",
            "2025-06-26 08:22:47,699 EPOCH 1903\n",
            "INFO:__main__:Epoch 1903: total training loss 0.00594\n",
            "2025-06-26 08:22:47,763 Epoch 1903: total training loss 0.00594\n",
            "INFO:__main__:EPOCH 1904\n",
            "2025-06-26 08:22:47,765 EPOCH 1904\n",
            "INFO:__main__:Epoch 1904: total training loss 0.00593\n",
            "2025-06-26 08:22:47,830 Epoch 1904: total training loss 0.00593\n",
            "INFO:__main__:EPOCH 1905\n",
            "2025-06-26 08:22:47,831 EPOCH 1905\n",
            "INFO:__main__:Epoch 1905: total training loss 0.00585\n",
            "2025-06-26 08:22:47,894 Epoch 1905: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1906\n",
            "2025-06-26 08:22:47,896 EPOCH 1906\n",
            "INFO:__main__:Epoch 1906: total training loss 0.00621\n",
            "2025-06-26 08:22:47,959 Epoch 1906: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1907\n",
            "2025-06-26 08:22:47,961 EPOCH 1907\n",
            "INFO:__main__:Epoch 1907: total training loss 0.00556\n",
            "2025-06-26 08:22:48,024 Epoch 1907: total training loss 0.00556\n",
            "INFO:__main__:EPOCH 1908\n",
            "2025-06-26 08:22:48,025 EPOCH 1908\n",
            "INFO:__main__:Epoch 1908: total training loss 0.00580\n",
            "2025-06-26 08:22:48,090 Epoch 1908: total training loss 0.00580\n",
            "INFO:__main__:EPOCH 1909\n",
            "2025-06-26 08:22:48,092 EPOCH 1909\n",
            "INFO:__main__:Epoch 1909: total training loss 0.00604\n",
            "2025-06-26 08:22:48,159 Epoch 1909: total training loss 0.00604\n",
            "INFO:__main__:EPOCH 1910\n",
            "2025-06-26 08:22:48,161 EPOCH 1910\n",
            "INFO:__main__:Epoch 1910: total training loss 0.00583\n",
            "2025-06-26 08:22:48,227 Epoch 1910: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1911\n",
            "2025-06-26 08:22:48,230 EPOCH 1911\n",
            "INFO:__main__:Epoch 1911: total training loss 0.00598\n",
            "2025-06-26 08:22:48,294 Epoch 1911: total training loss 0.00598\n",
            "INFO:__main__:EPOCH 1912\n",
            "2025-06-26 08:22:48,296 EPOCH 1912\n",
            "INFO:__main__:Epoch 1912: total training loss 0.00573\n",
            "2025-06-26 08:22:48,358 Epoch 1912: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1913\n",
            "2025-06-26 08:22:48,360 EPOCH 1913\n",
            "INFO:__main__:Epoch 1913: total training loss 0.00573\n",
            "2025-06-26 08:22:48,429 Epoch 1913: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1914\n",
            "2025-06-26 08:22:48,431 EPOCH 1914\n",
            "INFO:__main__:Epoch 1914: total training loss 0.00598\n",
            "2025-06-26 08:22:48,493 Epoch 1914: total training loss 0.00598\n",
            "INFO:__main__:EPOCH 1915\n",
            "2025-06-26 08:22:48,496 EPOCH 1915\n",
            "INFO:__main__:Epoch 1915: total training loss 0.00610\n",
            "2025-06-26 08:22:48,561 Epoch 1915: total training loss 0.00610\n",
            "INFO:__main__:EPOCH 1916\n",
            "2025-06-26 08:22:48,564 EPOCH 1916\n",
            "INFO:__main__:Epoch 1916: total training loss 0.00602\n",
            "2025-06-26 08:22:48,628 Epoch 1916: total training loss 0.00602\n",
            "INFO:__main__:EPOCH 1917\n",
            "2025-06-26 08:22:48,630 EPOCH 1917\n",
            "INFO:__main__:Epoch 1917: total training loss 0.00586\n",
            "2025-06-26 08:22:48,716 Epoch 1917: total training loss 0.00586\n",
            "INFO:__main__:EPOCH 1918\n",
            "2025-06-26 08:22:48,718 EPOCH 1918\n",
            "INFO:__main__:Epoch 1918: total training loss 0.00573\n",
            "2025-06-26 08:22:48,782 Epoch 1918: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1919\n",
            "2025-06-26 08:22:48,784 EPOCH 1919\n",
            "INFO:__main__:Epoch 1919: total training loss 0.00583\n",
            "2025-06-26 08:22:48,850 Epoch 1919: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1920\n",
            "2025-06-26 08:22:48,852 EPOCH 1920\n",
            "INFO:__main__:Epoch 1920: total training loss 0.00522\n",
            "2025-06-26 08:22:48,916 Epoch 1920: total training loss 0.00522\n",
            "INFO:__main__:EPOCH 1921\n",
            "2025-06-26 08:22:48,918 EPOCH 1921\n",
            "INFO:__main__:Epoch 1921: total training loss 0.00534\n",
            "2025-06-26 08:22:48,985 Epoch 1921: total training loss 0.00534\n",
            "INFO:__main__:EPOCH 1922\n",
            "2025-06-26 08:22:48,987 EPOCH 1922\n",
            "INFO:__main__:Epoch 1922: total training loss 0.00576\n",
            "2025-06-26 08:22:49,054 Epoch 1922: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1923\n",
            "2025-06-26 08:22:49,056 EPOCH 1923\n",
            "INFO:__main__:Epoch 1923: total training loss 0.00548\n",
            "2025-06-26 08:22:49,120 Epoch 1923: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1924\n",
            "2025-06-26 08:22:49,122 EPOCH 1924\n",
            "INFO:__main__:Epoch 1924: total training loss 0.00531\n",
            "2025-06-26 08:22:49,189 Epoch 1924: total training loss 0.00531\n",
            "INFO:__main__:EPOCH 1925\n",
            "2025-06-26 08:22:49,191 EPOCH 1925\n",
            "INFO:__main__:Epoch 1925: total training loss 0.00543\n",
            "2025-06-26 08:22:49,258 Epoch 1925: total training loss 0.00543\n",
            "INFO:__main__:EPOCH 1926\n",
            "2025-06-26 08:22:49,260 EPOCH 1926\n",
            "INFO:__main__:Epoch 1926: total training loss 0.00584\n",
            "2025-06-26 08:22:49,323 Epoch 1926: total training loss 0.00584\n",
            "INFO:__main__:EPOCH 1927\n",
            "2025-06-26 08:22:49,325 EPOCH 1927\n",
            "INFO:__main__:Epoch 1927: total training loss 0.00530\n",
            "2025-06-26 08:22:49,389 Epoch 1927: total training loss 0.00530\n",
            "INFO:__main__:EPOCH 1928\n",
            "2025-06-26 08:22:49,392 EPOCH 1928\n",
            "INFO:__main__:Epoch 1928: total training loss 0.00542\n",
            "2025-06-26 08:22:49,455 Epoch 1928: total training loss 0.00542\n",
            "INFO:__main__:EPOCH 1929\n",
            "2025-06-26 08:22:49,457 EPOCH 1929\n",
            "INFO:__main__:Epoch 1929: total training loss 0.00611\n",
            "2025-06-26 08:22:49,521 Epoch 1929: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1930\n",
            "2025-06-26 08:22:49,523 EPOCH 1930\n",
            "INFO:__main__:Epoch 1930: total training loss 0.00617\n",
            "2025-06-26 08:22:49,586 Epoch 1930: total training loss 0.00617\n",
            "INFO:__main__:EPOCH 1931\n",
            "2025-06-26 08:22:49,588 EPOCH 1931\n",
            "INFO:__main__:Epoch 1931: total training loss 0.00557\n",
            "2025-06-26 08:22:49,662 Epoch 1931: total training loss 0.00557\n",
            "INFO:__main__:EPOCH 1932\n",
            "2025-06-26 08:22:49,664 EPOCH 1932\n",
            "INFO:__main__:Epoch 1932: total training loss 0.00573\n",
            "2025-06-26 08:22:49,766 Epoch 1932: total training loss 0.00573\n",
            "INFO:__main__:EPOCH 1933\n",
            "2025-06-26 08:22:49,768 EPOCH 1933\n",
            "INFO:__main__:Epoch 1933: total training loss 0.00547\n",
            "2025-06-26 08:22:49,834 Epoch 1933: total training loss 0.00547\n",
            "INFO:__main__:EPOCH 1934\n",
            "2025-06-26 08:22:49,836 EPOCH 1934\n",
            "INFO:__main__:Epoch 1934: total training loss 0.00637\n",
            "2025-06-26 08:22:49,902 Epoch 1934: total training loss 0.00637\n",
            "INFO:__main__:EPOCH 1935\n",
            "2025-06-26 08:22:49,907 EPOCH 1935\n",
            "INFO:__main__:Epoch 1935: total training loss 0.00603\n",
            "2025-06-26 08:22:49,969 Epoch 1935: total training loss 0.00603\n",
            "INFO:__main__:EPOCH 1936\n",
            "2025-06-26 08:22:49,971 EPOCH 1936\n",
            "INFO:__main__:Epoch 1936: total training loss 0.00560\n",
            "2025-06-26 08:22:50,038 Epoch 1936: total training loss 0.00560\n",
            "INFO:__main__:EPOCH 1937\n",
            "2025-06-26 08:22:50,040 EPOCH 1937\n",
            "INFO:__main__:Epoch 1937: total training loss 0.00535\n",
            "2025-06-26 08:22:50,103 Epoch 1937: total training loss 0.00535\n",
            "INFO:__main__:EPOCH 1938\n",
            "2025-06-26 08:22:50,105 EPOCH 1938\n",
            "INFO:__main__:Epoch 1938: total training loss 0.00611\n",
            "2025-06-26 08:22:50,169 Epoch 1938: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1939\n",
            "2025-06-26 08:22:50,171 EPOCH 1939\n",
            "INFO:__main__:Epoch 1939: total training loss 0.00585\n",
            "2025-06-26 08:22:50,236 Epoch 1939: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1940\n",
            "2025-06-26 08:22:50,238 EPOCH 1940\n",
            "INFO:__main__:Epoch 1940: total training loss 0.00611\n",
            "2025-06-26 08:22:50,306 Epoch 1940: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1941\n",
            "2025-06-26 08:22:50,308 EPOCH 1941\n",
            "INFO:__main__:Epoch 1941: total training loss 0.00621\n",
            "2025-06-26 08:22:50,369 Epoch 1941: total training loss 0.00621\n",
            "INFO:__main__:EPOCH 1942\n",
            "2025-06-26 08:22:50,371 EPOCH 1942\n",
            "INFO:__main__:Epoch 1942: total training loss 0.00611\n",
            "2025-06-26 08:22:50,434 Epoch 1942: total training loss 0.00611\n",
            "INFO:__main__:EPOCH 1943\n",
            "2025-06-26 08:22:50,436 EPOCH 1943\n",
            "INFO:__main__:Epoch 1943: total training loss 0.00566\n",
            "2025-06-26 08:22:50,498 Epoch 1943: total training loss 0.00566\n",
            "INFO:__main__:EPOCH 1944\n",
            "2025-06-26 08:22:50,500 EPOCH 1944\n",
            "INFO:__main__:Epoch 1944: total training loss 0.00582\n",
            "2025-06-26 08:22:50,563 Epoch 1944: total training loss 0.00582\n",
            "INFO:__main__:EPOCH 1945\n",
            "2025-06-26 08:22:50,565 EPOCH 1945\n",
            "INFO:__main__:Epoch 1945: total training loss 0.00578\n",
            "2025-06-26 08:22:50,627 Epoch 1945: total training loss 0.00578\n",
            "INFO:__main__:EPOCH 1946\n",
            "2025-06-26 08:22:50,629 EPOCH 1946\n",
            "INFO:__main__:Epoch 1946: total training loss 0.00631\n",
            "2025-06-26 08:22:50,691 Epoch 1946: total training loss 0.00631\n",
            "INFO:__main__:EPOCH 1947\n",
            "2025-06-26 08:22:50,694 EPOCH 1947\n",
            "INFO:__main__:Epoch 1947: total training loss 0.00568\n",
            "2025-06-26 08:22:50,766 Epoch 1947: total training loss 0.00568\n",
            "INFO:__main__:EPOCH 1948\n",
            "2025-06-26 08:22:50,769 EPOCH 1948\n",
            "INFO:__main__:Epoch 1948: total training loss 0.00583\n",
            "2025-06-26 08:22:50,845 Epoch 1948: total training loss 0.00583\n",
            "INFO:__main__:EPOCH 1949\n",
            "2025-06-26 08:22:50,847 EPOCH 1949\n",
            "INFO:__main__:Epoch 1949: total training loss 0.00576\n",
            "2025-06-26 08:22:50,911 Epoch 1949: total training loss 0.00576\n",
            "INFO:__main__:EPOCH 1950\n",
            "2025-06-26 08:22:50,913 EPOCH 1950\n",
            "INFO:__main__:Epoch 1950: total training loss 0.00562\n",
            "2025-06-26 08:22:50,981 Epoch 1950: total training loss 0.00562\n",
            "INFO:__main__:EPOCH 1951\n",
            "2025-06-26 08:22:50,983 EPOCH 1951\n",
            "INFO:__main__:Epoch 1951: total training loss 0.00565\n",
            "2025-06-26 08:22:51,049 Epoch 1951: total training loss 0.00565\n",
            "INFO:__main__:EPOCH 1952\n",
            "2025-06-26 08:22:51,051 EPOCH 1952\n",
            "INFO:__main__:Epoch 1952: total training loss 0.00531\n",
            "2025-06-26 08:22:51,117 Epoch 1952: total training loss 0.00531\n",
            "INFO:__main__:EPOCH 1953\n",
            "2025-06-26 08:22:51,119 EPOCH 1953\n",
            "INFO:__main__:Epoch 1953: total training loss 0.00571\n",
            "2025-06-26 08:22:51,183 Epoch 1953: total training loss 0.00571\n",
            "INFO:__main__:EPOCH 1954\n",
            "2025-06-26 08:22:51,185 EPOCH 1954\n",
            "INFO:__main__:Epoch 1954: total training loss 0.00549\n",
            "2025-06-26 08:22:51,249 Epoch 1954: total training loss 0.00549\n",
            "INFO:__main__:EPOCH 1955\n",
            "2025-06-26 08:22:51,252 EPOCH 1955\n",
            "INFO:__main__:Epoch 1955: total training loss 0.00530\n",
            "2025-06-26 08:22:51,313 Epoch 1955: total training loss 0.00530\n",
            "INFO:__main__:EPOCH 1956\n",
            "2025-06-26 08:22:51,315 EPOCH 1956\n",
            "INFO:__main__:Epoch 1956: total training loss 0.00534\n",
            "2025-06-26 08:22:51,378 Epoch 1956: total training loss 0.00534\n",
            "INFO:__main__:EPOCH 1957\n",
            "2025-06-26 08:22:51,381 EPOCH 1957\n",
            "INFO:__main__:Epoch 1957: total training loss 0.00507\n",
            "2025-06-26 08:22:51,443 Epoch 1957: total training loss 0.00507\n",
            "INFO:__main__:EPOCH 1958\n",
            "2025-06-26 08:22:51,446 EPOCH 1958\n",
            "INFO:__main__:Epoch 1958: total training loss 0.00526\n",
            "2025-06-26 08:22:51,509 Epoch 1958: total training loss 0.00526\n",
            "INFO:__main__:EPOCH 1959\n",
            "2025-06-26 08:22:51,511 EPOCH 1959\n",
            "INFO:__main__:Epoch 1959: total training loss 0.00500\n",
            "2025-06-26 08:22:51,578 Epoch 1959: total training loss 0.00500\n",
            "INFO:__main__:EPOCH 1960\n",
            "2025-06-26 08:22:51,580 EPOCH 1960\n",
            "INFO:__main__:Epoch 1960: total training loss 0.00508\n",
            "2025-06-26 08:22:51,643 Epoch 1960: total training loss 0.00508\n",
            "INFO:__main__:EPOCH 1961\n",
            "2025-06-26 08:22:51,646 EPOCH 1961\n",
            "INFO:__main__:Epoch 1961: total training loss 0.00504\n",
            "2025-06-26 08:22:51,709 Epoch 1961: total training loss 0.00504\n",
            "INFO:__main__:EPOCH 1962\n",
            "2025-06-26 08:22:51,711 EPOCH 1962\n",
            "INFO:__main__:Epoch 1962: total training loss 0.00513\n",
            "2025-06-26 08:22:51,792 Epoch 1962: total training loss 0.00513\n",
            "INFO:__main__:EPOCH 1963\n",
            "2025-06-26 08:22:51,795 EPOCH 1963\n",
            "INFO:__main__:Epoch 1963: total training loss 0.00548\n",
            "2025-06-26 08:22:51,895 Epoch 1963: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1964\n",
            "2025-06-26 08:22:51,897 EPOCH 1964\n",
            "INFO:__main__:Epoch 1964: total training loss 0.00548\n",
            "2025-06-26 08:22:51,994 Epoch 1964: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1965\n",
            "2025-06-26 08:22:51,997 EPOCH 1965\n",
            "INFO:__main__:Epoch 1965: total training loss 0.00553\n",
            "2025-06-26 08:22:52,086 Epoch 1965: total training loss 0.00553\n",
            "INFO:__main__:EPOCH 1966\n",
            "2025-06-26 08:22:52,090 EPOCH 1966\n",
            "INFO:__main__:Epoch 1966: total training loss 0.00548\n",
            "2025-06-26 08:22:52,172 Epoch 1966: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1967\n",
            "2025-06-26 08:22:52,174 EPOCH 1967\n",
            "INFO:__main__:Epoch 1967: total training loss 0.00526\n",
            "2025-06-26 08:22:52,265 Epoch 1967: total training loss 0.00526\n",
            "INFO:__main__:EPOCH 1968\n",
            "2025-06-26 08:22:52,268 EPOCH 1968\n",
            "INFO:__main__:Epoch 1968: total training loss 0.00580\n",
            "2025-06-26 08:22:52,341 Epoch 1968: total training loss 0.00580\n",
            "INFO:__main__:EPOCH 1969\n",
            "2025-06-26 08:22:52,343 EPOCH 1969\n",
            "INFO:__main__:Epoch 1969: total training loss 0.00563\n",
            "2025-06-26 08:22:52,418 Epoch 1969: total training loss 0.00563\n",
            "INFO:__main__:EPOCH 1970\n",
            "2025-06-26 08:22:52,420 EPOCH 1970\n",
            "INFO:__main__:Epoch 1970: total training loss 0.00548\n",
            "2025-06-26 08:22:52,497 Epoch 1970: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1971\n",
            "2025-06-26 08:22:52,499 EPOCH 1971\n",
            "INFO:__main__:Epoch 1971: total training loss 0.00562\n",
            "2025-06-26 08:22:52,576 Epoch 1971: total training loss 0.00562\n",
            "INFO:__main__:EPOCH 1972\n",
            "2025-06-26 08:22:52,579 EPOCH 1972\n",
            "INFO:__main__:Epoch 1972: total training loss 0.00600\n",
            "2025-06-26 08:22:52,660 Epoch 1972: total training loss 0.00600\n",
            "INFO:__main__:EPOCH 1973\n",
            "2025-06-26 08:22:52,662 EPOCH 1973\n",
            "INFO:__main__:Epoch 1973: total training loss 0.00585\n",
            "2025-06-26 08:22:52,742 Epoch 1973: total training loss 0.00585\n",
            "INFO:__main__:EPOCH 1974\n",
            "2025-06-26 08:22:52,745 EPOCH 1974\n",
            "INFO:__main__:Epoch 1974: total training loss 0.00629\n",
            "2025-06-26 08:22:52,819 Epoch 1974: total training loss 0.00629\n",
            "INFO:__main__:EPOCH 1975\n",
            "2025-06-26 08:22:52,821 EPOCH 1975\n",
            "INFO:__main__:Epoch 1975: total training loss 0.00642\n",
            "2025-06-26 08:22:52,897 Epoch 1975: total training loss 0.00642\n",
            "INFO:__main__:EPOCH 1976\n",
            "2025-06-26 08:22:52,899 EPOCH 1976\n",
            "INFO:__main__:Epoch 1976: total training loss 0.00622\n",
            "2025-06-26 08:22:52,991 Epoch 1976: total training loss 0.00622\n",
            "INFO:__main__:EPOCH 1977\n",
            "2025-06-26 08:22:52,997 EPOCH 1977\n",
            "INFO:__main__:Epoch 1977: total training loss 0.00599\n",
            "2025-06-26 08:22:53,084 Epoch 1977: total training loss 0.00599\n",
            "INFO:__main__:EPOCH 1978\n",
            "2025-06-26 08:22:53,086 EPOCH 1978\n",
            "INFO:__main__:Epoch 1978: total training loss 0.00588\n",
            "2025-06-26 08:22:53,158 Epoch 1978: total training loss 0.00588\n",
            "INFO:__main__:EPOCH 1979\n",
            "2025-06-26 08:22:53,161 EPOCH 1979\n",
            "INFO:__main__:Epoch 1979: total training loss 0.00599\n",
            "2025-06-26 08:22:53,252 Epoch 1979: total training loss 0.00599\n",
            "INFO:__main__:EPOCH 1980\n",
            "2025-06-26 08:22:53,254 EPOCH 1980\n",
            "INFO:__main__:Epoch 1980: total training loss 0.00567\n",
            "2025-06-26 08:22:53,341 Epoch 1980: total training loss 0.00567\n",
            "INFO:__main__:EPOCH 1981\n",
            "2025-06-26 08:22:53,344 EPOCH 1981\n",
            "INFO:__main__:Epoch 1981: total training loss 0.00568\n",
            "2025-06-26 08:22:53,442 Epoch 1981: total training loss 0.00568\n",
            "INFO:__main__:EPOCH 1982\n",
            "2025-06-26 08:22:53,444 EPOCH 1982\n",
            "INFO:__main__:Epoch 1982: total training loss 0.00548\n",
            "2025-06-26 08:22:53,528 Epoch 1982: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1983\n",
            "2025-06-26 08:22:53,531 EPOCH 1983\n",
            "INFO:__main__:Epoch 1983: total training loss 0.00549\n",
            "2025-06-26 08:22:53,620 Epoch 1983: total training loss 0.00549\n",
            "INFO:__main__:EPOCH 1984\n",
            "2025-06-26 08:22:53,622 EPOCH 1984\n",
            "INFO:__main__:Epoch 1984: total training loss 0.00550\n",
            "2025-06-26 08:22:53,705 Epoch 1984: total training loss 0.00550\n",
            "INFO:__main__:EPOCH 1985\n",
            "2025-06-26 08:22:53,707 EPOCH 1985\n",
            "INFO:__main__:Epoch 1985: total training loss 0.00526\n",
            "2025-06-26 08:22:53,797 Epoch 1985: total training loss 0.00526\n",
            "INFO:__main__:EPOCH 1986\n",
            "2025-06-26 08:22:53,800 EPOCH 1986\n",
            "INFO:__main__:Epoch 1986: total training loss 0.00566\n",
            "2025-06-26 08:22:53,886 Epoch 1986: total training loss 0.00566\n",
            "INFO:__main__:EPOCH 1987\n",
            "2025-06-26 08:22:53,888 EPOCH 1987\n",
            "INFO:__main__:Epoch 1987: total training loss 0.00577\n",
            "2025-06-26 08:22:53,986 Epoch 1987: total training loss 0.00577\n",
            "INFO:__main__:EPOCH 1988\n",
            "2025-06-26 08:22:53,989 EPOCH 1988\n",
            "INFO:__main__:Epoch 1988: total training loss 0.00485\n",
            "2025-06-26 08:22:54,078 Epoch 1988: total training loss 0.00485\n",
            "INFO:__main__:EPOCH 1989\n",
            "2025-06-26 08:22:54,081 EPOCH 1989\n",
            "INFO:__main__:Epoch 1989: total training loss 0.00540\n",
            "2025-06-26 08:22:54,181 Epoch 1989: total training loss 0.00540\n",
            "INFO:__main__:EPOCH 1990\n",
            "2025-06-26 08:22:54,183 EPOCH 1990\n",
            "INFO:__main__:Epoch 1990: total training loss 0.00551\n",
            "2025-06-26 08:22:54,291 Epoch 1990: total training loss 0.00551\n",
            "INFO:__main__:EPOCH 1991\n",
            "2025-06-26 08:22:54,293 EPOCH 1991\n",
            "INFO:__main__:Epoch 1991: total training loss 0.00548\n",
            "2025-06-26 08:22:54,376 Epoch 1991: total training loss 0.00548\n",
            "INFO:__main__:EPOCH 1992\n",
            "2025-06-26 08:22:54,381 EPOCH 1992\n",
            "INFO:__main__:Epoch 1992: total training loss 0.00540\n",
            "2025-06-26 08:22:54,471 Epoch 1992: total training loss 0.00540\n",
            "INFO:__main__:EPOCH 1993\n",
            "2025-06-26 08:22:54,475 EPOCH 1993\n",
            "INFO:__main__:Epoch 1993: total training loss 0.00594\n",
            "2025-06-26 08:22:54,551 Epoch 1993: total training loss 0.00594\n",
            "INFO:__main__:EPOCH 1994\n",
            "2025-06-26 08:22:54,554 EPOCH 1994\n",
            "INFO:__main__:Epoch 1994: total training loss 0.00496\n",
            "2025-06-26 08:22:54,628 Epoch 1994: total training loss 0.00496\n",
            "INFO:__main__:EPOCH 1995\n",
            "2025-06-26 08:22:54,629 EPOCH 1995\n",
            "INFO:__main__:Epoch 1995: total training loss 0.00551\n",
            "2025-06-26 08:22:54,711 Epoch 1995: total training loss 0.00551\n",
            "INFO:__main__:EPOCH 1996\n",
            "2025-06-26 08:22:54,713 EPOCH 1996\n",
            "INFO:__main__:Epoch 1996: total training loss 0.00537\n",
            "2025-06-26 08:22:54,784 Epoch 1996: total training loss 0.00537\n",
            "INFO:__main__:EPOCH 1997\n",
            "2025-06-26 08:22:54,786 EPOCH 1997\n",
            "INFO:__main__:Epoch 1997: total training loss 0.00549\n",
            "2025-06-26 08:22:54,855 Epoch 1997: total training loss 0.00549\n",
            "INFO:__main__:EPOCH 1998\n",
            "2025-06-26 08:22:54,857 EPOCH 1998\n",
            "INFO:__main__:Epoch 1998: total training loss 0.00534\n",
            "2025-06-26 08:22:54,926 Epoch 1998: total training loss 0.00534\n",
            "INFO:__main__:EPOCH 1999\n",
            "2025-06-26 08:22:54,929 EPOCH 1999\n",
            "INFO:__main__:Epoch 1999: total training loss 0.00486\n",
            "2025-06-26 08:22:55,008 Epoch 1999: total training loss 0.00486\n",
            "INFO:__main__:EPOCH 2000\n",
            "2025-06-26 08:22:55,010 EPOCH 2000\n",
            "INFO:__main__:Epoch 2000 Step:     2000 Batch Loss:     0.005531 Tokens per Sec:  1795159, Lr: 0.001000\n",
            "2025-06-26 08:22:55,090 Epoch 2000 Step:     2000 Batch Loss:     0.005531 Tokens per Sec:  1795159, Lr: 0.001000\n",
            "INFO:__main__:Hooray! New best validation result [dtw]!\n",
            "2025-06-26 08:22:56,086 Hooray! New best validation result [dtw]!\n",
            "INFO:__main__:Saving new checkpoint.\n",
            "2025-06-26 08:22:56,088 Saving new checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev/11August_2010_Wednesday_tagesschau-2    dtw: 15.55\n",
            "dev/11August_2010_Wednesday_tagesschau-3    dtw: 12.38\n",
            "dev/11August_2010_Wednesday_tagesschau-8    dtw: 14.03\n",
            "dev/25October_2010_Monday_tagesschau-22    dtw: 15.34\n",
            "dev/05May_2011_Thursday_tagesschau-25    dtw: 10.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 2754\n",
            "2025-06-26 08:24:13,247 EPOCH 2754\n",
            "INFO:__main__:Epoch 2754: total training loss 0.00428\n",
            "2025-06-26 08:24:13,317 Epoch 2754: total training loss 0.00428\n",
            "INFO:__main__:EPOCH 2755\n",
            "2025-06-26 08:24:13,319 EPOCH 2755\n",
            "INFO:__main__:Epoch 2755: total training loss 0.00454\n",
            "2025-06-26 08:24:13,386 Epoch 2755: total training loss 0.00454\n",
            "INFO:__main__:EPOCH 2756\n",
            "2025-06-26 08:24:13,388 EPOCH 2756\n",
            "INFO:__main__:Epoch 2756: total training loss 0.00430\n",
            "2025-06-26 08:24:13,453 Epoch 2756: total training loss 0.00430\n",
            "INFO:__main__:EPOCH 2757\n",
            "2025-06-26 08:24:13,455 EPOCH 2757\n",
            "INFO:__main__:Epoch 2757: total training loss 0.00433\n",
            "2025-06-26 08:24:13,520 Epoch 2757: total training loss 0.00433\n",
            "INFO:__main__:EPOCH 2758\n",
            "2025-06-26 08:24:13,522 EPOCH 2758\n",
            "INFO:__main__:Epoch 2758: total training loss 0.00446\n",
            "2025-06-26 08:24:13,587 Epoch 2758: total training loss 0.00446\n",
            "INFO:__main__:EPOCH 2759\n",
            "2025-06-26 08:24:13,590 EPOCH 2759\n",
            "INFO:__main__:Epoch 2759: total training loss 0.00454\n",
            "2025-06-26 08:24:13,656 Epoch 2759: total training loss 0.00454\n",
            "INFO:__main__:EPOCH 2760\n",
            "2025-06-26 08:24:13,659 EPOCH 2760\n",
            "INFO:__main__:Epoch 2760: total training loss 0.00443\n",
            "2025-06-26 08:24:13,723 Epoch 2760: total training loss 0.00443\n",
            "INFO:__main__:EPOCH 2761\n",
            "2025-06-26 08:24:13,725 EPOCH 2761\n",
            "INFO:__main__:Epoch 2761: total training loss 0.00448\n",
            "2025-06-26 08:24:13,790 Epoch 2761: total training loss 0.00448\n",
            "INFO:__main__:EPOCH 2762\n",
            "2025-06-26 08:24:13,792 EPOCH 2762\n",
            "INFO:__main__:Epoch 2762: total training loss 0.00415\n",
            "2025-06-26 08:24:13,859 Epoch 2762: total training loss 0.00415\n",
            "INFO:__main__:EPOCH 2763\n",
            "2025-06-26 08:24:13,861 EPOCH 2763\n",
            "INFO:__main__:Epoch 2763: total training loss 0.00437\n",
            "2025-06-26 08:24:13,924 Epoch 2763: total training loss 0.00437\n",
            "INFO:__main__:EPOCH 2764\n",
            "2025-06-26 08:24:13,927 EPOCH 2764\n",
            "INFO:__main__:Epoch 2764: total training loss 0.00439\n",
            "2025-06-26 08:24:13,990 Epoch 2764: total training loss 0.00439\n",
            "INFO:__main__:EPOCH 2765\n",
            "2025-06-26 08:24:13,992 EPOCH 2765\n",
            "INFO:__main__:Epoch 2765: total training loss 0.00443\n",
            "2025-06-26 08:24:14,057 Epoch 2765: total training loss 0.00443\n",
            "INFO:__main__:EPOCH 2766\n",
            "2025-06-26 08:24:14,060 EPOCH 2766\n",
            "INFO:__main__:Epoch 2766: total training loss 0.00458\n",
            "2025-06-26 08:24:14,133 Epoch 2766: total training loss 0.00458\n",
            "INFO:__main__:EPOCH 2767\n",
            "2025-06-26 08:24:14,136 EPOCH 2767\n",
            "INFO:__main__:Epoch 2767: total training loss 0.00479\n",
            "2025-06-26 08:24:14,205 Epoch 2767: total training loss 0.00479\n",
            "INFO:__main__:EPOCH 2768\n",
            "2025-06-26 08:24:14,207 EPOCH 2768\n",
            "INFO:__main__:Epoch 2768: total training loss 0.00438\n",
            "2025-06-26 08:24:14,292 Epoch 2768: total training loss 0.00438\n",
            "INFO:__main__:EPOCH 2769\n",
            "2025-06-26 08:24:14,294 EPOCH 2769\n",
            "INFO:__main__:Epoch 2769: total training loss 0.00437\n",
            "2025-06-26 08:24:14,360 Epoch 2769: total training loss 0.00437\n",
            "INFO:__main__:EPOCH 2770\n",
            "2025-06-26 08:24:14,363 EPOCH 2770\n",
            "INFO:__main__:Epoch 2770: total training loss 0.00449\n",
            "2025-06-26 08:24:14,428 Epoch 2770: total training loss 0.00449\n",
            "INFO:__main__:EPOCH 2771\n",
            "2025-06-26 08:24:14,430 EPOCH 2771\n",
            "INFO:__main__:Epoch 2771: total training loss 0.00490\n",
            "2025-06-26 08:24:14,494 Epoch 2771: total training loss 0.00490\n",
            "INFO:__main__:EPOCH 2772\n",
            "2025-06-26 08:24:14,497 EPOCH 2772\n",
            "INFO:__main__:Epoch 2772: total training loss 0.00442\n",
            "2025-06-26 08:24:14,560 Epoch 2772: total training loss 0.00442\n",
            "INFO:__main__:EPOCH 2773\n",
            "2025-06-26 08:24:14,562 EPOCH 2773\n",
            "INFO:__main__:Epoch 2773: total training loss 0.00442\n",
            "2025-06-26 08:24:14,630 Epoch 2773: total training loss 0.00442\n",
            "INFO:__main__:EPOCH 2774\n",
            "2025-06-26 08:24:14,632 EPOCH 2774\n",
            "INFO:__main__:Epoch 2774: total training loss 0.00455\n",
            "2025-06-26 08:24:14,696 Epoch 2774: total training loss 0.00455\n",
            "INFO:__main__:EPOCH 2775\n",
            "2025-06-26 08:24:14,698 EPOCH 2775\n",
            "INFO:__main__:Epoch 2775: total training loss 0.00451\n",
            "2025-06-26 08:24:14,763 Epoch 2775: total training loss 0.00451\n",
            "INFO:__main__:EPOCH 2776\n",
            "2025-06-26 08:24:14,765 EPOCH 2776\n",
            "INFO:__main__:Epoch 2776: total training loss 0.00413\n",
            "2025-06-26 08:24:14,832 Epoch 2776: total training loss 0.00413\n",
            "INFO:__main__:EPOCH 2777\n",
            "2025-06-26 08:24:14,834 EPOCH 2777\n",
            "INFO:__main__:Epoch 2777: total training loss 0.00437\n",
            "2025-06-26 08:24:14,900 Epoch 2777: total training loss 0.00437\n",
            "INFO:__main__:EPOCH 2778\n",
            "2025-06-26 08:24:14,902 EPOCH 2778\n",
            "INFO:__main__:Epoch 2778: total training loss 0.00459\n",
            "2025-06-26 08:24:14,970 Epoch 2778: total training loss 0.00459\n",
            "INFO:__main__:EPOCH 2779\n",
            "2025-06-26 08:24:14,972 EPOCH 2779\n",
            "INFO:__main__:Epoch 2779: total training loss 0.00412\n",
            "2025-06-26 08:24:15,034 Epoch 2779: total training loss 0.00412\n",
            "INFO:__main__:EPOCH 2780\n",
            "2025-06-26 08:24:15,036 EPOCH 2780\n",
            "INFO:__main__:Epoch 2780: total training loss 0.00379\n",
            "2025-06-26 08:24:15,103 Epoch 2780: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 2781\n",
            "2025-06-26 08:24:15,105 EPOCH 2781\n",
            "INFO:__main__:Epoch 2781: total training loss 0.00429\n",
            "2025-06-26 08:24:15,178 Epoch 2781: total training loss 0.00429\n",
            "INFO:__main__:EPOCH 2782\n",
            "2025-06-26 08:24:15,180 EPOCH 2782\n",
            "INFO:__main__:Epoch 2782: total training loss 0.00389\n",
            "2025-06-26 08:24:15,248 Epoch 2782: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2783\n",
            "2025-06-26 08:24:15,250 EPOCH 2783\n",
            "INFO:__main__:Epoch 2783: total training loss 0.00391\n",
            "2025-06-26 08:24:15,333 Epoch 2783: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 2784\n",
            "2025-06-26 08:24:15,336 EPOCH 2784\n",
            "INFO:__main__:Epoch 2784: total training loss 0.00379\n",
            "2025-06-26 08:24:15,399 Epoch 2784: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 2785\n",
            "2025-06-26 08:24:15,401 EPOCH 2785\n",
            "INFO:__main__:Epoch 2785: total training loss 0.00363\n",
            "2025-06-26 08:24:15,468 Epoch 2785: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 2786\n",
            "2025-06-26 08:24:15,470 EPOCH 2786\n",
            "INFO:__main__:Epoch 2786: total training loss 0.00381\n",
            "2025-06-26 08:24:15,541 Epoch 2786: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 2787\n",
            "2025-06-26 08:24:15,543 EPOCH 2787\n",
            "INFO:__main__:Epoch 2787: total training loss 0.00337\n",
            "2025-06-26 08:24:15,614 Epoch 2787: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 2788\n",
            "2025-06-26 08:24:15,616 EPOCH 2788\n",
            "INFO:__main__:Epoch 2788: total training loss 0.00387\n",
            "2025-06-26 08:24:15,682 Epoch 2788: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 2789\n",
            "2025-06-26 08:24:15,685 EPOCH 2789\n",
            "INFO:__main__:Epoch 2789: total training loss 0.00398\n",
            "2025-06-26 08:24:15,753 Epoch 2789: total training loss 0.00398\n",
            "INFO:__main__:EPOCH 2790\n",
            "2025-06-26 08:24:15,755 EPOCH 2790\n",
            "INFO:__main__:Epoch 2790: total training loss 0.00354\n",
            "2025-06-26 08:24:15,848 Epoch 2790: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 2791\n",
            "2025-06-26 08:24:15,852 EPOCH 2791\n",
            "INFO:__main__:Epoch 2791: total training loss 0.00370\n",
            "2025-06-26 08:24:15,943 Epoch 2791: total training loss 0.00370\n",
            "INFO:__main__:EPOCH 2792\n",
            "2025-06-26 08:24:15,946 EPOCH 2792\n",
            "INFO:__main__:Epoch 2792: total training loss 0.00349\n",
            "2025-06-26 08:24:16,039 Epoch 2792: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 2793\n",
            "2025-06-26 08:24:16,048 EPOCH 2793\n",
            "INFO:__main__:Epoch 2793: total training loss 0.00375\n",
            "2025-06-26 08:24:16,145 Epoch 2793: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 2794\n",
            "2025-06-26 08:24:16,148 EPOCH 2794\n",
            "INFO:__main__:Epoch 2794: total training loss 0.00384\n",
            "2025-06-26 08:24:16,228 Epoch 2794: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 2795\n",
            "2025-06-26 08:24:16,230 EPOCH 2795\n",
            "INFO:__main__:Epoch 2795: total training loss 0.00424\n",
            "2025-06-26 08:24:16,341 Epoch 2795: total training loss 0.00424\n",
            "INFO:__main__:EPOCH 2796\n",
            "2025-06-26 08:24:16,343 EPOCH 2796\n",
            "INFO:__main__:Epoch 2796: total training loss 0.00391\n",
            "2025-06-26 08:24:16,437 Epoch 2796: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 2797\n",
            "2025-06-26 08:24:16,440 EPOCH 2797\n",
            "INFO:__main__:Epoch 2797: total training loss 0.00404\n",
            "2025-06-26 08:24:16,534 Epoch 2797: total training loss 0.00404\n",
            "INFO:__main__:EPOCH 2798\n",
            "2025-06-26 08:24:16,536 EPOCH 2798\n",
            "INFO:__main__:Epoch 2798: total training loss 0.00430\n",
            "2025-06-26 08:24:16,626 Epoch 2798: total training loss 0.00430\n",
            "INFO:__main__:EPOCH 2799\n",
            "2025-06-26 08:24:16,628 EPOCH 2799\n",
            "INFO:__main__:Epoch 2799: total training loss 0.00412\n",
            "2025-06-26 08:24:16,712 Epoch 2799: total training loss 0.00412\n",
            "INFO:__main__:EPOCH 2800\n",
            "2025-06-26 08:24:16,714 EPOCH 2800\n",
            "INFO:__main__:Epoch 2800: total training loss 0.00454\n",
            "2025-06-26 08:24:16,805 Epoch 2800: total training loss 0.00454\n",
            "INFO:__main__:EPOCH 2801\n",
            "2025-06-26 08:24:16,807 EPOCH 2801\n",
            "INFO:__main__:Epoch 2801: total training loss 0.00471\n",
            "2025-06-26 08:24:16,914 Epoch 2801: total training loss 0.00471\n",
            "INFO:__main__:EPOCH 2802\n",
            "2025-06-26 08:24:16,919 EPOCH 2802\n",
            "INFO:__main__:Epoch 2802: total training loss 0.00433\n",
            "2025-06-26 08:24:17,002 Epoch 2802: total training loss 0.00433\n",
            "INFO:__main__:EPOCH 2803\n",
            "2025-06-26 08:24:17,004 EPOCH 2803\n",
            "INFO:__main__:Epoch 2803: total training loss 0.00436\n",
            "2025-06-26 08:24:17,078 Epoch 2803: total training loss 0.00436\n",
            "INFO:__main__:EPOCH 2804\n",
            "2025-06-26 08:24:17,083 EPOCH 2804\n",
            "INFO:__main__:Epoch 2804: total training loss 0.00372\n",
            "2025-06-26 08:24:17,158 Epoch 2804: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2805\n",
            "2025-06-26 08:24:17,160 EPOCH 2805\n",
            "INFO:__main__:Epoch 2805: total training loss 0.00440\n",
            "2025-06-26 08:24:17,256 Epoch 2805: total training loss 0.00440\n",
            "INFO:__main__:EPOCH 2806\n",
            "2025-06-26 08:24:17,259 EPOCH 2806\n",
            "INFO:__main__:Epoch 2806: total training loss 0.00418\n",
            "2025-06-26 08:24:17,369 Epoch 2806: total training loss 0.00418\n",
            "INFO:__main__:EPOCH 2807\n",
            "2025-06-26 08:24:17,375 EPOCH 2807\n",
            "INFO:__main__:Epoch 2807: total training loss 0.00360\n",
            "2025-06-26 08:24:17,478 Epoch 2807: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 2808\n",
            "2025-06-26 08:24:17,482 EPOCH 2808\n",
            "INFO:__main__:Epoch 2808: total training loss 0.00424\n",
            "2025-06-26 08:24:17,567 Epoch 2808: total training loss 0.00424\n",
            "INFO:__main__:EPOCH 2809\n",
            "2025-06-26 08:24:17,570 EPOCH 2809\n",
            "INFO:__main__:Epoch 2809: total training loss 0.00421\n",
            "2025-06-26 08:24:17,644 Epoch 2809: total training loss 0.00421\n",
            "INFO:__main__:EPOCH 2810\n",
            "2025-06-26 08:24:17,646 EPOCH 2810\n",
            "INFO:__main__:Epoch 2810: total training loss 0.00388\n",
            "2025-06-26 08:24:17,732 Epoch 2810: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 2811\n",
            "2025-06-26 08:24:17,734 EPOCH 2811\n",
            "INFO:__main__:Epoch 2811: total training loss 0.00377\n",
            "2025-06-26 08:24:17,804 Epoch 2811: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 2812\n",
            "2025-06-26 08:24:17,806 EPOCH 2812\n",
            "INFO:__main__:Epoch 2812: total training loss 0.00384\n",
            "2025-06-26 08:24:17,884 Epoch 2812: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 2813\n",
            "2025-06-26 08:24:17,886 EPOCH 2813\n",
            "INFO:__main__:Epoch 2813: total training loss 0.00344\n",
            "2025-06-26 08:24:17,989 Epoch 2813: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 2814\n",
            "2025-06-26 08:24:17,990 EPOCH 2814\n",
            "INFO:__main__:Epoch 2814: total training loss 0.00396\n",
            "2025-06-26 08:24:18,086 Epoch 2814: total training loss 0.00396\n",
            "INFO:__main__:EPOCH 2815\n",
            "2025-06-26 08:24:18,090 EPOCH 2815\n",
            "INFO:__main__:Epoch 2815: total training loss 0.00352\n",
            "2025-06-26 08:24:18,197 Epoch 2815: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 2816\n",
            "2025-06-26 08:24:18,199 EPOCH 2816\n",
            "INFO:__main__:Epoch 2816: total training loss 0.00357\n",
            "2025-06-26 08:24:18,287 Epoch 2816: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 2817\n",
            "2025-06-26 08:24:18,289 EPOCH 2817\n",
            "INFO:__main__:Epoch 2817: total training loss 0.00367\n",
            "2025-06-26 08:24:18,375 Epoch 2817: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 2818\n",
            "2025-06-26 08:24:18,377 EPOCH 2818\n",
            "INFO:__main__:Epoch 2818: total training loss 0.00354\n",
            "2025-06-26 08:24:18,450 Epoch 2818: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 2819\n",
            "2025-06-26 08:24:18,452 EPOCH 2819\n",
            "INFO:__main__:Epoch 2819: total training loss 0.00351\n",
            "2025-06-26 08:24:18,536 Epoch 2819: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 2820\n",
            "2025-06-26 08:24:18,538 EPOCH 2820\n",
            "INFO:__main__:Epoch 2820: total training loss 0.00374\n",
            "2025-06-26 08:24:18,627 Epoch 2820: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2821\n",
            "2025-06-26 08:24:18,628 EPOCH 2821\n",
            "INFO:__main__:Epoch 2821: total training loss 0.00388\n",
            "2025-06-26 08:24:18,699 Epoch 2821: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 2822\n",
            "2025-06-26 08:24:18,701 EPOCH 2822\n",
            "INFO:__main__:Epoch 2822: total training loss 0.00382\n",
            "2025-06-26 08:24:18,773 Epoch 2822: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 2823\n",
            "2025-06-26 08:24:18,775 EPOCH 2823\n",
            "INFO:__main__:Epoch 2823: total training loss 0.00408\n",
            "2025-06-26 08:24:18,848 Epoch 2823: total training loss 0.00408\n",
            "INFO:__main__:EPOCH 2824\n",
            "2025-06-26 08:24:18,850 EPOCH 2824\n",
            "INFO:__main__:Epoch 2824: total training loss 0.00393\n",
            "2025-06-26 08:24:18,920 Epoch 2824: total training loss 0.00393\n",
            "INFO:__main__:EPOCH 2825\n",
            "2025-06-26 08:24:18,922 EPOCH 2825\n",
            "INFO:__main__:Epoch 2825: total training loss 0.00384\n",
            "2025-06-26 08:24:18,991 Epoch 2825: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 2826\n",
            "2025-06-26 08:24:18,993 EPOCH 2826\n",
            "INFO:__main__:Epoch 2826: total training loss 0.00416\n",
            "2025-06-26 08:24:19,065 Epoch 2826: total training loss 0.00416\n",
            "INFO:__main__:EPOCH 2827\n",
            "2025-06-26 08:24:19,067 EPOCH 2827\n",
            "INFO:__main__:Epoch 2827: total training loss 0.00355\n",
            "2025-06-26 08:24:19,138 Epoch 2827: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 2828\n",
            "2025-06-26 08:24:19,140 EPOCH 2828\n",
            "INFO:__main__:Epoch 2828: total training loss 0.00399\n",
            "2025-06-26 08:24:19,227 Epoch 2828: total training loss 0.00399\n",
            "INFO:__main__:EPOCH 2829\n",
            "2025-06-26 08:24:19,229 EPOCH 2829\n",
            "INFO:__main__:Epoch 2829: total training loss 0.00419\n",
            "2025-06-26 08:24:19,336 Epoch 2829: total training loss 0.00419\n",
            "INFO:__main__:EPOCH 2830\n",
            "2025-06-26 08:24:19,343 EPOCH 2830\n",
            "INFO:__main__:Epoch 2830: total training loss 0.00425\n",
            "2025-06-26 08:24:19,447 Epoch 2830: total training loss 0.00425\n",
            "INFO:__main__:EPOCH 2831\n",
            "2025-06-26 08:24:19,449 EPOCH 2831\n",
            "INFO:__main__:Epoch 2831: total training loss 0.00438\n",
            "2025-06-26 08:24:19,541 Epoch 2831: total training loss 0.00438\n",
            "INFO:__main__:EPOCH 2832\n",
            "2025-06-26 08:24:19,545 EPOCH 2832\n",
            "INFO:__main__:Epoch 2832: total training loss 0.00423\n",
            "2025-06-26 08:24:19,643 Epoch 2832: total training loss 0.00423\n",
            "INFO:__main__:EPOCH 2833\n",
            "2025-06-26 08:24:19,645 EPOCH 2833\n",
            "INFO:__main__:Epoch 2833: total training loss 0.00419\n",
            "2025-06-26 08:24:19,754 Epoch 2833: total training loss 0.00419\n",
            "INFO:__main__:EPOCH 2834\n",
            "2025-06-26 08:24:19,759 EPOCH 2834\n",
            "INFO:__main__:Epoch 2834: total training loss 0.00399\n",
            "2025-06-26 08:24:19,864 Epoch 2834: total training loss 0.00399\n",
            "INFO:__main__:EPOCH 2835\n",
            "2025-06-26 08:24:19,870 EPOCH 2835\n",
            "INFO:__main__:Epoch 2835: total training loss 0.00381\n",
            "2025-06-26 08:24:19,958 Epoch 2835: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 2836\n",
            "2025-06-26 08:24:19,960 EPOCH 2836\n",
            "INFO:__main__:Epoch 2836: total training loss 0.00394\n",
            "2025-06-26 08:24:20,055 Epoch 2836: total training loss 0.00394\n",
            "INFO:__main__:EPOCH 2837\n",
            "2025-06-26 08:24:20,062 EPOCH 2837\n",
            "INFO:__main__:Epoch 2837: total training loss 0.00400\n",
            "2025-06-26 08:24:20,159 Epoch 2837: total training loss 0.00400\n",
            "INFO:__main__:EPOCH 2838\n",
            "2025-06-26 08:24:20,161 EPOCH 2838\n",
            "INFO:__main__:Epoch 2838: total training loss 0.00423\n",
            "2025-06-26 08:24:20,254 Epoch 2838: total training loss 0.00423\n",
            "INFO:__main__:EPOCH 2839\n",
            "2025-06-26 08:24:20,256 EPOCH 2839\n",
            "INFO:__main__:Epoch 2839: total training loss 0.00387\n",
            "2025-06-26 08:24:20,342 Epoch 2839: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 2840\n",
            "2025-06-26 08:24:20,344 EPOCH 2840\n",
            "INFO:__main__:Epoch 2840: total training loss 0.00431\n",
            "2025-06-26 08:24:20,408 Epoch 2840: total training loss 0.00431\n",
            "INFO:__main__:EPOCH 2841\n",
            "2025-06-26 08:24:20,410 EPOCH 2841\n",
            "INFO:__main__:Epoch 2841: total training loss 0.00414\n",
            "2025-06-26 08:24:20,474 Epoch 2841: total training loss 0.00414\n",
            "INFO:__main__:EPOCH 2842\n",
            "2025-06-26 08:24:20,476 EPOCH 2842\n",
            "INFO:__main__:Epoch 2842: total training loss 0.00372\n",
            "2025-06-26 08:24:20,541 Epoch 2842: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2843\n",
            "2025-06-26 08:24:20,543 EPOCH 2843\n",
            "INFO:__main__:Epoch 2843: total training loss 0.00395\n",
            "2025-06-26 08:24:20,610 Epoch 2843: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2844\n",
            "2025-06-26 08:24:20,612 EPOCH 2844\n",
            "INFO:__main__:Epoch 2844: total training loss 0.00427\n",
            "2025-06-26 08:24:20,679 Epoch 2844: total training loss 0.00427\n",
            "INFO:__main__:EPOCH 2845\n",
            "2025-06-26 08:24:20,682 EPOCH 2845\n",
            "INFO:__main__:Epoch 2845: total training loss 0.00362\n",
            "2025-06-26 08:24:20,785 Epoch 2845: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 2846\n",
            "2025-06-26 08:24:20,788 EPOCH 2846\n",
            "INFO:__main__:Epoch 2846: total training loss 0.00426\n",
            "2025-06-26 08:24:20,863 Epoch 2846: total training loss 0.00426\n",
            "INFO:__main__:EPOCH 2847\n",
            "2025-06-26 08:24:20,865 EPOCH 2847\n",
            "INFO:__main__:Epoch 2847: total training loss 0.00359\n",
            "2025-06-26 08:24:20,931 Epoch 2847: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 2848\n",
            "2025-06-26 08:24:20,934 EPOCH 2848\n",
            "INFO:__main__:Epoch 2848: total training loss 0.00397\n",
            "2025-06-26 08:24:21,000 Epoch 2848: total training loss 0.00397\n",
            "INFO:__main__:EPOCH 2849\n",
            "2025-06-26 08:24:21,002 EPOCH 2849\n",
            "INFO:__main__:Epoch 2849: total training loss 0.00381\n",
            "2025-06-26 08:24:21,064 Epoch 2849: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 2850\n",
            "2025-06-26 08:24:21,066 EPOCH 2850\n",
            "INFO:__main__:Epoch 2850: total training loss 0.00409\n",
            "2025-06-26 08:24:21,132 Epoch 2850: total training loss 0.00409\n",
            "INFO:__main__:EPOCH 2851\n",
            "2025-06-26 08:24:21,134 EPOCH 2851\n",
            "INFO:__main__:Epoch 2851: total training loss 0.00448\n",
            "2025-06-26 08:24:21,207 Epoch 2851: total training loss 0.00448\n",
            "INFO:__main__:EPOCH 2852\n",
            "2025-06-26 08:24:21,209 EPOCH 2852\n",
            "INFO:__main__:Epoch 2852: total training loss 0.00427\n",
            "2025-06-26 08:24:21,273 Epoch 2852: total training loss 0.00427\n",
            "INFO:__main__:EPOCH 2853\n",
            "2025-06-26 08:24:21,275 EPOCH 2853\n",
            "INFO:__main__:Epoch 2853: total training loss 0.00372\n",
            "2025-06-26 08:24:21,338 Epoch 2853: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2854\n",
            "2025-06-26 08:24:21,340 EPOCH 2854\n",
            "INFO:__main__:Epoch 2854: total training loss 0.00405\n",
            "2025-06-26 08:24:21,403 Epoch 2854: total training loss 0.00405\n",
            "INFO:__main__:EPOCH 2855\n",
            "2025-06-26 08:24:21,405 EPOCH 2855\n",
            "INFO:__main__:Epoch 2855: total training loss 0.00389\n",
            "2025-06-26 08:24:21,471 Epoch 2855: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2856\n",
            "2025-06-26 08:24:21,473 EPOCH 2856\n",
            "INFO:__main__:Epoch 2856: total training loss 0.00401\n",
            "2025-06-26 08:24:21,537 Epoch 2856: total training loss 0.00401\n",
            "INFO:__main__:EPOCH 2857\n",
            "2025-06-26 08:24:21,539 EPOCH 2857\n",
            "INFO:__main__:Epoch 2857: total training loss 0.00434\n",
            "2025-06-26 08:24:21,603 Epoch 2857: total training loss 0.00434\n",
            "INFO:__main__:EPOCH 2858\n",
            "2025-06-26 08:24:21,605 EPOCH 2858\n",
            "INFO:__main__:Epoch 2858: total training loss 0.00406\n",
            "2025-06-26 08:24:21,668 Epoch 2858: total training loss 0.00406\n",
            "INFO:__main__:EPOCH 2859\n",
            "2025-06-26 08:24:21,670 EPOCH 2859\n",
            "INFO:__main__:Epoch 2859: total training loss 0.00385\n",
            "2025-06-26 08:24:21,736 Epoch 2859: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 2860\n",
            "2025-06-26 08:24:21,738 EPOCH 2860\n",
            "INFO:__main__:Epoch 2860: total training loss 0.00382\n",
            "2025-06-26 08:24:21,818 Epoch 2860: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 2861\n",
            "2025-06-26 08:24:21,820 EPOCH 2861\n",
            "INFO:__main__:Epoch 2861: total training loss 0.00405\n",
            "2025-06-26 08:24:21,887 Epoch 2861: total training loss 0.00405\n",
            "INFO:__main__:EPOCH 2862\n",
            "2025-06-26 08:24:21,889 EPOCH 2862\n",
            "INFO:__main__:Epoch 2862: total training loss 0.00385\n",
            "2025-06-26 08:24:21,955 Epoch 2862: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 2863\n",
            "2025-06-26 08:24:21,957 EPOCH 2863\n",
            "INFO:__main__:Epoch 2863: total training loss 0.00363\n",
            "2025-06-26 08:24:22,023 Epoch 2863: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 2864\n",
            "2025-06-26 08:24:22,025 EPOCH 2864\n",
            "INFO:__main__:Epoch 2864: total training loss 0.00378\n",
            "2025-06-26 08:24:22,088 Epoch 2864: total training loss 0.00378\n",
            "INFO:__main__:EPOCH 2865\n",
            "2025-06-26 08:24:22,090 EPOCH 2865\n",
            "INFO:__main__:Epoch 2865: total training loss 0.00383\n",
            "2025-06-26 08:24:22,153 Epoch 2865: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 2866\n",
            "2025-06-26 08:24:22,155 EPOCH 2866\n",
            "INFO:__main__:Epoch 2866: total training loss 0.00408\n",
            "2025-06-26 08:24:22,223 Epoch 2866: total training loss 0.00408\n",
            "INFO:__main__:EPOCH 2867\n",
            "2025-06-26 08:24:22,225 EPOCH 2867\n",
            "INFO:__main__:Epoch 2867: total training loss 0.00374\n",
            "2025-06-26 08:24:22,296 Epoch 2867: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2868\n",
            "2025-06-26 08:24:22,298 EPOCH 2868\n",
            "INFO:__main__:Epoch 2868: total training loss 0.00391\n",
            "2025-06-26 08:24:22,365 Epoch 2868: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 2869\n",
            "2025-06-26 08:24:22,367 EPOCH 2869\n",
            "INFO:__main__:Epoch 2869: total training loss 0.00360\n",
            "2025-06-26 08:24:22,435 Epoch 2869: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 2870\n",
            "2025-06-26 08:24:22,439 EPOCH 2870\n",
            "INFO:__main__:Epoch 2870: total training loss 0.00372\n",
            "2025-06-26 08:24:22,502 Epoch 2870: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2871\n",
            "2025-06-26 08:24:22,504 EPOCH 2871\n",
            "INFO:__main__:Epoch 2871: total training loss 0.00393\n",
            "2025-06-26 08:24:22,571 Epoch 2871: total training loss 0.00393\n",
            "INFO:__main__:EPOCH 2872\n",
            "2025-06-26 08:24:22,573 EPOCH 2872\n",
            "INFO:__main__:Epoch 2872: total training loss 0.00375\n",
            "2025-06-26 08:24:22,637 Epoch 2872: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 2873\n",
            "2025-06-26 08:24:22,639 EPOCH 2873\n",
            "INFO:__main__:Epoch 2873: total training loss 0.00380\n",
            "2025-06-26 08:24:22,705 Epoch 2873: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 2874\n",
            "2025-06-26 08:24:22,706 EPOCH 2874\n",
            "INFO:__main__:Epoch 2874: total training loss 0.00386\n",
            "2025-06-26 08:24:22,773 Epoch 2874: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 2875\n",
            "2025-06-26 08:24:22,775 EPOCH 2875\n",
            "INFO:__main__:Epoch 2875: total training loss 0.00366\n",
            "2025-06-26 08:24:22,861 Epoch 2875: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 2876\n",
            "2025-06-26 08:24:22,863 EPOCH 2876\n",
            "INFO:__main__:Epoch 2876: total training loss 0.00390\n",
            "2025-06-26 08:24:22,928 Epoch 2876: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 2877\n",
            "2025-06-26 08:24:22,930 EPOCH 2877\n",
            "INFO:__main__:Epoch 2877: total training loss 0.00369\n",
            "2025-06-26 08:24:22,995 Epoch 2877: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 2878\n",
            "2025-06-26 08:24:22,998 EPOCH 2878\n",
            "INFO:__main__:Epoch 2878: total training loss 0.00382\n",
            "2025-06-26 08:24:23,063 Epoch 2878: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 2879\n",
            "2025-06-26 08:24:23,066 EPOCH 2879\n",
            "INFO:__main__:Epoch 2879: total training loss 0.00375\n",
            "2025-06-26 08:24:23,136 Epoch 2879: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 2880\n",
            "2025-06-26 08:24:23,138 EPOCH 2880\n",
            "INFO:__main__:Epoch 2880: total training loss 0.00374\n",
            "2025-06-26 08:24:23,207 Epoch 2880: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2881\n",
            "2025-06-26 08:24:23,209 EPOCH 2881\n",
            "INFO:__main__:Epoch 2881: total training loss 0.00390\n",
            "2025-06-26 08:24:23,276 Epoch 2881: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 2882\n",
            "2025-06-26 08:24:23,278 EPOCH 2882\n",
            "INFO:__main__:Epoch 2882: total training loss 0.00395\n",
            "2025-06-26 08:24:23,345 Epoch 2882: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2883\n",
            "2025-06-26 08:24:23,347 EPOCH 2883\n",
            "INFO:__main__:Epoch 2883: total training loss 0.00374\n",
            "2025-06-26 08:24:23,411 Epoch 2883: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2884\n",
            "2025-06-26 08:24:23,413 EPOCH 2884\n",
            "INFO:__main__:Epoch 2884: total training loss 0.00400\n",
            "2025-06-26 08:24:23,479 Epoch 2884: total training loss 0.00400\n",
            "INFO:__main__:EPOCH 2885\n",
            "2025-06-26 08:24:23,481 EPOCH 2885\n",
            "INFO:__main__:Epoch 2885: total training loss 0.00388\n",
            "2025-06-26 08:24:23,546 Epoch 2885: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 2886\n",
            "2025-06-26 08:24:23,548 EPOCH 2886\n",
            "INFO:__main__:Epoch 2886: total training loss 0.00383\n",
            "2025-06-26 08:24:23,614 Epoch 2886: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 2887\n",
            "2025-06-26 08:24:23,616 EPOCH 2887\n",
            "INFO:__main__:Epoch 2887: total training loss 0.00417\n",
            "2025-06-26 08:24:23,682 Epoch 2887: total training loss 0.00417\n",
            "INFO:__main__:EPOCH 2888\n",
            "2025-06-26 08:24:23,684 EPOCH 2888\n",
            "INFO:__main__:Epoch 2888: total training loss 0.00395\n",
            "2025-06-26 08:24:23,749 Epoch 2888: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2889\n",
            "2025-06-26 08:24:23,751 EPOCH 2889\n",
            "INFO:__main__:Epoch 2889: total training loss 0.00409\n",
            "2025-06-26 08:24:23,815 Epoch 2889: total training loss 0.00409\n",
            "INFO:__main__:EPOCH 2890\n",
            "2025-06-26 08:24:23,817 EPOCH 2890\n",
            "INFO:__main__:Epoch 2890: total training loss 0.00348\n",
            "2025-06-26 08:24:23,898 Epoch 2890: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 2891\n",
            "2025-06-26 08:24:23,900 EPOCH 2891\n",
            "INFO:__main__:Epoch 2891: total training loss 0.00379\n",
            "2025-06-26 08:24:23,966 Epoch 2891: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 2892\n",
            "2025-06-26 08:24:23,969 EPOCH 2892\n",
            "INFO:__main__:Epoch 2892: total training loss 0.00380\n",
            "2025-06-26 08:24:24,036 Epoch 2892: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 2893\n",
            "2025-06-26 08:24:24,038 EPOCH 2893\n",
            "INFO:__main__:Epoch 2893: total training loss 0.00385\n",
            "2025-06-26 08:24:24,105 Epoch 2893: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 2894\n",
            "2025-06-26 08:24:24,107 EPOCH 2894\n",
            "INFO:__main__:Epoch 2894: total training loss 0.00400\n",
            "2025-06-26 08:24:24,175 Epoch 2894: total training loss 0.00400\n",
            "INFO:__main__:EPOCH 2895\n",
            "2025-06-26 08:24:24,177 EPOCH 2895\n",
            "INFO:__main__:Epoch 2895: total training loss 0.00354\n",
            "2025-06-26 08:24:24,246 Epoch 2895: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 2896\n",
            "2025-06-26 08:24:24,248 EPOCH 2896\n",
            "INFO:__main__:Epoch 2896: total training loss 0.00395\n",
            "2025-06-26 08:24:24,319 Epoch 2896: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2897\n",
            "2025-06-26 08:24:24,321 EPOCH 2897\n",
            "INFO:__main__:Epoch 2897: total training loss 0.00392\n",
            "2025-06-26 08:24:24,390 Epoch 2897: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 2898\n",
            "2025-06-26 08:24:24,393 EPOCH 2898\n",
            "INFO:__main__:Epoch 2898: total training loss 0.00415\n",
            "2025-06-26 08:24:24,463 Epoch 2898: total training loss 0.00415\n",
            "INFO:__main__:EPOCH 2899\n",
            "2025-06-26 08:24:24,466 EPOCH 2899\n",
            "INFO:__main__:Epoch 2899: total training loss 0.00385\n",
            "2025-06-26 08:24:24,532 Epoch 2899: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 2900\n",
            "2025-06-26 08:24:24,534 EPOCH 2900\n",
            "INFO:__main__:Epoch 2900: total training loss 0.00439\n",
            "2025-06-26 08:24:24,602 Epoch 2900: total training loss 0.00439\n",
            "INFO:__main__:EPOCH 2901\n",
            "2025-06-26 08:24:24,604 EPOCH 2901\n",
            "INFO:__main__:Epoch 2901: total training loss 0.00450\n",
            "2025-06-26 08:24:24,672 Epoch 2901: total training loss 0.00450\n",
            "INFO:__main__:EPOCH 2902\n",
            "2025-06-26 08:24:24,674 EPOCH 2902\n",
            "INFO:__main__:Epoch 2902: total training loss 0.00445\n",
            "2025-06-26 08:24:24,738 Epoch 2902: total training loss 0.00445\n",
            "INFO:__main__:EPOCH 2903\n",
            "2025-06-26 08:24:24,740 EPOCH 2903\n",
            "INFO:__main__:Epoch 2903: total training loss 0.00425\n",
            "2025-06-26 08:24:24,811 Epoch 2903: total training loss 0.00425\n",
            "INFO:__main__:EPOCH 2904\n",
            "2025-06-26 08:24:24,813 EPOCH 2904\n",
            "INFO:__main__:Epoch 2904: total training loss 0.00449\n",
            "2025-06-26 08:24:24,881 Epoch 2904: total training loss 0.00449\n",
            "INFO:__main__:EPOCH 2905\n",
            "2025-06-26 08:24:24,883 EPOCH 2905\n",
            "INFO:__main__:Epoch 2905: total training loss 0.00430\n",
            "2025-06-26 08:24:24,976 Epoch 2905: total training loss 0.00430\n",
            "INFO:__main__:EPOCH 2906\n",
            "2025-06-26 08:24:24,979 EPOCH 2906\n",
            "INFO:__main__:Epoch 2906: total training loss 0.00415\n",
            "2025-06-26 08:24:25,048 Epoch 2906: total training loss 0.00415\n",
            "INFO:__main__:EPOCH 2907\n",
            "2025-06-26 08:24:25,050 EPOCH 2907\n",
            "INFO:__main__:Epoch 2907: total training loss 0.00392\n",
            "2025-06-26 08:24:25,118 Epoch 2907: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 2908\n",
            "2025-06-26 08:24:25,120 EPOCH 2908\n",
            "INFO:__main__:Epoch 2908: total training loss 0.00400\n",
            "2025-06-26 08:24:25,185 Epoch 2908: total training loss 0.00400\n",
            "INFO:__main__:EPOCH 2909\n",
            "2025-06-26 08:24:25,188 EPOCH 2909\n",
            "INFO:__main__:Epoch 2909: total training loss 0.00390\n",
            "2025-06-26 08:24:25,252 Epoch 2909: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 2910\n",
            "2025-06-26 08:24:25,254 EPOCH 2910\n",
            "INFO:__main__:Epoch 2910: total training loss 0.00419\n",
            "2025-06-26 08:24:25,325 Epoch 2910: total training loss 0.00419\n",
            "INFO:__main__:EPOCH 2911\n",
            "2025-06-26 08:24:25,327 EPOCH 2911\n",
            "INFO:__main__:Epoch 2911: total training loss 0.00351\n",
            "2025-06-26 08:24:25,395 Epoch 2911: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 2912\n",
            "2025-06-26 08:24:25,398 EPOCH 2912\n",
            "INFO:__main__:Epoch 2912: total training loss 0.00406\n",
            "2025-06-26 08:24:25,463 Epoch 2912: total training loss 0.00406\n",
            "INFO:__main__:EPOCH 2913\n",
            "2025-06-26 08:24:25,465 EPOCH 2913\n",
            "INFO:__main__:Epoch 2913: total training loss 0.00379\n",
            "2025-06-26 08:24:25,529 Epoch 2913: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 2914\n",
            "2025-06-26 08:24:25,531 EPOCH 2914\n",
            "INFO:__main__:Epoch 2914: total training loss 0.00389\n",
            "2025-06-26 08:24:25,598 Epoch 2914: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2915\n",
            "2025-06-26 08:24:25,600 EPOCH 2915\n",
            "INFO:__main__:Epoch 2915: total training loss 0.00381\n",
            "2025-06-26 08:24:25,667 Epoch 2915: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 2916\n",
            "2025-06-26 08:24:25,669 EPOCH 2916\n",
            "INFO:__main__:Epoch 2916: total training loss 0.00361\n",
            "2025-06-26 08:24:25,738 Epoch 2916: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 2917\n",
            "2025-06-26 08:24:25,740 EPOCH 2917\n",
            "INFO:__main__:Epoch 2917: total training loss 0.00375\n",
            "2025-06-26 08:24:25,806 Epoch 2917: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 2918\n",
            "2025-06-26 08:24:25,808 EPOCH 2918\n",
            "INFO:__main__:Epoch 2918: total training loss 0.00372\n",
            "2025-06-26 08:24:25,871 Epoch 2918: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2919\n",
            "2025-06-26 08:24:25,875 EPOCH 2919\n",
            "INFO:__main__:Epoch 2919: total training loss 0.00350\n",
            "2025-06-26 08:24:25,941 Epoch 2919: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 2920\n",
            "2025-06-26 08:24:25,943 EPOCH 2920\n",
            "INFO:__main__:Epoch 2920: total training loss 0.00396\n",
            "2025-06-26 08:24:26,027 Epoch 2920: total training loss 0.00396\n",
            "INFO:__main__:EPOCH 2921\n",
            "2025-06-26 08:24:26,029 EPOCH 2921\n",
            "INFO:__main__:Epoch 2921: total training loss 0.00365\n",
            "2025-06-26 08:24:26,096 Epoch 2921: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 2922\n",
            "2025-06-26 08:24:26,098 EPOCH 2922\n",
            "INFO:__main__:Epoch 2922: total training loss 0.00367\n",
            "2025-06-26 08:24:26,164 Epoch 2922: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 2923\n",
            "2025-06-26 08:24:26,166 EPOCH 2923\n",
            "INFO:__main__:Epoch 2923: total training loss 0.00388\n",
            "2025-06-26 08:24:26,237 Epoch 2923: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 2924\n",
            "2025-06-26 08:24:26,239 EPOCH 2924\n",
            "INFO:__main__:Epoch 2924: total training loss 0.00359\n",
            "2025-06-26 08:24:26,310 Epoch 2924: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 2925\n",
            "2025-06-26 08:24:26,312 EPOCH 2925\n",
            "INFO:__main__:Epoch 2925: total training loss 0.00373\n",
            "2025-06-26 08:24:26,384 Epoch 2925: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 2926\n",
            "2025-06-26 08:24:26,386 EPOCH 2926\n",
            "INFO:__main__:Epoch 2926: total training loss 0.00368\n",
            "2025-06-26 08:24:26,454 Epoch 2926: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 2927\n",
            "2025-06-26 08:24:26,457 EPOCH 2927\n",
            "INFO:__main__:Epoch 2927: total training loss 0.00358\n",
            "2025-06-26 08:24:26,526 Epoch 2927: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 2928\n",
            "2025-06-26 08:24:26,528 EPOCH 2928\n",
            "INFO:__main__:Epoch 2928: total training loss 0.00387\n",
            "2025-06-26 08:24:26,593 Epoch 2928: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 2929\n",
            "2025-06-26 08:24:26,595 EPOCH 2929\n",
            "INFO:__main__:Epoch 2929: total training loss 0.00410\n",
            "2025-06-26 08:24:26,661 Epoch 2929: total training loss 0.00410\n",
            "INFO:__main__:EPOCH 2930\n",
            "2025-06-26 08:24:26,664 EPOCH 2930\n",
            "INFO:__main__:Epoch 2930: total training loss 0.00345\n",
            "2025-06-26 08:24:26,732 Epoch 2930: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 2931\n",
            "2025-06-26 08:24:26,734 EPOCH 2931\n",
            "INFO:__main__:Epoch 2931: total training loss 0.00403\n",
            "2025-06-26 08:24:26,804 Epoch 2931: total training loss 0.00403\n",
            "INFO:__main__:EPOCH 2932\n",
            "2025-06-26 08:24:26,807 EPOCH 2932\n",
            "INFO:__main__:Epoch 2932: total training loss 0.00384\n",
            "2025-06-26 08:24:26,872 Epoch 2932: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 2933\n",
            "2025-06-26 08:24:26,874 EPOCH 2933\n",
            "INFO:__main__:Epoch 2933: total training loss 0.00405\n",
            "2025-06-26 08:24:26,943 Epoch 2933: total training loss 0.00405\n",
            "INFO:__main__:EPOCH 2934\n",
            "2025-06-26 08:24:26,945 EPOCH 2934\n",
            "INFO:__main__:Epoch 2934: total training loss 0.00374\n",
            "2025-06-26 08:24:27,014 Epoch 2934: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2935\n",
            "2025-06-26 08:24:27,023 EPOCH 2935\n",
            "INFO:__main__:Epoch 2935: total training loss 0.00403\n",
            "2025-06-26 08:24:27,107 Epoch 2935: total training loss 0.00403\n",
            "INFO:__main__:EPOCH 2936\n",
            "2025-06-26 08:24:27,109 EPOCH 2936\n",
            "INFO:__main__:Epoch 2936: total training loss 0.00366\n",
            "2025-06-26 08:24:27,173 Epoch 2936: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 2937\n",
            "2025-06-26 08:24:27,175 EPOCH 2937\n",
            "INFO:__main__:Epoch 2937: total training loss 0.00389\n",
            "2025-06-26 08:24:27,240 Epoch 2937: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2938\n",
            "2025-06-26 08:24:27,242 EPOCH 2938\n",
            "INFO:__main__:Epoch 2938: total training loss 0.00426\n",
            "2025-06-26 08:24:27,309 Epoch 2938: total training loss 0.00426\n",
            "INFO:__main__:EPOCH 2939\n",
            "2025-06-26 08:24:27,311 EPOCH 2939\n",
            "INFO:__main__:Epoch 2939: total training loss 0.00418\n",
            "2025-06-26 08:24:27,376 Epoch 2939: total training loss 0.00418\n",
            "INFO:__main__:EPOCH 2940\n",
            "2025-06-26 08:24:27,378 EPOCH 2940\n",
            "INFO:__main__:Epoch 2940: total training loss 0.00430\n",
            "2025-06-26 08:24:27,442 Epoch 2940: total training loss 0.00430\n",
            "INFO:__main__:EPOCH 2941\n",
            "2025-06-26 08:24:27,444 EPOCH 2941\n",
            "INFO:__main__:Epoch 2941: total training loss 0.00385\n",
            "2025-06-26 08:24:27,510 Epoch 2941: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 2942\n",
            "2025-06-26 08:24:27,513 EPOCH 2942\n",
            "INFO:__main__:Epoch 2942: total training loss 0.00452\n",
            "2025-06-26 08:24:27,580 Epoch 2942: total training loss 0.00452\n",
            "INFO:__main__:EPOCH 2943\n",
            "2025-06-26 08:24:27,582 EPOCH 2943\n",
            "INFO:__main__:Epoch 2943: total training loss 0.00417\n",
            "2025-06-26 08:24:27,652 Epoch 2943: total training loss 0.00417\n",
            "INFO:__main__:EPOCH 2944\n",
            "2025-06-26 08:24:27,654 EPOCH 2944\n",
            "INFO:__main__:Epoch 2944: total training loss 0.00405\n",
            "2025-06-26 08:24:27,723 Epoch 2944: total training loss 0.00405\n",
            "INFO:__main__:EPOCH 2945\n",
            "2025-06-26 08:24:27,725 EPOCH 2945\n",
            "INFO:__main__:Epoch 2945: total training loss 0.00380\n",
            "2025-06-26 08:24:27,792 Epoch 2945: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 2946\n",
            "2025-06-26 08:24:27,794 EPOCH 2946\n",
            "INFO:__main__:Epoch 2946: total training loss 0.00403\n",
            "2025-06-26 08:24:27,861 Epoch 2946: total training loss 0.00403\n",
            "INFO:__main__:EPOCH 2947\n",
            "2025-06-26 08:24:27,863 EPOCH 2947\n",
            "INFO:__main__:Epoch 2947: total training loss 0.00391\n",
            "2025-06-26 08:24:27,931 Epoch 2947: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 2948\n",
            "2025-06-26 08:24:27,933 EPOCH 2948\n",
            "INFO:__main__:Epoch 2948: total training loss 0.00380\n",
            "2025-06-26 08:24:27,999 Epoch 2948: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 2949\n",
            "2025-06-26 08:24:28,001 EPOCH 2949\n",
            "INFO:__main__:Epoch 2949: total training loss 0.00357\n",
            "2025-06-26 08:24:28,068 Epoch 2949: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 2950\n",
            "2025-06-26 08:24:28,070 EPOCH 2950\n",
            "INFO:__main__:Epoch 2950: total training loss 0.00351\n",
            "2025-06-26 08:24:28,159 Epoch 2950: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 2951\n",
            "2025-06-26 08:24:28,161 EPOCH 2951\n",
            "INFO:__main__:Epoch 2951: total training loss 0.00363\n",
            "2025-06-26 08:24:28,234 Epoch 2951: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 2952\n",
            "2025-06-26 08:24:28,236 EPOCH 2952\n",
            "INFO:__main__:Epoch 2952: total training loss 0.00366\n",
            "2025-06-26 08:24:28,302 Epoch 2952: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 2953\n",
            "2025-06-26 08:24:28,303 EPOCH 2953\n",
            "INFO:__main__:Epoch 2953: total training loss 0.00382\n",
            "2025-06-26 08:24:28,366 Epoch 2953: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 2954\n",
            "2025-06-26 08:24:28,368 EPOCH 2954\n",
            "INFO:__main__:Epoch 2954: total training loss 0.00399\n",
            "2025-06-26 08:24:28,433 Epoch 2954: total training loss 0.00399\n",
            "INFO:__main__:EPOCH 2955\n",
            "2025-06-26 08:24:28,436 EPOCH 2955\n",
            "INFO:__main__:Epoch 2955: total training loss 0.00395\n",
            "2025-06-26 08:24:28,504 Epoch 2955: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2956\n",
            "2025-06-26 08:24:28,506 EPOCH 2956\n",
            "INFO:__main__:Epoch 2956: total training loss 0.00375\n",
            "2025-06-26 08:24:28,574 Epoch 2956: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 2957\n",
            "2025-06-26 08:24:28,577 EPOCH 2957\n",
            "INFO:__main__:Epoch 2957: total training loss 0.00401\n",
            "2025-06-26 08:24:28,646 Epoch 2957: total training loss 0.00401\n",
            "INFO:__main__:EPOCH 2958\n",
            "2025-06-26 08:24:28,648 EPOCH 2958\n",
            "INFO:__main__:Epoch 2958: total training loss 0.00373\n",
            "2025-06-26 08:24:28,718 Epoch 2958: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 2959\n",
            "2025-06-26 08:24:28,720 EPOCH 2959\n",
            "INFO:__main__:Epoch 2959: total training loss 0.00372\n",
            "2025-06-26 08:24:28,791 Epoch 2959: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 2960\n",
            "2025-06-26 08:24:28,793 EPOCH 2960\n",
            "INFO:__main__:Epoch 2960: total training loss 0.00391\n",
            "2025-06-26 08:24:28,859 Epoch 2960: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 2961\n",
            "2025-06-26 08:24:28,861 EPOCH 2961\n",
            "INFO:__main__:Epoch 2961: total training loss 0.00397\n",
            "2025-06-26 08:24:28,927 Epoch 2961: total training loss 0.00397\n",
            "INFO:__main__:EPOCH 2962\n",
            "2025-06-26 08:24:28,929 EPOCH 2962\n",
            "INFO:__main__:Epoch 2962: total training loss 0.00388\n",
            "2025-06-26 08:24:28,992 Epoch 2962: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 2963\n",
            "2025-06-26 08:24:28,994 EPOCH 2963\n",
            "INFO:__main__:Epoch 2963: total training loss 0.00386\n",
            "2025-06-26 08:24:29,062 Epoch 2963: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 2964\n",
            "2025-06-26 08:24:29,064 EPOCH 2964\n",
            "INFO:__main__:Epoch 2964: total training loss 0.00348\n",
            "2025-06-26 08:24:29,129 Epoch 2964: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 2965\n",
            "2025-06-26 08:24:29,131 EPOCH 2965\n",
            "INFO:__main__:Epoch 2965: total training loss 0.00396\n",
            "2025-06-26 08:24:29,223 Epoch 2965: total training loss 0.00396\n",
            "INFO:__main__:EPOCH 2966\n",
            "2025-06-26 08:24:29,225 EPOCH 2966\n",
            "INFO:__main__:Epoch 2966: total training loss 0.00348\n",
            "2025-06-26 08:24:29,293 Epoch 2966: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 2967\n",
            "2025-06-26 08:24:29,295 EPOCH 2967\n",
            "INFO:__main__:Epoch 2967: total training loss 0.00370\n",
            "2025-06-26 08:24:29,363 Epoch 2967: total training loss 0.00370\n",
            "INFO:__main__:EPOCH 2968\n",
            "2025-06-26 08:24:29,365 EPOCH 2968\n",
            "INFO:__main__:Epoch 2968: total training loss 0.00392\n",
            "2025-06-26 08:24:29,430 Epoch 2968: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 2969\n",
            "2025-06-26 08:24:29,432 EPOCH 2969\n",
            "INFO:__main__:Epoch 2969: total training loss 0.00374\n",
            "2025-06-26 08:24:29,511 Epoch 2969: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 2970\n",
            "2025-06-26 08:24:29,513 EPOCH 2970\n",
            "INFO:__main__:Epoch 2970: total training loss 0.00418\n",
            "2025-06-26 08:24:29,581 Epoch 2970: total training loss 0.00418\n",
            "INFO:__main__:EPOCH 2971\n",
            "2025-06-26 08:24:29,583 EPOCH 2971\n",
            "INFO:__main__:Epoch 2971: total training loss 0.00386\n",
            "2025-06-26 08:24:29,648 Epoch 2971: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 2972\n",
            "2025-06-26 08:24:29,650 EPOCH 2972\n",
            "INFO:__main__:Epoch 2972: total training loss 0.00386\n",
            "2025-06-26 08:24:29,717 Epoch 2972: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 2973\n",
            "2025-06-26 08:24:29,719 EPOCH 2973\n",
            "INFO:__main__:Epoch 2973: total training loss 0.00444\n",
            "2025-06-26 08:24:29,784 Epoch 2973: total training loss 0.00444\n",
            "INFO:__main__:EPOCH 2974\n",
            "2025-06-26 08:24:29,786 EPOCH 2974\n",
            "INFO:__main__:Epoch 2974: total training loss 0.00407\n",
            "2025-06-26 08:24:29,848 Epoch 2974: total training loss 0.00407\n",
            "INFO:__main__:EPOCH 2975\n",
            "2025-06-26 08:24:29,851 EPOCH 2975\n",
            "INFO:__main__:Epoch 2975: total training loss 0.00416\n",
            "2025-06-26 08:24:29,918 Epoch 2975: total training loss 0.00416\n",
            "INFO:__main__:EPOCH 2976\n",
            "2025-06-26 08:24:29,920 EPOCH 2976\n",
            "INFO:__main__:Epoch 2976: total training loss 0.00389\n",
            "2025-06-26 08:24:29,990 Epoch 2976: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2977\n",
            "2025-06-26 08:24:29,992 EPOCH 2977\n",
            "INFO:__main__:Epoch 2977: total training loss 0.00383\n",
            "2025-06-26 08:24:30,057 Epoch 2977: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 2978\n",
            "2025-06-26 08:24:30,059 EPOCH 2978\n",
            "INFO:__main__:Epoch 2978: total training loss 0.00382\n",
            "2025-06-26 08:24:30,124 Epoch 2978: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 2979\n",
            "2025-06-26 08:24:30,126 EPOCH 2979\n",
            "INFO:__main__:Epoch 2979: total training loss 0.00366\n",
            "2025-06-26 08:24:30,208 Epoch 2979: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 2980\n",
            "2025-06-26 08:24:30,211 EPOCH 2980\n",
            "INFO:__main__:Epoch 2980: total training loss 0.00407\n",
            "2025-06-26 08:24:30,280 Epoch 2980: total training loss 0.00407\n",
            "INFO:__main__:EPOCH 2981\n",
            "2025-06-26 08:24:30,282 EPOCH 2981\n",
            "INFO:__main__:Epoch 2981: total training loss 0.00408\n",
            "2025-06-26 08:24:30,355 Epoch 2981: total training loss 0.00408\n",
            "INFO:__main__:EPOCH 2982\n",
            "2025-06-26 08:24:30,358 EPOCH 2982\n",
            "INFO:__main__:Epoch 2982: total training loss 0.00395\n",
            "2025-06-26 08:24:30,439 Epoch 2982: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 2983\n",
            "2025-06-26 08:24:30,440 EPOCH 2983\n",
            "INFO:__main__:Epoch 2983: total training loss 0.00379\n",
            "2025-06-26 08:24:30,517 Epoch 2983: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 2984\n",
            "2025-06-26 08:24:30,519 EPOCH 2984\n",
            "INFO:__main__:Epoch 2984: total training loss 0.00387\n",
            "2025-06-26 08:24:30,618 Epoch 2984: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 2985\n",
            "2025-06-26 08:24:30,620 EPOCH 2985\n",
            "INFO:__main__:Epoch 2985: total training loss 0.00407\n",
            "2025-06-26 08:24:30,692 Epoch 2985: total training loss 0.00407\n",
            "INFO:__main__:EPOCH 2986\n",
            "2025-06-26 08:24:30,694 EPOCH 2986\n",
            "INFO:__main__:Epoch 2986: total training loss 0.00347\n",
            "2025-06-26 08:24:30,780 Epoch 2986: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 2987\n",
            "2025-06-26 08:24:30,783 EPOCH 2987\n",
            "INFO:__main__:Epoch 2987: total training loss 0.00389\n",
            "2025-06-26 08:24:30,878 Epoch 2987: total training loss 0.00389\n",
            "INFO:__main__:EPOCH 2988\n",
            "2025-06-26 08:24:30,880 EPOCH 2988\n",
            "INFO:__main__:Epoch 2988: total training loss 0.00403\n",
            "2025-06-26 08:24:30,952 Epoch 2988: total training loss 0.00403\n",
            "INFO:__main__:EPOCH 2989\n",
            "2025-06-26 08:24:30,954 EPOCH 2989\n",
            "INFO:__main__:Epoch 2989: total training loss 0.00377\n",
            "2025-06-26 08:24:31,025 Epoch 2989: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 2990\n",
            "2025-06-26 08:24:31,027 EPOCH 2990\n",
            "INFO:__main__:Epoch 2990: total training loss 0.00342\n",
            "2025-06-26 08:24:31,095 Epoch 2990: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 2991\n",
            "2025-06-26 08:24:31,096 EPOCH 2991\n",
            "INFO:__main__:Epoch 2991: total training loss 0.00383\n",
            "2025-06-26 08:24:31,167 Epoch 2991: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 2992\n",
            "2025-06-26 08:24:31,168 EPOCH 2992\n",
            "INFO:__main__:Epoch 2992: total training loss 0.00350\n",
            "2025-06-26 08:24:31,245 Epoch 2992: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 2993\n",
            "2025-06-26 08:24:31,246 EPOCH 2993\n",
            "INFO:__main__:Epoch 2993: total training loss 0.00342\n",
            "2025-06-26 08:24:31,335 Epoch 2993: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 2994\n",
            "2025-06-26 08:24:31,337 EPOCH 2994\n",
            "INFO:__main__:Epoch 2994: total training loss 0.00354\n",
            "2025-06-26 08:24:31,420 Epoch 2994: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 2995\n",
            "2025-06-26 08:24:31,422 EPOCH 2995\n",
            "INFO:__main__:Epoch 2995: total training loss 0.00355\n",
            "2025-06-26 08:24:31,499 Epoch 2995: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 2996\n",
            "2025-06-26 08:24:31,500 EPOCH 2996\n",
            "INFO:__main__:Epoch 2996: total training loss 0.00362\n",
            "2025-06-26 08:24:31,572 Epoch 2996: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 2997\n",
            "2025-06-26 08:24:31,574 EPOCH 2997\n",
            "INFO:__main__:Epoch 2997: total training loss 0.00358\n",
            "2025-06-26 08:24:31,644 Epoch 2997: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 2998\n",
            "2025-06-26 08:24:31,646 EPOCH 2998\n",
            "INFO:__main__:Epoch 2998: total training loss 0.00345\n",
            "2025-06-26 08:24:31,717 Epoch 2998: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 2999\n",
            "2025-06-26 08:24:31,721 EPOCH 2999\n",
            "INFO:__main__:Epoch 2999: total training loss 0.00373\n",
            "2025-06-26 08:24:31,794 Epoch 2999: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3000\n",
            "2025-06-26 08:24:31,795 EPOCH 3000\n",
            "INFO:__main__:Epoch 3000 Step:     3000 Batch Loss:     0.004037 Tokens per Sec:  1912133, Lr: 0.001000\n",
            "2025-06-26 08:24:31,870 Epoch 3000 Step:     3000 Batch Loss:     0.004037 Tokens per Sec:  1912133, Lr: 0.001000\n",
            "INFO:__main__:Epoch 3000: total training loss 0.00404\n",
            "2025-06-26 08:24:31,872 Epoch 3000: total training loss 0.00404\n",
            "INFO:__main__:EPOCH 3001\n",
            "2025-06-26 08:24:31,874 EPOCH 3001\n",
            "INFO:__main__:Epoch 3001: total training loss 0.00387\n",
            "2025-06-26 08:24:31,943 Epoch 3001: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3002\n",
            "2025-06-26 08:24:31,945 EPOCH 3002\n",
            "INFO:__main__:Epoch 3002: total training loss 0.00387\n",
            "2025-06-26 08:24:32,016 Epoch 3002: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3003\n",
            "2025-06-26 08:24:32,018 EPOCH 3003\n",
            "INFO:__main__:Epoch 3003: total training loss 0.00369\n",
            "2025-06-26 08:24:32,090 Epoch 3003: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3004\n",
            "2025-06-26 08:24:32,092 EPOCH 3004\n",
            "INFO:__main__:Epoch 3004: total training loss 0.00378\n",
            "2025-06-26 08:24:32,179 Epoch 3004: total training loss 0.00378\n",
            "INFO:__main__:EPOCH 3005\n",
            "2025-06-26 08:24:32,181 EPOCH 3005\n",
            "INFO:__main__:Epoch 3005: total training loss 0.00372\n",
            "2025-06-26 08:24:32,261 Epoch 3005: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3006\n",
            "2025-06-26 08:24:32,265 EPOCH 3006\n",
            "INFO:__main__:Epoch 3006: total training loss 0.00385\n",
            "2025-06-26 08:24:32,362 Epoch 3006: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 3007\n",
            "2025-06-26 08:24:32,368 EPOCH 3007\n",
            "INFO:__main__:Epoch 3007: total training loss 0.00387\n",
            "2025-06-26 08:24:32,466 Epoch 3007: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3008\n",
            "2025-06-26 08:24:32,469 EPOCH 3008\n",
            "INFO:__main__:Epoch 3008: total training loss 0.00381\n",
            "2025-06-26 08:24:32,570 Epoch 3008: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 3009\n",
            "2025-06-26 08:24:32,573 EPOCH 3009\n",
            "INFO:__main__:Epoch 3009: total training loss 0.00375\n",
            "2025-06-26 08:24:32,662 Epoch 3009: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3010\n",
            "2025-06-26 08:24:32,666 EPOCH 3010\n",
            "INFO:__main__:Epoch 3010: total training loss 0.00380\n",
            "2025-06-26 08:24:32,742 Epoch 3010: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 3011\n",
            "2025-06-26 08:24:32,747 EPOCH 3011\n",
            "INFO:__main__:Epoch 3011: total training loss 0.00377\n",
            "2025-06-26 08:24:32,828 Epoch 3011: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3012\n",
            "2025-06-26 08:24:32,834 EPOCH 3012\n",
            "INFO:__main__:Epoch 3012: total training loss 0.00392\n",
            "2025-06-26 08:24:32,917 Epoch 3012: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 3013\n",
            "2025-06-26 08:24:32,922 EPOCH 3013\n",
            "INFO:__main__:Epoch 3013: total training loss 0.00363\n",
            "2025-06-26 08:24:33,002 Epoch 3013: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3014\n",
            "2025-06-26 08:24:33,007 EPOCH 3014\n",
            "INFO:__main__:Epoch 3014: total training loss 0.00371\n",
            "2025-06-26 08:24:33,087 Epoch 3014: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3015\n",
            "2025-06-26 08:24:33,089 EPOCH 3015\n",
            "INFO:__main__:Epoch 3015: total training loss 0.00354\n",
            "2025-06-26 08:24:33,161 Epoch 3015: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3016\n",
            "2025-06-26 08:24:33,163 EPOCH 3016\n",
            "INFO:__main__:Epoch 3016: total training loss 0.00366\n",
            "2025-06-26 08:24:33,247 Epoch 3016: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3017\n",
            "2025-06-26 08:24:33,249 EPOCH 3017\n",
            "INFO:__main__:Epoch 3017: total training loss 0.00362\n",
            "2025-06-26 08:24:33,319 Epoch 3017: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3018\n",
            "2025-06-26 08:24:33,322 EPOCH 3018\n",
            "INFO:__main__:Epoch 3018: total training loss 0.00347\n",
            "2025-06-26 08:24:33,391 Epoch 3018: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3019\n",
            "2025-06-26 08:24:33,394 EPOCH 3019\n",
            "INFO:__main__:Epoch 3019: total training loss 0.00318\n",
            "2025-06-26 08:24:33,467 Epoch 3019: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3020\n",
            "2025-06-26 08:24:33,469 EPOCH 3020\n",
            "INFO:__main__:Epoch 3020: total training loss 0.00327\n",
            "2025-06-26 08:24:33,547 Epoch 3020: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3021\n",
            "2025-06-26 08:24:33,553 EPOCH 3021\n",
            "INFO:__main__:Epoch 3021: total training loss 0.00361\n",
            "2025-06-26 08:24:33,638 Epoch 3021: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3022\n",
            "2025-06-26 08:24:33,640 EPOCH 3022\n",
            "INFO:__main__:Epoch 3022: total training loss 0.00367\n",
            "2025-06-26 08:24:33,717 Epoch 3022: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3023\n",
            "2025-06-26 08:24:33,719 EPOCH 3023\n",
            "INFO:__main__:Epoch 3023: total training loss 0.00347\n",
            "2025-06-26 08:24:33,798 Epoch 3023: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3024\n",
            "2025-06-26 08:24:33,800 EPOCH 3024\n",
            "INFO:__main__:Epoch 3024: total training loss 0.00346\n",
            "2025-06-26 08:24:33,874 Epoch 3024: total training loss 0.00346\n",
            "INFO:__main__:EPOCH 3025\n",
            "2025-06-26 08:24:33,876 EPOCH 3025\n",
            "INFO:__main__:Epoch 3025: total training loss 0.00375\n",
            "2025-06-26 08:24:33,947 Epoch 3025: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3026\n",
            "2025-06-26 08:24:33,949 EPOCH 3026\n",
            "INFO:__main__:Epoch 3026: total training loss 0.00350\n",
            "2025-06-26 08:24:34,017 Epoch 3026: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3027\n",
            "2025-06-26 08:24:34,019 EPOCH 3027\n",
            "INFO:__main__:Epoch 3027: total training loss 0.00391\n",
            "2025-06-26 08:24:34,095 Epoch 3027: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 3028\n",
            "2025-06-26 08:24:34,098 EPOCH 3028\n",
            "INFO:__main__:Epoch 3028: total training loss 0.00343\n",
            "2025-06-26 08:24:34,172 Epoch 3028: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3029\n",
            "2025-06-26 08:24:34,174 EPOCH 3029\n",
            "INFO:__main__:Epoch 3029: total training loss 0.00379\n",
            "2025-06-26 08:24:34,246 Epoch 3029: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 3030\n",
            "2025-06-26 08:24:34,247 EPOCH 3030\n",
            "INFO:__main__:Epoch 3030: total training loss 0.00410\n",
            "2025-06-26 08:24:34,317 Epoch 3030: total training loss 0.00410\n",
            "INFO:__main__:EPOCH 3031\n",
            "2025-06-26 08:24:34,321 EPOCH 3031\n",
            "INFO:__main__:Epoch 3031: total training loss 0.00406\n",
            "2025-06-26 08:24:34,392 Epoch 3031: total training loss 0.00406\n",
            "INFO:__main__:EPOCH 3032\n",
            "2025-06-26 08:24:34,395 EPOCH 3032\n",
            "INFO:__main__:Epoch 3032: total training loss 0.00373\n",
            "2025-06-26 08:24:34,493 Epoch 3032: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3033\n",
            "2025-06-26 08:24:34,497 EPOCH 3033\n",
            "INFO:__main__:Epoch 3033: total training loss 0.00388\n",
            "2025-06-26 08:24:34,587 Epoch 3033: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 3034\n",
            "2025-06-26 08:24:34,591 EPOCH 3034\n",
            "INFO:__main__:Epoch 3034: total training loss 0.00373\n",
            "2025-06-26 08:24:34,696 Epoch 3034: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3035\n",
            "2025-06-26 08:24:34,699 EPOCH 3035\n",
            "INFO:__main__:Epoch 3035: total training loss 0.00363\n",
            "2025-06-26 08:24:34,793 Epoch 3035: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3036\n",
            "2025-06-26 08:24:34,798 EPOCH 3036\n",
            "INFO:__main__:Epoch 3036: total training loss 0.00355\n",
            "2025-06-26 08:24:34,879 Epoch 3036: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3037\n",
            "2025-06-26 08:24:34,885 EPOCH 3037\n",
            "INFO:__main__:Epoch 3037: total training loss 0.00343\n",
            "2025-06-26 08:24:34,976 Epoch 3037: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3038\n",
            "2025-06-26 08:24:34,983 EPOCH 3038\n",
            "INFO:__main__:Epoch 3038: total training loss 0.00373\n",
            "2025-06-26 08:24:35,083 Epoch 3038: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3039\n",
            "2025-06-26 08:24:35,086 EPOCH 3039\n",
            "INFO:__main__:Epoch 3039: total training loss 0.00391\n",
            "2025-06-26 08:24:35,182 Epoch 3039: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 3040\n",
            "2025-06-26 08:24:35,184 EPOCH 3040\n",
            "INFO:__main__:Epoch 3040: total training loss 0.00335\n",
            "2025-06-26 08:24:35,281 Epoch 3040: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3041\n",
            "2025-06-26 08:24:35,283 EPOCH 3041\n",
            "INFO:__main__:Epoch 3041: total training loss 0.00429\n",
            "2025-06-26 08:24:35,374 Epoch 3041: total training loss 0.00429\n",
            "INFO:__main__:EPOCH 3042\n",
            "2025-06-26 08:24:35,377 EPOCH 3042\n",
            "INFO:__main__:Epoch 3042: total training loss 0.00369\n",
            "2025-06-26 08:24:35,489 Epoch 3042: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3043\n",
            "2025-06-26 08:24:35,491 EPOCH 3043\n",
            "INFO:__main__:Epoch 3043: total training loss 0.00410\n",
            "2025-06-26 08:24:35,593 Epoch 3043: total training loss 0.00410\n",
            "INFO:__main__:EPOCH 3044\n",
            "2025-06-26 08:24:35,596 EPOCH 3044\n",
            "INFO:__main__:Epoch 3044: total training loss 0.00406\n",
            "2025-06-26 08:24:35,695 Epoch 3044: total training loss 0.00406\n",
            "INFO:__main__:EPOCH 3045\n",
            "2025-06-26 08:24:35,698 EPOCH 3045\n",
            "INFO:__main__:Epoch 3045: total training loss 0.00412\n",
            "2025-06-26 08:24:35,789 Epoch 3045: total training loss 0.00412\n",
            "INFO:__main__:EPOCH 3046\n",
            "2025-06-26 08:24:35,791 EPOCH 3046\n",
            "INFO:__main__:Epoch 3046: total training loss 0.00404\n",
            "2025-06-26 08:24:35,859 Epoch 3046: total training loss 0.00404\n",
            "INFO:__main__:EPOCH 3047\n",
            "2025-06-26 08:24:35,861 EPOCH 3047\n",
            "INFO:__main__:Epoch 3047: total training loss 0.00413\n",
            "2025-06-26 08:24:35,928 Epoch 3047: total training loss 0.00413\n",
            "INFO:__main__:EPOCH 3048\n",
            "2025-06-26 08:24:35,930 EPOCH 3048\n",
            "INFO:__main__:Epoch 3048: total training loss 0.00388\n",
            "2025-06-26 08:24:35,995 Epoch 3048: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 3049\n",
            "2025-06-26 08:24:35,997 EPOCH 3049\n",
            "INFO:__main__:Epoch 3049: total training loss 0.00380\n",
            "2025-06-26 08:24:36,062 Epoch 3049: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 3050\n",
            "2025-06-26 08:24:36,065 EPOCH 3050\n",
            "INFO:__main__:Epoch 3050: total training loss 0.00415\n",
            "2025-06-26 08:24:36,135 Epoch 3050: total training loss 0.00415\n",
            "INFO:__main__:EPOCH 3051\n",
            "2025-06-26 08:24:36,138 EPOCH 3051\n",
            "INFO:__main__:Epoch 3051: total training loss 0.00421\n",
            "2025-06-26 08:24:36,204 Epoch 3051: total training loss 0.00421\n",
            "INFO:__main__:EPOCH 3052\n",
            "2025-06-26 08:24:36,206 EPOCH 3052\n",
            "INFO:__main__:Epoch 3052: total training loss 0.00393\n",
            "2025-06-26 08:24:36,271 Epoch 3052: total training loss 0.00393\n",
            "INFO:__main__:EPOCH 3053\n",
            "2025-06-26 08:24:36,273 EPOCH 3053\n",
            "INFO:__main__:Epoch 3053: total training loss 0.00397\n",
            "2025-06-26 08:24:36,344 Epoch 3053: total training loss 0.00397\n",
            "INFO:__main__:EPOCH 3054\n",
            "2025-06-26 08:24:36,346 EPOCH 3054\n",
            "INFO:__main__:Epoch 3054: total training loss 0.00383\n",
            "2025-06-26 08:24:36,416 Epoch 3054: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 3055\n",
            "2025-06-26 08:24:36,418 EPOCH 3055\n",
            "INFO:__main__:Epoch 3055: total training loss 0.00379\n",
            "2025-06-26 08:24:36,486 Epoch 3055: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 3056\n",
            "2025-06-26 08:24:36,488 EPOCH 3056\n",
            "INFO:__main__:Epoch 3056: total training loss 0.00374\n",
            "2025-06-26 08:24:36,555 Epoch 3056: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3057\n",
            "2025-06-26 08:24:36,557 EPOCH 3057\n",
            "INFO:__main__:Epoch 3057: total training loss 0.00388\n",
            "2025-06-26 08:24:36,623 Epoch 3057: total training loss 0.00388\n",
            "INFO:__main__:EPOCH 3058\n",
            "2025-06-26 08:24:36,627 EPOCH 3058\n",
            "INFO:__main__:Epoch 3058: total training loss 0.00357\n",
            "2025-06-26 08:24:36,692 Epoch 3058: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3059\n",
            "2025-06-26 08:24:36,695 EPOCH 3059\n",
            "INFO:__main__:Epoch 3059: total training loss 0.00387\n",
            "2025-06-26 08:24:36,764 Epoch 3059: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3060\n",
            "2025-06-26 08:24:36,766 EPOCH 3060\n",
            "INFO:__main__:Epoch 3060: total training loss 0.00371\n",
            "2025-06-26 08:24:36,844 Epoch 3060: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3061\n",
            "2025-06-26 08:24:36,846 EPOCH 3061\n",
            "INFO:__main__:Epoch 3061: total training loss 0.00383\n",
            "2025-06-26 08:24:36,914 Epoch 3061: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 3062\n",
            "2025-06-26 08:24:36,916 EPOCH 3062\n",
            "INFO:__main__:Epoch 3062: total training loss 0.00366\n",
            "2025-06-26 08:24:36,984 Epoch 3062: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3063\n",
            "2025-06-26 08:24:36,986 EPOCH 3063\n",
            "INFO:__main__:Epoch 3063: total training loss 0.00362\n",
            "2025-06-26 08:24:37,050 Epoch 3063: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3064\n",
            "2025-06-26 08:24:37,052 EPOCH 3064\n",
            "INFO:__main__:Epoch 3064: total training loss 0.00369\n",
            "2025-06-26 08:24:37,118 Epoch 3064: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3065\n",
            "2025-06-26 08:24:37,120 EPOCH 3065\n",
            "INFO:__main__:Epoch 3065: total training loss 0.00368\n",
            "2025-06-26 08:24:37,187 Epoch 3065: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3066\n",
            "2025-06-26 08:24:37,189 EPOCH 3066\n",
            "INFO:__main__:Epoch 3066: total training loss 0.00335\n",
            "2025-06-26 08:24:37,259 Epoch 3066: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3067\n",
            "2025-06-26 08:24:37,261 EPOCH 3067\n",
            "INFO:__main__:Epoch 3067: total training loss 0.00353\n",
            "2025-06-26 08:24:37,328 Epoch 3067: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3068\n",
            "2025-06-26 08:24:37,330 EPOCH 3068\n",
            "INFO:__main__:Epoch 3068: total training loss 0.00362\n",
            "2025-06-26 08:24:37,393 Epoch 3068: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3069\n",
            "2025-06-26 08:24:37,395 EPOCH 3069\n",
            "INFO:__main__:Epoch 3069: total training loss 0.00336\n",
            "2025-06-26 08:24:37,460 Epoch 3069: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3070\n",
            "2025-06-26 08:24:37,462 EPOCH 3070\n",
            "INFO:__main__:Epoch 3070: total training loss 0.00341\n",
            "2025-06-26 08:24:37,531 Epoch 3070: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3071\n",
            "2025-06-26 08:24:37,533 EPOCH 3071\n",
            "INFO:__main__:Epoch 3071: total training loss 0.00354\n",
            "2025-06-26 08:24:37,606 Epoch 3071: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3072\n",
            "2025-06-26 08:24:37,608 EPOCH 3072\n",
            "INFO:__main__:Epoch 3072: total training loss 0.00358\n",
            "2025-06-26 08:24:37,672 Epoch 3072: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3073\n",
            "2025-06-26 08:24:37,675 EPOCH 3073\n",
            "INFO:__main__:Epoch 3073: total training loss 0.00352\n",
            "2025-06-26 08:24:37,745 Epoch 3073: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3074\n",
            "2025-06-26 08:24:37,747 EPOCH 3074\n",
            "INFO:__main__:Epoch 3074: total training loss 0.00361\n",
            "2025-06-26 08:24:37,817 Epoch 3074: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3075\n",
            "2025-06-26 08:24:37,822 EPOCH 3075\n",
            "INFO:__main__:Epoch 3075: total training loss 0.00353\n",
            "2025-06-26 08:24:37,908 Epoch 3075: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3076\n",
            "2025-06-26 08:24:37,911 EPOCH 3076\n",
            "INFO:__main__:Epoch 3076: total training loss 0.00314\n",
            "2025-06-26 08:24:37,979 Epoch 3076: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3077\n",
            "2025-06-26 08:24:37,981 EPOCH 3077\n",
            "INFO:__main__:Epoch 3077: total training loss 0.00350\n",
            "2025-06-26 08:24:38,049 Epoch 3077: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3078\n",
            "2025-06-26 08:24:38,051 EPOCH 3078\n",
            "INFO:__main__:Epoch 3078: total training loss 0.00373\n",
            "2025-06-26 08:24:38,122 Epoch 3078: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3079\n",
            "2025-06-26 08:24:38,124 EPOCH 3079\n",
            "INFO:__main__:Epoch 3079: total training loss 0.00344\n",
            "2025-06-26 08:24:38,191 Epoch 3079: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3080\n",
            "2025-06-26 08:24:38,202 EPOCH 3080\n",
            "INFO:__main__:Epoch 3080: total training loss 0.00341\n",
            "2025-06-26 08:24:38,268 Epoch 3080: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3081\n",
            "2025-06-26 08:24:38,270 EPOCH 3081\n",
            "INFO:__main__:Epoch 3081: total training loss 0.00373\n",
            "2025-06-26 08:24:38,338 Epoch 3081: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3082\n",
            "2025-06-26 08:24:38,340 EPOCH 3082\n",
            "INFO:__main__:Epoch 3082: total training loss 0.00348\n",
            "2025-06-26 08:24:38,406 Epoch 3082: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3083\n",
            "2025-06-26 08:24:38,408 EPOCH 3083\n",
            "INFO:__main__:Epoch 3083: total training loss 0.00346\n",
            "2025-06-26 08:24:38,473 Epoch 3083: total training loss 0.00346\n",
            "INFO:__main__:EPOCH 3084\n",
            "2025-06-26 08:24:38,475 EPOCH 3084\n",
            "INFO:__main__:Epoch 3084: total training loss 0.00374\n",
            "2025-06-26 08:24:38,542 Epoch 3084: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3085\n",
            "2025-06-26 08:24:38,544 EPOCH 3085\n",
            "INFO:__main__:Epoch 3085: total training loss 0.00353\n",
            "2025-06-26 08:24:38,612 Epoch 3085: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3086\n",
            "2025-06-26 08:24:38,614 EPOCH 3086\n",
            "INFO:__main__:Epoch 3086: total training loss 0.00348\n",
            "2025-06-26 08:24:38,679 Epoch 3086: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3087\n",
            "2025-06-26 08:24:38,681 EPOCH 3087\n",
            "INFO:__main__:Epoch 3087: total training loss 0.00352\n",
            "2025-06-26 08:24:38,747 Epoch 3087: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3088\n",
            "2025-06-26 08:24:38,749 EPOCH 3088\n",
            "INFO:__main__:Epoch 3088: total training loss 0.00331\n",
            "2025-06-26 08:24:38,819 Epoch 3088: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3089\n",
            "2025-06-26 08:24:38,821 EPOCH 3089\n",
            "INFO:__main__:Epoch 3089: total training loss 0.00337\n",
            "2025-06-26 08:24:38,895 Epoch 3089: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3090\n",
            "2025-06-26 08:24:38,898 EPOCH 3090\n",
            "INFO:__main__:Epoch 3090: total training loss 0.00336\n",
            "2025-06-26 08:24:38,977 Epoch 3090: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3091\n",
            "2025-06-26 08:24:38,979 EPOCH 3091\n",
            "INFO:__main__:Epoch 3091: total training loss 0.00330\n",
            "2025-06-26 08:24:39,049 Epoch 3091: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3092\n",
            "2025-06-26 08:24:39,050 EPOCH 3092\n",
            "INFO:__main__:Epoch 3092: total training loss 0.00333\n",
            "2025-06-26 08:24:39,119 Epoch 3092: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3093\n",
            "2025-06-26 08:24:39,121 EPOCH 3093\n",
            "INFO:__main__:Epoch 3093: total training loss 0.00317\n",
            "2025-06-26 08:24:39,193 Epoch 3093: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3094\n",
            "2025-06-26 08:24:39,195 EPOCH 3094\n",
            "INFO:__main__:Epoch 3094: total training loss 0.00317\n",
            "2025-06-26 08:24:39,269 Epoch 3094: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3095\n",
            "2025-06-26 08:24:39,271 EPOCH 3095\n",
            "INFO:__main__:Epoch 3095: total training loss 0.00352\n",
            "2025-06-26 08:24:39,341 Epoch 3095: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3096\n",
            "2025-06-26 08:24:39,343 EPOCH 3096\n",
            "INFO:__main__:Epoch 3096: total training loss 0.00322\n",
            "2025-06-26 08:24:39,411 Epoch 3096: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3097\n",
            "2025-06-26 08:24:39,413 EPOCH 3097\n",
            "INFO:__main__:Epoch 3097: total training loss 0.00305\n",
            "2025-06-26 08:24:39,482 Epoch 3097: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3098\n",
            "2025-06-26 08:24:39,484 EPOCH 3098\n",
            "INFO:__main__:Epoch 3098: total training loss 0.00344\n",
            "2025-06-26 08:24:39,555 Epoch 3098: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3099\n",
            "2025-06-26 08:24:39,558 EPOCH 3099\n",
            "INFO:__main__:Epoch 3099: total training loss 0.00315\n",
            "2025-06-26 08:24:39,631 Epoch 3099: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3100\n",
            "2025-06-26 08:24:39,633 EPOCH 3100\n",
            "INFO:__main__:Epoch 3100: total training loss 0.00332\n",
            "2025-06-26 08:24:39,699 Epoch 3100: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3101\n",
            "2025-06-26 08:24:39,701 EPOCH 3101\n",
            "INFO:__main__:Epoch 3101: total training loss 0.00372\n",
            "2025-06-26 08:24:39,769 Epoch 3101: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3102\n",
            "2025-06-26 08:24:39,771 EPOCH 3102\n",
            "INFO:__main__:Epoch 3102: total training loss 0.00347\n",
            "2025-06-26 08:24:39,839 Epoch 3102: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3103\n",
            "2025-06-26 08:24:39,841 EPOCH 3103\n",
            "INFO:__main__:Epoch 3103: total training loss 0.00382\n",
            "2025-06-26 08:24:39,910 Epoch 3103: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 3104\n",
            "2025-06-26 08:24:39,913 EPOCH 3104\n",
            "INFO:__main__:Epoch 3104: total training loss 0.00353\n",
            "2025-06-26 08:24:40,001 Epoch 3104: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3105\n",
            "2025-06-26 08:24:40,003 EPOCH 3105\n",
            "INFO:__main__:Epoch 3105: total training loss 0.00365\n",
            "2025-06-26 08:24:40,071 Epoch 3105: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3106\n",
            "2025-06-26 08:24:40,073 EPOCH 3106\n",
            "INFO:__main__:Epoch 3106: total training loss 0.00366\n",
            "2025-06-26 08:24:40,140 Epoch 3106: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3107\n",
            "2025-06-26 08:24:40,142 EPOCH 3107\n",
            "INFO:__main__:Epoch 3107: total training loss 0.00368\n",
            "2025-06-26 08:24:40,212 Epoch 3107: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3108\n",
            "2025-06-26 08:24:40,215 EPOCH 3108\n",
            "INFO:__main__:Epoch 3108: total training loss 0.00351\n",
            "2025-06-26 08:24:40,283 Epoch 3108: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3109\n",
            "2025-06-26 08:24:40,285 EPOCH 3109\n",
            "INFO:__main__:Epoch 3109: total training loss 0.00382\n",
            "2025-06-26 08:24:40,351 Epoch 3109: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 3110\n",
            "2025-06-26 08:24:40,353 EPOCH 3110\n",
            "INFO:__main__:Epoch 3110: total training loss 0.00352\n",
            "2025-06-26 08:24:40,423 Epoch 3110: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3111\n",
            "2025-06-26 08:24:40,426 EPOCH 3111\n",
            "INFO:__main__:Epoch 3111: total training loss 0.00382\n",
            "2025-06-26 08:24:40,495 Epoch 3111: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 3112\n",
            "2025-06-26 08:24:40,497 EPOCH 3112\n",
            "INFO:__main__:Epoch 3112: total training loss 0.00337\n",
            "2025-06-26 08:24:40,563 Epoch 3112: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3113\n",
            "2025-06-26 08:24:40,565 EPOCH 3113\n",
            "INFO:__main__:Epoch 3113: total training loss 0.00372\n",
            "2025-06-26 08:24:40,634 Epoch 3113: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3114\n",
            "2025-06-26 08:24:40,636 EPOCH 3114\n",
            "INFO:__main__:Epoch 3114: total training loss 0.00348\n",
            "2025-06-26 08:24:40,703 Epoch 3114: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3115\n",
            "2025-06-26 08:24:40,705 EPOCH 3115\n",
            "INFO:__main__:Epoch 3115: total training loss 0.00332\n",
            "2025-06-26 08:24:40,777 Epoch 3115: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3116\n",
            "2025-06-26 08:24:40,781 EPOCH 3116\n",
            "INFO:__main__:Epoch 3116: total training loss 0.00347\n",
            "2025-06-26 08:24:40,848 Epoch 3116: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3117\n",
            "2025-06-26 08:24:40,850 EPOCH 3117\n",
            "INFO:__main__:Epoch 3117: total training loss 0.00367\n",
            "2025-06-26 08:24:40,918 Epoch 3117: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3118\n",
            "2025-06-26 08:24:40,921 EPOCH 3118\n",
            "INFO:__main__:Epoch 3118: total training loss 0.00359\n",
            "2025-06-26 08:24:40,991 Epoch 3118: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 3119\n",
            "2025-06-26 08:24:40,993 EPOCH 3119\n",
            "INFO:__main__:Epoch 3119: total training loss 0.00339\n",
            "2025-06-26 08:24:41,078 Epoch 3119: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3120\n",
            "2025-06-26 08:24:41,080 EPOCH 3120\n",
            "INFO:__main__:Epoch 3120: total training loss 0.00328\n",
            "2025-06-26 08:24:41,146 Epoch 3120: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3121\n",
            "2025-06-26 08:24:41,148 EPOCH 3121\n",
            "INFO:__main__:Epoch 3121: total training loss 0.00367\n",
            "2025-06-26 08:24:41,216 Epoch 3121: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3122\n",
            "2025-06-26 08:24:41,218 EPOCH 3122\n",
            "INFO:__main__:Epoch 3122: total training loss 0.00357\n",
            "2025-06-26 08:24:41,288 Epoch 3122: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3123\n",
            "2025-06-26 08:24:41,290 EPOCH 3123\n",
            "INFO:__main__:Epoch 3123: total training loss 0.00347\n",
            "2025-06-26 08:24:41,358 Epoch 3123: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3124\n",
            "2025-06-26 08:24:41,360 EPOCH 3124\n",
            "INFO:__main__:Epoch 3124: total training loss 0.00357\n",
            "2025-06-26 08:24:41,430 Epoch 3124: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3125\n",
            "2025-06-26 08:24:41,432 EPOCH 3125\n",
            "INFO:__main__:Epoch 3125: total training loss 0.00349\n",
            "2025-06-26 08:24:41,499 Epoch 3125: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3126\n",
            "2025-06-26 08:24:41,501 EPOCH 3126\n",
            "INFO:__main__:Epoch 3126: total training loss 0.00328\n",
            "2025-06-26 08:24:41,565 Epoch 3126: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3127\n",
            "2025-06-26 08:24:41,567 EPOCH 3127\n",
            "INFO:__main__:Epoch 3127: total training loss 0.00366\n",
            "2025-06-26 08:24:41,635 Epoch 3127: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3128\n",
            "2025-06-26 08:24:41,637 EPOCH 3128\n",
            "INFO:__main__:Epoch 3128: total training loss 0.00338\n",
            "2025-06-26 08:24:41,699 Epoch 3128: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3129\n",
            "2025-06-26 08:24:41,701 EPOCH 3129\n",
            "INFO:__main__:Epoch 3129: total training loss 0.00371\n",
            "2025-06-26 08:24:41,770 Epoch 3129: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3130\n",
            "2025-06-26 08:24:41,773 EPOCH 3130\n",
            "INFO:__main__:Epoch 3130: total training loss 0.00353\n",
            "2025-06-26 08:24:41,840 Epoch 3130: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3131\n",
            "2025-06-26 08:24:41,842 EPOCH 3131\n",
            "INFO:__main__:Epoch 3131: total training loss 0.00375\n",
            "2025-06-26 08:24:41,911 Epoch 3131: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3132\n",
            "2025-06-26 08:24:41,913 EPOCH 3132\n",
            "INFO:__main__:Epoch 3132: total training loss 0.00337\n",
            "2025-06-26 08:24:41,979 Epoch 3132: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3133\n",
            "2025-06-26 08:24:41,981 EPOCH 3133\n",
            "INFO:__main__:Epoch 3133: total training loss 0.00347\n",
            "2025-06-26 08:24:42,050 Epoch 3133: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3134\n",
            "2025-06-26 08:24:42,052 EPOCH 3134\n",
            "INFO:__main__:Epoch 3134: total training loss 0.00380\n",
            "2025-06-26 08:24:42,139 Epoch 3134: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 3135\n",
            "2025-06-26 08:24:42,141 EPOCH 3135\n",
            "INFO:__main__:Epoch 3135: total training loss 0.00337\n",
            "2025-06-26 08:24:42,210 Epoch 3135: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3136\n",
            "2025-06-26 08:24:42,212 EPOCH 3136\n",
            "INFO:__main__:Epoch 3136: total training loss 0.00364\n",
            "2025-06-26 08:24:42,280 Epoch 3136: total training loss 0.00364\n",
            "INFO:__main__:EPOCH 3137\n",
            "2025-06-26 08:24:42,282 EPOCH 3137\n",
            "INFO:__main__:Epoch 3137: total training loss 0.00367\n",
            "2025-06-26 08:24:42,349 Epoch 3137: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3138\n",
            "2025-06-26 08:24:42,351 EPOCH 3138\n",
            "INFO:__main__:Epoch 3138: total training loss 0.00367\n",
            "2025-06-26 08:24:42,418 Epoch 3138: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3139\n",
            "2025-06-26 08:24:42,420 EPOCH 3139\n",
            "INFO:__main__:Epoch 3139: total training loss 0.00357\n",
            "2025-06-26 08:24:42,486 Epoch 3139: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3140\n",
            "2025-06-26 08:24:42,488 EPOCH 3140\n",
            "INFO:__main__:Epoch 3140: total training loss 0.00358\n",
            "2025-06-26 08:24:42,554 Epoch 3140: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3141\n",
            "2025-06-26 08:24:42,556 EPOCH 3141\n",
            "INFO:__main__:Epoch 3141: total training loss 0.00345\n",
            "2025-06-26 08:24:42,627 Epoch 3141: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3142\n",
            "2025-06-26 08:24:42,628 EPOCH 3142\n",
            "INFO:__main__:Epoch 3142: total training loss 0.00359\n",
            "2025-06-26 08:24:42,693 Epoch 3142: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 3143\n",
            "2025-06-26 08:24:42,695 EPOCH 3143\n",
            "INFO:__main__:Epoch 3143: total training loss 0.00377\n",
            "2025-06-26 08:24:42,765 Epoch 3143: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3144\n",
            "2025-06-26 08:24:42,767 EPOCH 3144\n",
            "INFO:__main__:Epoch 3144: total training loss 0.00360\n",
            "2025-06-26 08:24:42,832 Epoch 3144: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3145\n",
            "2025-06-26 08:24:42,834 EPOCH 3145\n",
            "INFO:__main__:Epoch 3145: total training loss 0.00386\n",
            "2025-06-26 08:24:42,901 Epoch 3145: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 3146\n",
            "2025-06-26 08:24:42,903 EPOCH 3146\n",
            "INFO:__main__:Epoch 3146: total training loss 0.00365\n",
            "2025-06-26 08:24:42,967 Epoch 3146: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3147\n",
            "2025-06-26 08:24:42,969 EPOCH 3147\n",
            "INFO:__main__:Epoch 3147: total training loss 0.00376\n",
            "2025-06-26 08:24:43,035 Epoch 3147: total training loss 0.00376\n",
            "INFO:__main__:EPOCH 3148\n",
            "2025-06-26 08:24:43,037 EPOCH 3148\n",
            "INFO:__main__:Epoch 3148: total training loss 0.00398\n",
            "2025-06-26 08:24:43,103 Epoch 3148: total training loss 0.00398\n",
            "INFO:__main__:EPOCH 3149\n",
            "2025-06-26 08:24:43,105 EPOCH 3149\n",
            "INFO:__main__:Epoch 3149: total training loss 0.00367\n",
            "2025-06-26 08:24:43,194 Epoch 3149: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3150\n",
            "2025-06-26 08:24:43,196 EPOCH 3150\n",
            "INFO:__main__:Epoch 3150: total training loss 0.00396\n",
            "2025-06-26 08:24:43,265 Epoch 3150: total training loss 0.00396\n",
            "INFO:__main__:EPOCH 3151\n",
            "2025-06-26 08:24:43,267 EPOCH 3151\n",
            "INFO:__main__:Epoch 3151: total training loss 0.00340\n",
            "2025-06-26 08:24:43,332 Epoch 3151: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3152\n",
            "2025-06-26 08:24:43,334 EPOCH 3152\n",
            "INFO:__main__:Epoch 3152: total training loss 0.00387\n",
            "2025-06-26 08:24:43,399 Epoch 3152: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3153\n",
            "2025-06-26 08:24:43,401 EPOCH 3153\n",
            "INFO:__main__:Epoch 3153: total training loss 0.00369\n",
            "2025-06-26 08:24:43,466 Epoch 3153: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3154\n",
            "2025-06-26 08:24:43,468 EPOCH 3154\n",
            "INFO:__main__:Epoch 3154: total training loss 0.00376\n",
            "2025-06-26 08:24:43,534 Epoch 3154: total training loss 0.00376\n",
            "INFO:__main__:EPOCH 3155\n",
            "2025-06-26 08:24:43,537 EPOCH 3155\n",
            "INFO:__main__:Epoch 3155: total training loss 0.00376\n",
            "2025-06-26 08:24:43,607 Epoch 3155: total training loss 0.00376\n",
            "INFO:__main__:EPOCH 3156\n",
            "2025-06-26 08:24:43,609 EPOCH 3156\n",
            "INFO:__main__:Epoch 3156: total training loss 0.00355\n",
            "2025-06-26 08:24:43,676 Epoch 3156: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3157\n",
            "2025-06-26 08:24:43,678 EPOCH 3157\n",
            "INFO:__main__:Epoch 3157: total training loss 0.00349\n",
            "2025-06-26 08:24:43,745 Epoch 3157: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3158\n",
            "2025-06-26 08:24:43,747 EPOCH 3158\n",
            "INFO:__main__:Epoch 3158: total training loss 0.00374\n",
            "2025-06-26 08:24:43,816 Epoch 3158: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3159\n",
            "2025-06-26 08:24:43,818 EPOCH 3159\n",
            "INFO:__main__:Epoch 3159: total training loss 0.00366\n",
            "2025-06-26 08:24:43,884 Epoch 3159: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3160\n",
            "2025-06-26 08:24:43,885 EPOCH 3160\n",
            "INFO:__main__:Epoch 3160: total training loss 0.00369\n",
            "2025-06-26 08:24:43,950 Epoch 3160: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3161\n",
            "2025-06-26 08:24:43,952 EPOCH 3161\n",
            "INFO:__main__:Epoch 3161: total training loss 0.00348\n",
            "2025-06-26 08:24:44,021 Epoch 3161: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3162\n",
            "2025-06-26 08:24:44,025 EPOCH 3162\n",
            "INFO:__main__:Epoch 3162: total training loss 0.00345\n",
            "2025-06-26 08:24:44,095 Epoch 3162: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3163\n",
            "2025-06-26 08:24:44,098 EPOCH 3163\n",
            "INFO:__main__:Epoch 3163: total training loss 0.00365\n",
            "2025-06-26 08:24:44,164 Epoch 3163: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3164\n",
            "2025-06-26 08:24:44,165 EPOCH 3164\n",
            "INFO:__main__:Epoch 3164: total training loss 0.00345\n",
            "2025-06-26 08:24:44,253 Epoch 3164: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3165\n",
            "2025-06-26 08:24:44,255 EPOCH 3165\n",
            "INFO:__main__:Epoch 3165: total training loss 0.00329\n",
            "2025-06-26 08:24:44,321 Epoch 3165: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3166\n",
            "2025-06-26 08:24:44,323 EPOCH 3166\n",
            "INFO:__main__:Epoch 3166: total training loss 0.00358\n",
            "2025-06-26 08:24:44,391 Epoch 3166: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3167\n",
            "2025-06-26 08:24:44,393 EPOCH 3167\n",
            "INFO:__main__:Epoch 3167: total training loss 0.00320\n",
            "2025-06-26 08:24:44,458 Epoch 3167: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3168\n",
            "2025-06-26 08:24:44,460 EPOCH 3168\n",
            "INFO:__main__:Epoch 3168: total training loss 0.00322\n",
            "2025-06-26 08:24:44,527 Epoch 3168: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3169\n",
            "2025-06-26 08:24:44,529 EPOCH 3169\n",
            "INFO:__main__:Epoch 3169: total training loss 0.00333\n",
            "2025-06-26 08:24:44,599 Epoch 3169: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3170\n",
            "2025-06-26 08:24:44,601 EPOCH 3170\n",
            "INFO:__main__:Epoch 3170: total training loss 0.00344\n",
            "2025-06-26 08:24:44,670 Epoch 3170: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3171\n",
            "2025-06-26 08:24:44,672 EPOCH 3171\n",
            "INFO:__main__:Epoch 3171: total training loss 0.00361\n",
            "2025-06-26 08:24:44,740 Epoch 3171: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3172\n",
            "2025-06-26 08:24:44,742 EPOCH 3172\n",
            "INFO:__main__:Epoch 3172: total training loss 0.00354\n",
            "2025-06-26 08:24:44,811 Epoch 3172: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3173\n",
            "2025-06-26 08:24:44,813 EPOCH 3173\n",
            "INFO:__main__:Epoch 3173: total training loss 0.00342\n",
            "2025-06-26 08:24:44,876 Epoch 3173: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 3174\n",
            "2025-06-26 08:24:44,879 EPOCH 3174\n",
            "INFO:__main__:Epoch 3174: total training loss 0.00319\n",
            "2025-06-26 08:24:44,947 Epoch 3174: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3175\n",
            "2025-06-26 08:24:44,949 EPOCH 3175\n",
            "INFO:__main__:Epoch 3175: total training loss 0.00311\n",
            "2025-06-26 08:24:45,021 Epoch 3175: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3176\n",
            "2025-06-26 08:24:45,023 EPOCH 3176\n",
            "INFO:__main__:Epoch 3176: total training loss 0.00311\n",
            "2025-06-26 08:24:45,090 Epoch 3176: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3177\n",
            "2025-06-26 08:24:45,092 EPOCH 3177\n",
            "INFO:__main__:Epoch 3177: total training loss 0.00326\n",
            "2025-06-26 08:24:45,162 Epoch 3177: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3178\n",
            "2025-06-26 08:24:45,164 EPOCH 3178\n",
            "INFO:__main__:Epoch 3178: total training loss 0.00327\n",
            "2025-06-26 08:24:45,248 Epoch 3178: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3179\n",
            "2025-06-26 08:24:45,250 EPOCH 3179\n",
            "INFO:__main__:Epoch 3179: total training loss 0.00329\n",
            "2025-06-26 08:24:45,316 Epoch 3179: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3180\n",
            "2025-06-26 08:24:45,319 EPOCH 3180\n",
            "INFO:__main__:Epoch 3180: total training loss 0.00304\n",
            "2025-06-26 08:24:45,384 Epoch 3180: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3181\n",
            "2025-06-26 08:24:45,387 EPOCH 3181\n",
            "INFO:__main__:Epoch 3181: total training loss 0.00321\n",
            "2025-06-26 08:24:45,454 Epoch 3181: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3182\n",
            "2025-06-26 08:24:45,456 EPOCH 3182\n",
            "INFO:__main__:Epoch 3182: total training loss 0.00344\n",
            "2025-06-26 08:24:45,534 Epoch 3182: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3183\n",
            "2025-06-26 08:24:45,536 EPOCH 3183\n",
            "INFO:__main__:Epoch 3183: total training loss 0.00356\n",
            "2025-06-26 08:24:45,605 Epoch 3183: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3184\n",
            "2025-06-26 08:24:45,607 EPOCH 3184\n",
            "INFO:__main__:Epoch 3184: total training loss 0.00340\n",
            "2025-06-26 08:24:45,675 Epoch 3184: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3185\n",
            "2025-06-26 08:24:45,676 EPOCH 3185\n",
            "INFO:__main__:Epoch 3185: total training loss 0.00345\n",
            "2025-06-26 08:24:45,745 Epoch 3185: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3186\n",
            "2025-06-26 08:24:45,747 EPOCH 3186\n",
            "INFO:__main__:Epoch 3186: total training loss 0.00362\n",
            "2025-06-26 08:24:45,834 Epoch 3186: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3187\n",
            "2025-06-26 08:24:45,842 EPOCH 3187\n",
            "INFO:__main__:Epoch 3187: total training loss 0.00365\n",
            "2025-06-26 08:24:45,947 Epoch 3187: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3188\n",
            "2025-06-26 08:24:45,949 EPOCH 3188\n",
            "INFO:__main__:Epoch 3188: total training loss 0.00397\n",
            "2025-06-26 08:24:46,037 Epoch 3188: total training loss 0.00397\n",
            "INFO:__main__:EPOCH 3189\n",
            "2025-06-26 08:24:46,039 EPOCH 3189\n",
            "INFO:__main__:Epoch 3189: total training loss 0.00385\n",
            "2025-06-26 08:24:46,126 Epoch 3189: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 3190\n",
            "2025-06-26 08:24:46,128 EPOCH 3190\n",
            "INFO:__main__:Epoch 3190: total training loss 0.00377\n",
            "2025-06-26 08:24:46,218 Epoch 3190: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3191\n",
            "2025-06-26 08:24:46,220 EPOCH 3191\n",
            "INFO:__main__:Epoch 3191: total training loss 0.00382\n",
            "2025-06-26 08:24:46,313 Epoch 3191: total training loss 0.00382\n",
            "INFO:__main__:EPOCH 3192\n",
            "2025-06-26 08:24:46,316 EPOCH 3192\n",
            "INFO:__main__:Epoch 3192: total training loss 0.00368\n",
            "2025-06-26 08:24:46,393 Epoch 3192: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3193\n",
            "2025-06-26 08:24:46,395 EPOCH 3193\n",
            "INFO:__main__:Epoch 3193: total training loss 0.00377\n",
            "2025-06-26 08:24:46,463 Epoch 3193: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3194\n",
            "2025-06-26 08:24:46,465 EPOCH 3194\n",
            "INFO:__main__:Epoch 3194: total training loss 0.00372\n",
            "2025-06-26 08:24:46,537 Epoch 3194: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3195\n",
            "2025-06-26 08:24:46,539 EPOCH 3195\n",
            "INFO:__main__:Epoch 3195: total training loss 0.00385\n",
            "2025-06-26 08:24:46,610 Epoch 3195: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 3196\n",
            "2025-06-26 08:24:46,612 EPOCH 3196\n",
            "INFO:__main__:Epoch 3196: total training loss 0.00358\n",
            "2025-06-26 08:24:46,683 Epoch 3196: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3197\n",
            "2025-06-26 08:24:46,685 EPOCH 3197\n",
            "INFO:__main__:Epoch 3197: total training loss 0.00376\n",
            "2025-06-26 08:24:46,759 Epoch 3197: total training loss 0.00376\n",
            "INFO:__main__:EPOCH 3198\n",
            "2025-06-26 08:24:46,761 EPOCH 3198\n",
            "INFO:__main__:Epoch 3198: total training loss 0.00346\n",
            "2025-06-26 08:24:46,834 Epoch 3198: total training loss 0.00346\n",
            "INFO:__main__:EPOCH 3199\n",
            "2025-06-26 08:24:46,835 EPOCH 3199\n",
            "INFO:__main__:Epoch 3199: total training loss 0.00350\n",
            "2025-06-26 08:24:46,914 Epoch 3199: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3200\n",
            "2025-06-26 08:24:46,916 EPOCH 3200\n",
            "INFO:__main__:Epoch 3200: total training loss 0.00354\n",
            "2025-06-26 08:24:46,996 Epoch 3200: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3201\n",
            "2025-06-26 08:24:46,998 EPOCH 3201\n",
            "INFO:__main__:Epoch 3201: total training loss 0.00335\n",
            "2025-06-26 08:24:47,067 Epoch 3201: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3202\n",
            "2025-06-26 08:24:47,069 EPOCH 3202\n",
            "INFO:__main__:Epoch 3202: total training loss 0.00329\n",
            "2025-06-26 08:24:47,138 Epoch 3202: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3203\n",
            "2025-06-26 08:24:47,140 EPOCH 3203\n",
            "INFO:__main__:Epoch 3203: total training loss 0.00316\n",
            "2025-06-26 08:24:47,222 Epoch 3203: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3204\n",
            "2025-06-26 08:24:47,224 EPOCH 3204\n",
            "INFO:__main__:Epoch 3204: total training loss 0.00328\n",
            "2025-06-26 08:24:47,311 Epoch 3204: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3205\n",
            "2025-06-26 08:24:47,318 EPOCH 3205\n",
            "INFO:__main__:Epoch 3205: total training loss 0.00311\n",
            "2025-06-26 08:24:47,426 Epoch 3205: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3206\n",
            "2025-06-26 08:24:47,431 EPOCH 3206\n",
            "INFO:__main__:Epoch 3206: total training loss 0.00314\n",
            "2025-06-26 08:24:47,513 Epoch 3206: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3207\n",
            "2025-06-26 08:24:47,523 EPOCH 3207\n",
            "INFO:__main__:Epoch 3207: total training loss 0.00321\n",
            "2025-06-26 08:24:47,595 Epoch 3207: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3208\n",
            "2025-06-26 08:24:47,601 EPOCH 3208\n",
            "INFO:__main__:Epoch 3208: total training loss 0.00282\n",
            "2025-06-26 08:24:47,700 Epoch 3208: total training loss 0.00282\n",
            "INFO:__main__:EPOCH 3209\n",
            "2025-06-26 08:24:47,702 EPOCH 3209\n",
            "INFO:__main__:Epoch 3209: total training loss 0.00309\n",
            "2025-06-26 08:24:47,809 Epoch 3209: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3210\n",
            "2025-06-26 08:24:47,816 EPOCH 3210\n",
            "INFO:__main__:Epoch 3210: total training loss 0.00323\n",
            "2025-06-26 08:24:47,926 Epoch 3210: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3211\n",
            "2025-06-26 08:24:47,932 EPOCH 3211\n",
            "INFO:__main__:Epoch 3211: total training loss 0.00292\n",
            "2025-06-26 08:24:48,064 Epoch 3211: total training loss 0.00292\n",
            "INFO:__main__:EPOCH 3212\n",
            "2025-06-26 08:24:48,066 EPOCH 3212\n",
            "INFO:__main__:Epoch 3212: total training loss 0.00322\n",
            "2025-06-26 08:24:48,165 Epoch 3212: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3213\n",
            "2025-06-26 08:24:48,172 EPOCH 3213\n",
            "INFO:__main__:Epoch 3213: total training loss 0.00323\n",
            "2025-06-26 08:24:48,269 Epoch 3213: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3214\n",
            "2025-06-26 08:24:48,270 EPOCH 3214\n",
            "INFO:__main__:Epoch 3214: total training loss 0.00414\n",
            "2025-06-26 08:24:48,365 Epoch 3214: total training loss 0.00414\n",
            "INFO:__main__:EPOCH 3215\n",
            "2025-06-26 08:24:48,367 EPOCH 3215\n",
            "INFO:__main__:Epoch 3215: total training loss 0.00362\n",
            "2025-06-26 08:24:48,466 Epoch 3215: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3216\n",
            "2025-06-26 08:24:48,468 EPOCH 3216\n",
            "INFO:__main__:Epoch 3216: total training loss 0.00377\n",
            "2025-06-26 08:24:48,579 Epoch 3216: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3217\n",
            "2025-06-26 08:24:48,581 EPOCH 3217\n",
            "INFO:__main__:Epoch 3217: total training loss 0.00386\n",
            "2025-06-26 08:24:48,652 Epoch 3217: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 3218\n",
            "2025-06-26 08:24:48,654 EPOCH 3218\n",
            "INFO:__main__:Epoch 3218: total training loss 0.00362\n",
            "2025-06-26 08:24:48,725 Epoch 3218: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3219\n",
            "2025-06-26 08:24:48,727 EPOCH 3219\n",
            "INFO:__main__:Epoch 3219: total training loss 0.00360\n",
            "2025-06-26 08:24:48,803 Epoch 3219: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3220\n",
            "2025-06-26 08:24:48,805 EPOCH 3220\n",
            "INFO:__main__:Epoch 3220: total training loss 0.00369\n",
            "2025-06-26 08:24:48,878 Epoch 3220: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3221\n",
            "2025-06-26 08:24:48,880 EPOCH 3221\n",
            "INFO:__main__:Epoch 3221: total training loss 0.00366\n",
            "2025-06-26 08:24:48,969 Epoch 3221: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3222\n",
            "2025-06-26 08:24:48,970 EPOCH 3222\n",
            "INFO:__main__:Epoch 3222: total training loss 0.00400\n",
            "2025-06-26 08:24:49,042 Epoch 3222: total training loss 0.00400\n",
            "INFO:__main__:EPOCH 3223\n",
            "2025-06-26 08:24:49,044 EPOCH 3223\n",
            "INFO:__main__:Epoch 3223: total training loss 0.00373\n",
            "2025-06-26 08:24:49,113 Epoch 3223: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3224\n",
            "2025-06-26 08:24:49,115 EPOCH 3224\n",
            "INFO:__main__:Epoch 3224: total training loss 0.00384\n",
            "2025-06-26 08:24:49,188 Epoch 3224: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3225\n",
            "2025-06-26 08:24:49,190 EPOCH 3225\n",
            "INFO:__main__:Epoch 3225: total training loss 0.00395\n",
            "2025-06-26 08:24:49,259 Epoch 3225: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 3226\n",
            "2025-06-26 08:24:49,261 EPOCH 3226\n",
            "INFO:__main__:Epoch 3226: total training loss 0.00359\n",
            "2025-06-26 08:24:49,335 Epoch 3226: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 3227\n",
            "2025-06-26 08:24:49,337 EPOCH 3227\n",
            "INFO:__main__:Epoch 3227: total training loss 0.00379\n",
            "2025-06-26 08:24:49,404 Epoch 3227: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 3228\n",
            "2025-06-26 08:24:49,407 EPOCH 3228\n",
            "INFO:__main__:Epoch 3228: total training loss 0.00361\n",
            "2025-06-26 08:24:49,482 Epoch 3228: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3229\n",
            "2025-06-26 08:24:49,484 EPOCH 3229\n",
            "INFO:__main__:Epoch 3229: total training loss 0.00362\n",
            "2025-06-26 08:24:49,561 Epoch 3229: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3230\n",
            "2025-06-26 08:24:49,563 EPOCH 3230\n",
            "INFO:__main__:Epoch 3230: total training loss 0.00394\n",
            "2025-06-26 08:24:49,643 Epoch 3230: total training loss 0.00394\n",
            "INFO:__main__:EPOCH 3231\n",
            "2025-06-26 08:24:49,645 EPOCH 3231\n",
            "INFO:__main__:Epoch 3231: total training loss 0.00363\n",
            "2025-06-26 08:24:49,715 Epoch 3231: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3232\n",
            "2025-06-26 08:24:49,716 EPOCH 3232\n",
            "INFO:__main__:Epoch 3232: total training loss 0.00358\n",
            "2025-06-26 08:24:49,807 Epoch 3232: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3233\n",
            "2025-06-26 08:24:49,809 EPOCH 3233\n",
            "INFO:__main__:Epoch 3233: total training loss 0.00354\n",
            "2025-06-26 08:24:49,918 Epoch 3233: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3234\n",
            "2025-06-26 08:24:49,920 EPOCH 3234\n",
            "INFO:__main__:Epoch 3234: total training loss 0.00387\n",
            "2025-06-26 08:24:50,026 Epoch 3234: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3235\n",
            "2025-06-26 08:24:50,036 EPOCH 3235\n",
            "INFO:__main__:Epoch 3235: total training loss 0.00349\n",
            "2025-06-26 08:24:50,144 Epoch 3235: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3236\n",
            "2025-06-26 08:24:50,150 EPOCH 3236\n",
            "INFO:__main__:Epoch 3236: total training loss 0.00347\n",
            "2025-06-26 08:24:50,257 Epoch 3236: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3237\n",
            "2025-06-26 08:24:50,259 EPOCH 3237\n",
            "INFO:__main__:Epoch 3237: total training loss 0.00365\n",
            "2025-06-26 08:24:50,357 Epoch 3237: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3238\n",
            "2025-06-26 08:24:50,359 EPOCH 3238\n",
            "INFO:__main__:Epoch 3238: total training loss 0.00322\n",
            "2025-06-26 08:24:50,452 Epoch 3238: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3239\n",
            "2025-06-26 08:24:50,453 EPOCH 3239\n",
            "INFO:__main__:Epoch 3239: total training loss 0.00334\n",
            "2025-06-26 08:24:50,552 Epoch 3239: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3240\n",
            "2025-06-26 08:24:50,555 EPOCH 3240\n",
            "INFO:__main__:Epoch 3240: total training loss 0.00317\n",
            "2025-06-26 08:24:50,701 Epoch 3240: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3241\n",
            "2025-06-26 08:24:50,704 EPOCH 3241\n",
            "INFO:__main__:Epoch 3241: total training loss 0.00329\n",
            "2025-06-26 08:24:50,823 Epoch 3241: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3242\n",
            "2025-06-26 08:24:50,825 EPOCH 3242\n",
            "INFO:__main__:Epoch 3242: total training loss 0.00330\n",
            "2025-06-26 08:24:50,931 Epoch 3242: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3243\n",
            "2025-06-26 08:24:50,933 EPOCH 3243\n",
            "INFO:__main__:Epoch 3243: total training loss 0.00302\n",
            "2025-06-26 08:24:51,020 Epoch 3243: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3244\n",
            "2025-06-26 08:24:51,022 EPOCH 3244\n",
            "INFO:__main__:Epoch 3244: total training loss 0.00317\n",
            "2025-06-26 08:24:51,100 Epoch 3244: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3245\n",
            "2025-06-26 08:24:51,102 EPOCH 3245\n",
            "INFO:__main__:Epoch 3245: total training loss 0.00328\n",
            "2025-06-26 08:24:51,188 Epoch 3245: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3246\n",
            "2025-06-26 08:24:51,190 EPOCH 3246\n",
            "INFO:__main__:Epoch 3246: total training loss 0.00332\n",
            "2025-06-26 08:24:51,261 Epoch 3246: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3247\n",
            "2025-06-26 08:24:51,263 EPOCH 3247\n",
            "INFO:__main__:Epoch 3247: total training loss 0.00331\n",
            "2025-06-26 08:24:51,335 Epoch 3247: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3248\n",
            "2025-06-26 08:24:51,338 EPOCH 3248\n",
            "INFO:__main__:Epoch 3248: total training loss 0.00329\n",
            "2025-06-26 08:24:51,411 Epoch 3248: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3249\n",
            "2025-06-26 08:24:51,413 EPOCH 3249\n",
            "INFO:__main__:Epoch 3249: total training loss 0.00320\n",
            "2025-06-26 08:24:51,484 Epoch 3249: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3250\n",
            "2025-06-26 08:24:51,486 EPOCH 3250\n",
            "INFO:__main__:Epoch 3250 Step:     3250 Batch Loss:     0.003441 Tokens per Sec:  2081179, Lr: 0.001000\n",
            "2025-06-26 08:24:51,556 Epoch 3250 Step:     3250 Batch Loss:     0.003441 Tokens per Sec:  2081179, Lr: 0.001000\n",
            "INFO:__main__:Epoch 3250: total training loss 0.00344\n",
            "2025-06-26 08:24:51,560 Epoch 3250: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3251\n",
            "2025-06-26 08:24:51,561 EPOCH 3251\n",
            "INFO:__main__:Epoch 3251: total training loss 0.00309\n",
            "2025-06-26 08:24:51,634 Epoch 3251: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3252\n",
            "2025-06-26 08:24:51,636 EPOCH 3252\n",
            "INFO:__main__:Epoch 3252: total training loss 0.00385\n",
            "2025-06-26 08:24:51,704 Epoch 3252: total training loss 0.00385\n",
            "INFO:__main__:EPOCH 3253\n",
            "2025-06-26 08:24:51,706 EPOCH 3253\n",
            "INFO:__main__:Epoch 3253: total training loss 0.00349\n",
            "2025-06-26 08:24:51,793 Epoch 3253: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3254\n",
            "2025-06-26 08:24:51,795 EPOCH 3254\n",
            "INFO:__main__:Epoch 3254: total training loss 0.00372\n",
            "2025-06-26 08:24:51,874 Epoch 3254: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3255\n",
            "2025-06-26 08:24:51,876 EPOCH 3255\n",
            "INFO:__main__:Epoch 3255: total training loss 0.00373\n",
            "2025-06-26 08:24:51,944 Epoch 3255: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3256\n",
            "2025-06-26 08:24:51,946 EPOCH 3256\n",
            "INFO:__main__:Epoch 3256: total training loss 0.00392\n",
            "2025-06-26 08:24:52,016 Epoch 3256: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 3257\n",
            "2025-06-26 08:24:52,017 EPOCH 3257\n",
            "INFO:__main__:Epoch 3257: total training loss 0.00390\n",
            "2025-06-26 08:24:52,093 Epoch 3257: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 3258\n",
            "2025-06-26 08:24:52,095 EPOCH 3258\n",
            "INFO:__main__:Epoch 3258: total training loss 0.00342\n",
            "2025-06-26 08:24:52,164 Epoch 3258: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 3259\n",
            "2025-06-26 08:24:52,166 EPOCH 3259\n",
            "INFO:__main__:Epoch 3259: total training loss 0.00408\n",
            "2025-06-26 08:24:52,238 Epoch 3259: total training loss 0.00408\n",
            "INFO:__main__:EPOCH 3260\n",
            "2025-06-26 08:24:52,240 EPOCH 3260\n",
            "INFO:__main__:Epoch 3260: total training loss 0.00356\n",
            "2025-06-26 08:24:52,308 Epoch 3260: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3261\n",
            "2025-06-26 08:24:52,310 EPOCH 3261\n",
            "INFO:__main__:Epoch 3261: total training loss 0.00375\n",
            "2025-06-26 08:24:52,379 Epoch 3261: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3262\n",
            "2025-06-26 08:24:52,381 EPOCH 3262\n",
            "INFO:__main__:Epoch 3262: total training loss 0.00350\n",
            "2025-06-26 08:24:52,448 Epoch 3262: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3263\n",
            "2025-06-26 08:24:52,450 EPOCH 3263\n",
            "INFO:__main__:Epoch 3263: total training loss 0.00355\n",
            "2025-06-26 08:24:52,518 Epoch 3263: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3264\n",
            "2025-06-26 08:24:52,520 EPOCH 3264\n",
            "INFO:__main__:Epoch 3264: total training loss 0.00392\n",
            "2025-06-26 08:24:52,589 Epoch 3264: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 3265\n",
            "2025-06-26 08:24:52,591 EPOCH 3265\n",
            "INFO:__main__:Epoch 3265: total training loss 0.00355\n",
            "2025-06-26 08:24:52,658 Epoch 3265: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3266\n",
            "2025-06-26 08:24:52,660 EPOCH 3266\n",
            "INFO:__main__:Epoch 3266: total training loss 0.00333\n",
            "2025-06-26 08:24:52,728 Epoch 3266: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3267\n",
            "2025-06-26 08:24:52,730 EPOCH 3267\n",
            "INFO:__main__:Epoch 3267: total training loss 0.00336\n",
            "2025-06-26 08:24:52,812 Epoch 3267: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3268\n",
            "2025-06-26 08:24:52,815 EPOCH 3268\n",
            "INFO:__main__:Epoch 3268: total training loss 0.00352\n",
            "2025-06-26 08:24:52,889 Epoch 3268: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3269\n",
            "2025-06-26 08:24:52,891 EPOCH 3269\n",
            "INFO:__main__:Epoch 3269: total training loss 0.00336\n",
            "2025-06-26 08:24:52,960 Epoch 3269: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3270\n",
            "2025-06-26 08:24:52,961 EPOCH 3270\n",
            "INFO:__main__:Epoch 3270: total training loss 0.00329\n",
            "2025-06-26 08:24:53,028 Epoch 3270: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3271\n",
            "2025-06-26 08:24:53,030 EPOCH 3271\n",
            "INFO:__main__:Epoch 3271: total training loss 0.00347\n",
            "2025-06-26 08:24:53,097 Epoch 3271: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3272\n",
            "2025-06-26 08:24:53,099 EPOCH 3272\n",
            "INFO:__main__:Epoch 3272: total training loss 0.00316\n",
            "2025-06-26 08:24:53,167 Epoch 3272: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3273\n",
            "2025-06-26 08:24:53,169 EPOCH 3273\n",
            "INFO:__main__:Epoch 3273: total training loss 0.00321\n",
            "2025-06-26 08:24:53,242 Epoch 3273: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3274\n",
            "2025-06-26 08:24:53,244 EPOCH 3274\n",
            "INFO:__main__:Epoch 3274: total training loss 0.00349\n",
            "2025-06-26 08:24:53,312 Epoch 3274: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3275\n",
            "2025-06-26 08:24:53,314 EPOCH 3275\n",
            "INFO:__main__:Epoch 3275: total training loss 0.00312\n",
            "2025-06-26 08:24:53,382 Epoch 3275: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3276\n",
            "2025-06-26 08:24:53,384 EPOCH 3276\n",
            "INFO:__main__:Epoch 3276: total training loss 0.00317\n",
            "2025-06-26 08:24:53,449 Epoch 3276: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3277\n",
            "2025-06-26 08:24:53,451 EPOCH 3277\n",
            "INFO:__main__:Epoch 3277: total training loss 0.00328\n",
            "2025-06-26 08:24:53,517 Epoch 3277: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3278\n",
            "2025-06-26 08:24:53,520 EPOCH 3278\n",
            "INFO:__main__:Epoch 3278: total training loss 0.00310\n",
            "2025-06-26 08:24:53,586 Epoch 3278: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3279\n",
            "2025-06-26 08:24:53,588 EPOCH 3279\n",
            "INFO:__main__:Epoch 3279: total training loss 0.00355\n",
            "2025-06-26 08:24:53,653 Epoch 3279: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3280\n",
            "2025-06-26 08:24:53,655 EPOCH 3280\n",
            "INFO:__main__:Epoch 3280: total training loss 0.00391\n",
            "2025-06-26 08:24:53,722 Epoch 3280: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 3281\n",
            "2025-06-26 08:24:53,725 EPOCH 3281\n",
            "INFO:__main__:Epoch 3281: total training loss 0.00351\n",
            "2025-06-26 08:24:53,795 Epoch 3281: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3282\n",
            "2025-06-26 08:24:53,798 EPOCH 3282\n",
            "INFO:__main__:Epoch 3282: total training loss 0.00362\n",
            "2025-06-26 08:24:53,878 Epoch 3282: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3283\n",
            "2025-06-26 08:24:53,882 EPOCH 3283\n",
            "INFO:__main__:Epoch 3283: total training loss 0.00335\n",
            "2025-06-26 08:24:53,948 Epoch 3283: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3284\n",
            "2025-06-26 08:24:53,950 EPOCH 3284\n",
            "INFO:__main__:Epoch 3284: total training loss 0.00354\n",
            "2025-06-26 08:24:54,020 Epoch 3284: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3285\n",
            "2025-06-26 08:24:54,022 EPOCH 3285\n",
            "INFO:__main__:Epoch 3285: total training loss 0.00356\n",
            "2025-06-26 08:24:54,092 Epoch 3285: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3286\n",
            "2025-06-26 08:24:54,094 EPOCH 3286\n",
            "INFO:__main__:Epoch 3286: total training loss 0.00399\n",
            "2025-06-26 08:24:54,160 Epoch 3286: total training loss 0.00399\n",
            "INFO:__main__:EPOCH 3287\n",
            "2025-06-26 08:24:54,162 EPOCH 3287\n",
            "INFO:__main__:Epoch 3287: total training loss 0.00376\n",
            "2025-06-26 08:24:54,235 Epoch 3287: total training loss 0.00376\n",
            "INFO:__main__:EPOCH 3288\n",
            "2025-06-26 08:24:54,237 EPOCH 3288\n",
            "INFO:__main__:Epoch 3288: total training loss 0.00417\n",
            "2025-06-26 08:24:54,308 Epoch 3288: total training loss 0.00417\n",
            "INFO:__main__:EPOCH 3289\n",
            "2025-06-26 08:24:54,311 EPOCH 3289\n",
            "INFO:__main__:Epoch 3289: total training loss 0.00362\n",
            "2025-06-26 08:24:54,379 Epoch 3289: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3290\n",
            "2025-06-26 08:24:54,383 EPOCH 3290\n",
            "INFO:__main__:Epoch 3290: total training loss 0.00373\n",
            "2025-06-26 08:24:54,447 Epoch 3290: total training loss 0.00373\n",
            "INFO:__main__:EPOCH 3291\n",
            "2025-06-26 08:24:54,449 EPOCH 3291\n",
            "INFO:__main__:Epoch 3291: total training loss 0.00397\n",
            "2025-06-26 08:24:54,518 Epoch 3291: total training loss 0.00397\n",
            "INFO:__main__:EPOCH 3292\n",
            "2025-06-26 08:24:54,522 EPOCH 3292\n",
            "INFO:__main__:Epoch 3292: total training loss 0.00355\n",
            "2025-06-26 08:24:54,588 Epoch 3292: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3293\n",
            "2025-06-26 08:24:54,590 EPOCH 3293\n",
            "INFO:__main__:Epoch 3293: total training loss 0.00358\n",
            "2025-06-26 08:24:54,656 Epoch 3293: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3294\n",
            "2025-06-26 08:24:54,658 EPOCH 3294\n",
            "INFO:__main__:Epoch 3294: total training loss 0.00326\n",
            "2025-06-26 08:24:54,726 Epoch 3294: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3295\n",
            "2025-06-26 08:24:54,728 EPOCH 3295\n",
            "INFO:__main__:Epoch 3295: total training loss 0.00370\n",
            "2025-06-26 08:24:54,800 Epoch 3295: total training loss 0.00370\n",
            "INFO:__main__:EPOCH 3296\n",
            "2025-06-26 08:24:54,802 EPOCH 3296\n",
            "INFO:__main__:Epoch 3296: total training loss 0.00357\n",
            "2025-06-26 08:24:54,871 Epoch 3296: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3297\n",
            "2025-06-26 08:24:54,873 EPOCH 3297\n",
            "INFO:__main__:Epoch 3297: total training loss 0.00386\n",
            "2025-06-26 08:24:54,969 Epoch 3297: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 3298\n",
            "2025-06-26 08:24:54,971 EPOCH 3298\n",
            "INFO:__main__:Epoch 3298: total training loss 0.00363\n",
            "2025-06-26 08:24:55,045 Epoch 3298: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3299\n",
            "2025-06-26 08:24:55,046 EPOCH 3299\n",
            "INFO:__main__:Epoch 3299: total training loss 0.00379\n",
            "2025-06-26 08:24:55,112 Epoch 3299: total training loss 0.00379\n",
            "INFO:__main__:EPOCH 3300\n",
            "2025-06-26 08:24:55,113 EPOCH 3300\n",
            "INFO:__main__:Epoch 3300: total training loss 0.00357\n",
            "2025-06-26 08:24:55,181 Epoch 3300: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3301\n",
            "2025-06-26 08:24:55,185 EPOCH 3301\n",
            "INFO:__main__:Epoch 3301: total training loss 0.00370\n",
            "2025-06-26 08:24:55,254 Epoch 3301: total training loss 0.00370\n",
            "INFO:__main__:EPOCH 3302\n",
            "2025-06-26 08:24:55,256 EPOCH 3302\n",
            "INFO:__main__:Epoch 3302: total training loss 0.00354\n",
            "2025-06-26 08:24:55,320 Epoch 3302: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3303\n",
            "2025-06-26 08:24:55,322 EPOCH 3303\n",
            "INFO:__main__:Epoch 3303: total training loss 0.00364\n",
            "2025-06-26 08:24:55,388 Epoch 3303: total training loss 0.00364\n",
            "INFO:__main__:EPOCH 3304\n",
            "2025-06-26 08:24:55,390 EPOCH 3304\n",
            "INFO:__main__:Epoch 3304: total training loss 0.00358\n",
            "2025-06-26 08:24:55,458 Epoch 3304: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3305\n",
            "2025-06-26 08:24:55,460 EPOCH 3305\n",
            "INFO:__main__:Epoch 3305: total training loss 0.00362\n",
            "2025-06-26 08:24:55,529 Epoch 3305: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3306\n",
            "2025-06-26 08:24:55,531 EPOCH 3306\n",
            "INFO:__main__:Epoch 3306: total training loss 0.00371\n",
            "2025-06-26 08:24:55,597 Epoch 3306: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3307\n",
            "2025-06-26 08:24:55,599 EPOCH 3307\n",
            "INFO:__main__:Epoch 3307: total training loss 0.00330\n",
            "2025-06-26 08:24:55,667 Epoch 3307: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3308\n",
            "2025-06-26 08:24:55,669 EPOCH 3308\n",
            "INFO:__main__:Epoch 3308: total training loss 0.00349\n",
            "2025-06-26 08:24:55,734 Epoch 3308: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3309\n",
            "2025-06-26 08:24:55,736 EPOCH 3309\n",
            "INFO:__main__:Epoch 3309: total training loss 0.00335\n",
            "2025-06-26 08:24:55,810 Epoch 3309: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3310\n",
            "2025-06-26 08:24:55,813 EPOCH 3310\n",
            "INFO:__main__:Epoch 3310: total training loss 0.00333\n",
            "2025-06-26 08:24:55,880 Epoch 3310: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3311\n",
            "2025-06-26 08:24:55,882 EPOCH 3311\n",
            "INFO:__main__:Epoch 3311: total training loss 0.00332\n",
            "2025-06-26 08:24:55,949 Epoch 3311: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3312\n",
            "2025-06-26 08:24:55,951 EPOCH 3312\n",
            "INFO:__main__:Epoch 3312: total training loss 0.00333\n",
            "2025-06-26 08:24:56,039 Epoch 3312: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3313\n",
            "2025-06-26 08:24:56,041 EPOCH 3313\n",
            "INFO:__main__:Epoch 3313: total training loss 0.00326\n",
            "2025-06-26 08:24:56,112 Epoch 3313: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3314\n",
            "2025-06-26 08:24:56,114 EPOCH 3314\n",
            "INFO:__main__:Epoch 3314: total training loss 0.00332\n",
            "2025-06-26 08:24:56,179 Epoch 3314: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3315\n",
            "2025-06-26 08:24:56,181 EPOCH 3315\n",
            "INFO:__main__:Epoch 3315: total training loss 0.00335\n",
            "2025-06-26 08:24:56,248 Epoch 3315: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3316\n",
            "2025-06-26 08:24:56,251 EPOCH 3316\n",
            "INFO:__main__:Epoch 3316: total training loss 0.00324\n",
            "2025-06-26 08:24:56,318 Epoch 3316: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3317\n",
            "2025-06-26 08:24:56,321 EPOCH 3317\n",
            "INFO:__main__:Epoch 3317: total training loss 0.00319\n",
            "2025-06-26 08:24:56,387 Epoch 3317: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3318\n",
            "2025-06-26 08:24:56,389 EPOCH 3318\n",
            "INFO:__main__:Epoch 3318: total training loss 0.00326\n",
            "2025-06-26 08:24:56,454 Epoch 3318: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3319\n",
            "2025-06-26 08:24:56,457 EPOCH 3319\n",
            "INFO:__main__:Epoch 3319: total training loss 0.00327\n",
            "2025-06-26 08:24:56,527 Epoch 3319: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3320\n",
            "2025-06-26 08:24:56,529 EPOCH 3320\n",
            "INFO:__main__:Epoch 3320: total training loss 0.00309\n",
            "2025-06-26 08:24:56,598 Epoch 3320: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3321\n",
            "2025-06-26 08:24:56,600 EPOCH 3321\n",
            "INFO:__main__:Epoch 3321: total training loss 0.00333\n",
            "2025-06-26 08:24:56,670 Epoch 3321: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3322\n",
            "2025-06-26 08:24:56,672 EPOCH 3322\n",
            "INFO:__main__:Epoch 3322: total training loss 0.00301\n",
            "2025-06-26 08:24:56,736 Epoch 3322: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3323\n",
            "2025-06-26 08:24:56,738 EPOCH 3323\n",
            "INFO:__main__:Epoch 3323: total training loss 0.00293\n",
            "2025-06-26 08:24:56,806 Epoch 3323: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3324\n",
            "2025-06-26 08:24:56,808 EPOCH 3324\n",
            "INFO:__main__:Epoch 3324: total training loss 0.00311\n",
            "2025-06-26 08:24:56,877 Epoch 3324: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3325\n",
            "2025-06-26 08:24:56,880 EPOCH 3325\n",
            "INFO:__main__:Epoch 3325: total training loss 0.00307\n",
            "2025-06-26 08:24:56,950 Epoch 3325: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3326\n",
            "2025-06-26 08:24:56,952 EPOCH 3326\n",
            "INFO:__main__:Epoch 3326: total training loss 0.00348\n",
            "2025-06-26 08:24:57,030 Epoch 3326: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3327\n",
            "2025-06-26 08:24:57,033 EPOCH 3327\n",
            "INFO:__main__:Epoch 3327: total training loss 0.00347\n",
            "2025-06-26 08:24:57,106 Epoch 3327: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3328\n",
            "2025-06-26 08:24:57,108 EPOCH 3328\n",
            "INFO:__main__:Epoch 3328: total training loss 0.00354\n",
            "2025-06-26 08:24:57,174 Epoch 3328: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3329\n",
            "2025-06-26 08:24:57,176 EPOCH 3329\n",
            "INFO:__main__:Epoch 3329: total training loss 0.00354\n",
            "2025-06-26 08:24:57,246 Epoch 3329: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3330\n",
            "2025-06-26 08:24:57,248 EPOCH 3330\n",
            "INFO:__main__:Epoch 3330: total training loss 0.00339\n",
            "2025-06-26 08:24:57,317 Epoch 3330: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3331\n",
            "2025-06-26 08:24:57,319 EPOCH 3331\n",
            "INFO:__main__:Epoch 3331: total training loss 0.00378\n",
            "2025-06-26 08:24:57,384 Epoch 3331: total training loss 0.00378\n",
            "INFO:__main__:EPOCH 3332\n",
            "2025-06-26 08:24:57,386 EPOCH 3332\n",
            "INFO:__main__:Epoch 3332: total training loss 0.00338\n",
            "2025-06-26 08:24:57,453 Epoch 3332: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3333\n",
            "2025-06-26 08:24:57,455 EPOCH 3333\n",
            "INFO:__main__:Epoch 3333: total training loss 0.00374\n",
            "2025-06-26 08:24:57,524 Epoch 3333: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3334\n",
            "2025-06-26 08:24:57,526 EPOCH 3334\n",
            "INFO:__main__:Epoch 3334: total training loss 0.00356\n",
            "2025-06-26 08:24:57,593 Epoch 3334: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3335\n",
            "2025-06-26 08:24:57,595 EPOCH 3335\n",
            "INFO:__main__:Epoch 3335: total training loss 0.00362\n",
            "2025-06-26 08:24:57,662 Epoch 3335: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3336\n",
            "2025-06-26 08:24:57,664 EPOCH 3336\n",
            "INFO:__main__:Epoch 3336: total training loss 0.00362\n",
            "2025-06-26 08:24:57,728 Epoch 3336: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3337\n",
            "2025-06-26 08:24:57,730 EPOCH 3337\n",
            "INFO:__main__:Epoch 3337: total training loss 0.00391\n",
            "2025-06-26 08:24:57,801 Epoch 3337: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 3338\n",
            "2025-06-26 08:24:57,803 EPOCH 3338\n",
            "INFO:__main__:Epoch 3338: total training loss 0.00351\n",
            "2025-06-26 08:24:57,869 Epoch 3338: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3339\n",
            "2025-06-26 08:24:57,873 EPOCH 3339\n",
            "INFO:__main__:Epoch 3339: total training loss 0.00410\n",
            "2025-06-26 08:24:57,943 Epoch 3339: total training loss 0.00410\n",
            "INFO:__main__:EPOCH 3340\n",
            "2025-06-26 08:24:57,945 EPOCH 3340\n",
            "INFO:__main__:Epoch 3340: total training loss 0.00411\n",
            "2025-06-26 08:24:58,011 Epoch 3340: total training loss 0.00411\n",
            "INFO:__main__:EPOCH 3341\n",
            "2025-06-26 08:24:58,012 EPOCH 3341\n",
            "INFO:__main__:Epoch 3341: total training loss 0.00366\n",
            "2025-06-26 08:24:58,099 Epoch 3341: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3342\n",
            "2025-06-26 08:24:58,101 EPOCH 3342\n",
            "INFO:__main__:Epoch 3342: total training loss 0.00390\n",
            "2025-06-26 08:24:58,170 Epoch 3342: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 3343\n",
            "2025-06-26 08:24:58,172 EPOCH 3343\n",
            "INFO:__main__:Epoch 3343: total training loss 0.00371\n",
            "2025-06-26 08:24:58,241 Epoch 3343: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3344\n",
            "2025-06-26 08:24:58,243 EPOCH 3344\n",
            "INFO:__main__:Epoch 3344: total training loss 0.00352\n",
            "2025-06-26 08:24:58,310 Epoch 3344: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3345\n",
            "2025-06-26 08:24:58,312 EPOCH 3345\n",
            "INFO:__main__:Epoch 3345: total training loss 0.00374\n",
            "2025-06-26 08:24:58,377 Epoch 3345: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3346\n",
            "2025-06-26 08:24:58,380 EPOCH 3346\n",
            "INFO:__main__:Epoch 3346: total training loss 0.00339\n",
            "2025-06-26 08:24:58,444 Epoch 3346: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3347\n",
            "2025-06-26 08:24:58,446 EPOCH 3347\n",
            "INFO:__main__:Epoch 3347: total training loss 0.00358\n",
            "2025-06-26 08:24:58,514 Epoch 3347: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3348\n",
            "2025-06-26 08:24:58,516 EPOCH 3348\n",
            "INFO:__main__:Epoch 3348: total training loss 0.00347\n",
            "2025-06-26 08:24:58,584 Epoch 3348: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3349\n",
            "2025-06-26 08:24:58,586 EPOCH 3349\n",
            "INFO:__main__:Epoch 3349: total training loss 0.00351\n",
            "2025-06-26 08:24:58,655 Epoch 3349: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3350\n",
            "2025-06-26 08:24:58,657 EPOCH 3350\n",
            "INFO:__main__:Epoch 3350: total training loss 0.00332\n",
            "2025-06-26 08:24:58,725 Epoch 3350: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3351\n",
            "2025-06-26 08:24:58,727 EPOCH 3351\n",
            "INFO:__main__:Epoch 3351: total training loss 0.00323\n",
            "2025-06-26 08:24:58,798 Epoch 3351: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3352\n",
            "2025-06-26 08:24:58,799 EPOCH 3352\n",
            "INFO:__main__:Epoch 3352: total training loss 0.00326\n",
            "2025-06-26 08:24:58,867 Epoch 3352: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3353\n",
            "2025-06-26 08:24:58,869 EPOCH 3353\n",
            "INFO:__main__:Epoch 3353: total training loss 0.00336\n",
            "2025-06-26 08:24:58,941 Epoch 3353: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3354\n",
            "2025-06-26 08:24:58,943 EPOCH 3354\n",
            "INFO:__main__:Epoch 3354: total training loss 0.00299\n",
            "2025-06-26 08:24:59,011 Epoch 3354: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3355\n",
            "2025-06-26 08:24:59,013 EPOCH 3355\n",
            "INFO:__main__:Epoch 3355: total training loss 0.00329\n",
            "2025-06-26 08:24:59,080 Epoch 3355: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3356\n",
            "2025-06-26 08:24:59,082 EPOCH 3356\n",
            "INFO:__main__:Epoch 3356: total training loss 0.00329\n",
            "2025-06-26 08:24:59,167 Epoch 3356: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3357\n",
            "2025-06-26 08:24:59,169 EPOCH 3357\n",
            "INFO:__main__:Epoch 3357: total training loss 0.00306\n",
            "2025-06-26 08:24:59,242 Epoch 3357: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3358\n",
            "2025-06-26 08:24:59,244 EPOCH 3358\n",
            "INFO:__main__:Epoch 3358: total training loss 0.00339\n",
            "2025-06-26 08:24:59,314 Epoch 3358: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3359\n",
            "2025-06-26 08:24:59,317 EPOCH 3359\n",
            "INFO:__main__:Epoch 3359: total training loss 0.00329\n",
            "2025-06-26 08:24:59,383 Epoch 3359: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3360\n",
            "2025-06-26 08:24:59,385 EPOCH 3360\n",
            "INFO:__main__:Epoch 3360: total training loss 0.00352\n",
            "2025-06-26 08:24:59,454 Epoch 3360: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3361\n",
            "2025-06-26 08:24:59,457 EPOCH 3361\n",
            "INFO:__main__:Epoch 3361: total training loss 0.00309\n",
            "2025-06-26 08:24:59,527 Epoch 3361: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3362\n",
            "2025-06-26 08:24:59,529 EPOCH 3362\n",
            "INFO:__main__:Epoch 3362: total training loss 0.00331\n",
            "2025-06-26 08:24:59,598 Epoch 3362: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3363\n",
            "2025-06-26 08:24:59,601 EPOCH 3363\n",
            "INFO:__main__:Epoch 3363: total training loss 0.00333\n",
            "2025-06-26 08:24:59,665 Epoch 3363: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3364\n",
            "2025-06-26 08:24:59,667 EPOCH 3364\n",
            "INFO:__main__:Epoch 3364: total training loss 0.00338\n",
            "2025-06-26 08:24:59,732 Epoch 3364: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3365\n",
            "2025-06-26 08:24:59,734 EPOCH 3365\n",
            "INFO:__main__:Epoch 3365: total training loss 0.00369\n",
            "2025-06-26 08:24:59,803 Epoch 3365: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3366\n",
            "2025-06-26 08:24:59,805 EPOCH 3366\n",
            "INFO:__main__:Epoch 3366: total training loss 0.00324\n",
            "2025-06-26 08:24:59,870 Epoch 3366: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3367\n",
            "2025-06-26 08:24:59,872 EPOCH 3367\n",
            "INFO:__main__:Epoch 3367: total training loss 0.00384\n",
            "2025-06-26 08:24:59,939 Epoch 3367: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3368\n",
            "2025-06-26 08:24:59,941 EPOCH 3368\n",
            "INFO:__main__:Epoch 3368: total training loss 0.00335\n",
            "2025-06-26 08:25:00,010 Epoch 3368: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3369\n",
            "2025-06-26 08:25:00,012 EPOCH 3369\n",
            "INFO:__main__:Epoch 3369: total training loss 0.00355\n",
            "2025-06-26 08:25:00,085 Epoch 3369: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3370\n",
            "2025-06-26 08:25:00,088 EPOCH 3370\n",
            "INFO:__main__:Epoch 3370: total training loss 0.00359\n",
            "2025-06-26 08:25:00,157 Epoch 3370: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 3371\n",
            "2025-06-26 08:25:00,160 EPOCH 3371\n",
            "INFO:__main__:Epoch 3371: total training loss 0.00374\n",
            "2025-06-26 08:25:00,249 Epoch 3371: total training loss 0.00374\n",
            "INFO:__main__:EPOCH 3372\n",
            "2025-06-26 08:25:00,251 EPOCH 3372\n",
            "INFO:__main__:Epoch 3372: total training loss 0.00368\n",
            "2025-06-26 08:25:00,321 Epoch 3372: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3373\n",
            "2025-06-26 08:25:00,323 EPOCH 3373\n",
            "INFO:__main__:Epoch 3373: total training loss 0.00335\n",
            "2025-06-26 08:25:00,392 Epoch 3373: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3374\n",
            "2025-06-26 08:25:00,394 EPOCH 3374\n",
            "INFO:__main__:Epoch 3374: total training loss 0.00349\n",
            "2025-06-26 08:25:00,462 Epoch 3374: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3375\n",
            "2025-06-26 08:25:00,464 EPOCH 3375\n",
            "INFO:__main__:Epoch 3375: total training loss 0.00357\n",
            "2025-06-26 08:25:00,531 Epoch 3375: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3376\n",
            "2025-06-26 08:25:00,533 EPOCH 3376\n",
            "INFO:__main__:Epoch 3376: total training loss 0.00344\n",
            "2025-06-26 08:25:00,601 Epoch 3376: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3377\n",
            "2025-06-26 08:25:00,605 EPOCH 3377\n",
            "INFO:__main__:Epoch 3377: total training loss 0.00357\n",
            "2025-06-26 08:25:00,674 Epoch 3377: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3378\n",
            "2025-06-26 08:25:00,677 EPOCH 3378\n",
            "INFO:__main__:Epoch 3378: total training loss 0.00311\n",
            "2025-06-26 08:25:00,742 Epoch 3378: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3379\n",
            "2025-06-26 08:25:00,744 EPOCH 3379\n",
            "INFO:__main__:Epoch 3379: total training loss 0.00341\n",
            "2025-06-26 08:25:00,828 Epoch 3379: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3380\n",
            "2025-06-26 08:25:00,830 EPOCH 3380\n",
            "INFO:__main__:Epoch 3380: total training loss 0.00354\n",
            "2025-06-26 08:25:00,899 Epoch 3380: total training loss 0.00354\n",
            "INFO:__main__:EPOCH 3381\n",
            "2025-06-26 08:25:00,902 EPOCH 3381\n",
            "INFO:__main__:Epoch 3381: total training loss 0.00332\n",
            "2025-06-26 08:25:00,973 Epoch 3381: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3382\n",
            "2025-06-26 08:25:00,977 EPOCH 3382\n",
            "INFO:__main__:Epoch 3382: total training loss 0.00329\n",
            "2025-06-26 08:25:01,062 Epoch 3382: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3383\n",
            "2025-06-26 08:25:01,065 EPOCH 3383\n",
            "INFO:__main__:Epoch 3383: total training loss 0.00336\n",
            "2025-06-26 08:25:01,160 Epoch 3383: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3384\n",
            "2025-06-26 08:25:01,162 EPOCH 3384\n",
            "INFO:__main__:Epoch 3384: total training loss 0.00330\n",
            "2025-06-26 08:25:01,262 Epoch 3384: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3385\n",
            "2025-06-26 08:25:01,264 EPOCH 3385\n",
            "INFO:__main__:Epoch 3385: total training loss 0.00319\n",
            "2025-06-26 08:25:01,347 Epoch 3385: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3386\n",
            "2025-06-26 08:25:01,349 EPOCH 3386\n",
            "INFO:__main__:Epoch 3386: total training loss 0.00368\n",
            "2025-06-26 08:25:01,430 Epoch 3386: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3387\n",
            "2025-06-26 08:25:01,432 EPOCH 3387\n",
            "INFO:__main__:Epoch 3387: total training loss 0.00318\n",
            "2025-06-26 08:25:01,519 Epoch 3387: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3388\n",
            "2025-06-26 08:25:01,521 EPOCH 3388\n",
            "INFO:__main__:Epoch 3388: total training loss 0.00349\n",
            "2025-06-26 08:25:01,621 Epoch 3388: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3389\n",
            "2025-06-26 08:25:01,627 EPOCH 3389\n",
            "INFO:__main__:Epoch 3389: total training loss 0.00383\n",
            "2025-06-26 08:25:01,727 Epoch 3389: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 3390\n",
            "2025-06-26 08:25:01,731 EPOCH 3390\n",
            "INFO:__main__:Epoch 3390: total training loss 0.00375\n",
            "2025-06-26 08:25:01,833 Epoch 3390: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3391\n",
            "2025-06-26 08:25:01,834 EPOCH 3391\n",
            "INFO:__main__:Epoch 3391: total training loss 0.00339\n",
            "2025-06-26 08:25:01,940 Epoch 3391: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3392\n",
            "2025-06-26 08:25:01,942 EPOCH 3392\n",
            "INFO:__main__:Epoch 3392: total training loss 0.00362\n",
            "2025-06-26 08:25:02,034 Epoch 3392: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3393\n",
            "2025-06-26 08:25:02,036 EPOCH 3393\n",
            "INFO:__main__:Epoch 3393: total training loss 0.00361\n",
            "2025-06-26 08:25:02,117 Epoch 3393: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3394\n",
            "2025-06-26 08:25:02,119 EPOCH 3394\n",
            "INFO:__main__:Epoch 3394: total training loss 0.00329\n",
            "2025-06-26 08:25:02,192 Epoch 3394: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3395\n",
            "2025-06-26 08:25:02,194 EPOCH 3395\n",
            "INFO:__main__:Epoch 3395: total training loss 0.00366\n",
            "2025-06-26 08:25:02,266 Epoch 3395: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3396\n",
            "2025-06-26 08:25:02,268 EPOCH 3396\n",
            "INFO:__main__:Epoch 3396: total training loss 0.00330\n",
            "2025-06-26 08:25:02,372 Epoch 3396: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3397\n",
            "2025-06-26 08:25:02,376 EPOCH 3397\n",
            "INFO:__main__:Epoch 3397: total training loss 0.00348\n",
            "2025-06-26 08:25:02,463 Epoch 3397: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3398\n",
            "2025-06-26 08:25:02,470 EPOCH 3398\n",
            "INFO:__main__:Epoch 3398: total training loss 0.00330\n",
            "2025-06-26 08:25:02,555 Epoch 3398: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3399\n",
            "2025-06-26 08:25:02,558 EPOCH 3399\n",
            "INFO:__main__:Epoch 3399: total training loss 0.00327\n",
            "2025-06-26 08:25:02,649 Epoch 3399: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3400\n",
            "2025-06-26 08:25:02,656 EPOCH 3400\n",
            "INFO:__main__:Epoch 3400: total training loss 0.00323\n",
            "2025-06-26 08:25:02,750 Epoch 3400: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3401\n",
            "2025-06-26 08:25:02,751 EPOCH 3401\n",
            "INFO:__main__:Epoch 3401: total training loss 0.00337\n",
            "2025-06-26 08:25:02,839 Epoch 3401: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3402\n",
            "2025-06-26 08:25:02,841 EPOCH 3402\n",
            "INFO:__main__:Epoch 3402: total training loss 0.00309\n",
            "2025-06-26 08:25:02,937 Epoch 3402: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3403\n",
            "2025-06-26 08:25:02,942 EPOCH 3403\n",
            "INFO:__main__:Epoch 3403: total training loss 0.00328\n",
            "2025-06-26 08:25:03,032 Epoch 3403: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3404\n",
            "2025-06-26 08:25:03,038 EPOCH 3404\n",
            "INFO:__main__:Epoch 3404: total training loss 0.00331\n",
            "2025-06-26 08:25:03,134 Epoch 3404: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3405\n",
            "2025-06-26 08:25:03,138 EPOCH 3405\n",
            "INFO:__main__:Epoch 3405: total training loss 0.00297\n",
            "2025-06-26 08:25:03,241 Epoch 3405: total training loss 0.00297\n",
            "INFO:__main__:EPOCH 3406\n",
            "2025-06-26 08:25:03,247 EPOCH 3406\n",
            "INFO:__main__:Epoch 3406: total training loss 0.00318\n",
            "2025-06-26 08:25:03,339 Epoch 3406: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3407\n",
            "2025-06-26 08:25:03,342 EPOCH 3407\n",
            "INFO:__main__:Epoch 3407: total training loss 0.00321\n",
            "2025-06-26 08:25:03,431 Epoch 3407: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3408\n",
            "2025-06-26 08:25:03,433 EPOCH 3408\n",
            "INFO:__main__:Epoch 3408: total training loss 0.00330\n",
            "2025-06-26 08:25:03,512 Epoch 3408: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3409\n",
            "2025-06-26 08:25:03,515 EPOCH 3409\n",
            "INFO:__main__:Epoch 3409: total training loss 0.00351\n",
            "2025-06-26 08:25:03,598 Epoch 3409: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3410\n",
            "2025-06-26 08:25:03,600 EPOCH 3410\n",
            "INFO:__main__:Epoch 3410: total training loss 0.00327\n",
            "2025-06-26 08:25:03,674 Epoch 3410: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3411\n",
            "2025-06-26 08:25:03,676 EPOCH 3411\n",
            "INFO:__main__:Epoch 3411: total training loss 0.00344\n",
            "2025-06-26 08:25:03,748 Epoch 3411: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3412\n",
            "2025-06-26 08:25:03,750 EPOCH 3412\n",
            "INFO:__main__:Epoch 3412: total training loss 0.00340\n",
            "2025-06-26 08:25:03,825 Epoch 3412: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3413\n",
            "2025-06-26 08:25:03,827 EPOCH 3413\n",
            "INFO:__main__:Epoch 3413: total training loss 0.00350\n",
            "2025-06-26 08:25:03,908 Epoch 3413: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3414\n",
            "2025-06-26 08:25:03,911 EPOCH 3414\n",
            "INFO:__main__:Epoch 3414: total training loss 0.00304\n",
            "2025-06-26 08:25:03,987 Epoch 3414: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3415\n",
            "2025-06-26 08:25:03,989 EPOCH 3415\n",
            "INFO:__main__:Epoch 3415: total training loss 0.00329\n",
            "2025-06-26 08:25:04,072 Epoch 3415: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3416\n",
            "2025-06-26 08:25:04,076 EPOCH 3416\n",
            "INFO:__main__:Epoch 3416: total training loss 0.00322\n",
            "2025-06-26 08:25:04,157 Epoch 3416: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3417\n",
            "2025-06-26 08:25:04,159 EPOCH 3417\n",
            "INFO:__main__:Epoch 3417: total training loss 0.00311\n",
            "2025-06-26 08:25:04,239 Epoch 3417: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3418\n",
            "2025-06-26 08:25:04,241 EPOCH 3418\n",
            "INFO:__main__:Epoch 3418: total training loss 0.00316\n",
            "2025-06-26 08:25:04,315 Epoch 3418: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3419\n",
            "2025-06-26 08:25:04,316 EPOCH 3419\n",
            "INFO:__main__:Epoch 3419: total training loss 0.00304\n",
            "2025-06-26 08:25:04,390 Epoch 3419: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3420\n",
            "2025-06-26 08:25:04,392 EPOCH 3420\n",
            "INFO:__main__:Epoch 3420: total training loss 0.00298\n",
            "2025-06-26 08:25:04,464 Epoch 3420: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3421\n",
            "2025-06-26 08:25:04,466 EPOCH 3421\n",
            "INFO:__main__:Epoch 3421: total training loss 0.00306\n",
            "2025-06-26 08:25:04,562 Epoch 3421: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3422\n",
            "2025-06-26 08:25:04,564 EPOCH 3422\n",
            "INFO:__main__:Epoch 3422: total training loss 0.00299\n",
            "2025-06-26 08:25:04,641 Epoch 3422: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3423\n",
            "2025-06-26 08:25:04,647 EPOCH 3423\n",
            "INFO:__main__:Epoch 3423: total training loss 0.00294\n",
            "2025-06-26 08:25:04,741 Epoch 3423: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3424\n",
            "2025-06-26 08:25:04,748 EPOCH 3424\n",
            "INFO:__main__:Epoch 3424: total training loss 0.00323\n",
            "2025-06-26 08:25:04,851 Epoch 3424: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3425\n",
            "2025-06-26 08:25:04,853 EPOCH 3425\n",
            "INFO:__main__:Epoch 3425: total training loss 0.00290\n",
            "2025-06-26 08:25:04,955 Epoch 3425: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3426\n",
            "2025-06-26 08:25:04,957 EPOCH 3426\n",
            "INFO:__main__:Epoch 3426: total training loss 0.00298\n",
            "2025-06-26 08:25:05,066 Epoch 3426: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3427\n",
            "2025-06-26 08:25:05,070 EPOCH 3427\n",
            "INFO:__main__:Epoch 3427: total training loss 0.00294\n",
            "2025-06-26 08:25:05,162 Epoch 3427: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3428\n",
            "2025-06-26 08:25:05,165 EPOCH 3428\n",
            "INFO:__main__:Epoch 3428: total training loss 0.00305\n",
            "2025-06-26 08:25:05,256 Epoch 3428: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3429\n",
            "2025-06-26 08:25:05,259 EPOCH 3429\n",
            "INFO:__main__:Epoch 3429: total training loss 0.00290\n",
            "2025-06-26 08:25:05,331 Epoch 3429: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3430\n",
            "2025-06-26 08:25:05,333 EPOCH 3430\n",
            "INFO:__main__:Epoch 3430: total training loss 0.00324\n",
            "2025-06-26 08:25:05,425 Epoch 3430: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3431\n",
            "2025-06-26 08:25:05,427 EPOCH 3431\n",
            "INFO:__main__:Epoch 3431: total training loss 0.00345\n",
            "2025-06-26 08:25:05,518 Epoch 3431: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3432\n",
            "2025-06-26 08:25:05,524 EPOCH 3432\n",
            "INFO:__main__:Epoch 3432: total training loss 0.00345\n",
            "2025-06-26 08:25:05,618 Epoch 3432: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3433\n",
            "2025-06-26 08:25:05,622 EPOCH 3433\n",
            "INFO:__main__:Epoch 3433: total training loss 0.00351\n",
            "2025-06-26 08:25:05,724 Epoch 3433: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3434\n",
            "2025-06-26 08:25:05,729 EPOCH 3434\n",
            "INFO:__main__:Epoch 3434: total training loss 0.00360\n",
            "2025-06-26 08:25:05,824 Epoch 3434: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3435\n",
            "2025-06-26 08:25:05,827 EPOCH 3435\n",
            "INFO:__main__:Epoch 3435: total training loss 0.00323\n",
            "2025-06-26 08:25:05,916 Epoch 3435: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3436\n",
            "2025-06-26 08:25:05,921 EPOCH 3436\n",
            "INFO:__main__:Epoch 3436: total training loss 0.00328\n",
            "2025-06-26 08:25:06,017 Epoch 3436: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3437\n",
            "2025-06-26 08:25:06,019 EPOCH 3437\n",
            "INFO:__main__:Epoch 3437: total training loss 0.00352\n",
            "2025-06-26 08:25:06,120 Epoch 3437: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3438\n",
            "2025-06-26 08:25:06,125 EPOCH 3438\n",
            "INFO:__main__:Epoch 3438: total training loss 0.00324\n",
            "2025-06-26 08:25:06,206 Epoch 3438: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3439\n",
            "2025-06-26 08:25:06,208 EPOCH 3439\n",
            "INFO:__main__:Epoch 3439: total training loss 0.00338\n",
            "2025-06-26 08:25:06,277 Epoch 3439: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3440\n",
            "2025-06-26 08:25:06,279 EPOCH 3440\n",
            "INFO:__main__:Epoch 3440: total training loss 0.00325\n",
            "2025-06-26 08:25:06,349 Epoch 3440: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3441\n",
            "2025-06-26 08:25:06,351 EPOCH 3441\n",
            "INFO:__main__:Epoch 3441: total training loss 0.00353\n",
            "2025-06-26 08:25:06,420 Epoch 3441: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3442\n",
            "2025-06-26 08:25:06,422 EPOCH 3442\n",
            "INFO:__main__:Epoch 3442: total training loss 0.00361\n",
            "2025-06-26 08:25:06,491 Epoch 3442: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3443\n",
            "2025-06-26 08:25:06,493 EPOCH 3443\n",
            "INFO:__main__:Epoch 3443: total training loss 0.00369\n",
            "2025-06-26 08:25:06,564 Epoch 3443: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3444\n",
            "2025-06-26 08:25:06,567 EPOCH 3444\n",
            "INFO:__main__:Epoch 3444: total training loss 0.00368\n",
            "2025-06-26 08:25:06,636 Epoch 3444: total training loss 0.00368\n",
            "INFO:__main__:EPOCH 3445\n",
            "2025-06-26 08:25:06,638 EPOCH 3445\n",
            "INFO:__main__:Epoch 3445: total training loss 0.00390\n",
            "2025-06-26 08:25:06,722 Epoch 3445: total training loss 0.00390\n",
            "INFO:__main__:EPOCH 3446\n",
            "2025-06-26 08:25:06,724 EPOCH 3446\n",
            "INFO:__main__:Epoch 3446: total training loss 0.00369\n",
            "2025-06-26 08:25:06,798 Epoch 3446: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3447\n",
            "2025-06-26 08:25:06,800 EPOCH 3447\n",
            "INFO:__main__:Epoch 3447: total training loss 0.00350\n",
            "2025-06-26 08:25:06,868 Epoch 3447: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3448\n",
            "2025-06-26 08:25:06,871 EPOCH 3448\n",
            "INFO:__main__:Epoch 3448: total training loss 0.00363\n",
            "2025-06-26 08:25:06,937 Epoch 3448: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3449\n",
            "2025-06-26 08:25:06,939 EPOCH 3449\n",
            "INFO:__main__:Epoch 3449: total training loss 0.00341\n",
            "2025-06-26 08:25:07,004 Epoch 3449: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3450\n",
            "2025-06-26 08:25:07,006 EPOCH 3450\n",
            "INFO:__main__:Epoch 3450: total training loss 0.00338\n",
            "2025-06-26 08:25:07,077 Epoch 3450: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3451\n",
            "2025-06-26 08:25:07,079 EPOCH 3451\n",
            "INFO:__main__:Epoch 3451: total training loss 0.00319\n",
            "2025-06-26 08:25:07,148 Epoch 3451: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3452\n",
            "2025-06-26 08:25:07,150 EPOCH 3452\n",
            "INFO:__main__:Epoch 3452: total training loss 0.00341\n",
            "2025-06-26 08:25:07,221 Epoch 3452: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3453\n",
            "2025-06-26 08:25:07,223 EPOCH 3453\n",
            "INFO:__main__:Epoch 3453: total training loss 0.00326\n",
            "2025-06-26 08:25:07,290 Epoch 3453: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3454\n",
            "2025-06-26 08:25:07,292 EPOCH 3454\n",
            "INFO:__main__:Epoch 3454: total training loss 0.00341\n",
            "2025-06-26 08:25:07,358 Epoch 3454: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3455\n",
            "2025-06-26 08:25:07,360 EPOCH 3455\n",
            "INFO:__main__:Epoch 3455: total training loss 0.00338\n",
            "2025-06-26 08:25:07,426 Epoch 3455: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3456\n",
            "2025-06-26 08:25:07,429 EPOCH 3456\n",
            "INFO:__main__:Epoch 3456: total training loss 0.00329\n",
            "2025-06-26 08:25:07,497 Epoch 3456: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3457\n",
            "2025-06-26 08:25:07,499 EPOCH 3457\n",
            "INFO:__main__:Epoch 3457: total training loss 0.00352\n",
            "2025-06-26 08:25:07,568 Epoch 3457: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3458\n",
            "2025-06-26 08:25:07,570 EPOCH 3458\n",
            "INFO:__main__:Epoch 3458: total training loss 0.00337\n",
            "2025-06-26 08:25:07,639 Epoch 3458: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3459\n",
            "2025-06-26 08:25:07,641 EPOCH 3459\n",
            "INFO:__main__:Epoch 3459: total training loss 0.00339\n",
            "2025-06-26 08:25:07,708 Epoch 3459: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3460\n",
            "2025-06-26 08:25:07,711 EPOCH 3460\n",
            "INFO:__main__:Epoch 3460: total training loss 0.00335\n",
            "2025-06-26 08:25:07,801 Epoch 3460: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3461\n",
            "2025-06-26 08:25:07,803 EPOCH 3461\n",
            "INFO:__main__:Epoch 3461: total training loss 0.00314\n",
            "2025-06-26 08:25:07,873 Epoch 3461: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3462\n",
            "2025-06-26 08:25:07,875 EPOCH 3462\n",
            "INFO:__main__:Epoch 3462: total training loss 0.00302\n",
            "2025-06-26 08:25:07,948 Epoch 3462: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3463\n",
            "2025-06-26 08:25:07,951 EPOCH 3463\n",
            "INFO:__main__:Epoch 3463: total training loss 0.00330\n",
            "2025-06-26 08:25:08,018 Epoch 3463: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3464\n",
            "2025-06-26 08:25:08,020 EPOCH 3464\n",
            "INFO:__main__:Epoch 3464: total training loss 0.00301\n",
            "2025-06-26 08:25:08,089 Epoch 3464: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3465\n",
            "2025-06-26 08:25:08,091 EPOCH 3465\n",
            "INFO:__main__:Epoch 3465: total training loss 0.00310\n",
            "2025-06-26 08:25:08,161 Epoch 3465: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3466\n",
            "2025-06-26 08:25:08,163 EPOCH 3466\n",
            "INFO:__main__:Epoch 3466: total training loss 0.00304\n",
            "2025-06-26 08:25:08,237 Epoch 3466: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3467\n",
            "2025-06-26 08:25:08,239 EPOCH 3467\n",
            "INFO:__main__:Epoch 3467: total training loss 0.00307\n",
            "2025-06-26 08:25:08,307 Epoch 3467: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3468\n",
            "2025-06-26 08:25:08,309 EPOCH 3468\n",
            "INFO:__main__:Epoch 3468: total training loss 0.00293\n",
            "2025-06-26 08:25:08,379 Epoch 3468: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3469\n",
            "2025-06-26 08:25:08,381 EPOCH 3469\n",
            "INFO:__main__:Epoch 3469: total training loss 0.00322\n",
            "2025-06-26 08:25:08,449 Epoch 3469: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3470\n",
            "2025-06-26 08:25:08,452 EPOCH 3470\n",
            "INFO:__main__:Epoch 3470: total training loss 0.00314\n",
            "2025-06-26 08:25:08,527 Epoch 3470: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3471\n",
            "2025-06-26 08:25:08,529 EPOCH 3471\n",
            "INFO:__main__:Epoch 3471: total training loss 0.00349\n",
            "2025-06-26 08:25:08,598 Epoch 3471: total training loss 0.00349\n",
            "INFO:__main__:EPOCH 3472\n",
            "2025-06-26 08:25:08,600 EPOCH 3472\n",
            "INFO:__main__:Epoch 3472: total training loss 0.00325\n",
            "2025-06-26 08:25:08,667 Epoch 3472: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3473\n",
            "2025-06-26 08:25:08,669 EPOCH 3473\n",
            "INFO:__main__:Epoch 3473: total training loss 0.00360\n",
            "2025-06-26 08:25:08,740 Epoch 3473: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3474\n",
            "2025-06-26 08:25:08,742 EPOCH 3474\n",
            "INFO:__main__:Epoch 3474: total training loss 0.00396\n",
            "2025-06-26 08:25:08,832 Epoch 3474: total training loss 0.00396\n",
            "INFO:__main__:EPOCH 3475\n",
            "2025-06-26 08:25:08,834 EPOCH 3475\n",
            "INFO:__main__:Epoch 3475: total training loss 0.00467\n",
            "2025-06-26 08:25:08,900 Epoch 3475: total training loss 0.00467\n",
            "INFO:__main__:EPOCH 3476\n",
            "2025-06-26 08:25:08,902 EPOCH 3476\n",
            "INFO:__main__:Epoch 3476: total training loss 0.00476\n",
            "2025-06-26 08:25:08,971 Epoch 3476: total training loss 0.00476\n",
            "INFO:__main__:EPOCH 3477\n",
            "2025-06-26 08:25:08,973 EPOCH 3477\n",
            "INFO:__main__:Epoch 3477: total training loss 0.00447\n",
            "2025-06-26 08:25:09,038 Epoch 3477: total training loss 0.00447\n",
            "INFO:__main__:EPOCH 3478\n",
            "2025-06-26 08:25:09,040 EPOCH 3478\n",
            "INFO:__main__:Epoch 3478: total training loss 0.00447\n",
            "2025-06-26 08:25:09,113 Epoch 3478: total training loss 0.00447\n",
            "INFO:__main__:EPOCH 3479\n",
            "2025-06-26 08:25:09,115 EPOCH 3479\n",
            "INFO:__main__:Epoch 3479: total training loss 0.00450\n",
            "2025-06-26 08:25:09,183 Epoch 3479: total training loss 0.00450\n",
            "INFO:__main__:EPOCH 3480\n",
            "2025-06-26 08:25:09,187 EPOCH 3480\n",
            "INFO:__main__:Epoch 3480: total training loss 0.00438\n",
            "2025-06-26 08:25:09,256 Epoch 3480: total training loss 0.00438\n",
            "INFO:__main__:EPOCH 3481\n",
            "2025-06-26 08:25:09,258 EPOCH 3481\n",
            "INFO:__main__:Epoch 3481: total training loss 0.00426\n",
            "2025-06-26 08:25:09,327 Epoch 3481: total training loss 0.00426\n",
            "INFO:__main__:EPOCH 3482\n",
            "2025-06-26 08:25:09,329 EPOCH 3482\n",
            "INFO:__main__:Epoch 3482: total training loss 0.00407\n",
            "2025-06-26 08:25:09,399 Epoch 3482: total training loss 0.00407\n",
            "INFO:__main__:EPOCH 3483\n",
            "2025-06-26 08:25:09,403 EPOCH 3483\n",
            "INFO:__main__:Epoch 3483: total training loss 0.00387\n",
            "2025-06-26 08:25:09,467 Epoch 3483: total training loss 0.00387\n",
            "INFO:__main__:EPOCH 3484\n",
            "2025-06-26 08:25:09,469 EPOCH 3484\n",
            "INFO:__main__:Epoch 3484: total training loss 0.00357\n",
            "2025-06-26 08:25:09,538 Epoch 3484: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3485\n",
            "2025-06-26 08:25:09,540 EPOCH 3485\n",
            "INFO:__main__:Epoch 3485: total training loss 0.00363\n",
            "2025-06-26 08:25:09,611 Epoch 3485: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3486\n",
            "2025-06-26 08:25:09,613 EPOCH 3486\n",
            "INFO:__main__:Epoch 3486: total training loss 0.00344\n",
            "2025-06-26 08:25:09,681 Epoch 3486: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3487\n",
            "2025-06-26 08:25:09,683 EPOCH 3487\n",
            "INFO:__main__:Epoch 3487: total training loss 0.00384\n",
            "2025-06-26 08:25:09,749 Epoch 3487: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3488\n",
            "2025-06-26 08:25:09,751 EPOCH 3488\n",
            "INFO:__main__:Epoch 3488: total training loss 0.00343\n",
            "2025-06-26 08:25:09,820 Epoch 3488: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3489\n",
            "2025-06-26 08:25:09,825 EPOCH 3489\n",
            "INFO:__main__:Epoch 3489: total training loss 0.00391\n",
            "2025-06-26 08:25:09,907 Epoch 3489: total training loss 0.00391\n",
            "INFO:__main__:EPOCH 3490\n",
            "2025-06-26 08:25:09,911 EPOCH 3490\n",
            "INFO:__main__:Epoch 3490: total training loss 0.00369\n",
            "2025-06-26 08:25:09,979 Epoch 3490: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3491\n",
            "2025-06-26 08:25:09,981 EPOCH 3491\n",
            "INFO:__main__:Epoch 3491: total training loss 0.00353\n",
            "2025-06-26 08:25:10,049 Epoch 3491: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3492\n",
            "2025-06-26 08:25:10,051 EPOCH 3492\n",
            "INFO:__main__:Epoch 3492: total training loss 0.00347\n",
            "2025-06-26 08:25:10,120 Epoch 3492: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3493\n",
            "2025-06-26 08:25:10,122 EPOCH 3493\n",
            "INFO:__main__:Epoch 3493: total training loss 0.00343\n",
            "2025-06-26 08:25:10,192 Epoch 3493: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3494\n",
            "2025-06-26 08:25:10,194 EPOCH 3494\n",
            "INFO:__main__:Epoch 3494: total training loss 0.00332\n",
            "2025-06-26 08:25:10,268 Epoch 3494: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3495\n",
            "2025-06-26 08:25:10,270 EPOCH 3495\n",
            "INFO:__main__:Epoch 3495: total training loss 0.00324\n",
            "2025-06-26 08:25:10,337 Epoch 3495: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3496\n",
            "2025-06-26 08:25:10,341 EPOCH 3496\n",
            "INFO:__main__:Epoch 3496: total training loss 0.00314\n",
            "2025-06-26 08:25:10,408 Epoch 3496: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3497\n",
            "2025-06-26 08:25:10,410 EPOCH 3497\n",
            "INFO:__main__:Epoch 3497: total training loss 0.00326\n",
            "2025-06-26 08:25:10,480 Epoch 3497: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3498\n",
            "2025-06-26 08:25:10,481 EPOCH 3498\n",
            "INFO:__main__:Epoch 3498: total training loss 0.00322\n",
            "2025-06-26 08:25:10,553 Epoch 3498: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3499\n",
            "2025-06-26 08:25:10,555 EPOCH 3499\n",
            "INFO:__main__:Epoch 3499: total training loss 0.00325\n",
            "2025-06-26 08:25:10,624 Epoch 3499: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3500\n",
            "2025-06-26 08:25:10,626 EPOCH 3500\n",
            "INFO:__main__:Epoch 3500 Step:     3500 Batch Loss:     0.003141 Tokens per Sec:  2231319, Lr: 0.001000\n",
            "2025-06-26 08:25:10,691 Epoch 3500 Step:     3500 Batch Loss:     0.003141 Tokens per Sec:  2231319, Lr: 0.001000\n",
            "INFO:__main__:Epoch 3500: total training loss 0.00314\n",
            "2025-06-26 08:25:10,693 Epoch 3500: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3501\n",
            "2025-06-26 08:25:10,694 EPOCH 3501\n",
            "INFO:__main__:Epoch 3501: total training loss 0.00298\n",
            "2025-06-26 08:25:10,765 Epoch 3501: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3502\n",
            "2025-06-26 08:25:10,767 EPOCH 3502\n",
            "INFO:__main__:Epoch 3502: total training loss 0.00289\n",
            "2025-06-26 08:25:10,841 Epoch 3502: total training loss 0.00289\n",
            "INFO:__main__:EPOCH 3503\n",
            "2025-06-26 08:25:10,843 EPOCH 3503\n",
            "INFO:__main__:Epoch 3503: total training loss 0.00298\n",
            "2025-06-26 08:25:10,927 Epoch 3503: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3504\n",
            "2025-06-26 08:25:10,928 EPOCH 3504\n",
            "INFO:__main__:Epoch 3504: total training loss 0.00311\n",
            "2025-06-26 08:25:10,994 Epoch 3504: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3505\n",
            "2025-06-26 08:25:10,996 EPOCH 3505\n",
            "INFO:__main__:Epoch 3505: total training loss 0.00312\n",
            "2025-06-26 08:25:11,062 Epoch 3505: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3506\n",
            "2025-06-26 08:25:11,064 EPOCH 3506\n",
            "INFO:__main__:Epoch 3506: total training loss 0.00303\n",
            "2025-06-26 08:25:11,138 Epoch 3506: total training loss 0.00303\n",
            "INFO:__main__:EPOCH 3507\n",
            "2025-06-26 08:25:11,140 EPOCH 3507\n",
            "INFO:__main__:Epoch 3507: total training loss 0.00309\n",
            "2025-06-26 08:25:11,209 Epoch 3507: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3508\n",
            "2025-06-26 08:25:11,211 EPOCH 3508\n",
            "INFO:__main__:Epoch 3508: total training loss 0.00284\n",
            "2025-06-26 08:25:11,276 Epoch 3508: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 3509\n",
            "2025-06-26 08:25:11,278 EPOCH 3509\n",
            "INFO:__main__:Epoch 3509: total training loss 0.00304\n",
            "2025-06-26 08:25:11,348 Epoch 3509: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3510\n",
            "2025-06-26 08:25:11,350 EPOCH 3510\n",
            "INFO:__main__:Epoch 3510: total training loss 0.00300\n",
            "2025-06-26 08:25:11,421 Epoch 3510: total training loss 0.00300\n",
            "INFO:__main__:EPOCH 3511\n",
            "2025-06-26 08:25:11,423 EPOCH 3511\n",
            "INFO:__main__:Epoch 3511: total training loss 0.00321\n",
            "2025-06-26 08:25:11,488 Epoch 3511: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3512\n",
            "2025-06-26 08:25:11,490 EPOCH 3512\n",
            "INFO:__main__:Epoch 3512: total training loss 0.00352\n",
            "2025-06-26 08:25:11,567 Epoch 3512: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3513\n",
            "2025-06-26 08:25:11,569 EPOCH 3513\n",
            "INFO:__main__:Epoch 3513: total training loss 0.00346\n",
            "2025-06-26 08:25:11,642 Epoch 3513: total training loss 0.00346\n",
            "INFO:__main__:EPOCH 3514\n",
            "2025-06-26 08:25:11,644 EPOCH 3514\n",
            "INFO:__main__:Epoch 3514: total training loss 0.00358\n",
            "2025-06-26 08:25:11,712 Epoch 3514: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3515\n",
            "2025-06-26 08:25:11,713 EPOCH 3515\n",
            "INFO:__main__:Epoch 3515: total training loss 0.00333\n",
            "2025-06-26 08:25:11,784 Epoch 3515: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3516\n",
            "2025-06-26 08:25:11,785 EPOCH 3516\n",
            "INFO:__main__:Epoch 3516: total training loss 0.00366\n",
            "2025-06-26 08:25:11,856 Epoch 3516: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3517\n",
            "2025-06-26 08:25:11,858 EPOCH 3517\n",
            "INFO:__main__:Epoch 3517: total training loss 0.00358\n",
            "2025-06-26 08:25:11,935 Epoch 3517: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3518\n",
            "2025-06-26 08:25:11,937 EPOCH 3518\n",
            "INFO:__main__:Epoch 3518: total training loss 0.00350\n",
            "2025-06-26 08:25:12,012 Epoch 3518: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3519\n",
            "2025-06-26 08:25:12,014 EPOCH 3519\n",
            "INFO:__main__:Epoch 3519: total training loss 0.00377\n",
            "2025-06-26 08:25:12,082 Epoch 3519: total training loss 0.00377\n",
            "INFO:__main__:EPOCH 3520\n",
            "2025-06-26 08:25:12,085 EPOCH 3520\n",
            "INFO:__main__:Epoch 3520: total training loss 0.00357\n",
            "2025-06-26 08:25:12,156 Epoch 3520: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3521\n",
            "2025-06-26 08:25:12,158 EPOCH 3521\n",
            "INFO:__main__:Epoch 3521: total training loss 0.00363\n",
            "2025-06-26 08:25:12,227 Epoch 3521: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3522\n",
            "2025-06-26 08:25:12,229 EPOCH 3522\n",
            "INFO:__main__:Epoch 3522: total training loss 0.00353\n",
            "2025-06-26 08:25:12,301 Epoch 3522: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3523\n",
            "2025-06-26 08:25:12,303 EPOCH 3523\n",
            "INFO:__main__:Epoch 3523: total training loss 0.00333\n",
            "2025-06-26 08:25:12,379 Epoch 3523: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3524\n",
            "2025-06-26 08:25:12,381 EPOCH 3524\n",
            "INFO:__main__:Epoch 3524: total training loss 0.00372\n",
            "2025-06-26 08:25:12,449 Epoch 3524: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3525\n",
            "2025-06-26 08:25:12,451 EPOCH 3525\n",
            "INFO:__main__:Epoch 3525: total training loss 0.00331\n",
            "2025-06-26 08:25:12,518 Epoch 3525: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3526\n",
            "2025-06-26 08:25:12,520 EPOCH 3526\n",
            "INFO:__main__:Epoch 3526: total training loss 0.00326\n",
            "2025-06-26 08:25:12,589 Epoch 3526: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3527\n",
            "2025-06-26 08:25:12,591 EPOCH 3527\n",
            "INFO:__main__:Epoch 3527: total training loss 0.00326\n",
            "2025-06-26 08:25:12,662 Epoch 3527: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3528\n",
            "2025-06-26 08:25:12,664 EPOCH 3528\n",
            "INFO:__main__:Epoch 3528: total training loss 0.00328\n",
            "2025-06-26 08:25:12,730 Epoch 3528: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3529\n",
            "2025-06-26 08:25:12,733 EPOCH 3529\n",
            "INFO:__main__:Epoch 3529: total training loss 0.00312\n",
            "2025-06-26 08:25:12,799 Epoch 3529: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3530\n",
            "2025-06-26 08:25:12,802 EPOCH 3530\n",
            "INFO:__main__:Epoch 3530: total training loss 0.00312\n",
            "2025-06-26 08:25:12,870 Epoch 3530: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3531\n",
            "2025-06-26 08:25:12,872 EPOCH 3531\n",
            "INFO:__main__:Epoch 3531: total training loss 0.00331\n",
            "2025-06-26 08:25:12,939 Epoch 3531: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3532\n",
            "2025-06-26 08:25:12,941 EPOCH 3532\n",
            "INFO:__main__:Epoch 3532: total training loss 0.00324\n",
            "2025-06-26 08:25:13,026 Epoch 3532: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3533\n",
            "2025-06-26 08:25:13,029 EPOCH 3533\n",
            "INFO:__main__:Epoch 3533: total training loss 0.00335\n",
            "2025-06-26 08:25:13,102 Epoch 3533: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3534\n",
            "2025-06-26 08:25:13,105 EPOCH 3534\n",
            "INFO:__main__:Epoch 3534: total training loss 0.00337\n",
            "2025-06-26 08:25:13,175 Epoch 3534: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3535\n",
            "2025-06-26 08:25:13,177 EPOCH 3535\n",
            "INFO:__main__:Epoch 3535: total training loss 0.00323\n",
            "2025-06-26 08:25:13,247 Epoch 3535: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3536\n",
            "2025-06-26 08:25:13,249 EPOCH 3536\n",
            "INFO:__main__:Epoch 3536: total training loss 0.00329\n",
            "2025-06-26 08:25:13,317 Epoch 3536: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3537\n",
            "2025-06-26 08:25:13,318 EPOCH 3537\n",
            "INFO:__main__:Epoch 3537: total training loss 0.00328\n",
            "2025-06-26 08:25:13,386 Epoch 3537: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3538\n",
            "2025-06-26 08:25:13,388 EPOCH 3538\n",
            "INFO:__main__:Epoch 3538: total training loss 0.00318\n",
            "2025-06-26 08:25:13,455 Epoch 3538: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3539\n",
            "2025-06-26 08:25:13,458 EPOCH 3539\n",
            "INFO:__main__:Epoch 3539: total training loss 0.00331\n",
            "2025-06-26 08:25:13,526 Epoch 3539: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3540\n",
            "2025-06-26 08:25:13,528 EPOCH 3540\n",
            "INFO:__main__:Epoch 3540: total training loss 0.00291\n",
            "2025-06-26 08:25:13,598 Epoch 3540: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 3541\n",
            "2025-06-26 08:25:13,600 EPOCH 3541\n",
            "INFO:__main__:Epoch 3541: total training loss 0.00334\n",
            "2025-06-26 08:25:13,669 Epoch 3541: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3542\n",
            "2025-06-26 08:25:13,672 EPOCH 3542\n",
            "INFO:__main__:Epoch 3542: total training loss 0.00357\n",
            "2025-06-26 08:25:13,737 Epoch 3542: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3543\n",
            "2025-06-26 08:25:13,739 EPOCH 3543\n",
            "INFO:__main__:Epoch 3543: total training loss 0.00339\n",
            "2025-06-26 08:25:13,809 Epoch 3543: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3544\n",
            "2025-06-26 08:25:13,811 EPOCH 3544\n",
            "INFO:__main__:Epoch 3544: total training loss 0.00333\n",
            "2025-06-26 08:25:13,881 Epoch 3544: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3545\n",
            "2025-06-26 08:25:13,883 EPOCH 3545\n",
            "INFO:__main__:Epoch 3545: total training loss 0.00322\n",
            "2025-06-26 08:25:13,951 Epoch 3545: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3546\n",
            "2025-06-26 08:25:13,952 EPOCH 3546\n",
            "INFO:__main__:Epoch 3546: total training loss 0.00352\n",
            "2025-06-26 08:25:14,028 Epoch 3546: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3547\n",
            "2025-06-26 08:25:14,030 EPOCH 3547\n",
            "INFO:__main__:Epoch 3547: total training loss 0.00322\n",
            "2025-06-26 08:25:14,101 Epoch 3547: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3548\n",
            "2025-06-26 08:25:14,104 EPOCH 3548\n",
            "INFO:__main__:Epoch 3548: total training loss 0.00334\n",
            "2025-06-26 08:25:14,170 Epoch 3548: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3549\n",
            "2025-06-26 08:25:14,173 EPOCH 3549\n",
            "INFO:__main__:Epoch 3549: total training loss 0.00342\n",
            "2025-06-26 08:25:14,242 Epoch 3549: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 3550\n",
            "2025-06-26 08:25:14,245 EPOCH 3550\n",
            "INFO:__main__:Epoch 3550: total training loss 0.00344\n",
            "2025-06-26 08:25:14,315 Epoch 3550: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3551\n",
            "2025-06-26 08:25:14,317 EPOCH 3551\n",
            "INFO:__main__:Epoch 3551: total training loss 0.00331\n",
            "2025-06-26 08:25:14,386 Epoch 3551: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3552\n",
            "2025-06-26 08:25:14,388 EPOCH 3552\n",
            "INFO:__main__:Epoch 3552: total training loss 0.00346\n",
            "2025-06-26 08:25:14,456 Epoch 3552: total training loss 0.00346\n",
            "INFO:__main__:EPOCH 3553\n",
            "2025-06-26 08:25:14,458 EPOCH 3553\n",
            "INFO:__main__:Epoch 3553: total training loss 0.00319\n",
            "2025-06-26 08:25:14,526 Epoch 3553: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3554\n",
            "2025-06-26 08:25:14,528 EPOCH 3554\n",
            "INFO:__main__:Epoch 3554: total training loss 0.00339\n",
            "2025-06-26 08:25:14,595 Epoch 3554: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3555\n",
            "2025-06-26 08:25:14,597 EPOCH 3555\n",
            "INFO:__main__:Epoch 3555: total training loss 0.00322\n",
            "2025-06-26 08:25:14,666 Epoch 3555: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3556\n",
            "2025-06-26 08:25:14,668 EPOCH 3556\n",
            "INFO:__main__:Epoch 3556: total training loss 0.00327\n",
            "2025-06-26 08:25:14,735 Epoch 3556: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3557\n",
            "2025-06-26 08:25:14,737 EPOCH 3557\n",
            "INFO:__main__:Epoch 3557: total training loss 0.00318\n",
            "2025-06-26 08:25:14,809 Epoch 3557: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3558\n",
            "2025-06-26 08:25:14,811 EPOCH 3558\n",
            "INFO:__main__:Epoch 3558: total training loss 0.00313\n",
            "2025-06-26 08:25:14,884 Epoch 3558: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3559\n",
            "2025-06-26 08:25:14,886 EPOCH 3559\n",
            "INFO:__main__:Epoch 3559: total training loss 0.00323\n",
            "2025-06-26 08:25:14,961 Epoch 3559: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3560\n",
            "2025-06-26 08:25:14,964 EPOCH 3560\n",
            "INFO:__main__:Epoch 3560: total training loss 0.00290\n",
            "2025-06-26 08:25:15,033 Epoch 3560: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3561\n",
            "2025-06-26 08:25:15,035 EPOCH 3561\n",
            "INFO:__main__:Epoch 3561: total training loss 0.00299\n",
            "2025-06-26 08:25:15,124 Epoch 3561: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3562\n",
            "2025-06-26 08:25:15,126 EPOCH 3562\n",
            "INFO:__main__:Epoch 3562: total training loss 0.00293\n",
            "2025-06-26 08:25:15,196 Epoch 3562: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3563\n",
            "2025-06-26 08:25:15,198 EPOCH 3563\n",
            "INFO:__main__:Epoch 3563: total training loss 0.00280\n",
            "2025-06-26 08:25:15,265 Epoch 3563: total training loss 0.00280\n",
            "INFO:__main__:EPOCH 3564\n",
            "2025-06-26 08:25:15,267 EPOCH 3564\n",
            "INFO:__main__:Epoch 3564: total training loss 0.00296\n",
            "2025-06-26 08:25:15,334 Epoch 3564: total training loss 0.00296\n",
            "INFO:__main__:EPOCH 3565\n",
            "2025-06-26 08:25:15,336 EPOCH 3565\n",
            "INFO:__main__:Epoch 3565: total training loss 0.00278\n",
            "2025-06-26 08:25:15,403 Epoch 3565: total training loss 0.00278\n",
            "INFO:__main__:EPOCH 3566\n",
            "2025-06-26 08:25:15,405 EPOCH 3566\n",
            "INFO:__main__:Epoch 3566: total training loss 0.00274\n",
            "2025-06-26 08:25:15,472 Epoch 3566: total training loss 0.00274\n",
            "INFO:__main__:EPOCH 3567\n",
            "2025-06-26 08:25:15,475 EPOCH 3567\n",
            "INFO:__main__:Epoch 3567: total training loss 0.00287\n",
            "2025-06-26 08:25:15,543 Epoch 3567: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 3568\n",
            "2025-06-26 08:25:15,545 EPOCH 3568\n",
            "INFO:__main__:Epoch 3568: total training loss 0.00303\n",
            "2025-06-26 08:25:15,613 Epoch 3568: total training loss 0.00303\n",
            "INFO:__main__:EPOCH 3569\n",
            "2025-06-26 08:25:15,615 EPOCH 3569\n",
            "INFO:__main__:Epoch 3569: total training loss 0.00338\n",
            "2025-06-26 08:25:15,683 Epoch 3569: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3570\n",
            "2025-06-26 08:25:15,685 EPOCH 3570\n",
            "INFO:__main__:Epoch 3570: total training loss 0.00369\n",
            "2025-06-26 08:25:15,751 Epoch 3570: total training loss 0.00369\n",
            "INFO:__main__:EPOCH 3571\n",
            "2025-06-26 08:25:15,754 EPOCH 3571\n",
            "INFO:__main__:Epoch 3571: total training loss 0.00344\n",
            "2025-06-26 08:25:15,823 Epoch 3571: total training loss 0.00344\n",
            "INFO:__main__:EPOCH 3572\n",
            "2025-06-26 08:25:15,826 EPOCH 3572\n",
            "INFO:__main__:Epoch 3572: total training loss 0.00367\n",
            "2025-06-26 08:25:15,897 Epoch 3572: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3573\n",
            "2025-06-26 08:25:15,899 EPOCH 3573\n",
            "INFO:__main__:Epoch 3573: total training loss 0.00370\n",
            "2025-06-26 08:25:15,970 Epoch 3573: total training loss 0.00370\n",
            "INFO:__main__:EPOCH 3574\n",
            "2025-06-26 08:25:15,973 EPOCH 3574\n",
            "INFO:__main__:Epoch 3574: total training loss 0.00345\n",
            "2025-06-26 08:25:16,055 Epoch 3574: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3575\n",
            "2025-06-26 08:25:16,057 EPOCH 3575\n",
            "INFO:__main__:Epoch 3575: total training loss 0.00356\n",
            "2025-06-26 08:25:16,135 Epoch 3575: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3576\n",
            "2025-06-26 08:25:16,138 EPOCH 3576\n",
            "INFO:__main__:Epoch 3576: total training loss 0.00380\n",
            "2025-06-26 08:25:16,211 Epoch 3576: total training loss 0.00380\n",
            "INFO:__main__:EPOCH 3577\n",
            "2025-06-26 08:25:16,213 EPOCH 3577\n",
            "INFO:__main__:Epoch 3577: total training loss 0.00339\n",
            "2025-06-26 08:25:16,310 Epoch 3577: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3578\n",
            "2025-06-26 08:25:16,312 EPOCH 3578\n",
            "INFO:__main__:Epoch 3578: total training loss 0.00350\n",
            "2025-06-26 08:25:16,393 Epoch 3578: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3579\n",
            "2025-06-26 08:25:16,395 EPOCH 3579\n",
            "INFO:__main__:Epoch 3579: total training loss 0.00336\n",
            "2025-06-26 08:25:16,478 Epoch 3579: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3580\n",
            "2025-06-26 08:25:16,484 EPOCH 3580\n",
            "INFO:__main__:Epoch 3580: total training loss 0.00330\n",
            "2025-06-26 08:25:16,577 Epoch 3580: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3581\n",
            "2025-06-26 08:25:16,579 EPOCH 3581\n",
            "INFO:__main__:Epoch 3581: total training loss 0.00345\n",
            "2025-06-26 08:25:16,666 Epoch 3581: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3582\n",
            "2025-06-26 08:25:16,668 EPOCH 3582\n",
            "INFO:__main__:Epoch 3582: total training loss 0.00321\n",
            "2025-06-26 08:25:16,762 Epoch 3582: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3583\n",
            "2025-06-26 08:25:16,764 EPOCH 3583\n",
            "INFO:__main__:Epoch 3583: total training loss 0.00348\n",
            "2025-06-26 08:25:16,844 Epoch 3583: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3584\n",
            "2025-06-26 08:25:16,846 EPOCH 3584\n",
            "INFO:__main__:Epoch 3584: total training loss 0.00335\n",
            "2025-06-26 08:25:16,921 Epoch 3584: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3585\n",
            "2025-06-26 08:25:16,923 EPOCH 3585\n",
            "INFO:__main__:Epoch 3585: total training loss 0.00341\n",
            "2025-06-26 08:25:17,003 Epoch 3585: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3586\n",
            "2025-06-26 08:25:17,011 EPOCH 3586\n",
            "INFO:__main__:Epoch 3586: total training loss 0.00329\n",
            "2025-06-26 08:25:17,087 Epoch 3586: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3587\n",
            "2025-06-26 08:25:17,093 EPOCH 3587\n",
            "INFO:__main__:Epoch 3587: total training loss 0.00321\n",
            "2025-06-26 08:25:17,217 Epoch 3587: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3588\n",
            "2025-06-26 08:25:17,226 EPOCH 3588\n",
            "INFO:__main__:Epoch 3588: total training loss 0.00311\n",
            "2025-06-26 08:25:17,323 Epoch 3588: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3589\n",
            "2025-06-26 08:25:17,325 EPOCH 3589\n",
            "INFO:__main__:Epoch 3589: total training loss 0.00334\n",
            "2025-06-26 08:25:17,426 Epoch 3589: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3590\n",
            "2025-06-26 08:25:17,428 EPOCH 3590\n",
            "INFO:__main__:Epoch 3590: total training loss 0.00313\n",
            "2025-06-26 08:25:17,510 Epoch 3590: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3591\n",
            "2025-06-26 08:25:17,512 EPOCH 3591\n",
            "INFO:__main__:Epoch 3591: total training loss 0.00332\n",
            "2025-06-26 08:25:17,605 Epoch 3591: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3592\n",
            "2025-06-26 08:25:17,607 EPOCH 3592\n",
            "INFO:__main__:Epoch 3592: total training loss 0.00339\n",
            "2025-06-26 08:25:17,696 Epoch 3592: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3593\n",
            "2025-06-26 08:25:17,698 EPOCH 3593\n",
            "INFO:__main__:Epoch 3593: total training loss 0.00284\n",
            "2025-06-26 08:25:17,785 Epoch 3593: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 3594\n",
            "2025-06-26 08:25:17,787 EPOCH 3594\n",
            "INFO:__main__:Epoch 3594: total training loss 0.00317\n",
            "2025-06-26 08:25:17,887 Epoch 3594: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3595\n",
            "2025-06-26 08:25:17,893 EPOCH 3595\n",
            "INFO:__main__:Epoch 3595: total training loss 0.00323\n",
            "2025-06-26 08:25:17,978 Epoch 3595: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3596\n",
            "2025-06-26 08:25:17,980 EPOCH 3596\n",
            "INFO:__main__:Epoch 3596: total training loss 0.00356\n",
            "2025-06-26 08:25:18,065 Epoch 3596: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3597\n",
            "2025-06-26 08:25:18,067 EPOCH 3597\n",
            "INFO:__main__:Epoch 3597: total training loss 0.00337\n",
            "2025-06-26 08:25:18,160 Epoch 3597: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3598\n",
            "2025-06-26 08:25:18,162 EPOCH 3598\n",
            "INFO:__main__:Epoch 3598: total training loss 0.00337\n",
            "2025-06-26 08:25:18,267 Epoch 3598: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3599\n",
            "2025-06-26 08:25:18,269 EPOCH 3599\n",
            "INFO:__main__:Epoch 3599: total training loss 0.00305\n",
            "2025-06-26 08:25:18,365 Epoch 3599: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3600\n",
            "2025-06-26 08:25:18,369 EPOCH 3600\n",
            "INFO:__main__:Epoch 3600: total training loss 0.00318\n",
            "2025-06-26 08:25:18,452 Epoch 3600: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3601\n",
            "2025-06-26 08:25:18,454 EPOCH 3601\n",
            "INFO:__main__:Epoch 3601: total training loss 0.00352\n",
            "2025-06-26 08:25:18,532 Epoch 3601: total training loss 0.00352\n",
            "INFO:__main__:EPOCH 3602\n",
            "2025-06-26 08:25:18,534 EPOCH 3602\n",
            "INFO:__main__:Epoch 3602: total training loss 0.00323\n",
            "2025-06-26 08:25:18,614 Epoch 3602: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3603\n",
            "2025-06-26 08:25:18,616 EPOCH 3603\n",
            "INFO:__main__:Epoch 3603: total training loss 0.00334\n",
            "2025-06-26 08:25:18,690 Epoch 3603: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3604\n",
            "2025-06-26 08:25:18,692 EPOCH 3604\n",
            "INFO:__main__:Epoch 3604: total training loss 0.00340\n",
            "2025-06-26 08:25:18,765 Epoch 3604: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3605\n",
            "2025-06-26 08:25:18,767 EPOCH 3605\n",
            "INFO:__main__:Epoch 3605: total training loss 0.00329\n",
            "2025-06-26 08:25:18,844 Epoch 3605: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3606\n",
            "2025-06-26 08:25:18,846 EPOCH 3606\n",
            "INFO:__main__:Epoch 3606: total training loss 0.00365\n",
            "2025-06-26 08:25:18,919 Epoch 3606: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3607\n",
            "2025-06-26 08:25:18,921 EPOCH 3607\n",
            "INFO:__main__:Epoch 3607: total training loss 0.00325\n",
            "2025-06-26 08:25:19,023 Epoch 3607: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3608\n",
            "2025-06-26 08:25:19,024 EPOCH 3608\n",
            "INFO:__main__:Epoch 3608: total training loss 0.00345\n",
            "2025-06-26 08:25:19,130 Epoch 3608: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3609\n",
            "2025-06-26 08:25:19,132 EPOCH 3609\n",
            "INFO:__main__:Epoch 3609: total training loss 0.00347\n",
            "2025-06-26 08:25:19,212 Epoch 3609: total training loss 0.00347\n",
            "INFO:__main__:EPOCH 3610\n",
            "2025-06-26 08:25:19,215 EPOCH 3610\n",
            "INFO:__main__:Epoch 3610: total training loss 0.00338\n",
            "2025-06-26 08:25:19,308 Epoch 3610: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3611\n",
            "2025-06-26 08:25:19,310 EPOCH 3611\n",
            "INFO:__main__:Epoch 3611: total training loss 0.00318\n",
            "2025-06-26 08:25:19,442 Epoch 3611: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3612\n",
            "2025-06-26 08:25:19,444 EPOCH 3612\n",
            "INFO:__main__:Epoch 3612: total training loss 0.00341\n",
            "2025-06-26 08:25:19,539 Epoch 3612: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3613\n",
            "2025-06-26 08:25:19,545 EPOCH 3613\n",
            "INFO:__main__:Epoch 3613: total training loss 0.00302\n",
            "2025-06-26 08:25:19,640 Epoch 3613: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3614\n",
            "2025-06-26 08:25:19,642 EPOCH 3614\n",
            "INFO:__main__:Epoch 3614: total training loss 0.00300\n",
            "2025-06-26 08:25:19,721 Epoch 3614: total training loss 0.00300\n",
            "INFO:__main__:EPOCH 3615\n",
            "2025-06-26 08:25:19,723 EPOCH 3615\n",
            "INFO:__main__:Epoch 3615: total training loss 0.00292\n",
            "2025-06-26 08:25:19,794 Epoch 3615: total training loss 0.00292\n",
            "INFO:__main__:EPOCH 3616\n",
            "2025-06-26 08:25:19,796 EPOCH 3616\n",
            "INFO:__main__:Epoch 3616: total training loss 0.00318\n",
            "2025-06-26 08:25:19,875 Epoch 3616: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3617\n",
            "2025-06-26 08:25:19,877 EPOCH 3617\n",
            "INFO:__main__:Epoch 3617: total training loss 0.00302\n",
            "2025-06-26 08:25:19,974 Epoch 3617: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3618\n",
            "2025-06-26 08:25:19,977 EPOCH 3618\n",
            "INFO:__main__:Epoch 3618: total training loss 0.00297\n",
            "2025-06-26 08:25:20,080 Epoch 3618: total training loss 0.00297\n",
            "INFO:__main__:EPOCH 3619\n",
            "2025-06-26 08:25:20,083 EPOCH 3619\n",
            "INFO:__main__:Epoch 3619: total training loss 0.00304\n",
            "2025-06-26 08:25:20,162 Epoch 3619: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3620\n",
            "2025-06-26 08:25:20,165 EPOCH 3620\n",
            "INFO:__main__:Epoch 3620: total training loss 0.00301\n",
            "2025-06-26 08:25:20,260 Epoch 3620: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3621\n",
            "2025-06-26 08:25:20,265 EPOCH 3621\n",
            "INFO:__main__:Epoch 3621: total training loss 0.00322\n",
            "2025-06-26 08:25:20,370 Epoch 3621: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3622\n",
            "2025-06-26 08:25:20,372 EPOCH 3622\n",
            "INFO:__main__:Epoch 3622: total training loss 0.00302\n",
            "2025-06-26 08:25:20,473 Epoch 3622: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3623\n",
            "2025-06-26 08:25:20,478 EPOCH 3623\n",
            "INFO:__main__:Epoch 3623: total training loss 0.00311\n",
            "2025-06-26 08:25:20,566 Epoch 3623: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3624\n",
            "2025-06-26 08:25:20,569 EPOCH 3624\n",
            "INFO:__main__:Epoch 3624: total training loss 0.00343\n",
            "2025-06-26 08:25:20,657 Epoch 3624: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3625\n",
            "2025-06-26 08:25:20,659 EPOCH 3625\n",
            "INFO:__main__:Epoch 3625: total training loss 0.00287\n",
            "2025-06-26 08:25:20,752 Epoch 3625: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 3626\n",
            "2025-06-26 08:25:20,755 EPOCH 3626\n",
            "INFO:__main__:Epoch 3626: total training loss 0.00328\n",
            "2025-06-26 08:25:20,848 Epoch 3626: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3627\n",
            "2025-06-26 08:25:20,852 EPOCH 3627\n",
            "INFO:__main__:Epoch 3627: total training loss 0.00287\n",
            "2025-06-26 08:25:20,950 Epoch 3627: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 3628\n",
            "2025-06-26 08:25:20,953 EPOCH 3628\n",
            "INFO:__main__:Epoch 3628: total training loss 0.00326\n",
            "2025-06-26 08:25:21,045 Epoch 3628: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3629\n",
            "2025-06-26 08:25:21,047 EPOCH 3629\n",
            "INFO:__main__:Epoch 3629: total training loss 0.00328\n",
            "2025-06-26 08:25:21,129 Epoch 3629: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3630\n",
            "2025-06-26 08:25:21,132 EPOCH 3630\n",
            "INFO:__main__:Epoch 3630: total training loss 0.00302\n",
            "2025-06-26 08:25:21,211 Epoch 3630: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3631\n",
            "2025-06-26 08:25:21,213 EPOCH 3631\n",
            "INFO:__main__:Epoch 3631: total training loss 0.00320\n",
            "2025-06-26 08:25:21,283 Epoch 3631: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3632\n",
            "2025-06-26 08:25:21,285 EPOCH 3632\n",
            "INFO:__main__:Epoch 3632: total training loss 0.00316\n",
            "2025-06-26 08:25:21,357 Epoch 3632: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3633\n",
            "2025-06-26 08:25:21,359 EPOCH 3633\n",
            "INFO:__main__:Epoch 3633: total training loss 0.00323\n",
            "2025-06-26 08:25:21,440 Epoch 3633: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3634\n",
            "2025-06-26 08:25:21,442 EPOCH 3634\n",
            "INFO:__main__:Epoch 3634: total training loss 0.00310\n",
            "2025-06-26 08:25:21,552 Epoch 3634: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3635\n",
            "2025-06-26 08:25:21,554 EPOCH 3635\n",
            "INFO:__main__:Epoch 3635: total training loss 0.00307\n",
            "2025-06-26 08:25:21,623 Epoch 3635: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3636\n",
            "2025-06-26 08:25:21,625 EPOCH 3636\n",
            "INFO:__main__:Epoch 3636: total training loss 0.00306\n",
            "2025-06-26 08:25:21,696 Epoch 3636: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3637\n",
            "2025-06-26 08:25:21,698 EPOCH 3637\n",
            "INFO:__main__:Epoch 3637: total training loss 0.00307\n",
            "2025-06-26 08:25:21,769 Epoch 3637: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3638\n",
            "2025-06-26 08:25:21,771 EPOCH 3638\n",
            "INFO:__main__:Epoch 3638: total training loss 0.00298\n",
            "2025-06-26 08:25:21,842 Epoch 3638: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3639\n",
            "2025-06-26 08:25:21,844 EPOCH 3639\n",
            "INFO:__main__:Epoch 3639: total training loss 0.00312\n",
            "2025-06-26 08:25:21,912 Epoch 3639: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3640\n",
            "2025-06-26 08:25:21,914 EPOCH 3640\n",
            "INFO:__main__:Epoch 3640: total training loss 0.00327\n",
            "2025-06-26 08:25:21,984 Epoch 3640: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3641\n",
            "2025-06-26 08:25:21,987 EPOCH 3641\n",
            "INFO:__main__:Epoch 3641: total training loss 0.00330\n",
            "2025-06-26 08:25:22,054 Epoch 3641: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3642\n",
            "2025-06-26 08:25:22,057 EPOCH 3642\n",
            "INFO:__main__:Epoch 3642: total training loss 0.00336\n",
            "2025-06-26 08:25:22,125 Epoch 3642: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3643\n",
            "2025-06-26 08:25:22,127 EPOCH 3643\n",
            "INFO:__main__:Epoch 3643: total training loss 0.00293\n",
            "2025-06-26 08:25:22,193 Epoch 3643: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3644\n",
            "2025-06-26 08:25:22,194 EPOCH 3644\n",
            "INFO:__main__:Epoch 3644: total training loss 0.00309\n",
            "2025-06-26 08:25:22,260 Epoch 3644: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3645\n",
            "2025-06-26 08:25:22,262 EPOCH 3645\n",
            "INFO:__main__:Epoch 3645: total training loss 0.00281\n",
            "2025-06-26 08:25:22,333 Epoch 3645: total training loss 0.00281\n",
            "INFO:__main__:EPOCH 3646\n",
            "2025-06-26 08:25:22,335 EPOCH 3646\n",
            "INFO:__main__:Epoch 3646: total training loss 0.00328\n",
            "2025-06-26 08:25:22,402 Epoch 3646: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3647\n",
            "2025-06-26 08:25:22,404 EPOCH 3647\n",
            "INFO:__main__:Epoch 3647: total training loss 0.00321\n",
            "2025-06-26 08:25:22,470 Epoch 3647: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3648\n",
            "2025-06-26 08:25:22,472 EPOCH 3648\n",
            "INFO:__main__:Epoch 3648: total training loss 0.00335\n",
            "2025-06-26 08:25:22,560 Epoch 3648: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3649\n",
            "2025-06-26 08:25:22,564 EPOCH 3649\n",
            "INFO:__main__:Epoch 3649: total training loss 0.00327\n",
            "2025-06-26 08:25:22,631 Epoch 3649: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3650\n",
            "2025-06-26 08:25:22,633 EPOCH 3650\n",
            "INFO:__main__:Epoch 3650: total training loss 0.00336\n",
            "2025-06-26 08:25:22,700 Epoch 3650: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3651\n",
            "2025-06-26 08:25:22,701 EPOCH 3651\n",
            "INFO:__main__:Epoch 3651: total training loss 0.00353\n",
            "2025-06-26 08:25:22,770 Epoch 3651: total training loss 0.00353\n",
            "INFO:__main__:EPOCH 3652\n",
            "2025-06-26 08:25:22,772 EPOCH 3652\n",
            "INFO:__main__:Epoch 3652: total training loss 0.00334\n",
            "2025-06-26 08:25:22,842 Epoch 3652: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3653\n",
            "2025-06-26 08:25:22,844 EPOCH 3653\n",
            "INFO:__main__:Epoch 3653: total training loss 0.00335\n",
            "2025-06-26 08:25:22,915 Epoch 3653: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3654\n",
            "2025-06-26 08:25:22,917 EPOCH 3654\n",
            "INFO:__main__:Epoch 3654: total training loss 0.00372\n",
            "2025-06-26 08:25:22,985 Epoch 3654: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3655\n",
            "2025-06-26 08:25:22,987 EPOCH 3655\n",
            "INFO:__main__:Epoch 3655: total training loss 0.00364\n",
            "2025-06-26 08:25:23,053 Epoch 3655: total training loss 0.00364\n",
            "INFO:__main__:EPOCH 3656\n",
            "2025-06-26 08:25:23,055 EPOCH 3656\n",
            "INFO:__main__:Epoch 3656: total training loss 0.00325\n",
            "2025-06-26 08:25:23,121 Epoch 3656: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3657\n",
            "2025-06-26 08:25:23,123 EPOCH 3657\n",
            "INFO:__main__:Epoch 3657: total training loss 0.00333\n",
            "2025-06-26 08:25:23,195 Epoch 3657: total training loss 0.00333\n",
            "INFO:__main__:EPOCH 3658\n",
            "2025-06-26 08:25:23,197 EPOCH 3658\n",
            "INFO:__main__:Epoch 3658: total training loss 0.00322\n",
            "2025-06-26 08:25:23,261 Epoch 3658: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3659\n",
            "2025-06-26 08:25:23,263 EPOCH 3659\n",
            "INFO:__main__:Epoch 3659: total training loss 0.00330\n",
            "2025-06-26 08:25:23,334 Epoch 3659: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3660\n",
            "2025-06-26 08:25:23,336 EPOCH 3660\n",
            "INFO:__main__:Epoch 3660: total training loss 0.00324\n",
            "2025-06-26 08:25:23,404 Epoch 3660: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3661\n",
            "2025-06-26 08:25:23,408 EPOCH 3661\n",
            "INFO:__main__:Epoch 3661: total training loss 0.00324\n",
            "2025-06-26 08:25:23,475 Epoch 3661: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3662\n",
            "2025-06-26 08:25:23,477 EPOCH 3662\n",
            "INFO:__main__:Epoch 3662: total training loss 0.00313\n",
            "2025-06-26 08:25:23,547 Epoch 3662: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3663\n",
            "2025-06-26 08:25:23,550 EPOCH 3663\n",
            "INFO:__main__:Epoch 3663: total training loss 0.00337\n",
            "2025-06-26 08:25:23,628 Epoch 3663: total training loss 0.00337\n",
            "INFO:__main__:EPOCH 3664\n",
            "2025-06-26 08:25:23,630 EPOCH 3664\n",
            "INFO:__main__:Epoch 3664: total training loss 0.00317\n",
            "2025-06-26 08:25:23,697 Epoch 3664: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3665\n",
            "2025-06-26 08:25:23,699 EPOCH 3665\n",
            "INFO:__main__:Epoch 3665: total training loss 0.00305\n",
            "2025-06-26 08:25:23,768 Epoch 3665: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3666\n",
            "2025-06-26 08:25:23,770 EPOCH 3666\n",
            "INFO:__main__:Epoch 3666: total training loss 0.00320\n",
            "2025-06-26 08:25:23,842 Epoch 3666: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3667\n",
            "2025-06-26 08:25:23,844 EPOCH 3667\n",
            "INFO:__main__:Epoch 3667: total training loss 0.00339\n",
            "2025-06-26 08:25:23,914 Epoch 3667: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3668\n",
            "2025-06-26 08:25:23,916 EPOCH 3668\n",
            "INFO:__main__:Epoch 3668: total training loss 0.00320\n",
            "2025-06-26 08:25:23,982 Epoch 3668: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3669\n",
            "2025-06-26 08:25:23,986 EPOCH 3669\n",
            "INFO:__main__:Epoch 3669: total training loss 0.00350\n",
            "2025-06-26 08:25:24,054 Epoch 3669: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3670\n",
            "2025-06-26 08:25:24,056 EPOCH 3670\n",
            "INFO:__main__:Epoch 3670: total training loss 0.00328\n",
            "2025-06-26 08:25:24,122 Epoch 3670: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3671\n",
            "2025-06-26 08:25:24,125 EPOCH 3671\n",
            "INFO:__main__:Epoch 3671: total training loss 0.00350\n",
            "2025-06-26 08:25:24,192 Epoch 3671: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3672\n",
            "2025-06-26 08:25:24,194 EPOCH 3672\n",
            "INFO:__main__:Epoch 3672: total training loss 0.00339\n",
            "2025-06-26 08:25:24,262 Epoch 3672: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3673\n",
            "2025-06-26 08:25:24,264 EPOCH 3673\n",
            "INFO:__main__:Epoch 3673: total training loss 0.00348\n",
            "2025-06-26 08:25:24,338 Epoch 3673: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3674\n",
            "2025-06-26 08:25:24,340 EPOCH 3674\n",
            "INFO:__main__:Epoch 3674: total training loss 0.00328\n",
            "2025-06-26 08:25:24,407 Epoch 3674: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3675\n",
            "2025-06-26 08:25:24,410 EPOCH 3675\n",
            "INFO:__main__:Epoch 3675: total training loss 0.00326\n",
            "2025-06-26 08:25:24,477 Epoch 3675: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3676\n",
            "2025-06-26 08:25:24,479 EPOCH 3676\n",
            "INFO:__main__:Epoch 3676: total training loss 0.00339\n",
            "2025-06-26 08:25:24,545 Epoch 3676: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3677\n",
            "2025-06-26 08:25:24,547 EPOCH 3677\n",
            "INFO:__main__:Epoch 3677: total training loss 0.00322\n",
            "2025-06-26 08:25:24,629 Epoch 3677: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3678\n",
            "2025-06-26 08:25:24,631 EPOCH 3678\n",
            "INFO:__main__:Epoch 3678: total training loss 0.00308\n",
            "2025-06-26 08:25:24,697 Epoch 3678: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3679\n",
            "2025-06-26 08:25:24,699 EPOCH 3679\n",
            "INFO:__main__:Epoch 3679: total training loss 0.00307\n",
            "2025-06-26 08:25:24,768 Epoch 3679: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3680\n",
            "2025-06-26 08:25:24,771 EPOCH 3680\n",
            "INFO:__main__:Epoch 3680: total training loss 0.00302\n",
            "2025-06-26 08:25:24,840 Epoch 3680: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3681\n",
            "2025-06-26 08:25:24,842 EPOCH 3681\n",
            "INFO:__main__:Epoch 3681: total training loss 0.00289\n",
            "2025-06-26 08:25:24,911 Epoch 3681: total training loss 0.00289\n",
            "INFO:__main__:EPOCH 3682\n",
            "2025-06-26 08:25:24,913 EPOCH 3682\n",
            "INFO:__main__:Epoch 3682: total training loss 0.00320\n",
            "2025-06-26 08:25:24,986 Epoch 3682: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3683\n",
            "2025-06-26 08:25:24,988 EPOCH 3683\n",
            "INFO:__main__:Epoch 3683: total training loss 0.00314\n",
            "2025-06-26 08:25:25,057 Epoch 3683: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3684\n",
            "2025-06-26 08:25:25,059 EPOCH 3684\n",
            "INFO:__main__:Epoch 3684: total training loss 0.00302\n",
            "2025-06-26 08:25:25,126 Epoch 3684: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3685\n",
            "2025-06-26 08:25:25,128 EPOCH 3685\n",
            "INFO:__main__:Epoch 3685: total training loss 0.00301\n",
            "2025-06-26 08:25:25,200 Epoch 3685: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3686\n",
            "2025-06-26 08:25:25,202 EPOCH 3686\n",
            "INFO:__main__:Epoch 3686: total training loss 0.00306\n",
            "2025-06-26 08:25:25,270 Epoch 3686: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3687\n",
            "2025-06-26 08:25:25,273 EPOCH 3687\n",
            "INFO:__main__:Epoch 3687: total training loss 0.00287\n",
            "2025-06-26 08:25:25,343 Epoch 3687: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 3688\n",
            "2025-06-26 08:25:25,345 EPOCH 3688\n",
            "INFO:__main__:Epoch 3688: total training loss 0.00326\n",
            "2025-06-26 08:25:25,415 Epoch 3688: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3689\n",
            "2025-06-26 08:25:25,417 EPOCH 3689\n",
            "INFO:__main__:Epoch 3689: total training loss 0.00323\n",
            "2025-06-26 08:25:25,485 Epoch 3689: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3690\n",
            "2025-06-26 08:25:25,487 EPOCH 3690\n",
            "INFO:__main__:Epoch 3690: total training loss 0.00371\n",
            "2025-06-26 08:25:25,553 Epoch 3690: total training loss 0.00371\n",
            "INFO:__main__:EPOCH 3691\n",
            "2025-06-26 08:25:25,554 EPOCH 3691\n",
            "INFO:__main__:Epoch 3691: total training loss 0.00432\n",
            "2025-06-26 08:25:25,619 Epoch 3691: total training loss 0.00432\n",
            "INFO:__main__:EPOCH 3692\n",
            "2025-06-26 08:25:25,621 EPOCH 3692\n",
            "INFO:__main__:Epoch 3692: total training loss 0.00563\n",
            "2025-06-26 08:25:25,708 Epoch 3692: total training loss 0.00563\n",
            "INFO:__main__:EPOCH 3693\n",
            "2025-06-26 08:25:25,710 EPOCH 3693\n",
            "INFO:__main__:Epoch 3693: total training loss 0.00571\n",
            "2025-06-26 08:25:25,779 Epoch 3693: total training loss 0.00571\n",
            "INFO:__main__:EPOCH 3694\n",
            "2025-06-26 08:25:25,781 EPOCH 3694\n",
            "INFO:__main__:Epoch 3694: total training loss 0.00651\n",
            "2025-06-26 08:25:25,850 Epoch 3694: total training loss 0.00651\n",
            "INFO:__main__:EPOCH 3695\n",
            "2025-06-26 08:25:25,852 EPOCH 3695\n",
            "INFO:__main__:Epoch 3695: total training loss 0.00622\n",
            "2025-06-26 08:25:25,922 Epoch 3695: total training loss 0.00622\n",
            "INFO:__main__:EPOCH 3696\n",
            "2025-06-26 08:25:25,924 EPOCH 3696\n",
            "INFO:__main__:Epoch 3696: total training loss 0.00612\n",
            "2025-06-26 08:25:25,990 Epoch 3696: total training loss 0.00612\n",
            "INFO:__main__:EPOCH 3697\n",
            "2025-06-26 08:25:25,992 EPOCH 3697\n",
            "INFO:__main__:Epoch 3697: total training loss 0.00708\n",
            "2025-06-26 08:25:26,063 Epoch 3697: total training loss 0.00708\n",
            "INFO:__main__:EPOCH 3698\n",
            "2025-06-26 08:25:26,065 EPOCH 3698\n",
            "INFO:__main__:Epoch 3698: total training loss 0.00849\n",
            "2025-06-26 08:25:26,132 Epoch 3698: total training loss 0.00849\n",
            "INFO:__main__:EPOCH 3699\n",
            "2025-06-26 08:25:26,134 EPOCH 3699\n",
            "INFO:__main__:Epoch 3699: total training loss 0.00653\n",
            "2025-06-26 08:25:26,204 Epoch 3699: total training loss 0.00653\n",
            "INFO:__main__:EPOCH 3700\n",
            "2025-06-26 08:25:26,207 EPOCH 3700\n",
            "INFO:__main__:Epoch 3700: total training loss 0.00682\n",
            "2025-06-26 08:25:26,274 Epoch 3700: total training loss 0.00682\n",
            "INFO:__main__:EPOCH 3701\n",
            "2025-06-26 08:25:26,276 EPOCH 3701\n",
            "INFO:__main__:Epoch 3701: total training loss 0.00648\n",
            "2025-06-26 08:25:26,348 Epoch 3701: total training loss 0.00648\n",
            "INFO:__main__:EPOCH 3702\n",
            "2025-06-26 08:25:26,351 EPOCH 3702\n",
            "INFO:__main__:Epoch 3702: total training loss 0.00606\n",
            "2025-06-26 08:25:26,422 Epoch 3702: total training loss 0.00606\n",
            "INFO:__main__:EPOCH 3703\n",
            "2025-06-26 08:25:26,424 EPOCH 3703\n",
            "INFO:__main__:Epoch 3703: total training loss 0.00555\n",
            "2025-06-26 08:25:26,491 Epoch 3703: total training loss 0.00555\n",
            "INFO:__main__:EPOCH 3704\n",
            "2025-06-26 08:25:26,493 EPOCH 3704\n",
            "INFO:__main__:Epoch 3704: total training loss 0.00552\n",
            "2025-06-26 08:25:26,562 Epoch 3704: total training loss 0.00552\n",
            "INFO:__main__:EPOCH 3705\n",
            "2025-06-26 08:25:26,565 EPOCH 3705\n",
            "INFO:__main__:Epoch 3705: total training loss 0.00544\n",
            "2025-06-26 08:25:26,633 Epoch 3705: total training loss 0.00544\n",
            "INFO:__main__:EPOCH 3706\n",
            "2025-06-26 08:25:26,635 EPOCH 3706\n",
            "INFO:__main__:Epoch 3706: total training loss 0.00512\n",
            "2025-06-26 08:25:26,706 Epoch 3706: total training loss 0.00512\n",
            "INFO:__main__:EPOCH 3707\n",
            "2025-06-26 08:25:26,708 EPOCH 3707\n",
            "INFO:__main__:Epoch 3707: total training loss 0.00516\n",
            "2025-06-26 08:25:26,792 Epoch 3707: total training loss 0.00516\n",
            "INFO:__main__:EPOCH 3708\n",
            "2025-06-26 08:25:26,794 EPOCH 3708\n",
            "INFO:__main__:Epoch 3708: total training loss 0.00469\n",
            "2025-06-26 08:25:26,865 Epoch 3708: total training loss 0.00469\n",
            "INFO:__main__:EPOCH 3709\n",
            "2025-06-26 08:25:26,867 EPOCH 3709\n",
            "INFO:__main__:Epoch 3709: total training loss 0.00504\n",
            "2025-06-26 08:25:26,934 Epoch 3709: total training loss 0.00504\n",
            "INFO:__main__:EPOCH 3710\n",
            "2025-06-26 08:25:26,937 EPOCH 3710\n",
            "INFO:__main__:Epoch 3710: total training loss 0.00456\n",
            "2025-06-26 08:25:27,004 Epoch 3710: total training loss 0.00456\n",
            "INFO:__main__:EPOCH 3711\n",
            "2025-06-26 08:25:27,006 EPOCH 3711\n",
            "INFO:__main__:Epoch 3711: total training loss 0.00456\n",
            "2025-06-26 08:25:27,075 Epoch 3711: total training loss 0.00456\n",
            "INFO:__main__:EPOCH 3712\n",
            "2025-06-26 08:25:27,077 EPOCH 3712\n",
            "INFO:__main__:Epoch 3712: total training loss 0.00469\n",
            "2025-06-26 08:25:27,147 Epoch 3712: total training loss 0.00469\n",
            "INFO:__main__:EPOCH 3713\n",
            "2025-06-26 08:25:27,149 EPOCH 3713\n",
            "INFO:__main__:Epoch 3713: total training loss 0.00409\n",
            "2025-06-26 08:25:27,219 Epoch 3713: total training loss 0.00409\n",
            "INFO:__main__:EPOCH 3714\n",
            "2025-06-26 08:25:27,221 EPOCH 3714\n",
            "INFO:__main__:Epoch 3714: total training loss 0.00446\n",
            "2025-06-26 08:25:27,288 Epoch 3714: total training loss 0.00446\n",
            "INFO:__main__:EPOCH 3715\n",
            "2025-06-26 08:25:27,291 EPOCH 3715\n",
            "INFO:__main__:Epoch 3715: total training loss 0.00449\n",
            "2025-06-26 08:25:27,360 Epoch 3715: total training loss 0.00449\n",
            "INFO:__main__:EPOCH 3716\n",
            "2025-06-26 08:25:27,363 EPOCH 3716\n",
            "INFO:__main__:Epoch 3716: total training loss 0.00430\n",
            "2025-06-26 08:25:27,441 Epoch 3716: total training loss 0.00430\n",
            "INFO:__main__:EPOCH 3717\n",
            "2025-06-26 08:25:27,442 EPOCH 3717\n",
            "INFO:__main__:Epoch 3717: total training loss 0.00506\n",
            "2025-06-26 08:25:27,512 Epoch 3717: total training loss 0.00506\n",
            "INFO:__main__:EPOCH 3718\n",
            "2025-06-26 08:25:27,514 EPOCH 3718\n",
            "INFO:__main__:Epoch 3718: total training loss 0.00448\n",
            "2025-06-26 08:25:27,585 Epoch 3718: total training loss 0.00448\n",
            "INFO:__main__:EPOCH 3719\n",
            "2025-06-26 08:25:27,586 EPOCH 3719\n",
            "INFO:__main__:Epoch 3719: total training loss 0.00481\n",
            "2025-06-26 08:25:27,655 Epoch 3719: total training loss 0.00481\n",
            "INFO:__main__:EPOCH 3720\n",
            "2025-06-26 08:25:27,657 EPOCH 3720\n",
            "INFO:__main__:Epoch 3720: total training loss 0.00431\n",
            "2025-06-26 08:25:27,726 Epoch 3720: total training loss 0.00431\n",
            "INFO:__main__:EPOCH 3721\n",
            "2025-06-26 08:25:27,728 EPOCH 3721\n",
            "INFO:__main__:Epoch 3721: total training loss 0.00399\n",
            "2025-06-26 08:25:27,810 Epoch 3721: total training loss 0.00399\n",
            "INFO:__main__:EPOCH 3722\n",
            "2025-06-26 08:25:27,812 EPOCH 3722\n",
            "INFO:__main__:Epoch 3722: total training loss 0.00461\n",
            "2025-06-26 08:25:27,881 Epoch 3722: total training loss 0.00461\n",
            "INFO:__main__:EPOCH 3723\n",
            "2025-06-26 08:25:27,883 EPOCH 3723\n",
            "INFO:__main__:Epoch 3723: total training loss 0.00405\n",
            "2025-06-26 08:25:27,950 Epoch 3723: total training loss 0.00405\n",
            "INFO:__main__:EPOCH 3724\n",
            "2025-06-26 08:25:27,951 EPOCH 3724\n",
            "INFO:__main__:Epoch 3724: total training loss 0.00395\n",
            "2025-06-26 08:25:28,019 Epoch 3724: total training loss 0.00395\n",
            "INFO:__main__:EPOCH 3725\n",
            "2025-06-26 08:25:28,021 EPOCH 3725\n",
            "INFO:__main__:Epoch 3725: total training loss 0.00384\n",
            "2025-06-26 08:25:28,090 Epoch 3725: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3726\n",
            "2025-06-26 08:25:28,092 EPOCH 3726\n",
            "INFO:__main__:Epoch 3726: total training loss 0.00392\n",
            "2025-06-26 08:25:28,157 Epoch 3726: total training loss 0.00392\n",
            "INFO:__main__:EPOCH 3727\n",
            "2025-06-26 08:25:28,160 EPOCH 3727\n",
            "INFO:__main__:Epoch 3727: total training loss 0.00358\n",
            "2025-06-26 08:25:28,225 Epoch 3727: total training loss 0.00358\n",
            "INFO:__main__:EPOCH 3728\n",
            "2025-06-26 08:25:28,227 EPOCH 3728\n",
            "INFO:__main__:Epoch 3728: total training loss 0.00338\n",
            "2025-06-26 08:25:28,297 Epoch 3728: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3729\n",
            "2025-06-26 08:25:28,299 EPOCH 3729\n",
            "INFO:__main__:Epoch 3729: total training loss 0.00375\n",
            "2025-06-26 08:25:28,365 Epoch 3729: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3730\n",
            "2025-06-26 08:25:28,367 EPOCH 3730\n",
            "INFO:__main__:Epoch 3730: total training loss 0.00359\n",
            "2025-06-26 08:25:28,433 Epoch 3730: total training loss 0.00359\n",
            "INFO:__main__:EPOCH 3731\n",
            "2025-06-26 08:25:28,435 EPOCH 3731\n",
            "INFO:__main__:Epoch 3731: total training loss 0.00384\n",
            "2025-06-26 08:25:28,499 Epoch 3731: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3732\n",
            "2025-06-26 08:25:28,501 EPOCH 3732\n",
            "INFO:__main__:Epoch 3732: total training loss 0.00386\n",
            "2025-06-26 08:25:28,566 Epoch 3732: total training loss 0.00386\n",
            "INFO:__main__:EPOCH 3733\n",
            "2025-06-26 08:25:28,568 EPOCH 3733\n",
            "INFO:__main__:Epoch 3733: total training loss 0.00372\n",
            "2025-06-26 08:25:28,634 Epoch 3733: total training loss 0.00372\n",
            "INFO:__main__:EPOCH 3734\n",
            "2025-06-26 08:25:28,636 EPOCH 3734\n",
            "INFO:__main__:Epoch 3734: total training loss 0.00383\n",
            "2025-06-26 08:25:28,700 Epoch 3734: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 3735\n",
            "2025-06-26 08:25:28,702 EPOCH 3735\n",
            "INFO:__main__:Epoch 3735: total training loss 0.00355\n",
            "2025-06-26 08:25:28,769 Epoch 3735: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3736\n",
            "2025-06-26 08:25:28,771 EPOCH 3736\n",
            "INFO:__main__:Epoch 3736: total training loss 0.00367\n",
            "2025-06-26 08:25:28,856 Epoch 3736: total training loss 0.00367\n",
            "INFO:__main__:EPOCH 3737\n",
            "2025-06-26 08:25:28,858 EPOCH 3737\n",
            "INFO:__main__:Epoch 3737: total training loss 0.00357\n",
            "2025-06-26 08:25:28,930 Epoch 3737: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3738\n",
            "2025-06-26 08:25:28,931 EPOCH 3738\n",
            "INFO:__main__:Epoch 3738: total training loss 0.00384\n",
            "2025-06-26 08:25:28,999 Epoch 3738: total training loss 0.00384\n",
            "INFO:__main__:EPOCH 3739\n",
            "2025-06-26 08:25:29,001 EPOCH 3739\n",
            "INFO:__main__:Epoch 3739: total training loss 0.00334\n",
            "2025-06-26 08:25:29,070 Epoch 3739: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3740\n",
            "2025-06-26 08:25:29,073 EPOCH 3740\n",
            "INFO:__main__:Epoch 3740: total training loss 0.00356\n",
            "2025-06-26 08:25:29,139 Epoch 3740: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3741\n",
            "2025-06-26 08:25:29,142 EPOCH 3741\n",
            "INFO:__main__:Epoch 3741: total training loss 0.00381\n",
            "2025-06-26 08:25:29,215 Epoch 3741: total training loss 0.00381\n",
            "INFO:__main__:EPOCH 3742\n",
            "2025-06-26 08:25:29,216 EPOCH 3742\n",
            "INFO:__main__:Epoch 3742: total training loss 0.00361\n",
            "2025-06-26 08:25:29,285 Epoch 3742: total training loss 0.00361\n",
            "INFO:__main__:EPOCH 3743\n",
            "2025-06-26 08:25:29,287 EPOCH 3743\n",
            "INFO:__main__:Epoch 3743: total training loss 0.00383\n",
            "2025-06-26 08:25:29,353 Epoch 3743: total training loss 0.00383\n",
            "INFO:__main__:EPOCH 3744\n",
            "2025-06-26 08:25:29,355 EPOCH 3744\n",
            "INFO:__main__:Epoch 3744: total training loss 0.00335\n",
            "2025-06-26 08:25:29,420 Epoch 3744: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3745\n",
            "2025-06-26 08:25:29,422 EPOCH 3745\n",
            "INFO:__main__:Epoch 3745: total training loss 0.00362\n",
            "2025-06-26 08:25:29,488 Epoch 3745: total training loss 0.00362\n",
            "INFO:__main__:EPOCH 3746\n",
            "2025-06-26 08:25:29,490 EPOCH 3746\n",
            "INFO:__main__:Epoch 3746: total training loss 0.00355\n",
            "2025-06-26 08:25:29,557 Epoch 3746: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3747\n",
            "2025-06-26 08:25:29,559 EPOCH 3747\n",
            "INFO:__main__:Epoch 3747: total training loss 0.00321\n",
            "2025-06-26 08:25:29,625 Epoch 3747: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3748\n",
            "2025-06-26 08:25:29,627 EPOCH 3748\n",
            "INFO:__main__:Epoch 3748: total training loss 0.00348\n",
            "2025-06-26 08:25:29,690 Epoch 3748: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3749\n",
            "2025-06-26 08:25:29,692 EPOCH 3749\n",
            "INFO:__main__:Epoch 3749: total training loss 0.00324\n",
            "2025-06-26 08:25:29,759 Epoch 3749: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3750\n",
            "2025-06-26 08:25:29,761 EPOCH 3750\n",
            "INFO:__main__:Epoch 3750 Step:     3750 Batch Loss:     0.003160 Tokens per Sec:  2181759, Lr: 0.001000\n",
            "2025-06-26 08:25:29,830 Epoch 3750 Step:     3750 Batch Loss:     0.003160 Tokens per Sec:  2181759, Lr: 0.001000\n",
            "INFO:__main__:Epoch 3750: total training loss 0.00316\n",
            "2025-06-26 08:25:29,832 Epoch 3750: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3751\n",
            "2025-06-26 08:25:29,834 EPOCH 3751\n",
            "INFO:__main__:Epoch 3751: total training loss 0.00334\n",
            "2025-06-26 08:25:29,926 Epoch 3751: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3752\n",
            "2025-06-26 08:25:29,928 EPOCH 3752\n",
            "INFO:__main__:Epoch 3752: total training loss 0.00323\n",
            "2025-06-26 08:25:29,994 Epoch 3752: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3753\n",
            "2025-06-26 08:25:29,997 EPOCH 3753\n",
            "INFO:__main__:Epoch 3753: total training loss 0.00300\n",
            "2025-06-26 08:25:30,065 Epoch 3753: total training loss 0.00300\n",
            "INFO:__main__:EPOCH 3754\n",
            "2025-06-26 08:25:30,067 EPOCH 3754\n",
            "INFO:__main__:Epoch 3754: total training loss 0.00318\n",
            "2025-06-26 08:25:30,132 Epoch 3754: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3755\n",
            "2025-06-26 08:25:30,135 EPOCH 3755\n",
            "INFO:__main__:Epoch 3755: total training loss 0.00324\n",
            "2025-06-26 08:25:30,203 Epoch 3755: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3756\n",
            "2025-06-26 08:25:30,206 EPOCH 3756\n",
            "INFO:__main__:Epoch 3756: total training loss 0.00315\n",
            "2025-06-26 08:25:30,275 Epoch 3756: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3757\n",
            "2025-06-26 08:25:30,277 EPOCH 3757\n",
            "INFO:__main__:Epoch 3757: total training loss 0.00410\n",
            "2025-06-26 08:25:30,346 Epoch 3757: total training loss 0.00410\n",
            "INFO:__main__:EPOCH 3758\n",
            "2025-06-26 08:25:30,348 EPOCH 3758\n",
            "INFO:__main__:Epoch 3758: total training loss 0.00340\n",
            "2025-06-26 08:25:30,420 Epoch 3758: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3759\n",
            "2025-06-26 08:25:30,422 EPOCH 3759\n",
            "INFO:__main__:Epoch 3759: total training loss 0.00324\n",
            "2025-06-26 08:25:30,487 Epoch 3759: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3760\n",
            "2025-06-26 08:25:30,489 EPOCH 3760\n",
            "INFO:__main__:Epoch 3760: total training loss 0.00339\n",
            "2025-06-26 08:25:30,558 Epoch 3760: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3761\n",
            "2025-06-26 08:25:30,560 EPOCH 3761\n",
            "INFO:__main__:Epoch 3761: total training loss 0.00317\n",
            "2025-06-26 08:25:30,628 Epoch 3761: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3762\n",
            "2025-06-26 08:25:30,630 EPOCH 3762\n",
            "INFO:__main__:Epoch 3762: total training loss 0.00316\n",
            "2025-06-26 08:25:30,699 Epoch 3762: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3763\n",
            "2025-06-26 08:25:30,702 EPOCH 3763\n",
            "INFO:__main__:Epoch 3763: total training loss 0.00329\n",
            "2025-06-26 08:25:30,773 Epoch 3763: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3764\n",
            "2025-06-26 08:25:30,775 EPOCH 3764\n",
            "INFO:__main__:Epoch 3764: total training loss 0.00343\n",
            "2025-06-26 08:25:30,842 Epoch 3764: total training loss 0.00343\n",
            "INFO:__main__:EPOCH 3765\n",
            "2025-06-26 08:25:30,844 EPOCH 3765\n",
            "INFO:__main__:Epoch 3765: total training loss 0.00308\n",
            "2025-06-26 08:25:30,911 Epoch 3765: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3766\n",
            "2025-06-26 08:25:30,915 EPOCH 3766\n",
            "INFO:__main__:Epoch 3766: total training loss 0.00335\n",
            "2025-06-26 08:25:30,996 Epoch 3766: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3767\n",
            "2025-06-26 08:25:30,998 EPOCH 3767\n",
            "INFO:__main__:Epoch 3767: total training loss 0.00303\n",
            "2025-06-26 08:25:31,065 Epoch 3767: total training loss 0.00303\n",
            "INFO:__main__:EPOCH 3768\n",
            "2025-06-26 08:25:31,067 EPOCH 3768\n",
            "INFO:__main__:Epoch 3768: total training loss 0.00307\n",
            "2025-06-26 08:25:31,160 Epoch 3768: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3769\n",
            "2025-06-26 08:25:31,162 EPOCH 3769\n",
            "INFO:__main__:Epoch 3769: total training loss 0.00299\n",
            "2025-06-26 08:25:31,254 Epoch 3769: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3770\n",
            "2025-06-26 08:25:31,256 EPOCH 3770\n",
            "INFO:__main__:Epoch 3770: total training loss 0.00328\n",
            "2025-06-26 08:25:31,358 Epoch 3770: total training loss 0.00328\n",
            "INFO:__main__:EPOCH 3771\n",
            "2025-06-26 08:25:31,360 EPOCH 3771\n",
            "INFO:__main__:Epoch 3771: total training loss 0.00297\n",
            "2025-06-26 08:25:31,467 Epoch 3771: total training loss 0.00297\n",
            "INFO:__main__:EPOCH 3772\n",
            "2025-06-26 08:25:31,469 EPOCH 3772\n",
            "INFO:__main__:Epoch 3772: total training loss 0.00331\n",
            "2025-06-26 08:25:31,558 Epoch 3772: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3773\n",
            "2025-06-26 08:25:31,560 EPOCH 3773\n",
            "INFO:__main__:Epoch 3773: total training loss 0.00317\n",
            "2025-06-26 08:25:31,640 Epoch 3773: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3774\n",
            "2025-06-26 08:25:31,642 EPOCH 3774\n",
            "INFO:__main__:Epoch 3774: total training loss 0.00335\n",
            "2025-06-26 08:25:31,717 Epoch 3774: total training loss 0.00335\n",
            "INFO:__main__:EPOCH 3775\n",
            "2025-06-26 08:25:31,719 EPOCH 3775\n",
            "INFO:__main__:Epoch 3775: total training loss 0.00304\n",
            "2025-06-26 08:25:31,812 Epoch 3775: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3776\n",
            "2025-06-26 08:25:31,816 EPOCH 3776\n",
            "INFO:__main__:Epoch 3776: total training loss 0.00356\n",
            "2025-06-26 08:25:31,913 Epoch 3776: total training loss 0.00356\n",
            "INFO:__main__:EPOCH 3777\n",
            "2025-06-26 08:25:31,915 EPOCH 3777\n",
            "INFO:__main__:Epoch 3777: total training loss 0.00305\n",
            "2025-06-26 08:25:31,998 Epoch 3777: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3778\n",
            "2025-06-26 08:25:32,000 EPOCH 3778\n",
            "INFO:__main__:Epoch 3778: total training loss 0.00321\n",
            "2025-06-26 08:25:32,079 Epoch 3778: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3779\n",
            "2025-06-26 08:25:32,082 EPOCH 3779\n",
            "INFO:__main__:Epoch 3779: total training loss 0.00311\n",
            "2025-06-26 08:25:32,158 Epoch 3779: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3780\n",
            "2025-06-26 08:25:32,160 EPOCH 3780\n",
            "INFO:__main__:Epoch 3780: total training loss 0.00295\n",
            "2025-06-26 08:25:32,233 Epoch 3780: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 3781\n",
            "2025-06-26 08:25:32,235 EPOCH 3781\n",
            "INFO:__main__:Epoch 3781: total training loss 0.00319\n",
            "2025-06-26 08:25:32,310 Epoch 3781: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3782\n",
            "2025-06-26 08:25:32,312 EPOCH 3782\n",
            "INFO:__main__:Epoch 3782: total training loss 0.00310\n",
            "2025-06-26 08:25:32,405 Epoch 3782: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3783\n",
            "2025-06-26 08:25:32,407 EPOCH 3783\n",
            "INFO:__main__:Epoch 3783: total training loss 0.00321\n",
            "2025-06-26 08:25:32,480 Epoch 3783: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3784\n",
            "2025-06-26 08:25:32,482 EPOCH 3784\n",
            "INFO:__main__:Epoch 3784: total training loss 0.00324\n",
            "2025-06-26 08:25:32,552 Epoch 3784: total training loss 0.00324\n",
            "INFO:__main__:EPOCH 3785\n",
            "2025-06-26 08:25:32,554 EPOCH 3785\n",
            "INFO:__main__:Epoch 3785: total training loss 0.00342\n",
            "2025-06-26 08:25:32,627 Epoch 3785: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 3786\n",
            "2025-06-26 08:25:32,629 EPOCH 3786\n",
            "INFO:__main__:Epoch 3786: total training loss 0.00313\n",
            "2025-06-26 08:25:32,698 Epoch 3786: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3787\n",
            "2025-06-26 08:25:32,700 EPOCH 3787\n",
            "INFO:__main__:Epoch 3787: total training loss 0.00357\n",
            "2025-06-26 08:25:32,779 Epoch 3787: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3788\n",
            "2025-06-26 08:25:32,781 EPOCH 3788\n",
            "INFO:__main__:Epoch 3788: total training loss 0.00351\n",
            "2025-06-26 08:25:32,874 Epoch 3788: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3789\n",
            "2025-06-26 08:25:32,880 EPOCH 3789\n",
            "INFO:__main__:Epoch 3789: total training loss 0.00364\n",
            "2025-06-26 08:25:32,972 Epoch 3789: total training loss 0.00364\n",
            "INFO:__main__:EPOCH 3790\n",
            "2025-06-26 08:25:32,975 EPOCH 3790\n",
            "INFO:__main__:Epoch 3790: total training loss 0.00363\n",
            "2025-06-26 08:25:33,062 Epoch 3790: total training loss 0.00363\n",
            "INFO:__main__:EPOCH 3791\n",
            "2025-06-26 08:25:33,065 EPOCH 3791\n",
            "INFO:__main__:Epoch 3791: total training loss 0.00360\n",
            "2025-06-26 08:25:33,150 Epoch 3791: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3792\n",
            "2025-06-26 08:25:33,152 EPOCH 3792\n",
            "INFO:__main__:Epoch 3792: total training loss 0.00325\n",
            "2025-06-26 08:25:33,249 Epoch 3792: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3793\n",
            "2025-06-26 08:25:33,251 EPOCH 3793\n",
            "INFO:__main__:Epoch 3793: total training loss 0.00340\n",
            "2025-06-26 08:25:33,356 Epoch 3793: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3794\n",
            "2025-06-26 08:25:33,361 EPOCH 3794\n",
            "INFO:__main__:Epoch 3794: total training loss 0.00312\n",
            "2025-06-26 08:25:33,452 Epoch 3794: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3795\n",
            "2025-06-26 08:25:33,457 EPOCH 3795\n",
            "INFO:__main__:Epoch 3795: total training loss 0.00306\n",
            "2025-06-26 08:25:33,549 Epoch 3795: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3796\n",
            "2025-06-26 08:25:33,552 EPOCH 3796\n",
            "INFO:__main__:Epoch 3796: total training loss 0.00304\n",
            "2025-06-26 08:25:33,638 Epoch 3796: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3797\n",
            "2025-06-26 08:25:33,641 EPOCH 3797\n",
            "INFO:__main__:Epoch 3797: total training loss 0.00288\n",
            "2025-06-26 08:25:33,732 Epoch 3797: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3798\n",
            "2025-06-26 08:25:33,740 EPOCH 3798\n",
            "INFO:__main__:Epoch 3798: total training loss 0.00282\n",
            "2025-06-26 08:25:33,830 Epoch 3798: total training loss 0.00282\n",
            "INFO:__main__:EPOCH 3799\n",
            "2025-06-26 08:25:33,832 EPOCH 3799\n",
            "INFO:__main__:Epoch 3799: total training loss 0.00294\n",
            "2025-06-26 08:25:33,938 Epoch 3799: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3800\n",
            "2025-06-26 08:25:33,943 EPOCH 3800\n",
            "INFO:__main__:Epoch 3800: total training loss 0.00299\n",
            "2025-06-26 08:25:34,027 Epoch 3800: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3801\n",
            "2025-06-26 08:25:34,035 EPOCH 3801\n",
            "INFO:__main__:Epoch 3801: total training loss 0.00279\n",
            "2025-06-26 08:25:34,117 Epoch 3801: total training loss 0.00279\n",
            "INFO:__main__:EPOCH 3802\n",
            "2025-06-26 08:25:34,124 EPOCH 3802\n",
            "INFO:__main__:Epoch 3802: total training loss 0.00296\n",
            "2025-06-26 08:25:34,211 Epoch 3802: total training loss 0.00296\n",
            "INFO:__main__:EPOCH 3803\n",
            "2025-06-26 08:25:34,217 EPOCH 3803\n",
            "INFO:__main__:Epoch 3803: total training loss 0.00280\n",
            "2025-06-26 08:25:34,314 Epoch 3803: total training loss 0.00280\n",
            "INFO:__main__:EPOCH 3804\n",
            "2025-06-26 08:25:34,321 EPOCH 3804\n",
            "INFO:__main__:Epoch 3804: total training loss 0.00326\n",
            "2025-06-26 08:25:34,389 Epoch 3804: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3805\n",
            "2025-06-26 08:25:34,393 EPOCH 3805\n",
            "INFO:__main__:Epoch 3805: total training loss 0.00336\n",
            "2025-06-26 08:25:34,468 Epoch 3805: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3806\n",
            "2025-06-26 08:25:34,473 EPOCH 3806\n",
            "INFO:__main__:Epoch 3806: total training loss 0.00350\n",
            "2025-06-26 08:25:34,554 Epoch 3806: total training loss 0.00350\n",
            "INFO:__main__:EPOCH 3807\n",
            "2025-06-26 08:25:34,561 EPOCH 3807\n",
            "INFO:__main__:Epoch 3807: total training loss 0.00360\n",
            "2025-06-26 08:25:34,657 Epoch 3807: total training loss 0.00360\n",
            "INFO:__main__:EPOCH 3808\n",
            "2025-06-26 08:25:34,659 EPOCH 3808\n",
            "INFO:__main__:Epoch 3808: total training loss 0.00366\n",
            "2025-06-26 08:25:34,734 Epoch 3808: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3809\n",
            "2025-06-26 08:25:34,736 EPOCH 3809\n",
            "INFO:__main__:Epoch 3809: total training loss 0.00394\n",
            "2025-06-26 08:25:34,810 Epoch 3809: total training loss 0.00394\n",
            "INFO:__main__:EPOCH 3810\n",
            "2025-06-26 08:25:34,812 EPOCH 3810\n",
            "INFO:__main__:Epoch 3810: total training loss 0.00355\n",
            "2025-06-26 08:25:34,886 Epoch 3810: total training loss 0.00355\n",
            "INFO:__main__:EPOCH 3811\n",
            "2025-06-26 08:25:34,888 EPOCH 3811\n",
            "INFO:__main__:Epoch 3811: total training loss 0.00375\n",
            "2025-06-26 08:25:34,988 Epoch 3811: total training loss 0.00375\n",
            "INFO:__main__:EPOCH 3812\n",
            "2025-06-26 08:25:34,990 EPOCH 3812\n",
            "INFO:__main__:Epoch 3812: total training loss 0.00357\n",
            "2025-06-26 08:25:35,099 Epoch 3812: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3813\n",
            "2025-06-26 08:25:35,100 EPOCH 3813\n",
            "INFO:__main__:Epoch 3813: total training loss 0.00366\n",
            "2025-06-26 08:25:35,200 Epoch 3813: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3814\n",
            "2025-06-26 08:25:35,202 EPOCH 3814\n",
            "INFO:__main__:Epoch 3814: total training loss 0.00357\n",
            "2025-06-26 08:25:35,280 Epoch 3814: total training loss 0.00357\n",
            "INFO:__main__:EPOCH 3815\n",
            "2025-06-26 08:25:35,282 EPOCH 3815\n",
            "INFO:__main__:Epoch 3815: total training loss 0.00338\n",
            "2025-06-26 08:25:35,392 Epoch 3815: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3816\n",
            "2025-06-26 08:25:35,394 EPOCH 3816\n",
            "INFO:__main__:Epoch 3816: total training loss 0.00351\n",
            "2025-06-26 08:25:35,498 Epoch 3816: total training loss 0.00351\n",
            "INFO:__main__:EPOCH 3817\n",
            "2025-06-26 08:25:35,500 EPOCH 3817\n",
            "INFO:__main__:Epoch 3817: total training loss 0.00366\n",
            "2025-06-26 08:25:35,590 Epoch 3817: total training loss 0.00366\n",
            "INFO:__main__:EPOCH 3818\n",
            "2025-06-26 08:25:35,594 EPOCH 3818\n",
            "INFO:__main__:Epoch 3818: total training loss 0.00330\n",
            "2025-06-26 08:25:35,675 Epoch 3818: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3819\n",
            "2025-06-26 08:25:35,677 EPOCH 3819\n",
            "INFO:__main__:Epoch 3819: total training loss 0.00339\n",
            "2025-06-26 08:25:35,758 Epoch 3819: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3820\n",
            "2025-06-26 08:25:35,761 EPOCH 3820\n",
            "INFO:__main__:Epoch 3820: total training loss 0.00339\n",
            "2025-06-26 08:25:35,846 Epoch 3820: total training loss 0.00339\n",
            "INFO:__main__:EPOCH 3821\n",
            "2025-06-26 08:25:35,850 EPOCH 3821\n",
            "INFO:__main__:Epoch 3821: total training loss 0.00321\n",
            "2025-06-26 08:25:35,941 Epoch 3821: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3822\n",
            "2025-06-26 08:25:35,944 EPOCH 3822\n",
            "INFO:__main__:Epoch 3822: total training loss 0.00309\n",
            "2025-06-26 08:25:36,046 Epoch 3822: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3823\n",
            "2025-06-26 08:25:36,048 EPOCH 3823\n",
            "INFO:__main__:Epoch 3823: total training loss 0.00307\n",
            "2025-06-26 08:25:36,133 Epoch 3823: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3824\n",
            "2025-06-26 08:25:36,136 EPOCH 3824\n",
            "INFO:__main__:Epoch 3824: total training loss 0.00285\n",
            "2025-06-26 08:25:36,210 Epoch 3824: total training loss 0.00285\n",
            "INFO:__main__:EPOCH 3825\n",
            "2025-06-26 08:25:36,212 EPOCH 3825\n",
            "INFO:__main__:Epoch 3825: total training loss 0.00301\n",
            "2025-06-26 08:25:36,283 Epoch 3825: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3826\n",
            "2025-06-26 08:25:36,285 EPOCH 3826\n",
            "INFO:__main__:Epoch 3826: total training loss 0.00284\n",
            "2025-06-26 08:25:36,355 Epoch 3826: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 3827\n",
            "2025-06-26 08:25:36,357 EPOCH 3827\n",
            "INFO:__main__:Epoch 3827: total training loss 0.00312\n",
            "2025-06-26 08:25:36,430 Epoch 3827: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3828\n",
            "2025-06-26 08:25:36,433 EPOCH 3828\n",
            "INFO:__main__:Epoch 3828: total training loss 0.00268\n",
            "2025-06-26 08:25:36,510 Epoch 3828: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 3829\n",
            "2025-06-26 08:25:36,512 EPOCH 3829\n",
            "INFO:__main__:Epoch 3829: total training loss 0.00315\n",
            "2025-06-26 08:25:36,579 Epoch 3829: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3830\n",
            "2025-06-26 08:25:36,581 EPOCH 3830\n",
            "INFO:__main__:Epoch 3830: total training loss 0.00294\n",
            "2025-06-26 08:25:36,651 Epoch 3830: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3831\n",
            "2025-06-26 08:25:36,652 EPOCH 3831\n",
            "INFO:__main__:Epoch 3831: total training loss 0.00312\n",
            "2025-06-26 08:25:36,719 Epoch 3831: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3832\n",
            "2025-06-26 08:25:36,721 EPOCH 3832\n",
            "INFO:__main__:Epoch 3832: total training loss 0.00320\n",
            "2025-06-26 08:25:36,790 Epoch 3832: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3833\n",
            "2025-06-26 08:25:36,793 EPOCH 3833\n",
            "INFO:__main__:Epoch 3833: total training loss 0.00319\n",
            "2025-06-26 08:25:36,860 Epoch 3833: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3834\n",
            "2025-06-26 08:25:36,862 EPOCH 3834\n",
            "INFO:__main__:Epoch 3834: total training loss 0.00306\n",
            "2025-06-26 08:25:36,930 Epoch 3834: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3835\n",
            "2025-06-26 08:25:36,932 EPOCH 3835\n",
            "INFO:__main__:Epoch 3835: total training loss 0.00334\n",
            "2025-06-26 08:25:37,000 Epoch 3835: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3836\n",
            "2025-06-26 08:25:37,003 EPOCH 3836\n",
            "INFO:__main__:Epoch 3836: total training loss 0.00348\n",
            "2025-06-26 08:25:37,075 Epoch 3836: total training loss 0.00348\n",
            "INFO:__main__:EPOCH 3837\n",
            "2025-06-26 08:25:37,077 EPOCH 3837\n",
            "INFO:__main__:Epoch 3837: total training loss 0.00298\n",
            "2025-06-26 08:25:37,147 Epoch 3837: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3838\n",
            "2025-06-26 08:25:37,150 EPOCH 3838\n",
            "INFO:__main__:Epoch 3838: total training loss 0.00342\n",
            "2025-06-26 08:25:37,221 Epoch 3838: total training loss 0.00342\n",
            "INFO:__main__:EPOCH 3839\n",
            "2025-06-26 08:25:37,223 EPOCH 3839\n",
            "INFO:__main__:Epoch 3839: total training loss 0.00329\n",
            "2025-06-26 08:25:37,291 Epoch 3839: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3840\n",
            "2025-06-26 08:25:37,294 EPOCH 3840\n",
            "INFO:__main__:Epoch 3840: total training loss 0.00309\n",
            "2025-06-26 08:25:37,360 Epoch 3840: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3841\n",
            "2025-06-26 08:25:37,362 EPOCH 3841\n",
            "INFO:__main__:Epoch 3841: total training loss 0.00318\n",
            "2025-06-26 08:25:37,433 Epoch 3841: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3842\n",
            "2025-06-26 08:25:37,435 EPOCH 3842\n",
            "INFO:__main__:Epoch 3842: total training loss 0.00315\n",
            "2025-06-26 08:25:37,511 Epoch 3842: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3843\n",
            "2025-06-26 08:25:37,513 EPOCH 3843\n",
            "INFO:__main__:Epoch 3843: total training loss 0.00307\n",
            "2025-06-26 08:25:37,587 Epoch 3843: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3844\n",
            "2025-06-26 08:25:37,588 EPOCH 3844\n",
            "INFO:__main__:Epoch 3844: total training loss 0.00313\n",
            "2025-06-26 08:25:37,655 Epoch 3844: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3845\n",
            "2025-06-26 08:25:37,657 EPOCH 3845\n",
            "INFO:__main__:Epoch 3845: total training loss 0.00327\n",
            "2025-06-26 08:25:37,724 Epoch 3845: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3846\n",
            "2025-06-26 08:25:37,727 EPOCH 3846\n",
            "INFO:__main__:Epoch 3846: total training loss 0.00310\n",
            "2025-06-26 08:25:37,799 Epoch 3846: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3847\n",
            "2025-06-26 08:25:37,802 EPOCH 3847\n",
            "INFO:__main__:Epoch 3847: total training loss 0.00288\n",
            "2025-06-26 08:25:37,874 Epoch 3847: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3848\n",
            "2025-06-26 08:25:37,877 EPOCH 3848\n",
            "INFO:__main__:Epoch 3848: total training loss 0.00316\n",
            "2025-06-26 08:25:37,954 Epoch 3848: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3849\n",
            "2025-06-26 08:25:37,956 EPOCH 3849\n",
            "INFO:__main__:Epoch 3849: total training loss 0.00271\n",
            "2025-06-26 08:25:38,023 Epoch 3849: total training loss 0.00271\n",
            "INFO:__main__:EPOCH 3850\n",
            "2025-06-26 08:25:38,025 EPOCH 3850\n",
            "INFO:__main__:Epoch 3850: total training loss 0.00308\n",
            "2025-06-26 08:25:38,091 Epoch 3850: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3851\n",
            "2025-06-26 08:25:38,093 EPOCH 3851\n",
            "INFO:__main__:Epoch 3851: total training loss 0.00271\n",
            "2025-06-26 08:25:38,159 Epoch 3851: total training loss 0.00271\n",
            "INFO:__main__:EPOCH 3852\n",
            "2025-06-26 08:25:38,161 EPOCH 3852\n",
            "INFO:__main__:Epoch 3852: total training loss 0.00279\n",
            "2025-06-26 08:25:38,232 Epoch 3852: total training loss 0.00279\n",
            "INFO:__main__:EPOCH 3853\n",
            "2025-06-26 08:25:38,234 EPOCH 3853\n",
            "INFO:__main__:Epoch 3853: total training loss 0.00281\n",
            "2025-06-26 08:25:38,305 Epoch 3853: total training loss 0.00281\n",
            "INFO:__main__:EPOCH 3854\n",
            "2025-06-26 08:25:38,307 EPOCH 3854\n",
            "INFO:__main__:Epoch 3854: total training loss 0.00288\n",
            "2025-06-26 08:25:38,374 Epoch 3854: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3855\n",
            "2025-06-26 08:25:38,376 EPOCH 3855\n",
            "INFO:__main__:Epoch 3855: total training loss 0.00277\n",
            "2025-06-26 08:25:38,445 Epoch 3855: total training loss 0.00277\n",
            "INFO:__main__:EPOCH 3856\n",
            "2025-06-26 08:25:38,447 EPOCH 3856\n",
            "INFO:__main__:Epoch 3856: total training loss 0.00256\n",
            "2025-06-26 08:25:38,517 Epoch 3856: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 3857\n",
            "2025-06-26 08:25:38,519 EPOCH 3857\n",
            "INFO:__main__:Epoch 3857: total training loss 0.00281\n",
            "2025-06-26 08:25:38,616 Epoch 3857: total training loss 0.00281\n",
            "INFO:__main__:EPOCH 3858\n",
            "2025-06-26 08:25:38,618 EPOCH 3858\n",
            "INFO:__main__:Epoch 3858: total training loss 0.00289\n",
            "2025-06-26 08:25:38,688 Epoch 3858: total training loss 0.00289\n",
            "INFO:__main__:EPOCH 3859\n",
            "2025-06-26 08:25:38,690 EPOCH 3859\n",
            "INFO:__main__:Epoch 3859: total training loss 0.00281\n",
            "2025-06-26 08:25:38,758 Epoch 3859: total training loss 0.00281\n",
            "INFO:__main__:EPOCH 3860\n",
            "2025-06-26 08:25:38,760 EPOCH 3860\n",
            "INFO:__main__:Epoch 3860: total training loss 0.00290\n",
            "2025-06-26 08:25:38,830 Epoch 3860: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3861\n",
            "2025-06-26 08:25:38,833 EPOCH 3861\n",
            "INFO:__main__:Epoch 3861: total training loss 0.00294\n",
            "2025-06-26 08:25:38,899 Epoch 3861: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3862\n",
            "2025-06-26 08:25:38,902 EPOCH 3862\n",
            "INFO:__main__:Epoch 3862: total training loss 0.00306\n",
            "2025-06-26 08:25:38,967 Epoch 3862: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3863\n",
            "2025-06-26 08:25:38,969 EPOCH 3863\n",
            "INFO:__main__:Epoch 3863: total training loss 0.00282\n",
            "2025-06-26 08:25:39,036 Epoch 3863: total training loss 0.00282\n",
            "INFO:__main__:EPOCH 3864\n",
            "2025-06-26 08:25:39,039 EPOCH 3864\n",
            "INFO:__main__:Epoch 3864: total training loss 0.00292\n",
            "2025-06-26 08:25:39,106 Epoch 3864: total training loss 0.00292\n",
            "INFO:__main__:EPOCH 3865\n",
            "2025-06-26 08:25:39,108 EPOCH 3865\n",
            "INFO:__main__:Epoch 3865: total training loss 0.00290\n",
            "2025-06-26 08:25:39,171 Epoch 3865: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3866\n",
            "2025-06-26 08:25:39,173 EPOCH 3866\n",
            "INFO:__main__:Epoch 3866: total training loss 0.00276\n",
            "2025-06-26 08:25:39,248 Epoch 3866: total training loss 0.00276\n",
            "INFO:__main__:EPOCH 3867\n",
            "2025-06-26 08:25:39,250 EPOCH 3867\n",
            "INFO:__main__:Epoch 3867: total training loss 0.00305\n",
            "2025-06-26 08:25:39,321 Epoch 3867: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3868\n",
            "2025-06-26 08:25:39,323 EPOCH 3868\n",
            "INFO:__main__:Epoch 3868: total training loss 0.00296\n",
            "2025-06-26 08:25:39,391 Epoch 3868: total training loss 0.00296\n",
            "INFO:__main__:EPOCH 3869\n",
            "2025-06-26 08:25:39,394 EPOCH 3869\n",
            "INFO:__main__:Epoch 3869: total training loss 0.00263\n",
            "2025-06-26 08:25:39,460 Epoch 3869: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 3870\n",
            "2025-06-26 08:25:39,462 EPOCH 3870\n",
            "INFO:__main__:Epoch 3870: total training loss 0.00301\n",
            "2025-06-26 08:25:39,531 Epoch 3870: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3871\n",
            "2025-06-26 08:25:39,533 EPOCH 3871\n",
            "INFO:__main__:Epoch 3871: total training loss 0.00295\n",
            "2025-06-26 08:25:39,602 Epoch 3871: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 3872\n",
            "2025-06-26 08:25:39,604 EPOCH 3872\n",
            "INFO:__main__:Epoch 3872: total training loss 0.00283\n",
            "2025-06-26 08:25:39,690 Epoch 3872: total training loss 0.00283\n",
            "INFO:__main__:EPOCH 3873\n",
            "2025-06-26 08:25:39,696 EPOCH 3873\n",
            "INFO:__main__:Epoch 3873: total training loss 0.00288\n",
            "2025-06-26 08:25:39,763 Epoch 3873: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3874\n",
            "2025-06-26 08:25:39,765 EPOCH 3874\n",
            "INFO:__main__:Epoch 3874: total training loss 0.00312\n",
            "2025-06-26 08:25:39,833 Epoch 3874: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3875\n",
            "2025-06-26 08:25:39,835 EPOCH 3875\n",
            "INFO:__main__:Epoch 3875: total training loss 0.00288\n",
            "2025-06-26 08:25:39,905 Epoch 3875: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3876\n",
            "2025-06-26 08:25:39,907 EPOCH 3876\n",
            "INFO:__main__:Epoch 3876: total training loss 0.00317\n",
            "2025-06-26 08:25:39,977 Epoch 3876: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3877\n",
            "2025-06-26 08:25:39,980 EPOCH 3877\n",
            "INFO:__main__:Epoch 3877: total training loss 0.00313\n",
            "2025-06-26 08:25:40,047 Epoch 3877: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3878\n",
            "2025-06-26 08:25:40,050 EPOCH 3878\n",
            "INFO:__main__:Epoch 3878: total training loss 0.00331\n",
            "2025-06-26 08:25:40,117 Epoch 3878: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3879\n",
            "2025-06-26 08:25:40,120 EPOCH 3879\n",
            "INFO:__main__:Epoch 3879: total training loss 0.00334\n",
            "2025-06-26 08:25:40,190 Epoch 3879: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3880\n",
            "2025-06-26 08:25:40,192 EPOCH 3880\n",
            "INFO:__main__:Epoch 3880: total training loss 0.00317\n",
            "2025-06-26 08:25:40,260 Epoch 3880: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3881\n",
            "2025-06-26 08:25:40,262 EPOCH 3881\n",
            "INFO:__main__:Epoch 3881: total training loss 0.00314\n",
            "2025-06-26 08:25:40,332 Epoch 3881: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3882\n",
            "2025-06-26 08:25:40,334 EPOCH 3882\n",
            "INFO:__main__:Epoch 3882: total training loss 0.00293\n",
            "2025-06-26 08:25:40,399 Epoch 3882: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3883\n",
            "2025-06-26 08:25:40,401 EPOCH 3883\n",
            "INFO:__main__:Epoch 3883: total training loss 0.00320\n",
            "2025-06-26 08:25:40,472 Epoch 3883: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3884\n",
            "2025-06-26 08:25:40,473 EPOCH 3884\n",
            "INFO:__main__:Epoch 3884: total training loss 0.00309\n",
            "2025-06-26 08:25:40,543 Epoch 3884: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3885\n",
            "2025-06-26 08:25:40,545 EPOCH 3885\n",
            "INFO:__main__:Epoch 3885: total training loss 0.00341\n",
            "2025-06-26 08:25:40,611 Epoch 3885: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3886\n",
            "2025-06-26 08:25:40,613 EPOCH 3886\n",
            "INFO:__main__:Epoch 3886: total training loss 0.00325\n",
            "2025-06-26 08:25:40,679 Epoch 3886: total training loss 0.00325\n",
            "INFO:__main__:EPOCH 3887\n",
            "2025-06-26 08:25:40,683 EPOCH 3887\n",
            "INFO:__main__:Epoch 3887: total training loss 0.00338\n",
            "2025-06-26 08:25:40,765 Epoch 3887: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3888\n",
            "2025-06-26 08:25:40,767 EPOCH 3888\n",
            "INFO:__main__:Epoch 3888: total training loss 0.00329\n",
            "2025-06-26 08:25:40,835 Epoch 3888: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3889\n",
            "2025-06-26 08:25:40,838 EPOCH 3889\n",
            "INFO:__main__:Epoch 3889: total training loss 0.00316\n",
            "2025-06-26 08:25:40,908 Epoch 3889: total training loss 0.00316\n",
            "INFO:__main__:EPOCH 3890\n",
            "2025-06-26 08:25:40,911 EPOCH 3890\n",
            "INFO:__main__:Epoch 3890: total training loss 0.00313\n",
            "2025-06-26 08:25:40,981 Epoch 3890: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3891\n",
            "2025-06-26 08:25:40,983 EPOCH 3891\n",
            "INFO:__main__:Epoch 3891: total training loss 0.00305\n",
            "2025-06-26 08:25:41,051 Epoch 3891: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3892\n",
            "2025-06-26 08:25:41,053 EPOCH 3892\n",
            "INFO:__main__:Epoch 3892: total training loss 0.00319\n",
            "2025-06-26 08:25:41,121 Epoch 3892: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3893\n",
            "2025-06-26 08:25:41,123 EPOCH 3893\n",
            "INFO:__main__:Epoch 3893: total training loss 0.00332\n",
            "2025-06-26 08:25:41,190 Epoch 3893: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3894\n",
            "2025-06-26 08:25:41,192 EPOCH 3894\n",
            "INFO:__main__:Epoch 3894: total training loss 0.00299\n",
            "2025-06-26 08:25:41,258 Epoch 3894: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3895\n",
            "2025-06-26 08:25:41,261 EPOCH 3895\n",
            "INFO:__main__:Epoch 3895: total training loss 0.00340\n",
            "2025-06-26 08:25:41,331 Epoch 3895: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 3896\n",
            "2025-06-26 08:25:41,333 EPOCH 3896\n",
            "INFO:__main__:Epoch 3896: total training loss 0.00331\n",
            "2025-06-26 08:25:41,404 Epoch 3896: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3897\n",
            "2025-06-26 08:25:41,406 EPOCH 3897\n",
            "INFO:__main__:Epoch 3897: total training loss 0.00308\n",
            "2025-06-26 08:25:41,472 Epoch 3897: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3898\n",
            "2025-06-26 08:25:41,474 EPOCH 3898\n",
            "INFO:__main__:Epoch 3898: total training loss 0.00332\n",
            "2025-06-26 08:25:41,545 Epoch 3898: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3899\n",
            "2025-06-26 08:25:41,548 EPOCH 3899\n",
            "INFO:__main__:Epoch 3899: total training loss 0.00330\n",
            "2025-06-26 08:25:41,617 Epoch 3899: total training loss 0.00330\n",
            "INFO:__main__:EPOCH 3900\n",
            "2025-06-26 08:25:41,619 EPOCH 3900\n",
            "INFO:__main__:Epoch 3900: total training loss 0.00291\n",
            "2025-06-26 08:25:41,685 Epoch 3900: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 3901\n",
            "2025-06-26 08:25:41,688 EPOCH 3901\n",
            "INFO:__main__:Epoch 3901: total training loss 0.00329\n",
            "2025-06-26 08:25:41,762 Epoch 3901: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3902\n",
            "2025-06-26 08:25:41,764 EPOCH 3902\n",
            "INFO:__main__:Epoch 3902: total training loss 0.00305\n",
            "2025-06-26 08:25:41,841 Epoch 3902: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3903\n",
            "2025-06-26 08:25:41,844 EPOCH 3903\n",
            "INFO:__main__:Epoch 3903: total training loss 0.00301\n",
            "2025-06-26 08:25:41,911 Epoch 3903: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3904\n",
            "2025-06-26 08:25:41,913 EPOCH 3904\n",
            "INFO:__main__:Epoch 3904: total training loss 0.00302\n",
            "2025-06-26 08:25:41,985 Epoch 3904: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3905\n",
            "2025-06-26 08:25:41,987 EPOCH 3905\n",
            "INFO:__main__:Epoch 3905: total training loss 0.00308\n",
            "2025-06-26 08:25:42,052 Epoch 3905: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3906\n",
            "2025-06-26 08:25:42,054 EPOCH 3906\n",
            "INFO:__main__:Epoch 3906: total training loss 0.00293\n",
            "2025-06-26 08:25:42,124 Epoch 3906: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3907\n",
            "2025-06-26 08:25:42,126 EPOCH 3907\n",
            "INFO:__main__:Epoch 3907: total training loss 0.00323\n",
            "2025-06-26 08:25:42,198 Epoch 3907: total training loss 0.00323\n",
            "INFO:__main__:EPOCH 3908\n",
            "2025-06-26 08:25:42,200 EPOCH 3908\n",
            "INFO:__main__:Epoch 3908: total training loss 0.00286\n",
            "2025-06-26 08:25:42,264 Epoch 3908: total training loss 0.00286\n",
            "INFO:__main__:EPOCH 3909\n",
            "2025-06-26 08:25:42,266 EPOCH 3909\n",
            "INFO:__main__:Epoch 3909: total training loss 0.00302\n",
            "2025-06-26 08:25:42,329 Epoch 3909: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3910\n",
            "2025-06-26 08:25:42,331 EPOCH 3910\n",
            "INFO:__main__:Epoch 3910: total training loss 0.00291\n",
            "2025-06-26 08:25:42,398 Epoch 3910: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 3911\n",
            "2025-06-26 08:25:42,400 EPOCH 3911\n",
            "INFO:__main__:Epoch 3911: total training loss 0.00283\n",
            "2025-06-26 08:25:42,467 Epoch 3911: total training loss 0.00283\n",
            "INFO:__main__:EPOCH 3912\n",
            "2025-06-26 08:25:42,470 EPOCH 3912\n",
            "INFO:__main__:Epoch 3912: total training loss 0.00327\n",
            "2025-06-26 08:25:42,539 Epoch 3912: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3913\n",
            "2025-06-26 08:25:42,541 EPOCH 3913\n",
            "INFO:__main__:Epoch 3913: total training loss 0.00301\n",
            "2025-06-26 08:25:42,611 Epoch 3913: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3914\n",
            "2025-06-26 08:25:42,613 EPOCH 3914\n",
            "INFO:__main__:Epoch 3914: total training loss 0.00292\n",
            "2025-06-26 08:25:42,681 Epoch 3914: total training loss 0.00292\n",
            "INFO:__main__:EPOCH 3915\n",
            "2025-06-26 08:25:42,683 EPOCH 3915\n",
            "INFO:__main__:Epoch 3915: total training loss 0.00327\n",
            "2025-06-26 08:25:42,753 Epoch 3915: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3916\n",
            "2025-06-26 08:25:42,755 EPOCH 3916\n",
            "INFO:__main__:Epoch 3916: total training loss 0.00303\n",
            "2025-06-26 08:25:42,835 Epoch 3916: total training loss 0.00303\n",
            "INFO:__main__:EPOCH 3917\n",
            "2025-06-26 08:25:42,837 EPOCH 3917\n",
            "INFO:__main__:Epoch 3917: total training loss 0.00326\n",
            "2025-06-26 08:25:42,904 Epoch 3917: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3918\n",
            "2025-06-26 08:25:42,906 EPOCH 3918\n",
            "INFO:__main__:Epoch 3918: total training loss 0.00317\n",
            "2025-06-26 08:25:42,976 Epoch 3918: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3919\n",
            "2025-06-26 08:25:42,978 EPOCH 3919\n",
            "INFO:__main__:Epoch 3919: total training loss 0.00332\n",
            "2025-06-26 08:25:43,048 Epoch 3919: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3920\n",
            "2025-06-26 08:25:43,050 EPOCH 3920\n",
            "INFO:__main__:Epoch 3920: total training loss 0.00327\n",
            "2025-06-26 08:25:43,117 Epoch 3920: total training loss 0.00327\n",
            "INFO:__main__:EPOCH 3921\n",
            "2025-06-26 08:25:43,119 EPOCH 3921\n",
            "INFO:__main__:Epoch 3921: total training loss 0.00307\n",
            "2025-06-26 08:25:43,187 Epoch 3921: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3922\n",
            "2025-06-26 08:25:43,189 EPOCH 3922\n",
            "INFO:__main__:Epoch 3922: total training loss 0.00294\n",
            "2025-06-26 08:25:43,256 Epoch 3922: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3923\n",
            "2025-06-26 08:25:43,257 EPOCH 3923\n",
            "INFO:__main__:Epoch 3923: total training loss 0.00326\n",
            "2025-06-26 08:25:43,329 Epoch 3923: total training loss 0.00326\n",
            "INFO:__main__:EPOCH 3924\n",
            "2025-06-26 08:25:43,331 EPOCH 3924\n",
            "INFO:__main__:Epoch 3924: total training loss 0.00320\n",
            "2025-06-26 08:25:43,398 Epoch 3924: total training loss 0.00320\n",
            "INFO:__main__:EPOCH 3925\n",
            "2025-06-26 08:25:43,400 EPOCH 3925\n",
            "INFO:__main__:Epoch 3925: total training loss 0.00338\n",
            "2025-06-26 08:25:43,466 Epoch 3925: total training loss 0.00338\n",
            "INFO:__main__:EPOCH 3926\n",
            "2025-06-26 08:25:43,468 EPOCH 3926\n",
            "INFO:__main__:Epoch 3926: total training loss 0.00322\n",
            "2025-06-26 08:25:43,534 Epoch 3926: total training loss 0.00322\n",
            "INFO:__main__:EPOCH 3927\n",
            "2025-06-26 08:25:43,536 EPOCH 3927\n",
            "INFO:__main__:Epoch 3927: total training loss 0.00336\n",
            "2025-06-26 08:25:43,607 Epoch 3927: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3928\n",
            "2025-06-26 08:25:43,609 EPOCH 3928\n",
            "INFO:__main__:Epoch 3928: total training loss 0.00291\n",
            "2025-06-26 08:25:43,676 Epoch 3928: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 3929\n",
            "2025-06-26 08:25:43,678 EPOCH 3929\n",
            "INFO:__main__:Epoch 3929: total training loss 0.00332\n",
            "2025-06-26 08:25:43,747 Epoch 3929: total training loss 0.00332\n",
            "INFO:__main__:EPOCH 3930\n",
            "2025-06-26 08:25:43,749 EPOCH 3930\n",
            "INFO:__main__:Epoch 3930: total training loss 0.00319\n",
            "2025-06-26 08:25:43,816 Epoch 3930: total training loss 0.00319\n",
            "INFO:__main__:EPOCH 3931\n",
            "2025-06-26 08:25:43,819 EPOCH 3931\n",
            "INFO:__main__:Epoch 3931: total training loss 0.00318\n",
            "2025-06-26 08:25:43,903 Epoch 3931: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 3932\n",
            "2025-06-26 08:25:43,906 EPOCH 3932\n",
            "INFO:__main__:Epoch 3932: total training loss 0.00312\n",
            "2025-06-26 08:25:43,977 Epoch 3932: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3933\n",
            "2025-06-26 08:25:43,980 EPOCH 3933\n",
            "INFO:__main__:Epoch 3933: total training loss 0.00309\n",
            "2025-06-26 08:25:44,047 Epoch 3933: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3934\n",
            "2025-06-26 08:25:44,049 EPOCH 3934\n",
            "INFO:__main__:Epoch 3934: total training loss 0.00311\n",
            "2025-06-26 08:25:44,116 Epoch 3934: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3935\n",
            "2025-06-26 08:25:44,118 EPOCH 3935\n",
            "INFO:__main__:Epoch 3935: total training loss 0.00308\n",
            "2025-06-26 08:25:44,189 Epoch 3935: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3936\n",
            "2025-06-26 08:25:44,191 EPOCH 3936\n",
            "INFO:__main__:Epoch 3936: total training loss 0.00300\n",
            "2025-06-26 08:25:44,259 Epoch 3936: total training loss 0.00300\n",
            "INFO:__main__:EPOCH 3937\n",
            "2025-06-26 08:25:44,262 EPOCH 3937\n",
            "INFO:__main__:Epoch 3937: total training loss 0.00312\n",
            "2025-06-26 08:25:44,326 Epoch 3937: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3938\n",
            "2025-06-26 08:25:44,329 EPOCH 3938\n",
            "INFO:__main__:Epoch 3938: total training loss 0.00293\n",
            "2025-06-26 08:25:44,397 Epoch 3938: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3939\n",
            "2025-06-26 08:25:44,399 EPOCH 3939\n",
            "INFO:__main__:Epoch 3939: total training loss 0.00302\n",
            "2025-06-26 08:25:44,470 Epoch 3939: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3940\n",
            "2025-06-26 08:25:44,472 EPOCH 3940\n",
            "INFO:__main__:Epoch 3940: total training loss 0.00312\n",
            "2025-06-26 08:25:44,538 Epoch 3940: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3941\n",
            "2025-06-26 08:25:44,540 EPOCH 3941\n",
            "INFO:__main__:Epoch 3941: total training loss 0.00296\n",
            "2025-06-26 08:25:44,608 Epoch 3941: total training loss 0.00296\n",
            "INFO:__main__:EPOCH 3942\n",
            "2025-06-26 08:25:44,609 EPOCH 3942\n",
            "INFO:__main__:Epoch 3942: total training loss 0.00287\n",
            "2025-06-26 08:25:44,676 Epoch 3942: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 3943\n",
            "2025-06-26 08:25:44,678 EPOCH 3943\n",
            "INFO:__main__:Epoch 3943: total training loss 0.00309\n",
            "2025-06-26 08:25:44,745 Epoch 3943: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3944\n",
            "2025-06-26 08:25:44,747 EPOCH 3944\n",
            "INFO:__main__:Epoch 3944: total training loss 0.00311\n",
            "2025-06-26 08:25:44,814 Epoch 3944: total training loss 0.00311\n",
            "INFO:__main__:EPOCH 3945\n",
            "2025-06-26 08:25:44,816 EPOCH 3945\n",
            "INFO:__main__:Epoch 3945: total training loss 0.00299\n",
            "2025-06-26 08:25:44,886 Epoch 3945: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 3946\n",
            "2025-06-26 08:25:44,890 EPOCH 3946\n",
            "INFO:__main__:Epoch 3946: total training loss 0.00305\n",
            "2025-06-26 08:25:44,974 Epoch 3946: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3947\n",
            "2025-06-26 08:25:44,977 EPOCH 3947\n",
            "INFO:__main__:Epoch 3947: total training loss 0.00310\n",
            "2025-06-26 08:25:45,046 Epoch 3947: total training loss 0.00310\n",
            "INFO:__main__:EPOCH 3948\n",
            "2025-06-26 08:25:45,048 EPOCH 3948\n",
            "INFO:__main__:Epoch 3948: total training loss 0.00305\n",
            "2025-06-26 08:25:45,114 Epoch 3948: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3949\n",
            "2025-06-26 08:25:45,116 EPOCH 3949\n",
            "INFO:__main__:Epoch 3949: total training loss 0.00302\n",
            "2025-06-26 08:25:45,182 Epoch 3949: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3950\n",
            "2025-06-26 08:25:45,184 EPOCH 3950\n",
            "INFO:__main__:Epoch 3950: total training loss 0.00298\n",
            "2025-06-26 08:25:45,253 Epoch 3950: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3951\n",
            "2025-06-26 08:25:45,256 EPOCH 3951\n",
            "INFO:__main__:Epoch 3951: total training loss 0.00268\n",
            "2025-06-26 08:25:45,325 Epoch 3951: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 3952\n",
            "2025-06-26 08:25:45,328 EPOCH 3952\n",
            "INFO:__main__:Epoch 3952: total training loss 0.00300\n",
            "2025-06-26 08:25:45,394 Epoch 3952: total training loss 0.00300\n",
            "INFO:__main__:EPOCH 3953\n",
            "2025-06-26 08:25:45,396 EPOCH 3953\n",
            "INFO:__main__:Epoch 3953: total training loss 0.00283\n",
            "2025-06-26 08:25:45,461 Epoch 3953: total training loss 0.00283\n",
            "INFO:__main__:EPOCH 3954\n",
            "2025-06-26 08:25:45,463 EPOCH 3954\n",
            "INFO:__main__:Epoch 3954: total training loss 0.00268\n",
            "2025-06-26 08:25:45,531 Epoch 3954: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 3955\n",
            "2025-06-26 08:25:45,533 EPOCH 3955\n",
            "INFO:__main__:Epoch 3955: total training loss 0.00305\n",
            "2025-06-26 08:25:45,609 Epoch 3955: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3956\n",
            "2025-06-26 08:25:45,611 EPOCH 3956\n",
            "INFO:__main__:Epoch 3956: total training loss 0.00282\n",
            "2025-06-26 08:25:45,681 Epoch 3956: total training loss 0.00282\n",
            "INFO:__main__:EPOCH 3957\n",
            "2025-06-26 08:25:45,684 EPOCH 3957\n",
            "INFO:__main__:Epoch 3957: total training loss 0.00288\n",
            "2025-06-26 08:25:45,759 Epoch 3957: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 3958\n",
            "2025-06-26 08:25:45,761 EPOCH 3958\n",
            "INFO:__main__:Epoch 3958: total training loss 0.00284\n",
            "2025-06-26 08:25:45,831 Epoch 3958: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 3959\n",
            "2025-06-26 08:25:45,834 EPOCH 3959\n",
            "INFO:__main__:Epoch 3959: total training loss 0.00298\n",
            "2025-06-26 08:25:45,902 Epoch 3959: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 3960\n",
            "2025-06-26 08:25:45,904 EPOCH 3960\n",
            "INFO:__main__:Epoch 3960: total training loss 0.00290\n",
            "2025-06-26 08:25:45,982 Epoch 3960: total training loss 0.00290\n",
            "INFO:__main__:EPOCH 3961\n",
            "2025-06-26 08:25:45,985 EPOCH 3961\n",
            "INFO:__main__:Epoch 3961: total training loss 0.00286\n",
            "2025-06-26 08:25:46,053 Epoch 3961: total training loss 0.00286\n",
            "INFO:__main__:EPOCH 3962\n",
            "2025-06-26 08:25:46,055 EPOCH 3962\n",
            "INFO:__main__:Epoch 3962: total training loss 0.00301\n",
            "2025-06-26 08:25:46,122 Epoch 3962: total training loss 0.00301\n",
            "INFO:__main__:EPOCH 3963\n",
            "2025-06-26 08:25:46,124 EPOCH 3963\n",
            "INFO:__main__:Epoch 3963: total training loss 0.00307\n",
            "2025-06-26 08:25:46,216 Epoch 3963: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3964\n",
            "2025-06-26 08:25:46,219 EPOCH 3964\n",
            "INFO:__main__:Epoch 3964: total training loss 0.00295\n",
            "2025-06-26 08:25:46,298 Epoch 3964: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 3965\n",
            "2025-06-26 08:25:46,300 EPOCH 3965\n",
            "INFO:__main__:Epoch 3965: total training loss 0.00294\n",
            "2025-06-26 08:25:46,380 Epoch 3965: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 3966\n",
            "2025-06-26 08:25:46,382 EPOCH 3966\n",
            "INFO:__main__:Epoch 3966: total training loss 0.00295\n",
            "2025-06-26 08:25:46,479 Epoch 3966: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 3967\n",
            "2025-06-26 08:25:46,486 EPOCH 3967\n",
            "INFO:__main__:Epoch 3967: total training loss 0.00331\n",
            "2025-06-26 08:25:46,562 Epoch 3967: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3968\n",
            "2025-06-26 08:25:46,564 EPOCH 3968\n",
            "INFO:__main__:Epoch 3968: total training loss 0.00329\n",
            "2025-06-26 08:25:46,659 Epoch 3968: total training loss 0.00329\n",
            "INFO:__main__:EPOCH 3969\n",
            "2025-06-26 08:25:46,662 EPOCH 3969\n",
            "INFO:__main__:Epoch 3969: total training loss 0.00309\n",
            "2025-06-26 08:25:46,750 Epoch 3969: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3970\n",
            "2025-06-26 08:25:46,752 EPOCH 3970\n",
            "INFO:__main__:Epoch 3970: total training loss 0.00309\n",
            "2025-06-26 08:25:46,826 Epoch 3970: total training loss 0.00309\n",
            "INFO:__main__:EPOCH 3971\n",
            "2025-06-26 08:25:46,828 EPOCH 3971\n",
            "INFO:__main__:Epoch 3971: total training loss 0.00331\n",
            "2025-06-26 08:25:46,899 Epoch 3971: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 3972\n",
            "2025-06-26 08:25:46,901 EPOCH 3972\n",
            "INFO:__main__:Epoch 3972: total training loss 0.00307\n",
            "2025-06-26 08:25:46,987 Epoch 3972: total training loss 0.00307\n",
            "INFO:__main__:EPOCH 3973\n",
            "2025-06-26 08:25:46,989 EPOCH 3973\n",
            "INFO:__main__:Epoch 3973: total training loss 0.00306\n",
            "2025-06-26 08:25:47,113 Epoch 3973: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3974\n",
            "2025-06-26 08:25:47,115 EPOCH 3974\n",
            "INFO:__main__:Epoch 3974: total training loss 0.00293\n",
            "2025-06-26 08:25:47,192 Epoch 3974: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3975\n",
            "2025-06-26 08:25:47,194 EPOCH 3975\n",
            "INFO:__main__:Epoch 3975: total training loss 0.00308\n",
            "2025-06-26 08:25:47,286 Epoch 3975: total training loss 0.00308\n",
            "INFO:__main__:EPOCH 3976\n",
            "2025-06-26 08:25:47,288 EPOCH 3976\n",
            "INFO:__main__:Epoch 3976: total training loss 0.00304\n",
            "2025-06-26 08:25:47,379 Epoch 3976: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 3977\n",
            "2025-06-26 08:25:47,381 EPOCH 3977\n",
            "INFO:__main__:Epoch 3977: total training loss 0.00305\n",
            "2025-06-26 08:25:47,452 Epoch 3977: total training loss 0.00305\n",
            "INFO:__main__:EPOCH 3978\n",
            "2025-06-26 08:25:47,454 EPOCH 3978\n",
            "INFO:__main__:Epoch 3978: total training loss 0.00312\n",
            "2025-06-26 08:25:47,525 Epoch 3978: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 3979\n",
            "2025-06-26 08:25:47,527 EPOCH 3979\n",
            "INFO:__main__:Epoch 3979: total training loss 0.00292\n",
            "2025-06-26 08:25:47,597 Epoch 3979: total training loss 0.00292\n",
            "INFO:__main__:EPOCH 3980\n",
            "2025-06-26 08:25:47,599 EPOCH 3980\n",
            "INFO:__main__:Epoch 3980: total training loss 0.00302\n",
            "2025-06-26 08:25:47,677 Epoch 3980: total training loss 0.00302\n",
            "INFO:__main__:EPOCH 3981\n",
            "2025-06-26 08:25:47,679 EPOCH 3981\n",
            "INFO:__main__:Epoch 3981: total training loss 0.00317\n",
            "2025-06-26 08:25:47,750 Epoch 3981: total training loss 0.00317\n",
            "INFO:__main__:EPOCH 3982\n",
            "2025-06-26 08:25:47,753 EPOCH 3982\n",
            "INFO:__main__:Epoch 3982: total training loss 0.00314\n",
            "2025-06-26 08:25:47,854 Epoch 3982: total training loss 0.00314\n",
            "INFO:__main__:EPOCH 3983\n",
            "2025-06-26 08:25:47,856 EPOCH 3983\n",
            "INFO:__main__:Epoch 3983: total training loss 0.00295\n",
            "2025-06-26 08:25:47,974 Epoch 3983: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 3984\n",
            "2025-06-26 08:25:47,977 EPOCH 3984\n",
            "INFO:__main__:Epoch 3984: total training loss 0.00291\n",
            "2025-06-26 08:25:48,075 Epoch 3984: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 3985\n",
            "2025-06-26 08:25:48,078 EPOCH 3985\n",
            "INFO:__main__:Epoch 3985: total training loss 0.00306\n",
            "2025-06-26 08:25:48,176 Epoch 3985: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3986\n",
            "2025-06-26 08:25:48,178 EPOCH 3986\n",
            "INFO:__main__:Epoch 3986: total training loss 0.00313\n",
            "2025-06-26 08:25:48,285 Epoch 3986: total training loss 0.00313\n",
            "INFO:__main__:EPOCH 3987\n",
            "2025-06-26 08:25:48,288 EPOCH 3987\n",
            "INFO:__main__:Epoch 3987: total training loss 0.00306\n",
            "2025-06-26 08:25:48,362 Epoch 3987: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3988\n",
            "2025-06-26 08:25:48,364 EPOCH 3988\n",
            "INFO:__main__:Epoch 3988: total training loss 0.00293\n",
            "2025-06-26 08:25:48,444 Epoch 3988: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 3989\n",
            "2025-06-26 08:25:48,446 EPOCH 3989\n",
            "INFO:__main__:Epoch 3989: total training loss 0.00321\n",
            "2025-06-26 08:25:48,518 Epoch 3989: total training loss 0.00321\n",
            "INFO:__main__:EPOCH 3990\n",
            "2025-06-26 08:25:48,520 EPOCH 3990\n",
            "INFO:__main__:Epoch 3990: total training loss 0.00315\n",
            "2025-06-26 08:25:48,594 Epoch 3990: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3991\n",
            "2025-06-26 08:25:48,596 EPOCH 3991\n",
            "INFO:__main__:Epoch 3991: total training loss 0.00334\n",
            "2025-06-26 08:25:48,675 Epoch 3991: total training loss 0.00334\n",
            "INFO:__main__:EPOCH 3992\n",
            "2025-06-26 08:25:48,677 EPOCH 3992\n",
            "INFO:__main__:Epoch 3992: total training loss 0.00345\n",
            "2025-06-26 08:25:48,750 Epoch 3992: total training loss 0.00345\n",
            "INFO:__main__:EPOCH 3993\n",
            "2025-06-26 08:25:48,752 EPOCH 3993\n",
            "INFO:__main__:Epoch 3993: total training loss 0.00336\n",
            "2025-06-26 08:25:48,827 Epoch 3993: total training loss 0.00336\n",
            "INFO:__main__:EPOCH 3994\n",
            "2025-06-26 08:25:48,829 EPOCH 3994\n",
            "INFO:__main__:Epoch 3994: total training loss 0.00365\n",
            "2025-06-26 08:25:48,902 Epoch 3994: total training loss 0.00365\n",
            "INFO:__main__:EPOCH 3995\n",
            "2025-06-26 08:25:48,905 EPOCH 3995\n",
            "INFO:__main__:Epoch 3995: total training loss 0.00306\n",
            "2025-06-26 08:25:48,983 Epoch 3995: total training loss 0.00306\n",
            "INFO:__main__:EPOCH 3996\n",
            "2025-06-26 08:25:48,990 EPOCH 3996\n",
            "INFO:__main__:Epoch 3996: total training loss 0.00341\n",
            "2025-06-26 08:25:49,090 Epoch 3996: total training loss 0.00341\n",
            "INFO:__main__:EPOCH 3997\n",
            "2025-06-26 08:25:49,096 EPOCH 3997\n",
            "INFO:__main__:Epoch 3997: total training loss 0.00315\n",
            "2025-06-26 08:25:49,176 Epoch 3997: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3998\n",
            "2025-06-26 08:25:49,182 EPOCH 3998\n",
            "INFO:__main__:Epoch 3998: total training loss 0.00315\n",
            "2025-06-26 08:25:49,280 Epoch 3998: total training loss 0.00315\n",
            "INFO:__main__:EPOCH 3999\n",
            "2025-06-26 08:25:49,285 EPOCH 3999\n",
            "INFO:__main__:Epoch 3999: total training loss 0.00278\n",
            "2025-06-26 08:25:49,360 Epoch 3999: total training loss 0.00278\n",
            "INFO:__main__:EPOCH 4000\n",
            "2025-06-26 08:25:49,366 EPOCH 4000\n",
            "INFO:__main__:Epoch 4000 Step:     4000 Batch Loss:     0.003085 Tokens per Sec:  1520046, Lr: 0.001000\n",
            "2025-06-26 08:25:49,460 Epoch 4000 Step:     4000 Batch Loss:     0.003085 Tokens per Sec:  1520046, Lr: 0.001000\n",
            "INFO:__main__:Hooray! New best validation result [dtw]!\n",
            "2025-06-26 08:25:50,443 Hooray! New best validation result [dtw]!\n",
            "INFO:__main__:Saving new checkpoint.\n",
            "2025-06-26 08:25:50,445 Saving new checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev/11August_2010_Wednesday_tagesschau-2    dtw: 15.03\n",
            "dev/11August_2010_Wednesday_tagesschau-3    dtw: 11.91\n",
            "dev/11August_2010_Wednesday_tagesschau-8    dtw: 14.43\n",
            "dev/25October_2010_Monday_tagesschau-22    dtw: 15.90\n",
            "dev/05May_2011_Thursday_tagesschau-25    dtw: 10.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 4754\n",
            "2025-06-26 08:27:09,959 EPOCH 4754\n",
            "INFO:__main__:Epoch 4754: total training loss 0.00272\n",
            "2025-06-26 08:27:10,026 Epoch 4754: total training loss 0.00272\n",
            "INFO:__main__:EPOCH 4755\n",
            "2025-06-26 08:27:10,028 EPOCH 4755\n",
            "INFO:__main__:Epoch 4755: total training loss 0.00269\n",
            "2025-06-26 08:27:10,099 Epoch 4755: total training loss 0.00269\n",
            "INFO:__main__:EPOCH 4756\n",
            "2025-06-26 08:27:10,102 EPOCH 4756\n",
            "INFO:__main__:Epoch 4756: total training loss 0.00250\n",
            "2025-06-26 08:27:10,169 Epoch 4756: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 4757\n",
            "2025-06-26 08:27:10,171 EPOCH 4757\n",
            "INFO:__main__:Epoch 4757: total training loss 0.00270\n",
            "2025-06-26 08:27:10,242 Epoch 4757: total training loss 0.00270\n",
            "INFO:__main__:EPOCH 4758\n",
            "2025-06-26 08:27:10,245 EPOCH 4758\n",
            "INFO:__main__:Epoch 4758: total training loss 0.00260\n",
            "2025-06-26 08:27:10,311 Epoch 4758: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 4759\n",
            "2025-06-26 08:27:10,313 EPOCH 4759\n",
            "INFO:__main__:Epoch 4759: total training loss 0.00241\n",
            "2025-06-26 08:27:10,380 Epoch 4759: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 4760\n",
            "2025-06-26 08:27:10,384 EPOCH 4760\n",
            "INFO:__main__:Epoch 4760: total training loss 0.00266\n",
            "2025-06-26 08:27:10,451 Epoch 4760: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 4761\n",
            "2025-06-26 08:27:10,454 EPOCH 4761\n",
            "INFO:__main__:Epoch 4761: total training loss 0.00255\n",
            "2025-06-26 08:27:10,521 Epoch 4761: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4762\n",
            "2025-06-26 08:27:10,523 EPOCH 4762\n",
            "INFO:__main__:Epoch 4762: total training loss 0.00244\n",
            "2025-06-26 08:27:10,597 Epoch 4762: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 4763\n",
            "2025-06-26 08:27:10,599 EPOCH 4763\n",
            "INFO:__main__:Epoch 4763: total training loss 0.00242\n",
            "2025-06-26 08:27:10,665 Epoch 4763: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4764\n",
            "2025-06-26 08:27:10,667 EPOCH 4764\n",
            "INFO:__main__:Epoch 4764: total training loss 0.00260\n",
            "2025-06-26 08:27:10,742 Epoch 4764: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 4765\n",
            "2025-06-26 08:27:10,744 EPOCH 4765\n",
            "INFO:__main__:Epoch 4765: total training loss 0.00236\n",
            "2025-06-26 08:27:10,824 Epoch 4765: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4766\n",
            "2025-06-26 08:27:10,826 EPOCH 4766\n",
            "INFO:__main__:Epoch 4766: total training loss 0.00244\n",
            "2025-06-26 08:27:10,898 Epoch 4766: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 4767\n",
            "2025-06-26 08:27:10,900 EPOCH 4767\n",
            "INFO:__main__:Epoch 4767: total training loss 0.00249\n",
            "2025-06-26 08:27:10,971 Epoch 4767: total training loss 0.00249\n",
            "INFO:__main__:EPOCH 4768\n",
            "2025-06-26 08:27:10,973 EPOCH 4768\n",
            "INFO:__main__:Epoch 4768: total training loss 0.00253\n",
            "2025-06-26 08:27:11,040 Epoch 4768: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4769\n",
            "2025-06-26 08:27:11,042 EPOCH 4769\n",
            "INFO:__main__:Epoch 4769: total training loss 0.00250\n",
            "2025-06-26 08:27:11,110 Epoch 4769: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 4770\n",
            "2025-06-26 08:27:11,112 EPOCH 4770\n",
            "INFO:__main__:Epoch 4770: total training loss 0.00253\n",
            "2025-06-26 08:27:11,179 Epoch 4770: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4771\n",
            "2025-06-26 08:27:11,182 EPOCH 4771\n",
            "INFO:__main__:Epoch 4771: total training loss 0.00272\n",
            "2025-06-26 08:27:11,257 Epoch 4771: total training loss 0.00272\n",
            "INFO:__main__:EPOCH 4772\n",
            "2025-06-26 08:27:11,260 EPOCH 4772\n",
            "INFO:__main__:Epoch 4772: total training loss 0.00257\n",
            "2025-06-26 08:27:11,326 Epoch 4772: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 4773\n",
            "2025-06-26 08:27:11,328 EPOCH 4773\n",
            "INFO:__main__:Epoch 4773: total training loss 0.00285\n",
            "2025-06-26 08:27:11,397 Epoch 4773: total training loss 0.00285\n",
            "INFO:__main__:EPOCH 4774\n",
            "2025-06-26 08:27:11,399 EPOCH 4774\n",
            "INFO:__main__:Epoch 4774: total training loss 0.00235\n",
            "2025-06-26 08:27:11,465 Epoch 4774: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 4775\n",
            "2025-06-26 08:27:11,467 EPOCH 4775\n",
            "INFO:__main__:Epoch 4775: total training loss 0.00239\n",
            "2025-06-26 08:27:11,535 Epoch 4775: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4776\n",
            "2025-06-26 08:27:11,537 EPOCH 4776\n",
            "INFO:__main__:Epoch 4776: total training loss 0.00253\n",
            "2025-06-26 08:27:11,604 Epoch 4776: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4777\n",
            "2025-06-26 08:27:11,606 EPOCH 4777\n",
            "INFO:__main__:Epoch 4777: total training loss 0.00244\n",
            "2025-06-26 08:27:11,674 Epoch 4777: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 4778\n",
            "2025-06-26 08:27:11,676 EPOCH 4778\n",
            "INFO:__main__:Epoch 4778: total training loss 0.00263\n",
            "2025-06-26 08:27:11,738 Epoch 4778: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 4779\n",
            "2025-06-26 08:27:11,740 EPOCH 4779\n",
            "INFO:__main__:Epoch 4779: total training loss 0.00254\n",
            "2025-06-26 08:27:11,825 Epoch 4779: total training loss 0.00254\n",
            "INFO:__main__:EPOCH 4780\n",
            "2025-06-26 08:27:11,829 EPOCH 4780\n",
            "INFO:__main__:Epoch 4780: total training loss 0.00280\n",
            "2025-06-26 08:27:11,898 Epoch 4780: total training loss 0.00280\n",
            "INFO:__main__:EPOCH 4781\n",
            "2025-06-26 08:27:11,900 EPOCH 4781\n",
            "INFO:__main__:Epoch 4781: total training loss 0.00289\n",
            "2025-06-26 08:27:11,969 Epoch 4781: total training loss 0.00289\n",
            "INFO:__main__:EPOCH 4782\n",
            "2025-06-26 08:27:11,971 EPOCH 4782\n",
            "INFO:__main__:Epoch 4782: total training loss 0.00277\n",
            "2025-06-26 08:27:12,037 Epoch 4782: total training loss 0.00277\n",
            "INFO:__main__:EPOCH 4783\n",
            "2025-06-26 08:27:12,039 EPOCH 4783\n",
            "INFO:__main__:Epoch 4783: total training loss 0.00276\n",
            "2025-06-26 08:27:12,110 Epoch 4783: total training loss 0.00276\n",
            "INFO:__main__:EPOCH 4784\n",
            "2025-06-26 08:27:12,112 EPOCH 4784\n",
            "INFO:__main__:Epoch 4784: total training loss 0.00259\n",
            "2025-06-26 08:27:12,181 Epoch 4784: total training loss 0.00259\n",
            "INFO:__main__:EPOCH 4785\n",
            "2025-06-26 08:27:12,183 EPOCH 4785\n",
            "INFO:__main__:Epoch 4785: total training loss 0.00299\n",
            "2025-06-26 08:27:12,256 Epoch 4785: total training loss 0.00299\n",
            "INFO:__main__:EPOCH 4786\n",
            "2025-06-26 08:27:12,258 EPOCH 4786\n",
            "INFO:__main__:Epoch 4786: total training loss 0.00262\n",
            "2025-06-26 08:27:12,330 Epoch 4786: total training loss 0.00262\n",
            "INFO:__main__:EPOCH 4787\n",
            "2025-06-26 08:27:12,332 EPOCH 4787\n",
            "INFO:__main__:Epoch 4787: total training loss 0.00293\n",
            "2025-06-26 08:27:12,400 Epoch 4787: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 4788\n",
            "2025-06-26 08:27:12,402 EPOCH 4788\n",
            "INFO:__main__:Epoch 4788: total training loss 0.00270\n",
            "2025-06-26 08:27:12,471 Epoch 4788: total training loss 0.00270\n",
            "INFO:__main__:EPOCH 4789\n",
            "2025-06-26 08:27:12,473 EPOCH 4789\n",
            "INFO:__main__:Epoch 4789: total training loss 0.00287\n",
            "2025-06-26 08:27:12,542 Epoch 4789: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 4790\n",
            "2025-06-26 08:27:12,544 EPOCH 4790\n",
            "INFO:__main__:Epoch 4790: total training loss 0.00263\n",
            "2025-06-26 08:27:12,617 Epoch 4790: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 4791\n",
            "2025-06-26 08:27:12,619 EPOCH 4791\n",
            "INFO:__main__:Epoch 4791: total training loss 0.00284\n",
            "2025-06-26 08:27:12,688 Epoch 4791: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 4792\n",
            "2025-06-26 08:27:12,691 EPOCH 4792\n",
            "INFO:__main__:Epoch 4792: total training loss 0.00247\n",
            "2025-06-26 08:27:12,757 Epoch 4792: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4793\n",
            "2025-06-26 08:27:12,759 EPOCH 4793\n",
            "INFO:__main__:Epoch 4793: total training loss 0.00293\n",
            "2025-06-26 08:27:12,825 Epoch 4793: total training loss 0.00293\n",
            "INFO:__main__:EPOCH 4794\n",
            "2025-06-26 08:27:12,828 EPOCH 4794\n",
            "INFO:__main__:Epoch 4794: total training loss 0.00266\n",
            "2025-06-26 08:27:12,936 Epoch 4794: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 4795\n",
            "2025-06-26 08:27:12,938 EPOCH 4795\n",
            "INFO:__main__:Epoch 4795: total training loss 0.00255\n",
            "2025-06-26 08:27:13,024 Epoch 4795: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4796\n",
            "2025-06-26 08:27:13,026 EPOCH 4796\n",
            "INFO:__main__:Epoch 4796: total training loss 0.00239\n",
            "2025-06-26 08:27:13,127 Epoch 4796: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4797\n",
            "2025-06-26 08:27:13,129 EPOCH 4797\n",
            "INFO:__main__:Epoch 4797: total training loss 0.00267\n",
            "2025-06-26 08:27:13,220 Epoch 4797: total training loss 0.00267\n",
            "INFO:__main__:EPOCH 4798\n",
            "2025-06-26 08:27:13,222 EPOCH 4798\n",
            "INFO:__main__:Epoch 4798: total training loss 0.00236\n",
            "2025-06-26 08:27:13,329 Epoch 4798: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4799\n",
            "2025-06-26 08:27:13,331 EPOCH 4799\n",
            "INFO:__main__:Epoch 4799: total training loss 0.00255\n",
            "2025-06-26 08:27:13,420 Epoch 4799: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4800\n",
            "2025-06-26 08:27:13,422 EPOCH 4800\n",
            "INFO:__main__:Epoch 4800: total training loss 0.00247\n",
            "2025-06-26 08:27:13,496 Epoch 4800: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4801\n",
            "2025-06-26 08:27:13,500 EPOCH 4801\n",
            "INFO:__main__:Epoch 4801: total training loss 0.00241\n",
            "2025-06-26 08:27:13,585 Epoch 4801: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 4802\n",
            "2025-06-26 08:27:13,587 EPOCH 4802\n",
            "INFO:__main__:Epoch 4802: total training loss 0.00231\n",
            "2025-06-26 08:27:13,675 Epoch 4802: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 4803\n",
            "2025-06-26 08:27:13,680 EPOCH 4803\n",
            "INFO:__main__:Epoch 4803: total training loss 0.00260\n",
            "2025-06-26 08:27:13,781 Epoch 4803: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 4804\n",
            "2025-06-26 08:27:13,788 EPOCH 4804\n",
            "INFO:__main__:Epoch 4804: total training loss 0.00246\n",
            "2025-06-26 08:27:13,895 Epoch 4804: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 4805\n",
            "2025-06-26 08:27:13,897 EPOCH 4805\n",
            "INFO:__main__:Epoch 4805: total training loss 0.00258\n",
            "2025-06-26 08:27:13,995 Epoch 4805: total training loss 0.00258\n",
            "INFO:__main__:EPOCH 4806\n",
            "2025-06-26 08:27:14,001 EPOCH 4806\n",
            "INFO:__main__:Epoch 4806: total training loss 0.00243\n",
            "2025-06-26 08:27:14,077 Epoch 4806: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 4807\n",
            "2025-06-26 08:27:14,080 EPOCH 4807\n",
            "INFO:__main__:Epoch 4807: total training loss 0.00262\n",
            "2025-06-26 08:27:14,153 Epoch 4807: total training loss 0.00262\n",
            "INFO:__main__:EPOCH 4808\n",
            "2025-06-26 08:27:14,154 EPOCH 4808\n",
            "INFO:__main__:Epoch 4808: total training loss 0.00257\n",
            "2025-06-26 08:27:14,227 Epoch 4808: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 4809\n",
            "2025-06-26 08:27:14,229 EPOCH 4809\n",
            "INFO:__main__:Epoch 4809: total training loss 0.00252\n",
            "2025-06-26 08:27:14,300 Epoch 4809: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 4810\n",
            "2025-06-26 08:27:14,303 EPOCH 4810\n",
            "INFO:__main__:Epoch 4810: total training loss 0.00253\n",
            "2025-06-26 08:27:14,373 Epoch 4810: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4811\n",
            "2025-06-26 08:27:14,375 EPOCH 4811\n",
            "INFO:__main__:Epoch 4811: total training loss 0.00233\n",
            "2025-06-26 08:27:14,446 Epoch 4811: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 4812\n",
            "2025-06-26 08:27:14,448 EPOCH 4812\n",
            "INFO:__main__:Epoch 4812: total training loss 0.00253\n",
            "2025-06-26 08:27:14,517 Epoch 4812: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4813\n",
            "2025-06-26 08:27:14,519 EPOCH 4813\n",
            "INFO:__main__:Epoch 4813: total training loss 0.00228\n",
            "2025-06-26 08:27:14,590 Epoch 4813: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 4814\n",
            "2025-06-26 08:27:14,593 EPOCH 4814\n",
            "INFO:__main__:Epoch 4814: total training loss 0.00247\n",
            "2025-06-26 08:27:14,669 Epoch 4814: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4815\n",
            "2025-06-26 08:27:14,671 EPOCH 4815\n",
            "INFO:__main__:Epoch 4815: total training loss 0.00220\n",
            "2025-06-26 08:27:14,758 Epoch 4815: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 4816\n",
            "2025-06-26 08:27:14,762 EPOCH 4816\n",
            "INFO:__main__:Epoch 4816: total training loss 0.00245\n",
            "2025-06-26 08:27:14,853 Epoch 4816: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 4817\n",
            "2025-06-26 08:27:14,855 EPOCH 4817\n",
            "INFO:__main__:Epoch 4817: total training loss 0.00223\n",
            "2025-06-26 08:27:14,933 Epoch 4817: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 4818\n",
            "2025-06-26 08:27:14,937 EPOCH 4818\n",
            "INFO:__main__:Epoch 4818: total training loss 0.00242\n",
            "2025-06-26 08:27:15,021 Epoch 4818: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4819\n",
            "2025-06-26 08:27:15,025 EPOCH 4819\n",
            "INFO:__main__:Epoch 4819: total training loss 0.00239\n",
            "2025-06-26 08:27:15,123 Epoch 4819: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4820\n",
            "2025-06-26 08:27:15,126 EPOCH 4820\n",
            "INFO:__main__:Epoch 4820: total training loss 0.00239\n",
            "2025-06-26 08:27:15,216 Epoch 4820: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4821\n",
            "2025-06-26 08:27:15,219 EPOCH 4821\n",
            "INFO:__main__:Epoch 4821: total training loss 0.00258\n",
            "2025-06-26 08:27:15,298 Epoch 4821: total training loss 0.00258\n",
            "INFO:__main__:EPOCH 4822\n",
            "2025-06-26 08:27:15,300 EPOCH 4822\n",
            "INFO:__main__:Epoch 4822: total training loss 0.00230\n",
            "2025-06-26 08:27:15,377 Epoch 4822: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4823\n",
            "2025-06-26 08:27:15,380 EPOCH 4823\n",
            "INFO:__main__:Epoch 4823: total training loss 0.00221\n",
            "2025-06-26 08:27:15,450 Epoch 4823: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 4824\n",
            "2025-06-26 08:27:15,452 EPOCH 4824\n",
            "INFO:__main__:Epoch 4824: total training loss 0.00215\n",
            "2025-06-26 08:27:15,541 Epoch 4824: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 4825\n",
            "2025-06-26 08:27:15,543 EPOCH 4825\n",
            "INFO:__main__:Epoch 4825: total training loss 0.00239\n",
            "2025-06-26 08:27:15,622 Epoch 4825: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4826\n",
            "2025-06-26 08:27:15,628 EPOCH 4826\n",
            "INFO:__main__:Epoch 4826: total training loss 0.00238\n",
            "2025-06-26 08:27:15,703 Epoch 4826: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 4827\n",
            "2025-06-26 08:27:15,707 EPOCH 4827\n",
            "INFO:__main__:Epoch 4827: total training loss 0.00234\n",
            "2025-06-26 08:27:15,786 Epoch 4827: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 4828\n",
            "2025-06-26 08:27:15,791 EPOCH 4828\n",
            "INFO:__main__:Epoch 4828: total training loss 0.00239\n",
            "2025-06-26 08:27:15,869 Epoch 4828: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4829\n",
            "2025-06-26 08:27:15,875 EPOCH 4829\n",
            "INFO:__main__:Epoch 4829: total training loss 0.00217\n",
            "2025-06-26 08:27:15,980 Epoch 4829: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 4830\n",
            "2025-06-26 08:27:15,983 EPOCH 4830\n",
            "INFO:__main__:Epoch 4830: total training loss 0.00242\n",
            "2025-06-26 08:27:16,074 Epoch 4830: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4831\n",
            "2025-06-26 08:27:16,084 EPOCH 4831\n",
            "INFO:__main__:Epoch 4831: total training loss 0.00236\n",
            "2025-06-26 08:27:16,202 Epoch 4831: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4832\n",
            "2025-06-26 08:27:16,204 EPOCH 4832\n",
            "INFO:__main__:Epoch 4832: total training loss 0.00231\n",
            "2025-06-26 08:27:16,305 Epoch 4832: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 4833\n",
            "2025-06-26 08:27:16,307 EPOCH 4833\n",
            "INFO:__main__:Epoch 4833: total training loss 0.00243\n",
            "2025-06-26 08:27:16,419 Epoch 4833: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 4834\n",
            "2025-06-26 08:27:16,427 EPOCH 4834\n",
            "INFO:__main__:Epoch 4834: total training loss 0.00271\n",
            "2025-06-26 08:27:16,505 Epoch 4834: total training loss 0.00271\n",
            "INFO:__main__:EPOCH 4835\n",
            "2025-06-26 08:27:16,513 EPOCH 4835\n",
            "INFO:__main__:Epoch 4835: total training loss 0.00257\n",
            "2025-06-26 08:27:16,615 Epoch 4835: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 4836\n",
            "2025-06-26 08:27:16,617 EPOCH 4836\n",
            "INFO:__main__:Epoch 4836: total training loss 0.00254\n",
            "2025-06-26 08:27:16,693 Epoch 4836: total training loss 0.00254\n",
            "INFO:__main__:EPOCH 4837\n",
            "2025-06-26 08:27:16,701 EPOCH 4837\n",
            "INFO:__main__:Epoch 4837: total training loss 0.00253\n",
            "2025-06-26 08:27:16,777 Epoch 4837: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4838\n",
            "2025-06-26 08:27:16,781 EPOCH 4838\n",
            "INFO:__main__:Epoch 4838: total training loss 0.00242\n",
            "2025-06-26 08:27:16,876 Epoch 4838: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4839\n",
            "2025-06-26 08:27:16,878 EPOCH 4839\n",
            "INFO:__main__:Epoch 4839: total training loss 0.00248\n",
            "2025-06-26 08:27:16,974 Epoch 4839: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 4840\n",
            "2025-06-26 08:27:16,979 EPOCH 4840\n",
            "INFO:__main__:Epoch 4840: total training loss 0.00251\n",
            "2025-06-26 08:27:17,077 Epoch 4840: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 4841\n",
            "2025-06-26 08:27:17,082 EPOCH 4841\n",
            "INFO:__main__:Epoch 4841: total training loss 0.00247\n",
            "2025-06-26 08:27:17,180 Epoch 4841: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4842\n",
            "2025-06-26 08:27:17,183 EPOCH 4842\n",
            "INFO:__main__:Epoch 4842: total training loss 0.00240\n",
            "2025-06-26 08:27:17,281 Epoch 4842: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4843\n",
            "2025-06-26 08:27:17,285 EPOCH 4843\n",
            "INFO:__main__:Epoch 4843: total training loss 0.00240\n",
            "2025-06-26 08:27:17,380 Epoch 4843: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4844\n",
            "2025-06-26 08:27:17,383 EPOCH 4844\n",
            "INFO:__main__:Epoch 4844: total training loss 0.00226\n",
            "2025-06-26 08:27:17,491 Epoch 4844: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 4845\n",
            "2025-06-26 08:27:17,495 EPOCH 4845\n",
            "INFO:__main__:Epoch 4845: total training loss 0.00233\n",
            "2025-06-26 08:27:17,605 Epoch 4845: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 4846\n",
            "2025-06-26 08:27:17,608 EPOCH 4846\n",
            "INFO:__main__:Epoch 4846: total training loss 0.00219\n",
            "2025-06-26 08:27:17,692 Epoch 4846: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 4847\n",
            "2025-06-26 08:27:17,698 EPOCH 4847\n",
            "INFO:__main__:Epoch 4847: total training loss 0.00225\n",
            "2025-06-26 08:27:17,779 Epoch 4847: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 4848\n",
            "2025-06-26 08:27:17,782 EPOCH 4848\n",
            "INFO:__main__:Epoch 4848: total training loss 0.00220\n",
            "2025-06-26 08:27:17,882 Epoch 4848: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 4849\n",
            "2025-06-26 08:27:17,884 EPOCH 4849\n",
            "INFO:__main__:Epoch 4849: total training loss 0.00215\n",
            "2025-06-26 08:27:17,994 Epoch 4849: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 4850\n",
            "2025-06-26 08:27:17,999 EPOCH 4850\n",
            "INFO:__main__:Epoch 4850: total training loss 0.00208\n",
            "2025-06-26 08:27:18,096 Epoch 4850: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 4851\n",
            "2025-06-26 08:27:18,099 EPOCH 4851\n",
            "INFO:__main__:Epoch 4851: total training loss 0.00225\n",
            "2025-06-26 08:27:18,181 Epoch 4851: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 4852\n",
            "2025-06-26 08:27:18,183 EPOCH 4852\n",
            "INFO:__main__:Epoch 4852: total training loss 0.00222\n",
            "2025-06-26 08:27:18,259 Epoch 4852: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 4853\n",
            "2025-06-26 08:27:18,261 EPOCH 4853\n",
            "INFO:__main__:Epoch 4853: total training loss 0.00224\n",
            "2025-06-26 08:27:18,348 Epoch 4853: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4854\n",
            "2025-06-26 08:27:18,351 EPOCH 4854\n",
            "INFO:__main__:Epoch 4854: total training loss 0.00225\n",
            "2025-06-26 08:27:18,418 Epoch 4854: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 4855\n",
            "2025-06-26 08:27:18,420 EPOCH 4855\n",
            "INFO:__main__:Epoch 4855: total training loss 0.00216\n",
            "2025-06-26 08:27:18,490 Epoch 4855: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 4856\n",
            "2025-06-26 08:27:18,492 EPOCH 4856\n",
            "INFO:__main__:Epoch 4856: total training loss 0.00224\n",
            "2025-06-26 08:27:18,566 Epoch 4856: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4857\n",
            "2025-06-26 08:27:18,568 EPOCH 4857\n",
            "INFO:__main__:Epoch 4857: total training loss 0.00227\n",
            "2025-06-26 08:27:18,637 Epoch 4857: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 4858\n",
            "2025-06-26 08:27:18,639 EPOCH 4858\n",
            "INFO:__main__:Epoch 4858: total training loss 0.00277\n",
            "2025-06-26 08:27:18,707 Epoch 4858: total training loss 0.00277\n",
            "INFO:__main__:EPOCH 4859\n",
            "2025-06-26 08:27:18,709 EPOCH 4859\n",
            "INFO:__main__:Epoch 4859: total training loss 0.00250\n",
            "2025-06-26 08:27:18,779 Epoch 4859: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 4860\n",
            "2025-06-26 08:27:18,783 EPOCH 4860\n",
            "INFO:__main__:Epoch 4860: total training loss 0.00273\n",
            "2025-06-26 08:27:18,850 Epoch 4860: total training loss 0.00273\n",
            "INFO:__main__:EPOCH 4861\n",
            "2025-06-26 08:27:18,852 EPOCH 4861\n",
            "INFO:__main__:Epoch 4861: total training loss 0.00272\n",
            "2025-06-26 08:27:18,921 Epoch 4861: total training loss 0.00272\n",
            "INFO:__main__:EPOCH 4862\n",
            "2025-06-26 08:27:18,923 EPOCH 4862\n",
            "INFO:__main__:Epoch 4862: total training loss 0.00259\n",
            "2025-06-26 08:27:18,992 Epoch 4862: total training loss 0.00259\n",
            "INFO:__main__:EPOCH 4863\n",
            "2025-06-26 08:27:18,994 EPOCH 4863\n",
            "INFO:__main__:Epoch 4863: total training loss 0.00294\n",
            "2025-06-26 08:27:19,065 Epoch 4863: total training loss 0.00294\n",
            "INFO:__main__:EPOCH 4864\n",
            "2025-06-26 08:27:19,067 EPOCH 4864\n",
            "INFO:__main__:Epoch 4864: total training loss 0.00271\n",
            "2025-06-26 08:27:19,138 Epoch 4864: total training loss 0.00271\n",
            "INFO:__main__:EPOCH 4865\n",
            "2025-06-26 08:27:19,140 EPOCH 4865\n",
            "INFO:__main__:Epoch 4865: total training loss 0.00304\n",
            "2025-06-26 08:27:19,213 Epoch 4865: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 4866\n",
            "2025-06-26 08:27:19,215 EPOCH 4866\n",
            "INFO:__main__:Epoch 4866: total training loss 0.00267\n",
            "2025-06-26 08:27:19,284 Epoch 4866: total training loss 0.00267\n",
            "INFO:__main__:EPOCH 4867\n",
            "2025-06-26 08:27:19,286 EPOCH 4867\n",
            "INFO:__main__:Epoch 4867: total training loss 0.00285\n",
            "2025-06-26 08:27:19,365 Epoch 4867: total training loss 0.00285\n",
            "INFO:__main__:EPOCH 4868\n",
            "2025-06-26 08:27:19,367 EPOCH 4868\n",
            "INFO:__main__:Epoch 4868: total training loss 0.00246\n",
            "2025-06-26 08:27:19,440 Epoch 4868: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 4869\n",
            "2025-06-26 08:27:19,443 EPOCH 4869\n",
            "INFO:__main__:Epoch 4869: total training loss 0.00295\n",
            "2025-06-26 08:27:19,509 Epoch 4869: total training loss 0.00295\n",
            "INFO:__main__:EPOCH 4870\n",
            "2025-06-26 08:27:19,512 EPOCH 4870\n",
            "INFO:__main__:Epoch 4870: total training loss 0.00263\n",
            "2025-06-26 08:27:19,583 Epoch 4870: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 4871\n",
            "2025-06-26 08:27:19,585 EPOCH 4871\n",
            "INFO:__main__:Epoch 4871: total training loss 0.00283\n",
            "2025-06-26 08:27:19,655 Epoch 4871: total training loss 0.00283\n",
            "INFO:__main__:EPOCH 4872\n",
            "2025-06-26 08:27:19,657 EPOCH 4872\n",
            "INFO:__main__:Epoch 4872: total training loss 0.00253\n",
            "2025-06-26 08:27:19,736 Epoch 4872: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4873\n",
            "2025-06-26 08:27:19,738 EPOCH 4873\n",
            "INFO:__main__:Epoch 4873: total training loss 0.00243\n",
            "2025-06-26 08:27:19,807 Epoch 4873: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 4874\n",
            "2025-06-26 08:27:19,809 EPOCH 4874\n",
            "INFO:__main__:Epoch 4874: total training loss 0.00255\n",
            "2025-06-26 08:27:19,876 Epoch 4874: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4875\n",
            "2025-06-26 08:27:19,878 EPOCH 4875\n",
            "INFO:__main__:Epoch 4875: total training loss 0.00240\n",
            "2025-06-26 08:27:19,946 Epoch 4875: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4876\n",
            "2025-06-26 08:27:19,948 EPOCH 4876\n",
            "INFO:__main__:Epoch 4876: total training loss 0.00240\n",
            "2025-06-26 08:27:20,017 Epoch 4876: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4877\n",
            "2025-06-26 08:27:20,019 EPOCH 4877\n",
            "INFO:__main__:Epoch 4877: total training loss 0.00230\n",
            "2025-06-26 08:27:20,096 Epoch 4877: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4878\n",
            "2025-06-26 08:27:20,099 EPOCH 4878\n",
            "INFO:__main__:Epoch 4878: total training loss 0.00224\n",
            "2025-06-26 08:27:20,167 Epoch 4878: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4879\n",
            "2025-06-26 08:27:20,168 EPOCH 4879\n",
            "INFO:__main__:Epoch 4879: total training loss 0.00231\n",
            "2025-06-26 08:27:20,238 Epoch 4879: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 4880\n",
            "2025-06-26 08:27:20,240 EPOCH 4880\n",
            "INFO:__main__:Epoch 4880: total training loss 0.00217\n",
            "2025-06-26 08:27:20,309 Epoch 4880: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 4881\n",
            "2025-06-26 08:27:20,312 EPOCH 4881\n",
            "INFO:__main__:Epoch 4881: total training loss 0.00224\n",
            "2025-06-26 08:27:20,380 Epoch 4881: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4882\n",
            "2025-06-26 08:27:20,382 EPOCH 4882\n",
            "INFO:__main__:Epoch 4882: total training loss 0.00219\n",
            "2025-06-26 08:27:20,470 Epoch 4882: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 4883\n",
            "2025-06-26 08:27:20,472 EPOCH 4883\n",
            "INFO:__main__:Epoch 4883: total training loss 0.00228\n",
            "2025-06-26 08:27:20,540 Epoch 4883: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 4884\n",
            "2025-06-26 08:27:20,542 EPOCH 4884\n",
            "INFO:__main__:Epoch 4884: total training loss 0.00238\n",
            "2025-06-26 08:27:20,610 Epoch 4884: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 4885\n",
            "2025-06-26 08:27:20,612 EPOCH 4885\n",
            "INFO:__main__:Epoch 4885: total training loss 0.00253\n",
            "2025-06-26 08:27:20,679 Epoch 4885: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4886\n",
            "2025-06-26 08:27:20,681 EPOCH 4886\n",
            "INFO:__main__:Epoch 4886: total training loss 0.00268\n",
            "2025-06-26 08:27:20,751 Epoch 4886: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 4887\n",
            "2025-06-26 08:27:20,753 EPOCH 4887\n",
            "INFO:__main__:Epoch 4887: total training loss 0.00255\n",
            "2025-06-26 08:27:20,824 Epoch 4887: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4888\n",
            "2025-06-26 08:27:20,828 EPOCH 4888\n",
            "INFO:__main__:Epoch 4888: total training loss 0.00289\n",
            "2025-06-26 08:27:20,897 Epoch 4888: total training loss 0.00289\n",
            "INFO:__main__:EPOCH 4889\n",
            "2025-06-26 08:27:20,900 EPOCH 4889\n",
            "INFO:__main__:Epoch 4889: total training loss 0.00264\n",
            "2025-06-26 08:27:20,967 Epoch 4889: total training loss 0.00264\n",
            "INFO:__main__:EPOCH 4890\n",
            "2025-06-26 08:27:20,969 EPOCH 4890\n",
            "INFO:__main__:Epoch 4890: total training loss 0.00270\n",
            "2025-06-26 08:27:21,035 Epoch 4890: total training loss 0.00270\n",
            "INFO:__main__:EPOCH 4891\n",
            "2025-06-26 08:27:21,037 EPOCH 4891\n",
            "INFO:__main__:Epoch 4891: total training loss 0.00286\n",
            "2025-06-26 08:27:21,112 Epoch 4891: total training loss 0.00286\n",
            "INFO:__main__:EPOCH 4892\n",
            "2025-06-26 08:27:21,115 EPOCH 4892\n",
            "INFO:__main__:Epoch 4892: total training loss 0.00253\n",
            "2025-06-26 08:27:21,183 Epoch 4892: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4893\n",
            "2025-06-26 08:27:21,187 EPOCH 4893\n",
            "INFO:__main__:Epoch 4893: total training loss 0.00244\n",
            "2025-06-26 08:27:21,257 Epoch 4893: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 4894\n",
            "2025-06-26 08:27:21,259 EPOCH 4894\n",
            "INFO:__main__:Epoch 4894: total training loss 0.00241\n",
            "2025-06-26 08:27:21,334 Epoch 4894: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 4895\n",
            "2025-06-26 08:27:21,336 EPOCH 4895\n",
            "INFO:__main__:Epoch 4895: total training loss 0.00236\n",
            "2025-06-26 08:27:21,403 Epoch 4895: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4896\n",
            "2025-06-26 08:27:21,406 EPOCH 4896\n",
            "INFO:__main__:Epoch 4896: total training loss 0.00261\n",
            "2025-06-26 08:27:21,496 Epoch 4896: total training loss 0.00261\n",
            "INFO:__main__:EPOCH 4897\n",
            "2025-06-26 08:27:21,500 EPOCH 4897\n",
            "INFO:__main__:Epoch 4897: total training loss 0.00249\n",
            "2025-06-26 08:27:21,570 Epoch 4897: total training loss 0.00249\n",
            "INFO:__main__:EPOCH 4898\n",
            "2025-06-26 08:27:21,572 EPOCH 4898\n",
            "INFO:__main__:Epoch 4898: total training loss 0.00263\n",
            "2025-06-26 08:27:21,639 Epoch 4898: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 4899\n",
            "2025-06-26 08:27:21,641 EPOCH 4899\n",
            "INFO:__main__:Epoch 4899: total training loss 0.00250\n",
            "2025-06-26 08:27:21,708 Epoch 4899: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 4900\n",
            "2025-06-26 08:27:21,710 EPOCH 4900\n",
            "INFO:__main__:Epoch 4900: total training loss 0.00230\n",
            "2025-06-26 08:27:21,778 Epoch 4900: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4901\n",
            "2025-06-26 08:27:21,780 EPOCH 4901\n",
            "INFO:__main__:Epoch 4901: total training loss 0.00252\n",
            "2025-06-26 08:27:21,852 Epoch 4901: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 4902\n",
            "2025-06-26 08:27:21,854 EPOCH 4902\n",
            "INFO:__main__:Epoch 4902: total training loss 0.00239\n",
            "2025-06-26 08:27:21,921 Epoch 4902: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 4903\n",
            "2025-06-26 08:27:21,924 EPOCH 4903\n",
            "INFO:__main__:Epoch 4903: total training loss 0.00232\n",
            "2025-06-26 08:27:21,995 Epoch 4903: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4904\n",
            "2025-06-26 08:27:21,997 EPOCH 4904\n",
            "INFO:__main__:Epoch 4904: total training loss 0.00233\n",
            "2025-06-26 08:27:22,063 Epoch 4904: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 4905\n",
            "2025-06-26 08:27:22,066 EPOCH 4905\n",
            "INFO:__main__:Epoch 4905: total training loss 0.00240\n",
            "2025-06-26 08:27:22,140 Epoch 4905: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4906\n",
            "2025-06-26 08:27:22,142 EPOCH 4906\n",
            "INFO:__main__:Epoch 4906: total training loss 0.00247\n",
            "2025-06-26 08:27:22,211 Epoch 4906: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4907\n",
            "2025-06-26 08:27:22,213 EPOCH 4907\n",
            "INFO:__main__:Epoch 4907: total training loss 0.00224\n",
            "2025-06-26 08:27:22,282 Epoch 4907: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4908\n",
            "2025-06-26 08:27:22,284 EPOCH 4908\n",
            "INFO:__main__:Epoch 4908: total training loss 0.00225\n",
            "2025-06-26 08:27:22,354 Epoch 4908: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 4909\n",
            "2025-06-26 08:27:22,356 EPOCH 4909\n",
            "INFO:__main__:Epoch 4909: total training loss 0.00212\n",
            "2025-06-26 08:27:22,423 Epoch 4909: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 4910\n",
            "2025-06-26 08:27:22,425 EPOCH 4910\n",
            "INFO:__main__:Epoch 4910: total training loss 0.00224\n",
            "2025-06-26 08:27:22,510 Epoch 4910: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4911\n",
            "2025-06-26 08:27:22,512 EPOCH 4911\n",
            "INFO:__main__:Epoch 4911: total training loss 0.00218\n",
            "2025-06-26 08:27:22,585 Epoch 4911: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 4912\n",
            "2025-06-26 08:27:22,587 EPOCH 4912\n",
            "INFO:__main__:Epoch 4912: total training loss 0.00221\n",
            "2025-06-26 08:27:22,654 Epoch 4912: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 4913\n",
            "2025-06-26 08:27:22,656 EPOCH 4913\n",
            "INFO:__main__:Epoch 4913: total training loss 0.00208\n",
            "2025-06-26 08:27:22,730 Epoch 4913: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 4914\n",
            "2025-06-26 08:27:22,732 EPOCH 4914\n",
            "INFO:__main__:Epoch 4914: total training loss 0.00214\n",
            "2025-06-26 08:27:22,810 Epoch 4914: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 4915\n",
            "2025-06-26 08:27:22,817 EPOCH 4915\n",
            "INFO:__main__:Epoch 4915: total training loss 0.00211\n",
            "2025-06-26 08:27:22,894 Epoch 4915: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 4916\n",
            "2025-06-26 08:27:22,896 EPOCH 4916\n",
            "INFO:__main__:Epoch 4916: total training loss 0.00214\n",
            "2025-06-26 08:27:22,964 Epoch 4916: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 4917\n",
            "2025-06-26 08:27:22,966 EPOCH 4917\n",
            "INFO:__main__:Epoch 4917: total training loss 0.00206\n",
            "2025-06-26 08:27:23,035 Epoch 4917: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 4918\n",
            "2025-06-26 08:27:23,038 EPOCH 4918\n",
            "INFO:__main__:Epoch 4918: total training loss 0.00228\n",
            "2025-06-26 08:27:23,103 Epoch 4918: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 4919\n",
            "2025-06-26 08:27:23,107 EPOCH 4919\n",
            "INFO:__main__:Epoch 4919: total training loss 0.00221\n",
            "2025-06-26 08:27:23,174 Epoch 4919: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 4920\n",
            "2025-06-26 08:27:23,175 EPOCH 4920\n",
            "INFO:__main__:Epoch 4920: total training loss 0.00232\n",
            "2025-06-26 08:27:23,243 Epoch 4920: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4921\n",
            "2025-06-26 08:27:23,245 EPOCH 4921\n",
            "INFO:__main__:Epoch 4921: total training loss 0.00253\n",
            "2025-06-26 08:27:23,317 Epoch 4921: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 4922\n",
            "2025-06-26 08:27:23,320 EPOCH 4922\n",
            "INFO:__main__:Epoch 4922: total training loss 0.00266\n",
            "2025-06-26 08:27:23,386 Epoch 4922: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 4923\n",
            "2025-06-26 08:27:23,388 EPOCH 4923\n",
            "INFO:__main__:Epoch 4923: total training loss 0.00284\n",
            "2025-06-26 08:27:23,454 Epoch 4923: total training loss 0.00284\n",
            "INFO:__main__:EPOCH 4924\n",
            "2025-06-26 08:27:23,456 EPOCH 4924\n",
            "INFO:__main__:Epoch 4924: total training loss 0.00257\n",
            "2025-06-26 08:27:23,535 Epoch 4924: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 4925\n",
            "2025-06-26 08:27:23,538 EPOCH 4925\n",
            "INFO:__main__:Epoch 4925: total training loss 0.00274\n",
            "2025-06-26 08:27:23,610 Epoch 4925: total training loss 0.00274\n",
            "INFO:__main__:EPOCH 4926\n",
            "2025-06-26 08:27:23,612 EPOCH 4926\n",
            "INFO:__main__:Epoch 4926: total training loss 0.00286\n",
            "2025-06-26 08:27:23,678 Epoch 4926: total training loss 0.00286\n",
            "INFO:__main__:EPOCH 4927\n",
            "2025-06-26 08:27:23,680 EPOCH 4927\n",
            "INFO:__main__:Epoch 4927: total training loss 0.00318\n",
            "2025-06-26 08:27:23,750 Epoch 4927: total training loss 0.00318\n",
            "INFO:__main__:EPOCH 4928\n",
            "2025-06-26 08:27:23,751 EPOCH 4928\n",
            "INFO:__main__:Epoch 4928: total training loss 0.00331\n",
            "2025-06-26 08:27:23,822 Epoch 4928: total training loss 0.00331\n",
            "INFO:__main__:EPOCH 4929\n",
            "2025-06-26 08:27:23,824 EPOCH 4929\n",
            "INFO:__main__:Epoch 4929: total training loss 0.00340\n",
            "2025-06-26 08:27:23,893 Epoch 4929: total training loss 0.00340\n",
            "INFO:__main__:EPOCH 4930\n",
            "2025-06-26 08:27:23,895 EPOCH 4930\n",
            "INFO:__main__:Epoch 4930: total training loss 0.00312\n",
            "2025-06-26 08:27:23,966 Epoch 4930: total training loss 0.00312\n",
            "INFO:__main__:EPOCH 4931\n",
            "2025-06-26 08:27:23,968 EPOCH 4931\n",
            "INFO:__main__:Epoch 4931: total training loss 0.00288\n",
            "2025-06-26 08:27:24,036 Epoch 4931: total training loss 0.00288\n",
            "INFO:__main__:EPOCH 4932\n",
            "2025-06-26 08:27:24,038 EPOCH 4932\n",
            "INFO:__main__:Epoch 4932: total training loss 0.00281\n",
            "2025-06-26 08:27:24,108 Epoch 4932: total training loss 0.00281\n",
            "INFO:__main__:EPOCH 4933\n",
            "2025-06-26 08:27:24,111 EPOCH 4933\n",
            "INFO:__main__:Epoch 4933: total training loss 0.00264\n",
            "2025-06-26 08:27:24,189 Epoch 4933: total training loss 0.00264\n",
            "INFO:__main__:EPOCH 4934\n",
            "2025-06-26 08:27:24,191 EPOCH 4934\n",
            "INFO:__main__:Epoch 4934: total training loss 0.00273\n",
            "2025-06-26 08:27:24,261 Epoch 4934: total training loss 0.00273\n",
            "INFO:__main__:EPOCH 4935\n",
            "2025-06-26 08:27:24,263 EPOCH 4935\n",
            "INFO:__main__:Epoch 4935: total training loss 0.00243\n",
            "2025-06-26 08:27:24,335 Epoch 4935: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 4936\n",
            "2025-06-26 08:27:24,337 EPOCH 4936\n",
            "INFO:__main__:Epoch 4936: total training loss 0.00258\n",
            "2025-06-26 08:27:24,404 Epoch 4936: total training loss 0.00258\n",
            "INFO:__main__:EPOCH 4937\n",
            "2025-06-26 08:27:24,406 EPOCH 4937\n",
            "INFO:__main__:Epoch 4937: total training loss 0.00240\n",
            "2025-06-26 08:27:24,475 Epoch 4937: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 4938\n",
            "2025-06-26 08:27:24,477 EPOCH 4938\n",
            "INFO:__main__:Epoch 4938: total training loss 0.00227\n",
            "2025-06-26 08:27:24,546 Epoch 4938: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 4939\n",
            "2025-06-26 08:27:24,550 EPOCH 4939\n",
            "INFO:__main__:Epoch 4939: total training loss 0.00232\n",
            "2025-06-26 08:27:24,637 Epoch 4939: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4940\n",
            "2025-06-26 08:27:24,639 EPOCH 4940\n",
            "INFO:__main__:Epoch 4940: total training loss 0.00255\n",
            "2025-06-26 08:27:24,711 Epoch 4940: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4941\n",
            "2025-06-26 08:27:24,713 EPOCH 4941\n",
            "INFO:__main__:Epoch 4941: total training loss 0.00237\n",
            "2025-06-26 08:27:24,784 Epoch 4941: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 4942\n",
            "2025-06-26 08:27:24,786 EPOCH 4942\n",
            "INFO:__main__:Epoch 4942: total training loss 0.00250\n",
            "2025-06-26 08:27:24,853 Epoch 4942: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 4943\n",
            "2025-06-26 08:27:24,855 EPOCH 4943\n",
            "INFO:__main__:Epoch 4943: total training loss 0.00236\n",
            "2025-06-26 08:27:24,926 Epoch 4943: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4944\n",
            "2025-06-26 08:27:24,928 EPOCH 4944\n",
            "INFO:__main__:Epoch 4944: total training loss 0.00243\n",
            "2025-06-26 08:27:25,000 Epoch 4944: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 4945\n",
            "2025-06-26 08:27:25,002 EPOCH 4945\n",
            "INFO:__main__:Epoch 4945: total training loss 0.00224\n",
            "2025-06-26 08:27:25,077 Epoch 4945: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4946\n",
            "2025-06-26 08:27:25,080 EPOCH 4946\n",
            "INFO:__main__:Epoch 4946: total training loss 0.00230\n",
            "2025-06-26 08:27:25,150 Epoch 4946: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4947\n",
            "2025-06-26 08:27:25,152 EPOCH 4947\n",
            "INFO:__main__:Epoch 4947: total training loss 0.00217\n",
            "2025-06-26 08:27:25,231 Epoch 4947: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 4948\n",
            "2025-06-26 08:27:25,233 EPOCH 4948\n",
            "INFO:__main__:Epoch 4948: total training loss 0.00224\n",
            "2025-06-26 08:27:25,301 Epoch 4948: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4949\n",
            "2025-06-26 08:27:25,303 EPOCH 4949\n",
            "INFO:__main__:Epoch 4949: total training loss 0.00241\n",
            "2025-06-26 08:27:25,374 Epoch 4949: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 4950\n",
            "2025-06-26 08:27:25,377 EPOCH 4950\n",
            "INFO:__main__:Epoch 4950: total training loss 0.00255\n",
            "2025-06-26 08:27:25,447 Epoch 4950: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 4951\n",
            "2025-06-26 08:27:25,451 EPOCH 4951\n",
            "INFO:__main__:Epoch 4951: total training loss 0.00218\n",
            "2025-06-26 08:27:25,521 Epoch 4951: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 4952\n",
            "2025-06-26 08:27:25,524 EPOCH 4952\n",
            "INFO:__main__:Epoch 4952: total training loss 0.00252\n",
            "2025-06-26 08:27:25,593 Epoch 4952: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 4953\n",
            "2025-06-26 08:27:25,595 EPOCH 4953\n",
            "INFO:__main__:Epoch 4953: total training loss 0.00226\n",
            "2025-06-26 08:27:25,677 Epoch 4953: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 4954\n",
            "2025-06-26 08:27:25,679 EPOCH 4954\n",
            "INFO:__main__:Epoch 4954: total training loss 0.00218\n",
            "2025-06-26 08:27:25,748 Epoch 4954: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 4955\n",
            "2025-06-26 08:27:25,750 EPOCH 4955\n",
            "INFO:__main__:Epoch 4955: total training loss 0.00229\n",
            "2025-06-26 08:27:25,817 Epoch 4955: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 4956\n",
            "2025-06-26 08:27:25,819 EPOCH 4956\n",
            "INFO:__main__:Epoch 4956: total training loss 0.00230\n",
            "2025-06-26 08:27:25,889 Epoch 4956: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4957\n",
            "2025-06-26 08:27:25,894 EPOCH 4957\n",
            "INFO:__main__:Epoch 4957: total training loss 0.00229\n",
            "2025-06-26 08:27:25,962 Epoch 4957: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 4958\n",
            "2025-06-26 08:27:25,964 EPOCH 4958\n",
            "INFO:__main__:Epoch 4958: total training loss 0.00231\n",
            "2025-06-26 08:27:26,031 Epoch 4958: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 4959\n",
            "2025-06-26 08:27:26,033 EPOCH 4959\n",
            "INFO:__main__:Epoch 4959: total training loss 0.00238\n",
            "2025-06-26 08:27:26,099 Epoch 4959: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 4960\n",
            "2025-06-26 08:27:26,101 EPOCH 4960\n",
            "INFO:__main__:Epoch 4960: total training loss 0.00247\n",
            "2025-06-26 08:27:26,173 Epoch 4960: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 4961\n",
            "2025-06-26 08:27:26,175 EPOCH 4961\n",
            "INFO:__main__:Epoch 4961: total training loss 0.00234\n",
            "2025-06-26 08:27:26,247 Epoch 4961: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 4962\n",
            "2025-06-26 08:27:26,249 EPOCH 4962\n",
            "INFO:__main__:Epoch 4962: total training loss 0.00242\n",
            "2025-06-26 08:27:26,319 Epoch 4962: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4963\n",
            "2025-06-26 08:27:26,322 EPOCH 4963\n",
            "INFO:__main__:Epoch 4963: total training loss 0.00238\n",
            "2025-06-26 08:27:26,391 Epoch 4963: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 4964\n",
            "2025-06-26 08:27:26,393 EPOCH 4964\n",
            "INFO:__main__:Epoch 4964: total training loss 0.00232\n",
            "2025-06-26 08:27:26,461 Epoch 4964: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4965\n",
            "2025-06-26 08:27:26,463 EPOCH 4965\n",
            "INFO:__main__:Epoch 4965: total training loss 0.00209\n",
            "2025-06-26 08:27:26,534 Epoch 4965: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 4966\n",
            "2025-06-26 08:27:26,536 EPOCH 4966\n",
            "INFO:__main__:Epoch 4966: total training loss 0.00231\n",
            "2025-06-26 08:27:26,606 Epoch 4966: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 4967\n",
            "2025-06-26 08:27:26,608 EPOCH 4967\n",
            "INFO:__main__:Epoch 4967: total training loss 0.00227\n",
            "2025-06-26 08:27:26,676 Epoch 4967: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 4968\n",
            "2025-06-26 08:27:26,678 EPOCH 4968\n",
            "INFO:__main__:Epoch 4968: total training loss 0.00230\n",
            "2025-06-26 08:27:26,768 Epoch 4968: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 4969\n",
            "2025-06-26 08:27:26,770 EPOCH 4969\n",
            "INFO:__main__:Epoch 4969: total training loss 0.00221\n",
            "2025-06-26 08:27:26,841 Epoch 4969: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 4970\n",
            "2025-06-26 08:27:26,843 EPOCH 4970\n",
            "INFO:__main__:Epoch 4970: total training loss 0.00223\n",
            "2025-06-26 08:27:26,910 Epoch 4970: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 4971\n",
            "2025-06-26 08:27:26,911 EPOCH 4971\n",
            "INFO:__main__:Epoch 4971: total training loss 0.00219\n",
            "2025-06-26 08:27:26,978 Epoch 4971: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 4972\n",
            "2025-06-26 08:27:26,980 EPOCH 4972\n",
            "INFO:__main__:Epoch 4972: total training loss 0.00236\n",
            "2025-06-26 08:27:27,049 Epoch 4972: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 4973\n",
            "2025-06-26 08:27:27,052 EPOCH 4973\n",
            "INFO:__main__:Epoch 4973: total training loss 0.00213\n",
            "2025-06-26 08:27:27,125 Epoch 4973: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 4974\n",
            "2025-06-26 08:27:27,127 EPOCH 4974\n",
            "INFO:__main__:Epoch 4974: total training loss 0.00216\n",
            "2025-06-26 08:27:27,199 Epoch 4974: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 4975\n",
            "2025-06-26 08:27:27,201 EPOCH 4975\n",
            "INFO:__main__:Epoch 4975: total training loss 0.00232\n",
            "2025-06-26 08:27:27,268 Epoch 4975: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4976\n",
            "2025-06-26 08:27:27,270 EPOCH 4976\n",
            "INFO:__main__:Epoch 4976: total training loss 0.00216\n",
            "2025-06-26 08:27:27,344 Epoch 4976: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 4977\n",
            "2025-06-26 08:27:27,346 EPOCH 4977\n",
            "INFO:__main__:Epoch 4977: total training loss 0.00209\n",
            "2025-06-26 08:27:27,418 Epoch 4977: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 4978\n",
            "2025-06-26 08:27:27,420 EPOCH 4978\n",
            "INFO:__main__:Epoch 4978: total training loss 0.00207\n",
            "2025-06-26 08:27:27,487 Epoch 4978: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 4979\n",
            "2025-06-26 08:27:27,489 EPOCH 4979\n",
            "INFO:__main__:Epoch 4979: total training loss 0.00221\n",
            "2025-06-26 08:27:27,557 Epoch 4979: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 4980\n",
            "2025-06-26 08:27:27,560 EPOCH 4980\n",
            "INFO:__main__:Epoch 4980: total training loss 0.00238\n",
            "2025-06-26 08:27:27,628 Epoch 4980: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 4981\n",
            "2025-06-26 08:27:27,630 EPOCH 4981\n",
            "INFO:__main__:Epoch 4981: total training loss 0.00213\n",
            "2025-06-26 08:27:27,699 Epoch 4981: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 4982\n",
            "2025-06-26 08:27:27,701 EPOCH 4982\n",
            "INFO:__main__:Epoch 4982: total training loss 0.00225\n",
            "2025-06-26 08:27:27,786 Epoch 4982: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 4983\n",
            "2025-06-26 08:27:27,789 EPOCH 4983\n",
            "INFO:__main__:Epoch 4983: total training loss 0.00216\n",
            "2025-06-26 08:27:27,856 Epoch 4983: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 4984\n",
            "2025-06-26 08:27:27,858 EPOCH 4984\n",
            "INFO:__main__:Epoch 4984: total training loss 0.00224\n",
            "2025-06-26 08:27:27,928 Epoch 4984: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 4985\n",
            "2025-06-26 08:27:27,930 EPOCH 4985\n",
            "INFO:__main__:Epoch 4985: total training loss 0.00217\n",
            "2025-06-26 08:27:28,002 Epoch 4985: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 4986\n",
            "2025-06-26 08:27:28,004 EPOCH 4986\n",
            "INFO:__main__:Epoch 4986: total training loss 0.00235\n",
            "2025-06-26 08:27:28,074 Epoch 4986: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 4987\n",
            "2025-06-26 08:27:28,075 EPOCH 4987\n",
            "INFO:__main__:Epoch 4987: total training loss 0.00242\n",
            "2025-06-26 08:27:28,143 Epoch 4987: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 4988\n",
            "2025-06-26 08:27:28,145 EPOCH 4988\n",
            "INFO:__main__:Epoch 4988: total training loss 0.00233\n",
            "2025-06-26 08:27:28,226 Epoch 4988: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 4989\n",
            "2025-06-26 08:27:28,229 EPOCH 4989\n",
            "INFO:__main__:Epoch 4989: total training loss 0.00244\n",
            "2025-06-26 08:27:28,319 Epoch 4989: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 4990\n",
            "2025-06-26 08:27:28,321 EPOCH 4990\n",
            "INFO:__main__:Epoch 4990: total training loss 0.00241\n",
            "2025-06-26 08:27:28,401 Epoch 4990: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 4991\n",
            "2025-06-26 08:27:28,404 EPOCH 4991\n",
            "INFO:__main__:Epoch 4991: total training loss 0.00229\n",
            "2025-06-26 08:27:28,505 Epoch 4991: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 4992\n",
            "2025-06-26 08:27:28,510 EPOCH 4992\n",
            "INFO:__main__:Epoch 4992: total training loss 0.00237\n",
            "2025-06-26 08:27:28,620 Epoch 4992: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 4993\n",
            "2025-06-26 08:27:28,622 EPOCH 4993\n",
            "INFO:__main__:Epoch 4993: total training loss 0.00232\n",
            "2025-06-26 08:27:28,709 Epoch 4993: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 4994\n",
            "2025-06-26 08:27:28,711 EPOCH 4994\n",
            "INFO:__main__:Epoch 4994: total training loss 0.00228\n",
            "2025-06-26 08:27:28,802 Epoch 4994: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 4995\n",
            "2025-06-26 08:27:28,805 EPOCH 4995\n",
            "INFO:__main__:Epoch 4995: total training loss 0.00234\n",
            "2025-06-26 08:27:28,909 Epoch 4995: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 4996\n",
            "2025-06-26 08:27:28,911 EPOCH 4996\n",
            "INFO:__main__:Epoch 4996: total training loss 0.00223\n",
            "2025-06-26 08:27:29,010 Epoch 4996: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 4997\n",
            "2025-06-26 08:27:29,012 EPOCH 4997\n",
            "INFO:__main__:Epoch 4997: total training loss 0.00227\n",
            "2025-06-26 08:27:29,109 Epoch 4997: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 4998\n",
            "2025-06-26 08:27:29,111 EPOCH 4998\n",
            "INFO:__main__:Epoch 4998: total training loss 0.00218\n",
            "2025-06-26 08:27:29,222 Epoch 4998: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 4999\n",
            "2025-06-26 08:27:29,228 EPOCH 4999\n",
            "INFO:__main__:Epoch 4999: total training loss 0.00226\n",
            "2025-06-26 08:27:29,316 Epoch 4999: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5000\n",
            "2025-06-26 08:27:29,317 EPOCH 5000\n",
            "INFO:__main__:Epoch 5000 Step:     5000 Batch Loss:     0.002170 Tokens per Sec:  1471670, Lr: 0.001000\n",
            "2025-06-26 08:27:29,415 Epoch 5000 Step:     5000 Batch Loss:     0.002170 Tokens per Sec:  1471670, Lr: 0.001000\n",
            "INFO:__main__:Epoch 5000: total training loss 0.00217\n",
            "2025-06-26 08:27:29,417 Epoch 5000: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5001\n",
            "2025-06-26 08:27:29,419 EPOCH 5001\n",
            "INFO:__main__:Epoch 5001: total training loss 0.00227\n",
            "2025-06-26 08:27:29,509 Epoch 5001: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5002\n",
            "2025-06-26 08:27:29,511 EPOCH 5002\n",
            "INFO:__main__:Epoch 5002: total training loss 0.00226\n",
            "2025-06-26 08:27:29,581 Epoch 5002: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5003\n",
            "2025-06-26 08:27:29,583 EPOCH 5003\n",
            "INFO:__main__:Epoch 5003: total training loss 0.00221\n",
            "2025-06-26 08:27:29,653 Epoch 5003: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5004\n",
            "2025-06-26 08:27:29,655 EPOCH 5004\n",
            "INFO:__main__:Epoch 5004: total training loss 0.00245\n",
            "2025-06-26 08:27:29,725 Epoch 5004: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5005\n",
            "2025-06-26 08:27:29,727 EPOCH 5005\n",
            "INFO:__main__:Epoch 5005: total training loss 0.00236\n",
            "2025-06-26 08:27:29,801 Epoch 5005: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5006\n",
            "2025-06-26 08:27:29,803 EPOCH 5006\n",
            "INFO:__main__:Epoch 5006: total training loss 0.00261\n",
            "2025-06-26 08:27:29,877 Epoch 5006: total training loss 0.00261\n",
            "INFO:__main__:EPOCH 5007\n",
            "2025-06-26 08:27:29,879 EPOCH 5007\n",
            "INFO:__main__:Epoch 5007: total training loss 0.00286\n",
            "2025-06-26 08:27:29,988 Epoch 5007: total training loss 0.00286\n",
            "INFO:__main__:EPOCH 5008\n",
            "2025-06-26 08:27:29,990 EPOCH 5008\n",
            "INFO:__main__:Epoch 5008: total training loss 0.00236\n",
            "2025-06-26 08:27:30,093 Epoch 5008: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5009\n",
            "2025-06-26 08:27:30,095 EPOCH 5009\n",
            "INFO:__main__:Epoch 5009: total training loss 0.00273\n",
            "2025-06-26 08:27:30,175 Epoch 5009: total training loss 0.00273\n",
            "INFO:__main__:EPOCH 5010\n",
            "2025-06-26 08:27:30,177 EPOCH 5010\n",
            "INFO:__main__:Epoch 5010: total training loss 0.00253\n",
            "2025-06-26 08:27:30,278 Epoch 5010: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 5011\n",
            "2025-06-26 08:27:30,282 EPOCH 5011\n",
            "INFO:__main__:Epoch 5011: total training loss 0.00266\n",
            "2025-06-26 08:27:30,385 Epoch 5011: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 5012\n",
            "2025-06-26 08:27:30,387 EPOCH 5012\n",
            "INFO:__main__:Epoch 5012: total training loss 0.00243\n",
            "2025-06-26 08:27:30,497 Epoch 5012: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 5013\n",
            "2025-06-26 08:27:30,501 EPOCH 5013\n",
            "INFO:__main__:Epoch 5013: total training loss 0.00240\n",
            "2025-06-26 08:27:30,602 Epoch 5013: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5014\n",
            "2025-06-26 08:27:30,604 EPOCH 5014\n",
            "INFO:__main__:Epoch 5014: total training loss 0.00217\n",
            "2025-06-26 08:27:30,716 Epoch 5014: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5015\n",
            "2025-06-26 08:27:30,718 EPOCH 5015\n",
            "INFO:__main__:Epoch 5015: total training loss 0.00234\n",
            "2025-06-26 08:27:30,822 Epoch 5015: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5016\n",
            "2025-06-26 08:27:30,828 EPOCH 5016\n",
            "INFO:__main__:Epoch 5016: total training loss 0.00210\n",
            "2025-06-26 08:27:30,932 Epoch 5016: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5017\n",
            "2025-06-26 08:27:30,933 EPOCH 5017\n",
            "INFO:__main__:Epoch 5017: total training loss 0.00237\n",
            "2025-06-26 08:27:31,050 Epoch 5017: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5018\n",
            "2025-06-26 08:27:31,052 EPOCH 5018\n",
            "INFO:__main__:Epoch 5018: total training loss 0.00197\n",
            "2025-06-26 08:27:31,165 Epoch 5018: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5019\n",
            "2025-06-26 08:27:31,167 EPOCH 5019\n",
            "INFO:__main__:Epoch 5019: total training loss 0.00234\n",
            "2025-06-26 08:27:31,277 Epoch 5019: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5020\n",
            "2025-06-26 08:27:31,280 EPOCH 5020\n",
            "INFO:__main__:Epoch 5020: total training loss 0.00209\n",
            "2025-06-26 08:27:31,364 Epoch 5020: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5021\n",
            "2025-06-26 08:27:31,366 EPOCH 5021\n",
            "INFO:__main__:Epoch 5021: total training loss 0.00232\n",
            "2025-06-26 08:27:31,436 Epoch 5021: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5022\n",
            "2025-06-26 08:27:31,438 EPOCH 5022\n",
            "INFO:__main__:Epoch 5022: total training loss 0.00231\n",
            "2025-06-26 08:27:31,508 Epoch 5022: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5023\n",
            "2025-06-26 08:27:31,510 EPOCH 5023\n",
            "INFO:__main__:Epoch 5023: total training loss 0.00228\n",
            "2025-06-26 08:27:31,582 Epoch 5023: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5024\n",
            "2025-06-26 08:27:31,584 EPOCH 5024\n",
            "INFO:__main__:Epoch 5024: total training loss 0.00233\n",
            "2025-06-26 08:27:31,655 Epoch 5024: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5025\n",
            "2025-06-26 08:27:31,657 EPOCH 5025\n",
            "INFO:__main__:Epoch 5025: total training loss 0.00224\n",
            "2025-06-26 08:27:31,725 Epoch 5025: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5026\n",
            "2025-06-26 08:27:31,727 EPOCH 5026\n",
            "INFO:__main__:Epoch 5026: total training loss 0.00260\n",
            "2025-06-26 08:27:31,797 Epoch 5026: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 5027\n",
            "2025-06-26 08:27:31,799 EPOCH 5027\n",
            "INFO:__main__:Epoch 5027: total training loss 0.00277\n",
            "2025-06-26 08:27:31,870 Epoch 5027: total training loss 0.00277\n",
            "INFO:__main__:EPOCH 5028\n",
            "2025-06-26 08:27:31,872 EPOCH 5028\n",
            "INFO:__main__:Epoch 5028: total training loss 0.00252\n",
            "2025-06-26 08:27:31,942 Epoch 5028: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 5029\n",
            "2025-06-26 08:27:31,945 EPOCH 5029\n",
            "INFO:__main__:Epoch 5029: total training loss 0.00256\n",
            "2025-06-26 08:27:32,016 Epoch 5029: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5030\n",
            "2025-06-26 08:27:32,020 EPOCH 5030\n",
            "INFO:__main__:Epoch 5030: total training loss 0.00257\n",
            "2025-06-26 08:27:32,112 Epoch 5030: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 5031\n",
            "2025-06-26 08:27:32,119 EPOCH 5031\n",
            "INFO:__main__:Epoch 5031: total training loss 0.00276\n",
            "2025-06-26 08:27:32,206 Epoch 5031: total training loss 0.00276\n",
            "INFO:__main__:EPOCH 5032\n",
            "2025-06-26 08:27:32,212 EPOCH 5032\n",
            "INFO:__main__:Epoch 5032: total training loss 0.00260\n",
            "2025-06-26 08:27:32,293 Epoch 5032: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 5033\n",
            "2025-06-26 08:27:32,297 EPOCH 5033\n",
            "INFO:__main__:Epoch 5033: total training loss 0.00257\n",
            "2025-06-26 08:27:32,389 Epoch 5033: total training loss 0.00257\n",
            "INFO:__main__:EPOCH 5034\n",
            "2025-06-26 08:27:32,393 EPOCH 5034\n",
            "INFO:__main__:Epoch 5034: total training loss 0.00269\n",
            "2025-06-26 08:27:32,481 Epoch 5034: total training loss 0.00269\n",
            "INFO:__main__:EPOCH 5035\n",
            "2025-06-26 08:27:32,485 EPOCH 5035\n",
            "INFO:__main__:Epoch 5035: total training loss 0.00251\n",
            "2025-06-26 08:27:32,564 Epoch 5035: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5036\n",
            "2025-06-26 08:27:32,567 EPOCH 5036\n",
            "INFO:__main__:Epoch 5036: total training loss 0.00233\n",
            "2025-06-26 08:27:32,663 Epoch 5036: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5037\n",
            "2025-06-26 08:27:32,664 EPOCH 5037\n",
            "INFO:__main__:Epoch 5037: total training loss 0.00248\n",
            "2025-06-26 08:27:32,763 Epoch 5037: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5038\n",
            "2025-06-26 08:27:32,769 EPOCH 5038\n",
            "INFO:__main__:Epoch 5038: total training loss 0.00250\n",
            "2025-06-26 08:27:32,878 Epoch 5038: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5039\n",
            "2025-06-26 08:27:32,882 EPOCH 5039\n",
            "INFO:__main__:Epoch 5039: total training loss 0.00232\n",
            "2025-06-26 08:27:32,986 Epoch 5039: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5040\n",
            "2025-06-26 08:27:32,990 EPOCH 5040\n",
            "INFO:__main__:Epoch 5040: total training loss 0.00234\n",
            "2025-06-26 08:27:33,085 Epoch 5040: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5041\n",
            "2025-06-26 08:27:33,087 EPOCH 5041\n",
            "INFO:__main__:Epoch 5041: total training loss 0.00236\n",
            "2025-06-26 08:27:33,184 Epoch 5041: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5042\n",
            "2025-06-26 08:27:33,190 EPOCH 5042\n",
            "INFO:__main__:Epoch 5042: total training loss 0.00226\n",
            "2025-06-26 08:27:33,284 Epoch 5042: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5043\n",
            "2025-06-26 08:27:33,287 EPOCH 5043\n",
            "INFO:__main__:Epoch 5043: total training loss 0.00260\n",
            "2025-06-26 08:27:33,381 Epoch 5043: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 5044\n",
            "2025-06-26 08:27:33,384 EPOCH 5044\n",
            "INFO:__main__:Epoch 5044: total training loss 0.00218\n",
            "2025-06-26 08:27:33,474 Epoch 5044: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5045\n",
            "2025-06-26 08:27:33,477 EPOCH 5045\n",
            "INFO:__main__:Epoch 5045: total training loss 0.00235\n",
            "2025-06-26 08:27:33,547 Epoch 5045: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 5046\n",
            "2025-06-26 08:27:33,548 EPOCH 5046\n",
            "INFO:__main__:Epoch 5046: total training loss 0.00241\n",
            "2025-06-26 08:27:33,617 Epoch 5046: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5047\n",
            "2025-06-26 08:27:33,619 EPOCH 5047\n",
            "INFO:__main__:Epoch 5047: total training loss 0.00209\n",
            "2025-06-26 08:27:33,686 Epoch 5047: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5048\n",
            "2025-06-26 08:27:33,689 EPOCH 5048\n",
            "INFO:__main__:Epoch 5048: total training loss 0.00231\n",
            "2025-06-26 08:27:33,765 Epoch 5048: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5049\n",
            "2025-06-26 08:27:33,767 EPOCH 5049\n",
            "INFO:__main__:Epoch 5049: total training loss 0.00229\n",
            "2025-06-26 08:27:33,846 Epoch 5049: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5050\n",
            "2025-06-26 08:27:33,848 EPOCH 5050\n",
            "INFO:__main__:Epoch 5050: total training loss 0.00225\n",
            "2025-06-26 08:27:33,924 Epoch 5050: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5051\n",
            "2025-06-26 08:27:33,926 EPOCH 5051\n",
            "INFO:__main__:Epoch 5051: total training loss 0.00236\n",
            "2025-06-26 08:27:33,997 Epoch 5051: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5052\n",
            "2025-06-26 08:27:33,999 EPOCH 5052\n",
            "INFO:__main__:Epoch 5052: total training loss 0.00261\n",
            "2025-06-26 08:27:34,068 Epoch 5052: total training loss 0.00261\n",
            "INFO:__main__:EPOCH 5053\n",
            "2025-06-26 08:27:34,070 EPOCH 5053\n",
            "INFO:__main__:Epoch 5053: total training loss 0.00238\n",
            "2025-06-26 08:27:34,137 Epoch 5053: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 5054\n",
            "2025-06-26 08:27:34,139 EPOCH 5054\n",
            "INFO:__main__:Epoch 5054: total training loss 0.00234\n",
            "2025-06-26 08:27:34,226 Epoch 5054: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5055\n",
            "2025-06-26 08:27:34,228 EPOCH 5055\n",
            "INFO:__main__:Epoch 5055: total training loss 0.00245\n",
            "2025-06-26 08:27:34,300 Epoch 5055: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5056\n",
            "2025-06-26 08:27:34,302 EPOCH 5056\n",
            "INFO:__main__:Epoch 5056: total training loss 0.00229\n",
            "2025-06-26 08:27:34,374 Epoch 5056: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5057\n",
            "2025-06-26 08:27:34,376 EPOCH 5057\n",
            "INFO:__main__:Epoch 5057: total training loss 0.00243\n",
            "2025-06-26 08:27:34,447 Epoch 5057: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 5058\n",
            "2025-06-26 08:27:34,449 EPOCH 5058\n",
            "INFO:__main__:Epoch 5058: total training loss 0.00233\n",
            "2025-06-26 08:27:34,517 Epoch 5058: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5059\n",
            "2025-06-26 08:27:34,519 EPOCH 5059\n",
            "INFO:__main__:Epoch 5059: total training loss 0.00233\n",
            "2025-06-26 08:27:34,587 Epoch 5059: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5060\n",
            "2025-06-26 08:27:34,589 EPOCH 5060\n",
            "INFO:__main__:Epoch 5060: total training loss 0.00230\n",
            "2025-06-26 08:27:34,656 Epoch 5060: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5061\n",
            "2025-06-26 08:27:34,658 EPOCH 5061\n",
            "INFO:__main__:Epoch 5061: total training loss 0.00236\n",
            "2025-06-26 08:27:34,723 Epoch 5061: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5062\n",
            "2025-06-26 08:27:34,725 EPOCH 5062\n",
            "INFO:__main__:Epoch 5062: total training loss 0.00221\n",
            "2025-06-26 08:27:34,793 Epoch 5062: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5063\n",
            "2025-06-26 08:27:34,795 EPOCH 5063\n",
            "INFO:__main__:Epoch 5063: total training loss 0.00226\n",
            "2025-06-26 08:27:34,862 Epoch 5063: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5064\n",
            "2025-06-26 08:27:34,863 EPOCH 5064\n",
            "INFO:__main__:Epoch 5064: total training loss 0.00229\n",
            "2025-06-26 08:27:34,932 Epoch 5064: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5065\n",
            "2025-06-26 08:27:34,934 EPOCH 5065\n",
            "INFO:__main__:Epoch 5065: total training loss 0.00229\n",
            "2025-06-26 08:27:35,004 Epoch 5065: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5066\n",
            "2025-06-26 08:27:35,006 EPOCH 5066\n",
            "INFO:__main__:Epoch 5066: total training loss 0.00237\n",
            "2025-06-26 08:27:35,077 Epoch 5066: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5067\n",
            "2025-06-26 08:27:35,080 EPOCH 5067\n",
            "INFO:__main__:Epoch 5067: total training loss 0.00208\n",
            "2025-06-26 08:27:35,150 Epoch 5067: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5068\n",
            "2025-06-26 08:27:35,152 EPOCH 5068\n",
            "INFO:__main__:Epoch 5068: total training loss 0.00228\n",
            "2025-06-26 08:27:35,220 Epoch 5068: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5069\n",
            "2025-06-26 08:27:35,222 EPOCH 5069\n",
            "INFO:__main__:Epoch 5069: total training loss 0.00210\n",
            "2025-06-26 08:27:35,308 Epoch 5069: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5070\n",
            "2025-06-26 08:27:35,310 EPOCH 5070\n",
            "INFO:__main__:Epoch 5070: total training loss 0.00221\n",
            "2025-06-26 08:27:35,379 Epoch 5070: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5071\n",
            "2025-06-26 08:27:35,381 EPOCH 5071\n",
            "INFO:__main__:Epoch 5071: total training loss 0.00232\n",
            "2025-06-26 08:27:35,451 Epoch 5071: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5072\n",
            "2025-06-26 08:27:35,453 EPOCH 5072\n",
            "INFO:__main__:Epoch 5072: total training loss 0.00228\n",
            "2025-06-26 08:27:35,522 Epoch 5072: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5073\n",
            "2025-06-26 08:27:35,523 EPOCH 5073\n",
            "INFO:__main__:Epoch 5073: total training loss 0.00218\n",
            "2025-06-26 08:27:35,592 Epoch 5073: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5074\n",
            "2025-06-26 08:27:35,594 EPOCH 5074\n",
            "INFO:__main__:Epoch 5074: total training loss 0.00223\n",
            "2025-06-26 08:27:35,663 Epoch 5074: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5075\n",
            "2025-06-26 08:27:35,665 EPOCH 5075\n",
            "INFO:__main__:Epoch 5075: total training loss 0.00204\n",
            "2025-06-26 08:27:35,736 Epoch 5075: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5076\n",
            "2025-06-26 08:27:35,738 EPOCH 5076\n",
            "INFO:__main__:Epoch 5076: total training loss 0.00221\n",
            "2025-06-26 08:27:35,810 Epoch 5076: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5077\n",
            "2025-06-26 08:27:35,812 EPOCH 5077\n",
            "INFO:__main__:Epoch 5077: total training loss 0.00219\n",
            "2025-06-26 08:27:35,883 Epoch 5077: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5078\n",
            "2025-06-26 08:27:35,885 EPOCH 5078\n",
            "INFO:__main__:Epoch 5078: total training loss 0.00215\n",
            "2025-06-26 08:27:35,954 Epoch 5078: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5079\n",
            "2025-06-26 08:27:35,956 EPOCH 5079\n",
            "INFO:__main__:Epoch 5079: total training loss 0.00227\n",
            "2025-06-26 08:27:36,024 Epoch 5079: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5080\n",
            "2025-06-26 08:27:36,026 EPOCH 5080\n",
            "INFO:__main__:Epoch 5080: total training loss 0.00217\n",
            "2025-06-26 08:27:36,094 Epoch 5080: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5081\n",
            "2025-06-26 08:27:36,096 EPOCH 5081\n",
            "INFO:__main__:Epoch 5081: total training loss 0.00219\n",
            "2025-06-26 08:27:36,165 Epoch 5081: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5082\n",
            "2025-06-26 08:27:36,167 EPOCH 5082\n",
            "INFO:__main__:Epoch 5082: total training loss 0.00250\n",
            "2025-06-26 08:27:36,239 Epoch 5082: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5083\n",
            "2025-06-26 08:27:36,241 EPOCH 5083\n",
            "INFO:__main__:Epoch 5083: total training loss 0.00225\n",
            "2025-06-26 08:27:36,308 Epoch 5083: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5084\n",
            "2025-06-26 08:27:36,312 EPOCH 5084\n",
            "INFO:__main__:Epoch 5084: total training loss 0.00239\n",
            "2025-06-26 08:27:36,400 Epoch 5084: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 5085\n",
            "2025-06-26 08:27:36,403 EPOCH 5085\n",
            "INFO:__main__:Epoch 5085: total training loss 0.00224\n",
            "2025-06-26 08:27:36,474 Epoch 5085: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5086\n",
            "2025-06-26 08:27:36,476 EPOCH 5086\n",
            "INFO:__main__:Epoch 5086: total training loss 0.00226\n",
            "2025-06-26 08:27:36,547 Epoch 5086: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5087\n",
            "2025-06-26 08:27:36,549 EPOCH 5087\n",
            "INFO:__main__:Epoch 5087: total training loss 0.00212\n",
            "2025-06-26 08:27:36,619 Epoch 5087: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5088\n",
            "2025-06-26 08:27:36,621 EPOCH 5088\n",
            "INFO:__main__:Epoch 5088: total training loss 0.00240\n",
            "2025-06-26 08:27:36,687 Epoch 5088: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5089\n",
            "2025-06-26 08:27:36,689 EPOCH 5089\n",
            "INFO:__main__:Epoch 5089: total training loss 0.00229\n",
            "2025-06-26 08:27:36,759 Epoch 5089: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5090\n",
            "2025-06-26 08:27:36,760 EPOCH 5090\n",
            "INFO:__main__:Epoch 5090: total training loss 0.00245\n",
            "2025-06-26 08:27:36,830 Epoch 5090: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5091\n",
            "2025-06-26 08:27:36,832 EPOCH 5091\n",
            "INFO:__main__:Epoch 5091: total training loss 0.00227\n",
            "2025-06-26 08:27:36,900 Epoch 5091: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5092\n",
            "2025-06-26 08:27:36,902 EPOCH 5092\n",
            "INFO:__main__:Epoch 5092: total training loss 0.00253\n",
            "2025-06-26 08:27:36,968 Epoch 5092: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 5093\n",
            "2025-06-26 08:27:36,970 EPOCH 5093\n",
            "INFO:__main__:Epoch 5093: total training loss 0.00216\n",
            "2025-06-26 08:27:37,043 Epoch 5093: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5094\n",
            "2025-06-26 08:27:37,045 EPOCH 5094\n",
            "INFO:__main__:Epoch 5094: total training loss 0.00244\n",
            "2025-06-26 08:27:37,118 Epoch 5094: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 5095\n",
            "2025-06-26 08:27:37,120 EPOCH 5095\n",
            "INFO:__main__:Epoch 5095: total training loss 0.00256\n",
            "2025-06-26 08:27:37,191 Epoch 5095: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5096\n",
            "2025-06-26 08:27:37,193 EPOCH 5096\n",
            "INFO:__main__:Epoch 5096: total training loss 0.00263\n",
            "2025-06-26 08:27:37,264 Epoch 5096: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 5097\n",
            "2025-06-26 08:27:37,266 EPOCH 5097\n",
            "INFO:__main__:Epoch 5097: total training loss 0.00260\n",
            "2025-06-26 08:27:37,340 Epoch 5097: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 5098\n",
            "2025-06-26 08:27:37,342 EPOCH 5098\n",
            "INFO:__main__:Epoch 5098: total training loss 0.00248\n",
            "2025-06-26 08:27:37,432 Epoch 5098: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5099\n",
            "2025-06-26 08:27:37,434 EPOCH 5099\n",
            "INFO:__main__:Epoch 5099: total training loss 0.00248\n",
            "2025-06-26 08:27:37,506 Epoch 5099: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5100\n",
            "2025-06-26 08:27:37,508 EPOCH 5100\n",
            "INFO:__main__:Epoch 5100: total training loss 0.00252\n",
            "2025-06-26 08:27:37,580 Epoch 5100: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 5101\n",
            "2025-06-26 08:27:37,582 EPOCH 5101\n",
            "INFO:__main__:Epoch 5101: total training loss 0.00247\n",
            "2025-06-26 08:27:37,649 Epoch 5101: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5102\n",
            "2025-06-26 08:27:37,651 EPOCH 5102\n",
            "INFO:__main__:Epoch 5102: total training loss 0.00228\n",
            "2025-06-26 08:27:37,721 Epoch 5102: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5103\n",
            "2025-06-26 08:27:37,723 EPOCH 5103\n",
            "INFO:__main__:Epoch 5103: total training loss 0.00231\n",
            "2025-06-26 08:27:37,794 Epoch 5103: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5104\n",
            "2025-06-26 08:27:37,796 EPOCH 5104\n",
            "INFO:__main__:Epoch 5104: total training loss 0.00233\n",
            "2025-06-26 08:27:37,865 Epoch 5104: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5105\n",
            "2025-06-26 08:27:37,867 EPOCH 5105\n",
            "INFO:__main__:Epoch 5105: total training loss 0.00237\n",
            "2025-06-26 08:27:37,939 Epoch 5105: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5106\n",
            "2025-06-26 08:27:37,941 EPOCH 5106\n",
            "INFO:__main__:Epoch 5106: total training loss 0.00231\n",
            "2025-06-26 08:27:38,013 Epoch 5106: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5107\n",
            "2025-06-26 08:27:38,015 EPOCH 5107\n",
            "INFO:__main__:Epoch 5107: total training loss 0.00230\n",
            "2025-06-26 08:27:38,085 Epoch 5107: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5108\n",
            "2025-06-26 08:27:38,087 EPOCH 5108\n",
            "INFO:__main__:Epoch 5108: total training loss 0.00228\n",
            "2025-06-26 08:27:38,154 Epoch 5108: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5109\n",
            "2025-06-26 08:27:38,156 EPOCH 5109\n",
            "INFO:__main__:Epoch 5109: total training loss 0.00243\n",
            "2025-06-26 08:27:38,228 Epoch 5109: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 5110\n",
            "2025-06-26 08:27:38,230 EPOCH 5110\n",
            "INFO:__main__:Epoch 5110: total training loss 0.00202\n",
            "2025-06-26 08:27:38,316 Epoch 5110: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5111\n",
            "2025-06-26 08:27:38,318 EPOCH 5111\n",
            "INFO:__main__:Epoch 5111: total training loss 0.00232\n",
            "2025-06-26 08:27:38,389 Epoch 5111: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5112\n",
            "2025-06-26 08:27:38,391 EPOCH 5112\n",
            "INFO:__main__:Epoch 5112: total training loss 0.00224\n",
            "2025-06-26 08:27:38,473 Epoch 5112: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5113\n",
            "2025-06-26 08:27:38,476 EPOCH 5113\n",
            "INFO:__main__:Epoch 5113: total training loss 0.00223\n",
            "2025-06-26 08:27:38,546 Epoch 5113: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5114\n",
            "2025-06-26 08:27:38,548 EPOCH 5114\n",
            "INFO:__main__:Epoch 5114: total training loss 0.00210\n",
            "2025-06-26 08:27:38,619 Epoch 5114: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5115\n",
            "2025-06-26 08:27:38,621 EPOCH 5115\n",
            "INFO:__main__:Epoch 5115: total training loss 0.00211\n",
            "2025-06-26 08:27:38,690 Epoch 5115: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5116\n",
            "2025-06-26 08:27:38,693 EPOCH 5116\n",
            "INFO:__main__:Epoch 5116: total training loss 0.00216\n",
            "2025-06-26 08:27:38,762 Epoch 5116: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5117\n",
            "2025-06-26 08:27:38,764 EPOCH 5117\n",
            "INFO:__main__:Epoch 5117: total training loss 0.00217\n",
            "2025-06-26 08:27:38,838 Epoch 5117: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5118\n",
            "2025-06-26 08:27:38,840 EPOCH 5118\n",
            "INFO:__main__:Epoch 5118: total training loss 0.00228\n",
            "2025-06-26 08:27:38,910 Epoch 5118: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5119\n",
            "2025-06-26 08:27:38,912 EPOCH 5119\n",
            "INFO:__main__:Epoch 5119: total training loss 0.00217\n",
            "2025-06-26 08:27:38,979 Epoch 5119: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5120\n",
            "2025-06-26 08:27:38,981 EPOCH 5120\n",
            "INFO:__main__:Epoch 5120: total training loss 0.00209\n",
            "2025-06-26 08:27:39,050 Epoch 5120: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5121\n",
            "2025-06-26 08:27:39,052 EPOCH 5121\n",
            "INFO:__main__:Epoch 5121: total training loss 0.00242\n",
            "2025-06-26 08:27:39,122 Epoch 5121: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 5122\n",
            "2025-06-26 08:27:39,124 EPOCH 5122\n",
            "INFO:__main__:Epoch 5122: total training loss 0.00250\n",
            "2025-06-26 08:27:39,196 Epoch 5122: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5123\n",
            "2025-06-26 08:27:39,198 EPOCH 5123\n",
            "INFO:__main__:Epoch 5123: total training loss 0.00233\n",
            "2025-06-26 08:27:39,268 Epoch 5123: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5124\n",
            "2025-06-26 08:27:39,270 EPOCH 5124\n",
            "INFO:__main__:Epoch 5124: total training loss 0.00227\n",
            "2025-06-26 08:27:39,343 Epoch 5124: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5125\n",
            "2025-06-26 08:27:39,345 EPOCH 5125\n",
            "INFO:__main__:Epoch 5125: total training loss 0.00236\n",
            "2025-06-26 08:27:39,415 Epoch 5125: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5126\n",
            "2025-06-26 08:27:39,417 EPOCH 5126\n",
            "INFO:__main__:Epoch 5126: total training loss 0.00237\n",
            "2025-06-26 08:27:39,491 Epoch 5126: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5127\n",
            "2025-06-26 08:27:39,494 EPOCH 5127\n",
            "INFO:__main__:Epoch 5127: total training loss 0.00255\n",
            "2025-06-26 08:27:39,570 Epoch 5127: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 5128\n",
            "2025-06-26 08:27:39,572 EPOCH 5128\n",
            "INFO:__main__:Epoch 5128: total training loss 0.00223\n",
            "2025-06-26 08:27:39,643 Epoch 5128: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5129\n",
            "2025-06-26 08:27:39,645 EPOCH 5129\n",
            "INFO:__main__:Epoch 5129: total training loss 0.00235\n",
            "2025-06-26 08:27:39,715 Epoch 5129: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 5130\n",
            "2025-06-26 08:27:39,718 EPOCH 5130\n",
            "INFO:__main__:Epoch 5130: total training loss 0.00213\n",
            "2025-06-26 08:27:39,787 Epoch 5130: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5131\n",
            "2025-06-26 08:27:39,789 EPOCH 5131\n",
            "INFO:__main__:Epoch 5131: total training loss 0.00234\n",
            "2025-06-26 08:27:39,859 Epoch 5131: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5132\n",
            "2025-06-26 08:27:39,861 EPOCH 5132\n",
            "INFO:__main__:Epoch 5132: total training loss 0.00217\n",
            "2025-06-26 08:27:39,928 Epoch 5132: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5133\n",
            "2025-06-26 08:27:39,930 EPOCH 5133\n",
            "INFO:__main__:Epoch 5133: total training loss 0.00199\n",
            "2025-06-26 08:27:40,002 Epoch 5133: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5134\n",
            "2025-06-26 08:27:40,005 EPOCH 5134\n",
            "INFO:__main__:Epoch 5134: total training loss 0.00220\n",
            "2025-06-26 08:27:40,072 Epoch 5134: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5135\n",
            "2025-06-26 08:27:40,074 EPOCH 5135\n",
            "INFO:__main__:Epoch 5135: total training loss 0.00216\n",
            "2025-06-26 08:27:40,141 Epoch 5135: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5136\n",
            "2025-06-26 08:27:40,142 EPOCH 5136\n",
            "INFO:__main__:Epoch 5136: total training loss 0.00206\n",
            "2025-06-26 08:27:40,210 Epoch 5136: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5137\n",
            "2025-06-26 08:27:40,212 EPOCH 5137\n",
            "INFO:__main__:Epoch 5137: total training loss 0.00202\n",
            "2025-06-26 08:27:40,282 Epoch 5137: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5138\n",
            "2025-06-26 08:27:40,284 EPOCH 5138\n",
            "INFO:__main__:Epoch 5138: total training loss 0.00218\n",
            "2025-06-26 08:27:40,357 Epoch 5138: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5139\n",
            "2025-06-26 08:27:40,359 EPOCH 5139\n",
            "INFO:__main__:Epoch 5139: total training loss 0.00203\n",
            "2025-06-26 08:27:40,428 Epoch 5139: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5140\n",
            "2025-06-26 08:27:40,429 EPOCH 5140\n",
            "INFO:__main__:Epoch 5140: total training loss 0.00224\n",
            "2025-06-26 08:27:40,498 Epoch 5140: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5141\n",
            "2025-06-26 08:27:40,500 EPOCH 5141\n",
            "INFO:__main__:Epoch 5141: total training loss 0.00212\n",
            "2025-06-26 08:27:40,592 Epoch 5141: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5142\n",
            "2025-06-26 08:27:40,594 EPOCH 5142\n",
            "INFO:__main__:Epoch 5142: total training loss 0.00226\n",
            "2025-06-26 08:27:40,662 Epoch 5142: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5143\n",
            "2025-06-26 08:27:40,664 EPOCH 5143\n",
            "INFO:__main__:Epoch 5143: total training loss 0.00233\n",
            "2025-06-26 08:27:40,734 Epoch 5143: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5144\n",
            "2025-06-26 08:27:40,736 EPOCH 5144\n",
            "INFO:__main__:Epoch 5144: total training loss 0.00226\n",
            "2025-06-26 08:27:40,808 Epoch 5144: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5145\n",
            "2025-06-26 08:27:40,810 EPOCH 5145\n",
            "INFO:__main__:Epoch 5145: total training loss 0.00223\n",
            "2025-06-26 08:27:40,882 Epoch 5145: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5146\n",
            "2025-06-26 08:27:40,886 EPOCH 5146\n",
            "INFO:__main__:Epoch 5146: total training loss 0.00209\n",
            "2025-06-26 08:27:40,957 Epoch 5146: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5147\n",
            "2025-06-26 08:27:40,959 EPOCH 5147\n",
            "INFO:__main__:Epoch 5147: total training loss 0.00215\n",
            "2025-06-26 08:27:41,026 Epoch 5147: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5148\n",
            "2025-06-26 08:27:41,028 EPOCH 5148\n",
            "INFO:__main__:Epoch 5148: total training loss 0.00212\n",
            "2025-06-26 08:27:41,100 Epoch 5148: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5149\n",
            "2025-06-26 08:27:41,102 EPOCH 5149\n",
            "INFO:__main__:Epoch 5149: total training loss 0.00225\n",
            "2025-06-26 08:27:41,172 Epoch 5149: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5150\n",
            "2025-06-26 08:27:41,174 EPOCH 5150\n",
            "INFO:__main__:Epoch 5150: total training loss 0.00234\n",
            "2025-06-26 08:27:41,245 Epoch 5150: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5151\n",
            "2025-06-26 08:27:41,247 EPOCH 5151\n",
            "INFO:__main__:Epoch 5151: total training loss 0.00226\n",
            "2025-06-26 08:27:41,320 Epoch 5151: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5152\n",
            "2025-06-26 08:27:41,321 EPOCH 5152\n",
            "INFO:__main__:Epoch 5152: total training loss 0.00243\n",
            "2025-06-26 08:27:41,394 Epoch 5152: total training loss 0.00243\n",
            "INFO:__main__:EPOCH 5153\n",
            "2025-06-26 08:27:41,396 EPOCH 5153\n",
            "INFO:__main__:Epoch 5153: total training loss 0.00241\n",
            "2025-06-26 08:27:41,468 Epoch 5153: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5154\n",
            "2025-06-26 08:27:41,470 EPOCH 5154\n",
            "INFO:__main__:Epoch 5154: total training loss 0.00210\n",
            "2025-06-26 08:27:41,545 Epoch 5154: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5155\n",
            "2025-06-26 08:27:41,547 EPOCH 5155\n",
            "INFO:__main__:Epoch 5155: total training loss 0.00238\n",
            "2025-06-26 08:27:41,636 Epoch 5155: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 5156\n",
            "2025-06-26 08:27:41,638 EPOCH 5156\n",
            "INFO:__main__:Epoch 5156: total training loss 0.00214\n",
            "2025-06-26 08:27:41,708 Epoch 5156: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5157\n",
            "2025-06-26 08:27:41,710 EPOCH 5157\n",
            "INFO:__main__:Epoch 5157: total training loss 0.00218\n",
            "2025-06-26 08:27:41,781 Epoch 5157: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5158\n",
            "2025-06-26 08:27:41,783 EPOCH 5158\n",
            "INFO:__main__:Epoch 5158: total training loss 0.00225\n",
            "2025-06-26 08:27:41,857 Epoch 5158: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5159\n",
            "2025-06-26 08:27:41,859 EPOCH 5159\n",
            "INFO:__main__:Epoch 5159: total training loss 0.00216\n",
            "2025-06-26 08:27:41,930 Epoch 5159: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5160\n",
            "2025-06-26 08:27:41,932 EPOCH 5160\n",
            "INFO:__main__:Epoch 5160: total training loss 0.00227\n",
            "2025-06-26 08:27:42,003 Epoch 5160: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5161\n",
            "2025-06-26 08:27:42,005 EPOCH 5161\n",
            "INFO:__main__:Epoch 5161: total training loss 0.00220\n",
            "2025-06-26 08:27:42,073 Epoch 5161: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5162\n",
            "2025-06-26 08:27:42,075 EPOCH 5162\n",
            "INFO:__main__:Epoch 5162: total training loss 0.00229\n",
            "2025-06-26 08:27:42,149 Epoch 5162: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5163\n",
            "2025-06-26 08:27:42,151 EPOCH 5163\n",
            "INFO:__main__:Epoch 5163: total training loss 0.00223\n",
            "2025-06-26 08:27:42,222 Epoch 5163: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5164\n",
            "2025-06-26 08:27:42,223 EPOCH 5164\n",
            "INFO:__main__:Epoch 5164: total training loss 0.00228\n",
            "2025-06-26 08:27:42,299 Epoch 5164: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5165\n",
            "2025-06-26 08:27:42,301 EPOCH 5165\n",
            "INFO:__main__:Epoch 5165: total training loss 0.00223\n",
            "2025-06-26 08:27:42,370 Epoch 5165: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5166\n",
            "2025-06-26 08:27:42,371 EPOCH 5166\n",
            "INFO:__main__:Epoch 5166: total training loss 0.00230\n",
            "2025-06-26 08:27:42,441 Epoch 5166: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5167\n",
            "2025-06-26 08:27:42,443 EPOCH 5167\n",
            "INFO:__main__:Epoch 5167: total training loss 0.00225\n",
            "2025-06-26 08:27:42,511 Epoch 5167: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5168\n",
            "2025-06-26 08:27:42,513 EPOCH 5168\n",
            "INFO:__main__:Epoch 5168: total training loss 0.00252\n",
            "2025-06-26 08:27:42,589 Epoch 5168: total training loss 0.00252\n",
            "INFO:__main__:EPOCH 5169\n",
            "2025-06-26 08:27:42,591 EPOCH 5169\n",
            "INFO:__main__:Epoch 5169: total training loss 0.00220\n",
            "2025-06-26 08:27:42,678 Epoch 5169: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5170\n",
            "2025-06-26 08:27:42,680 EPOCH 5170\n",
            "INFO:__main__:Epoch 5170: total training loss 0.00253\n",
            "2025-06-26 08:27:42,754 Epoch 5170: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 5171\n",
            "2025-06-26 08:27:42,756 EPOCH 5171\n",
            "INFO:__main__:Epoch 5171: total training loss 0.00238\n",
            "2025-06-26 08:27:42,825 Epoch 5171: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 5172\n",
            "2025-06-26 08:27:42,827 EPOCH 5172\n",
            "INFO:__main__:Epoch 5172: total training loss 0.00228\n",
            "2025-06-26 08:27:42,896 Epoch 5172: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5173\n",
            "2025-06-26 08:27:42,898 EPOCH 5173\n",
            "INFO:__main__:Epoch 5173: total training loss 0.00226\n",
            "2025-06-26 08:27:42,969 Epoch 5173: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5174\n",
            "2025-06-26 08:27:42,971 EPOCH 5174\n",
            "INFO:__main__:Epoch 5174: total training loss 0.00231\n",
            "2025-06-26 08:27:43,042 Epoch 5174: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5175\n",
            "2025-06-26 08:27:43,044 EPOCH 5175\n",
            "INFO:__main__:Epoch 5175: total training loss 0.00229\n",
            "2025-06-26 08:27:43,120 Epoch 5175: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5176\n",
            "2025-06-26 08:27:43,122 EPOCH 5176\n",
            "INFO:__main__:Epoch 5176: total training loss 0.00209\n",
            "2025-06-26 08:27:43,193 Epoch 5176: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5177\n",
            "2025-06-26 08:27:43,195 EPOCH 5177\n",
            "INFO:__main__:Epoch 5177: total training loss 0.00221\n",
            "2025-06-26 08:27:43,267 Epoch 5177: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5178\n",
            "2025-06-26 08:27:43,269 EPOCH 5178\n",
            "INFO:__main__:Epoch 5178: total training loss 0.00216\n",
            "2025-06-26 08:27:43,339 Epoch 5178: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5179\n",
            "2025-06-26 08:27:43,342 EPOCH 5179\n",
            "INFO:__main__:Epoch 5179: total training loss 0.00201\n",
            "2025-06-26 08:27:43,412 Epoch 5179: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5180\n",
            "2025-06-26 08:27:43,414 EPOCH 5180\n",
            "INFO:__main__:Epoch 5180: total training loss 0.00218\n",
            "2025-06-26 08:27:43,479 Epoch 5180: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5181\n",
            "2025-06-26 08:27:43,481 EPOCH 5181\n",
            "INFO:__main__:Epoch 5181: total training loss 0.00195\n",
            "2025-06-26 08:27:43,550 Epoch 5181: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5182\n",
            "2025-06-26 08:27:43,552 EPOCH 5182\n",
            "INFO:__main__:Epoch 5182: total training loss 0.00198\n",
            "2025-06-26 08:27:43,637 Epoch 5182: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5183\n",
            "2025-06-26 08:27:43,640 EPOCH 5183\n",
            "INFO:__main__:Epoch 5183: total training loss 0.00194\n",
            "2025-06-26 08:27:43,738 Epoch 5183: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5184\n",
            "2025-06-26 08:27:43,745 EPOCH 5184\n",
            "INFO:__main__:Epoch 5184: total training loss 0.00221\n",
            "2025-06-26 08:27:43,827 Epoch 5184: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5185\n",
            "2025-06-26 08:27:43,833 EPOCH 5185\n",
            "INFO:__main__:Epoch 5185: total training loss 0.00225\n",
            "2025-06-26 08:27:43,918 Epoch 5185: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5186\n",
            "2025-06-26 08:27:43,925 EPOCH 5186\n",
            "INFO:__main__:Epoch 5186: total training loss 0.00233\n",
            "2025-06-26 08:27:44,018 Epoch 5186: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5187\n",
            "2025-06-26 08:27:44,022 EPOCH 5187\n",
            "INFO:__main__:Epoch 5187: total training loss 0.00215\n",
            "2025-06-26 08:27:44,120 Epoch 5187: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5188\n",
            "2025-06-26 08:27:44,122 EPOCH 5188\n",
            "INFO:__main__:Epoch 5188: total training loss 0.00241\n",
            "2025-06-26 08:27:44,203 Epoch 5188: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5189\n",
            "2025-06-26 08:27:44,206 EPOCH 5189\n",
            "INFO:__main__:Epoch 5189: total training loss 0.00230\n",
            "2025-06-26 08:27:44,305 Epoch 5189: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5190\n",
            "2025-06-26 08:27:44,307 EPOCH 5190\n",
            "INFO:__main__:Epoch 5190: total training loss 0.00233\n",
            "2025-06-26 08:27:44,380 Epoch 5190: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5191\n",
            "2025-06-26 08:27:44,409 EPOCH 5191\n",
            "INFO:__main__:Epoch 5191: total training loss 0.00233\n",
            "2025-06-26 08:27:44,482 Epoch 5191: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5192\n",
            "2025-06-26 08:27:44,485 EPOCH 5192\n",
            "INFO:__main__:Epoch 5192: total training loss 0.00220\n",
            "2025-06-26 08:27:44,558 Epoch 5192: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5193\n",
            "2025-06-26 08:27:44,561 EPOCH 5193\n",
            "INFO:__main__:Epoch 5193: total training loss 0.00237\n",
            "2025-06-26 08:27:44,634 Epoch 5193: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5194\n",
            "2025-06-26 08:27:44,637 EPOCH 5194\n",
            "INFO:__main__:Epoch 5194: total training loss 0.00222\n",
            "2025-06-26 08:27:44,706 Epoch 5194: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5195\n",
            "2025-06-26 08:27:44,708 EPOCH 5195\n",
            "INFO:__main__:Epoch 5195: total training loss 0.00268\n",
            "2025-06-26 08:27:44,784 Epoch 5195: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 5196\n",
            "2025-06-26 08:27:44,787 EPOCH 5196\n",
            "INFO:__main__:Epoch 5196: total training loss 0.00246\n",
            "2025-06-26 08:27:44,878 Epoch 5196: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 5197\n",
            "2025-06-26 08:27:44,880 EPOCH 5197\n",
            "INFO:__main__:Epoch 5197: total training loss 0.00254\n",
            "2025-06-26 08:27:44,960 Epoch 5197: total training loss 0.00254\n",
            "INFO:__main__:EPOCH 5198\n",
            "2025-06-26 08:27:44,962 EPOCH 5198\n",
            "INFO:__main__:Epoch 5198: total training loss 0.00268\n",
            "2025-06-26 08:27:45,030 Epoch 5198: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 5199\n",
            "2025-06-26 08:27:45,032 EPOCH 5199\n",
            "INFO:__main__:Epoch 5199: total training loss 0.00249\n",
            "2025-06-26 08:27:45,107 Epoch 5199: total training loss 0.00249\n",
            "INFO:__main__:EPOCH 5200\n",
            "2025-06-26 08:27:45,109 EPOCH 5200\n",
            "INFO:__main__:Epoch 5200: total training loss 0.00247\n",
            "2025-06-26 08:27:45,178 Epoch 5200: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5201\n",
            "2025-06-26 08:27:45,180 EPOCH 5201\n",
            "INFO:__main__:Epoch 5201: total training loss 0.00240\n",
            "2025-06-26 08:27:45,250 Epoch 5201: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5202\n",
            "2025-06-26 08:27:45,252 EPOCH 5202\n",
            "INFO:__main__:Epoch 5202: total training loss 0.00263\n",
            "2025-06-26 08:27:45,321 Epoch 5202: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 5203\n",
            "2025-06-26 08:27:45,323 EPOCH 5203\n",
            "INFO:__main__:Epoch 5203: total training loss 0.00249\n",
            "2025-06-26 08:27:45,394 Epoch 5203: total training loss 0.00249\n",
            "INFO:__main__:EPOCH 5204\n",
            "2025-06-26 08:27:45,396 EPOCH 5204\n",
            "INFO:__main__:Epoch 5204: total training loss 0.00285\n",
            "2025-06-26 08:27:45,464 Epoch 5204: total training loss 0.00285\n",
            "INFO:__main__:EPOCH 5205\n",
            "2025-06-26 08:27:45,466 EPOCH 5205\n",
            "INFO:__main__:Epoch 5205: total training loss 0.00291\n",
            "2025-06-26 08:27:45,536 Epoch 5205: total training loss 0.00291\n",
            "INFO:__main__:EPOCH 5206\n",
            "2025-06-26 08:27:45,538 EPOCH 5206\n",
            "INFO:__main__:Epoch 5206: total training loss 0.00263\n",
            "2025-06-26 08:27:45,617 Epoch 5206: total training loss 0.00263\n",
            "INFO:__main__:EPOCH 5207\n",
            "2025-06-26 08:27:45,621 EPOCH 5207\n",
            "INFO:__main__:Epoch 5207: total training loss 0.00261\n",
            "2025-06-26 08:27:45,713 Epoch 5207: total training loss 0.00261\n",
            "INFO:__main__:EPOCH 5208\n",
            "2025-06-26 08:27:45,717 EPOCH 5208\n",
            "INFO:__main__:Epoch 5208: total training loss 0.00272\n",
            "2025-06-26 08:27:45,811 Epoch 5208: total training loss 0.00272\n",
            "INFO:__main__:EPOCH 5209\n",
            "2025-06-26 08:27:45,817 EPOCH 5209\n",
            "INFO:__main__:Epoch 5209: total training loss 0.00245\n",
            "2025-06-26 08:27:45,904 Epoch 5209: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5210\n",
            "2025-06-26 08:27:45,905 EPOCH 5210\n",
            "INFO:__main__:Epoch 5210: total training loss 0.00241\n",
            "2025-06-26 08:27:46,012 Epoch 5210: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5211\n",
            "2025-06-26 08:27:46,014 EPOCH 5211\n",
            "INFO:__main__:Epoch 5211: total training loss 0.00247\n",
            "2025-06-26 08:27:46,100 Epoch 5211: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5212\n",
            "2025-06-26 08:27:46,103 EPOCH 5212\n",
            "INFO:__main__:Epoch 5212: total training loss 0.00224\n",
            "2025-06-26 08:27:46,191 Epoch 5212: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5213\n",
            "2025-06-26 08:27:46,195 EPOCH 5213\n",
            "INFO:__main__:Epoch 5213: total training loss 0.00225\n",
            "2025-06-26 08:27:46,269 Epoch 5213: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5214\n",
            "2025-06-26 08:27:46,271 EPOCH 5214\n",
            "INFO:__main__:Epoch 5214: total training loss 0.00221\n",
            "2025-06-26 08:27:46,347 Epoch 5214: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5215\n",
            "2025-06-26 08:27:46,350 EPOCH 5215\n",
            "INFO:__main__:Epoch 5215: total training loss 0.00236\n",
            "2025-06-26 08:27:46,434 Epoch 5215: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5216\n",
            "2025-06-26 08:27:46,437 EPOCH 5216\n",
            "INFO:__main__:Epoch 5216: total training loss 0.00223\n",
            "2025-06-26 08:27:46,526 Epoch 5216: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5217\n",
            "2025-06-26 08:27:46,534 EPOCH 5217\n",
            "INFO:__main__:Epoch 5217: total training loss 0.00232\n",
            "2025-06-26 08:27:46,621 Epoch 5217: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5218\n",
            "2025-06-26 08:27:46,627 EPOCH 5218\n",
            "INFO:__main__:Epoch 5218: total training loss 0.00232\n",
            "2025-06-26 08:27:46,708 Epoch 5218: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5219\n",
            "2025-06-26 08:27:46,713 EPOCH 5219\n",
            "INFO:__main__:Epoch 5219: total training loss 0.00251\n",
            "2025-06-26 08:27:46,789 Epoch 5219: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5220\n",
            "2025-06-26 08:27:46,795 EPOCH 5220\n",
            "INFO:__main__:Epoch 5220: total training loss 0.00237\n",
            "2025-06-26 08:27:46,870 Epoch 5220: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5221\n",
            "2025-06-26 08:27:46,875 EPOCH 5221\n",
            "INFO:__main__:Epoch 5221: total training loss 0.00218\n",
            "2025-06-26 08:27:46,967 Epoch 5221: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5222\n",
            "2025-06-26 08:27:46,972 EPOCH 5222\n",
            "INFO:__main__:Epoch 5222: total training loss 0.00234\n",
            "2025-06-26 08:27:47,060 Epoch 5222: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5223\n",
            "2025-06-26 08:27:47,067 EPOCH 5223\n",
            "INFO:__main__:Epoch 5223: total training loss 0.00237\n",
            "2025-06-26 08:27:47,149 Epoch 5223: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5224\n",
            "2025-06-26 08:27:47,156 EPOCH 5224\n",
            "INFO:__main__:Epoch 5224: total training loss 0.00221\n",
            "2025-06-26 08:27:47,237 Epoch 5224: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5225\n",
            "2025-06-26 08:27:47,241 EPOCH 5225\n",
            "INFO:__main__:Epoch 5225: total training loss 0.00224\n",
            "2025-06-26 08:27:47,316 Epoch 5225: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5226\n",
            "2025-06-26 08:27:47,321 EPOCH 5226\n",
            "INFO:__main__:Epoch 5226: total training loss 0.00253\n",
            "2025-06-26 08:27:47,414 Epoch 5226: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 5227\n",
            "2025-06-26 08:27:47,418 EPOCH 5227\n",
            "INFO:__main__:Epoch 5227: total training loss 0.00246\n",
            "2025-06-26 08:27:47,525 Epoch 5227: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 5228\n",
            "2025-06-26 08:27:47,527 EPOCH 5228\n",
            "INFO:__main__:Epoch 5228: total training loss 0.00256\n",
            "2025-06-26 08:27:47,627 Epoch 5228: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5229\n",
            "2025-06-26 08:27:47,630 EPOCH 5229\n",
            "INFO:__main__:Epoch 5229: total training loss 0.00220\n",
            "2025-06-26 08:27:47,711 Epoch 5229: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5230\n",
            "2025-06-26 08:27:47,722 EPOCH 5230\n",
            "INFO:__main__:Epoch 5230: total training loss 0.00220\n",
            "2025-06-26 08:27:47,823 Epoch 5230: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5231\n",
            "2025-06-26 08:27:47,829 EPOCH 5231\n",
            "INFO:__main__:Epoch 5231: total training loss 0.00207\n",
            "2025-06-26 08:27:47,921 Epoch 5231: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5232\n",
            "2025-06-26 08:27:47,927 EPOCH 5232\n",
            "INFO:__main__:Epoch 5232: total training loss 0.00212\n",
            "2025-06-26 08:27:48,001 Epoch 5232: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5233\n",
            "2025-06-26 08:27:48,007 EPOCH 5233\n",
            "INFO:__main__:Epoch 5233: total training loss 0.00236\n",
            "2025-06-26 08:27:48,093 Epoch 5233: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5234\n",
            "2025-06-26 08:27:48,097 EPOCH 5234\n",
            "INFO:__main__:Epoch 5234: total training loss 0.00217\n",
            "2025-06-26 08:27:48,207 Epoch 5234: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5235\n",
            "2025-06-26 08:27:48,211 EPOCH 5235\n",
            "INFO:__main__:Epoch 5235: total training loss 0.00221\n",
            "2025-06-26 08:27:48,319 Epoch 5235: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5236\n",
            "2025-06-26 08:27:48,322 EPOCH 5236\n",
            "INFO:__main__:Epoch 5236: total training loss 0.00223\n",
            "2025-06-26 08:27:48,430 Epoch 5236: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5237\n",
            "2025-06-26 08:27:48,432 EPOCH 5237\n",
            "INFO:__main__:Epoch 5237: total training loss 0.00234\n",
            "2025-06-26 08:27:48,526 Epoch 5237: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5238\n",
            "2025-06-26 08:27:48,528 EPOCH 5238\n",
            "INFO:__main__:Epoch 5238: total training loss 0.00208\n",
            "2025-06-26 08:27:48,622 Epoch 5238: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5239\n",
            "2025-06-26 08:27:48,623 EPOCH 5239\n",
            "INFO:__main__:Epoch 5239: total training loss 0.00212\n",
            "2025-06-26 08:27:48,701 Epoch 5239: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5240\n",
            "2025-06-26 08:27:48,706 EPOCH 5240\n",
            "INFO:__main__:Epoch 5240: total training loss 0.00231\n",
            "2025-06-26 08:27:48,804 Epoch 5240: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5241\n",
            "2025-06-26 08:27:48,806 EPOCH 5241\n",
            "INFO:__main__:Epoch 5241: total training loss 0.00215\n",
            "2025-06-26 08:27:48,901 Epoch 5241: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5242\n",
            "2025-06-26 08:27:48,903 EPOCH 5242\n",
            "INFO:__main__:Epoch 5242: total training loss 0.00219\n",
            "2025-06-26 08:27:48,991 Epoch 5242: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5243\n",
            "2025-06-26 08:27:48,995 EPOCH 5243\n",
            "INFO:__main__:Epoch 5243: total training loss 0.00208\n",
            "2025-06-26 08:27:49,116 Epoch 5243: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5244\n",
            "2025-06-26 08:27:49,118 EPOCH 5244\n",
            "INFO:__main__:Epoch 5244: total training loss 0.00219\n",
            "2025-06-26 08:27:49,227 Epoch 5244: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5245\n",
            "2025-06-26 08:27:49,232 EPOCH 5245\n",
            "INFO:__main__:Epoch 5245: total training loss 0.00208\n",
            "2025-06-26 08:27:49,305 Epoch 5245: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5246\n",
            "2025-06-26 08:27:49,307 EPOCH 5246\n",
            "INFO:__main__:Epoch 5246: total training loss 0.00221\n",
            "2025-06-26 08:27:49,387 Epoch 5246: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5247\n",
            "2025-06-26 08:27:49,390 EPOCH 5247\n",
            "INFO:__main__:Epoch 5247: total training loss 0.00205\n",
            "2025-06-26 08:27:49,465 Epoch 5247: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5248\n",
            "2025-06-26 08:27:49,467 EPOCH 5248\n",
            "INFO:__main__:Epoch 5248: total training loss 0.00202\n",
            "2025-06-26 08:27:49,541 Epoch 5248: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5249\n",
            "2025-06-26 08:27:49,543 EPOCH 5249\n",
            "INFO:__main__:Epoch 5249: total training loss 0.00222\n",
            "2025-06-26 08:27:49,616 Epoch 5249: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5250\n",
            "2025-06-26 08:27:49,619 EPOCH 5250\n",
            "INFO:__main__:Epoch 5250 Step:     5250 Batch Loss:     0.002107 Tokens per Sec:  2034949, Lr: 0.001000\n",
            "2025-06-26 08:27:49,689 Epoch 5250 Step:     5250 Batch Loss:     0.002107 Tokens per Sec:  2034949, Lr: 0.001000\n",
            "INFO:__main__:Epoch 5250: total training loss 0.00211\n",
            "2025-06-26 08:27:49,692 Epoch 5250: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5251\n",
            "2025-06-26 08:27:49,693 EPOCH 5251\n",
            "INFO:__main__:Epoch 5251: total training loss 0.00192\n",
            "2025-06-26 08:27:49,766 Epoch 5251: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5252\n",
            "2025-06-26 08:27:49,768 EPOCH 5252\n",
            "INFO:__main__:Epoch 5252: total training loss 0.00191\n",
            "2025-06-26 08:27:49,842 Epoch 5252: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5253\n",
            "2025-06-26 08:27:49,844 EPOCH 5253\n",
            "INFO:__main__:Epoch 5253: total training loss 0.00208\n",
            "2025-06-26 08:27:49,916 Epoch 5253: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5254\n",
            "2025-06-26 08:27:49,918 EPOCH 5254\n",
            "INFO:__main__:Epoch 5254: total training loss 0.00221\n",
            "2025-06-26 08:27:49,991 Epoch 5254: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5255\n",
            "2025-06-26 08:27:49,993 EPOCH 5255\n",
            "INFO:__main__:Epoch 5255: total training loss 0.00211\n",
            "2025-06-26 08:27:50,064 Epoch 5255: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5256\n",
            "2025-06-26 08:27:50,066 EPOCH 5256\n",
            "INFO:__main__:Epoch 5256: total training loss 0.00246\n",
            "2025-06-26 08:27:50,136 Epoch 5256: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 5257\n",
            "2025-06-26 08:27:50,138 EPOCH 5257\n",
            "INFO:__main__:Epoch 5257: total training loss 0.00211\n",
            "2025-06-26 08:27:50,208 Epoch 5257: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5258\n",
            "2025-06-26 08:27:50,210 EPOCH 5258\n",
            "INFO:__main__:Epoch 5258: total training loss 0.00220\n",
            "2025-06-26 08:27:50,315 Epoch 5258: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5259\n",
            "2025-06-26 08:27:50,317 EPOCH 5259\n",
            "INFO:__main__:Epoch 5259: total training loss 0.00231\n",
            "2025-06-26 08:27:50,389 Epoch 5259: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5260\n",
            "2025-06-26 08:27:50,391 EPOCH 5260\n",
            "INFO:__main__:Epoch 5260: total training loss 0.00276\n",
            "2025-06-26 08:27:50,464 Epoch 5260: total training loss 0.00276\n",
            "INFO:__main__:EPOCH 5261\n",
            "2025-06-26 08:27:50,466 EPOCH 5261\n",
            "INFO:__main__:Epoch 5261: total training loss 0.00298\n",
            "2025-06-26 08:27:50,540 Epoch 5261: total training loss 0.00298\n",
            "INFO:__main__:EPOCH 5262\n",
            "2025-06-26 08:27:50,542 EPOCH 5262\n",
            "INFO:__main__:Epoch 5262: total training loss 0.00274\n",
            "2025-06-26 08:27:50,615 Epoch 5262: total training loss 0.00274\n",
            "INFO:__main__:EPOCH 5263\n",
            "2025-06-26 08:27:50,617 EPOCH 5263\n",
            "INFO:__main__:Epoch 5263: total training loss 0.00283\n",
            "2025-06-26 08:27:50,688 Epoch 5263: total training loss 0.00283\n",
            "INFO:__main__:EPOCH 5264\n",
            "2025-06-26 08:27:50,690 EPOCH 5264\n",
            "INFO:__main__:Epoch 5264: total training loss 0.00282\n",
            "2025-06-26 08:27:50,763 Epoch 5264: total training loss 0.00282\n",
            "INFO:__main__:EPOCH 5265\n",
            "2025-06-26 08:27:50,765 EPOCH 5265\n",
            "INFO:__main__:Epoch 5265: total training loss 0.00304\n",
            "2025-06-26 08:27:50,843 Epoch 5265: total training loss 0.00304\n",
            "INFO:__main__:EPOCH 5266\n",
            "2025-06-26 08:27:50,845 EPOCH 5266\n",
            "INFO:__main__:Epoch 5266: total training loss 0.00266\n",
            "2025-06-26 08:27:50,919 Epoch 5266: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 5267\n",
            "2025-06-26 08:27:50,921 EPOCH 5267\n",
            "INFO:__main__:Epoch 5267: total training loss 0.00267\n",
            "2025-06-26 08:27:50,992 Epoch 5267: total training loss 0.00267\n",
            "INFO:__main__:EPOCH 5268\n",
            "2025-06-26 08:27:50,994 EPOCH 5268\n",
            "INFO:__main__:Epoch 5268: total training loss 0.00276\n",
            "2025-06-26 08:27:51,067 Epoch 5268: total training loss 0.00276\n",
            "INFO:__main__:EPOCH 5269\n",
            "2025-06-26 08:27:51,071 EPOCH 5269\n",
            "INFO:__main__:Epoch 5269: total training loss 0.00266\n",
            "2025-06-26 08:27:51,146 Epoch 5269: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 5270\n",
            "2025-06-26 08:27:51,150 EPOCH 5270\n",
            "INFO:__main__:Epoch 5270: total training loss 0.00278\n",
            "2025-06-26 08:27:51,222 Epoch 5270: total training loss 0.00278\n",
            "INFO:__main__:EPOCH 5271\n",
            "2025-06-26 08:27:51,224 EPOCH 5271\n",
            "INFO:__main__:Epoch 5271: total training loss 0.00273\n",
            "2025-06-26 08:27:51,303 Epoch 5271: total training loss 0.00273\n",
            "INFO:__main__:EPOCH 5272\n",
            "2025-06-26 08:27:51,305 EPOCH 5272\n",
            "INFO:__main__:Epoch 5272: total training loss 0.00239\n",
            "2025-06-26 08:27:51,396 Epoch 5272: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 5273\n",
            "2025-06-26 08:27:51,398 EPOCH 5273\n",
            "INFO:__main__:Epoch 5273: total training loss 0.00232\n",
            "2025-06-26 08:27:51,475 Epoch 5273: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5274\n",
            "2025-06-26 08:27:51,478 EPOCH 5274\n",
            "INFO:__main__:Epoch 5274: total training loss 0.00248\n",
            "2025-06-26 08:27:51,548 Epoch 5274: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5275\n",
            "2025-06-26 08:27:51,551 EPOCH 5275\n",
            "INFO:__main__:Epoch 5275: total training loss 0.00215\n",
            "2025-06-26 08:27:51,621 Epoch 5275: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5276\n",
            "2025-06-26 08:27:51,623 EPOCH 5276\n",
            "INFO:__main__:Epoch 5276: total training loss 0.00234\n",
            "2025-06-26 08:27:51,692 Epoch 5276: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5277\n",
            "2025-06-26 08:27:51,694 EPOCH 5277\n",
            "INFO:__main__:Epoch 5277: total training loss 0.00220\n",
            "2025-06-26 08:27:51,770 Epoch 5277: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5278\n",
            "2025-06-26 08:27:51,772 EPOCH 5278\n",
            "INFO:__main__:Epoch 5278: total training loss 0.00202\n",
            "2025-06-26 08:27:51,847 Epoch 5278: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5279\n",
            "2025-06-26 08:27:51,850 EPOCH 5279\n",
            "INFO:__main__:Epoch 5279: total training loss 0.00215\n",
            "2025-06-26 08:27:51,919 Epoch 5279: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5280\n",
            "2025-06-26 08:27:51,922 EPOCH 5280\n",
            "INFO:__main__:Epoch 5280: total training loss 0.00198\n",
            "2025-06-26 08:27:51,991 Epoch 5280: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5281\n",
            "2025-06-26 08:27:51,993 EPOCH 5281\n",
            "INFO:__main__:Epoch 5281: total training loss 0.00200\n",
            "2025-06-26 08:27:52,069 Epoch 5281: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5282\n",
            "2025-06-26 08:27:52,071 EPOCH 5282\n",
            "INFO:__main__:Epoch 5282: total training loss 0.00209\n",
            "2025-06-26 08:27:52,141 Epoch 5282: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5283\n",
            "2025-06-26 08:27:52,143 EPOCH 5283\n",
            "INFO:__main__:Epoch 5283: total training loss 0.00248\n",
            "2025-06-26 08:27:52,214 Epoch 5283: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5284\n",
            "2025-06-26 08:27:52,216 EPOCH 5284\n",
            "INFO:__main__:Epoch 5284: total training loss 0.00240\n",
            "2025-06-26 08:27:52,286 Epoch 5284: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5285\n",
            "2025-06-26 08:27:52,288 EPOCH 5285\n",
            "INFO:__main__:Epoch 5285: total training loss 0.00240\n",
            "2025-06-26 08:27:52,371 Epoch 5285: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5286\n",
            "2025-06-26 08:27:52,373 EPOCH 5286\n",
            "INFO:__main__:Epoch 5286: total training loss 0.00234\n",
            "2025-06-26 08:27:52,450 Epoch 5286: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5287\n",
            "2025-06-26 08:27:52,452 EPOCH 5287\n",
            "INFO:__main__:Epoch 5287: total training loss 0.00245\n",
            "2025-06-26 08:27:52,522 Epoch 5287: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5288\n",
            "2025-06-26 08:27:52,524 EPOCH 5288\n",
            "INFO:__main__:Epoch 5288: total training loss 0.00233\n",
            "2025-06-26 08:27:52,596 Epoch 5288: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5289\n",
            "2025-06-26 08:27:52,598 EPOCH 5289\n",
            "INFO:__main__:Epoch 5289: total training loss 0.00223\n",
            "2025-06-26 08:27:52,668 Epoch 5289: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5290\n",
            "2025-06-26 08:27:52,670 EPOCH 5290\n",
            "INFO:__main__:Epoch 5290: total training loss 0.00236\n",
            "2025-06-26 08:27:52,740 Epoch 5290: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5291\n",
            "2025-06-26 08:27:52,742 EPOCH 5291\n",
            "INFO:__main__:Epoch 5291: total training loss 0.00211\n",
            "2025-06-26 08:27:52,815 Epoch 5291: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5292\n",
            "2025-06-26 08:27:52,818 EPOCH 5292\n",
            "INFO:__main__:Epoch 5292: total training loss 0.00212\n",
            "2025-06-26 08:27:52,890 Epoch 5292: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5293\n",
            "2025-06-26 08:27:52,892 EPOCH 5293\n",
            "INFO:__main__:Epoch 5293: total training loss 0.00228\n",
            "2025-06-26 08:27:52,973 Epoch 5293: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5294\n",
            "2025-06-26 08:27:52,975 EPOCH 5294\n",
            "INFO:__main__:Epoch 5294: total training loss 0.00211\n",
            "2025-06-26 08:27:53,057 Epoch 5294: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5295\n",
            "2025-06-26 08:27:53,059 EPOCH 5295\n",
            "INFO:__main__:Epoch 5295: total training loss 0.00211\n",
            "2025-06-26 08:27:53,146 Epoch 5295: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5296\n",
            "2025-06-26 08:27:53,149 EPOCH 5296\n",
            "INFO:__main__:Epoch 5296: total training loss 0.00220\n",
            "2025-06-26 08:27:53,229 Epoch 5296: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5297\n",
            "2025-06-26 08:27:53,231 EPOCH 5297\n",
            "INFO:__main__:Epoch 5297: total training loss 0.00216\n",
            "2025-06-26 08:27:53,300 Epoch 5297: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5298\n",
            "2025-06-26 08:27:53,302 EPOCH 5298\n",
            "INFO:__main__:Epoch 5298: total training loss 0.00211\n",
            "2025-06-26 08:27:53,374 Epoch 5298: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5299\n",
            "2025-06-26 08:27:53,376 EPOCH 5299\n",
            "INFO:__main__:Epoch 5299: total training loss 0.00211\n",
            "2025-06-26 08:27:53,460 Epoch 5299: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5300\n",
            "2025-06-26 08:27:53,462 EPOCH 5300\n",
            "INFO:__main__:Epoch 5300: total training loss 0.00228\n",
            "2025-06-26 08:27:53,533 Epoch 5300: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5301\n",
            "2025-06-26 08:27:53,535 EPOCH 5301\n",
            "INFO:__main__:Epoch 5301: total training loss 0.00218\n",
            "2025-06-26 08:27:53,604 Epoch 5301: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5302\n",
            "2025-06-26 08:27:53,606 EPOCH 5302\n",
            "INFO:__main__:Epoch 5302: total training loss 0.00212\n",
            "2025-06-26 08:27:53,675 Epoch 5302: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5303\n",
            "2025-06-26 08:27:53,677 EPOCH 5303\n",
            "INFO:__main__:Epoch 5303: total training loss 0.00211\n",
            "2025-06-26 08:27:53,746 Epoch 5303: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5304\n",
            "2025-06-26 08:27:53,748 EPOCH 5304\n",
            "INFO:__main__:Epoch 5304: total training loss 0.00232\n",
            "2025-06-26 08:27:53,821 Epoch 5304: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5305\n",
            "2025-06-26 08:27:53,823 EPOCH 5305\n",
            "INFO:__main__:Epoch 5305: total training loss 0.00219\n",
            "2025-06-26 08:27:53,897 Epoch 5305: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5306\n",
            "2025-06-26 08:27:53,899 EPOCH 5306\n",
            "INFO:__main__:Epoch 5306: total training loss 0.00220\n",
            "2025-06-26 08:27:53,973 Epoch 5306: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5307\n",
            "2025-06-26 08:27:53,975 EPOCH 5307\n",
            "INFO:__main__:Epoch 5307: total training loss 0.00227\n",
            "2025-06-26 08:27:54,046 Epoch 5307: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5308\n",
            "2025-06-26 08:27:54,048 EPOCH 5308\n",
            "INFO:__main__:Epoch 5308: total training loss 0.00231\n",
            "2025-06-26 08:27:54,121 Epoch 5308: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5309\n",
            "2025-06-26 08:27:54,123 EPOCH 5309\n",
            "INFO:__main__:Epoch 5309: total training loss 0.00227\n",
            "2025-06-26 08:27:54,196 Epoch 5309: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5310\n",
            "2025-06-26 08:27:54,198 EPOCH 5310\n",
            "INFO:__main__:Epoch 5310: total training loss 0.00228\n",
            "2025-06-26 08:27:54,272 Epoch 5310: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5311\n",
            "2025-06-26 08:27:54,274 EPOCH 5311\n",
            "INFO:__main__:Epoch 5311: total training loss 0.00215\n",
            "2025-06-26 08:27:54,349 Epoch 5311: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5312\n",
            "2025-06-26 08:27:54,351 EPOCH 5312\n",
            "INFO:__main__:Epoch 5312: total training loss 0.00217\n",
            "2025-06-26 08:27:54,423 Epoch 5312: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5313\n",
            "2025-06-26 08:27:54,425 EPOCH 5313\n",
            "INFO:__main__:Epoch 5313: total training loss 0.00211\n",
            "2025-06-26 08:27:54,516 Epoch 5313: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5314\n",
            "2025-06-26 08:27:54,518 EPOCH 5314\n",
            "INFO:__main__:Epoch 5314: total training loss 0.00209\n",
            "2025-06-26 08:27:54,587 Epoch 5314: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5315\n",
            "2025-06-26 08:27:54,589 EPOCH 5315\n",
            "INFO:__main__:Epoch 5315: total training loss 0.00214\n",
            "2025-06-26 08:27:54,661 Epoch 5315: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5316\n",
            "2025-06-26 08:27:54,663 EPOCH 5316\n",
            "INFO:__main__:Epoch 5316: total training loss 0.00200\n",
            "2025-06-26 08:27:54,740 Epoch 5316: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5317\n",
            "2025-06-26 08:27:54,742 EPOCH 5317\n",
            "INFO:__main__:Epoch 5317: total training loss 0.00195\n",
            "2025-06-26 08:27:54,817 Epoch 5317: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5318\n",
            "2025-06-26 08:27:54,819 EPOCH 5318\n",
            "INFO:__main__:Epoch 5318: total training loss 0.00219\n",
            "2025-06-26 08:27:54,892 Epoch 5318: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5319\n",
            "2025-06-26 08:27:54,893 EPOCH 5319\n",
            "INFO:__main__:Epoch 5319: total training loss 0.00210\n",
            "2025-06-26 08:27:54,966 Epoch 5319: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5320\n",
            "2025-06-26 08:27:54,968 EPOCH 5320\n",
            "INFO:__main__:Epoch 5320: total training loss 0.00221\n",
            "2025-06-26 08:27:55,044 Epoch 5320: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5321\n",
            "2025-06-26 08:27:55,046 EPOCH 5321\n",
            "INFO:__main__:Epoch 5321: total training loss 0.00217\n",
            "2025-06-26 08:27:55,116 Epoch 5321: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5322\n",
            "2025-06-26 08:27:55,118 EPOCH 5322\n",
            "INFO:__main__:Epoch 5322: total training loss 0.00207\n",
            "2025-06-26 08:27:55,187 Epoch 5322: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5323\n",
            "2025-06-26 08:27:55,188 EPOCH 5323\n",
            "INFO:__main__:Epoch 5323: total training loss 0.00218\n",
            "2025-06-26 08:27:55,258 Epoch 5323: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5324\n",
            "2025-06-26 08:27:55,260 EPOCH 5324\n",
            "INFO:__main__:Epoch 5324: total training loss 0.00213\n",
            "2025-06-26 08:27:55,332 Epoch 5324: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5325\n",
            "2025-06-26 08:27:55,334 EPOCH 5325\n",
            "INFO:__main__:Epoch 5325: total training loss 0.00224\n",
            "2025-06-26 08:27:55,407 Epoch 5325: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5326\n",
            "2025-06-26 08:27:55,409 EPOCH 5326\n",
            "INFO:__main__:Epoch 5326: total training loss 0.00251\n",
            "2025-06-26 08:27:55,479 Epoch 5326: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5327\n",
            "2025-06-26 08:27:55,480 EPOCH 5327\n",
            "INFO:__main__:Epoch 5327: total training loss 0.00234\n",
            "2025-06-26 08:27:55,570 Epoch 5327: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5328\n",
            "2025-06-26 08:27:55,572 EPOCH 5328\n",
            "INFO:__main__:Epoch 5328: total training loss 0.00225\n",
            "2025-06-26 08:27:55,644 Epoch 5328: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5329\n",
            "2025-06-26 08:27:55,646 EPOCH 5329\n",
            "INFO:__main__:Epoch 5329: total training loss 0.00231\n",
            "2025-06-26 08:27:55,718 Epoch 5329: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5330\n",
            "2025-06-26 08:27:55,720 EPOCH 5330\n",
            "INFO:__main__:Epoch 5330: total training loss 0.00241\n",
            "2025-06-26 08:27:55,792 Epoch 5330: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5331\n",
            "2025-06-26 08:27:55,794 EPOCH 5331\n",
            "INFO:__main__:Epoch 5331: total training loss 0.00227\n",
            "2025-06-26 08:27:55,865 Epoch 5331: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5332\n",
            "2025-06-26 08:27:55,867 EPOCH 5332\n",
            "INFO:__main__:Epoch 5332: total training loss 0.00244\n",
            "2025-06-26 08:27:55,940 Epoch 5332: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 5333\n",
            "2025-06-26 08:27:55,942 EPOCH 5333\n",
            "INFO:__main__:Epoch 5333: total training loss 0.00220\n",
            "2025-06-26 08:27:56,014 Epoch 5333: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5334\n",
            "2025-06-26 08:27:56,016 EPOCH 5334\n",
            "INFO:__main__:Epoch 5334: total training loss 0.00213\n",
            "2025-06-26 08:27:56,088 Epoch 5334: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5335\n",
            "2025-06-26 08:27:56,090 EPOCH 5335\n",
            "INFO:__main__:Epoch 5335: total training loss 0.00214\n",
            "2025-06-26 08:27:56,158 Epoch 5335: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5336\n",
            "2025-06-26 08:27:56,160 EPOCH 5336\n",
            "INFO:__main__:Epoch 5336: total training loss 0.00204\n",
            "2025-06-26 08:27:56,235 Epoch 5336: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5337\n",
            "2025-06-26 08:27:56,237 EPOCH 5337\n",
            "INFO:__main__:Epoch 5337: total training loss 0.00230\n",
            "2025-06-26 08:27:56,306 Epoch 5337: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5338\n",
            "2025-06-26 08:27:56,308 EPOCH 5338\n",
            "INFO:__main__:Epoch 5338: total training loss 0.00222\n",
            "2025-06-26 08:27:56,378 Epoch 5338: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5339\n",
            "2025-06-26 08:27:56,380 EPOCH 5339\n",
            "INFO:__main__:Epoch 5339: total training loss 0.00248\n",
            "2025-06-26 08:27:56,454 Epoch 5339: total training loss 0.00248\n",
            "INFO:__main__:EPOCH 5340\n",
            "2025-06-26 08:27:56,456 EPOCH 5340\n",
            "INFO:__main__:Epoch 5340: total training loss 0.00228\n",
            "2025-06-26 08:27:56,527 Epoch 5340: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5341\n",
            "2025-06-26 08:27:56,530 EPOCH 5341\n",
            "INFO:__main__:Epoch 5341: total training loss 0.00251\n",
            "2025-06-26 08:27:56,620 Epoch 5341: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5342\n",
            "2025-06-26 08:27:56,622 EPOCH 5342\n",
            "INFO:__main__:Epoch 5342: total training loss 0.00268\n",
            "2025-06-26 08:27:56,693 Epoch 5342: total training loss 0.00268\n",
            "INFO:__main__:EPOCH 5343\n",
            "2025-06-26 08:27:56,695 EPOCH 5343\n",
            "INFO:__main__:Epoch 5343: total training loss 0.00251\n",
            "2025-06-26 08:27:56,763 Epoch 5343: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5344\n",
            "2025-06-26 08:27:56,766 EPOCH 5344\n",
            "INFO:__main__:Epoch 5344: total training loss 0.00244\n",
            "2025-06-26 08:27:56,836 Epoch 5344: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 5345\n",
            "2025-06-26 08:27:56,838 EPOCH 5345\n",
            "INFO:__main__:Epoch 5345: total training loss 0.00244\n",
            "2025-06-26 08:27:56,907 Epoch 5345: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 5346\n",
            "2025-06-26 08:27:56,909 EPOCH 5346\n",
            "INFO:__main__:Epoch 5346: total training loss 0.00225\n",
            "2025-06-26 08:27:56,979 Epoch 5346: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5347\n",
            "2025-06-26 08:27:56,981 EPOCH 5347\n",
            "INFO:__main__:Epoch 5347: total training loss 0.00226\n",
            "2025-06-26 08:27:57,048 Epoch 5347: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5348\n",
            "2025-06-26 08:27:57,050 EPOCH 5348\n",
            "INFO:__main__:Epoch 5348: total training loss 0.00230\n",
            "2025-06-26 08:27:57,123 Epoch 5348: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5349\n",
            "2025-06-26 08:27:57,126 EPOCH 5349\n",
            "INFO:__main__:Epoch 5349: total training loss 0.00246\n",
            "2025-06-26 08:27:57,199 Epoch 5349: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 5350\n",
            "2025-06-26 08:27:57,201 EPOCH 5350\n",
            "INFO:__main__:Epoch 5350: total training loss 0.00226\n",
            "2025-06-26 08:27:57,270 Epoch 5350: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5351\n",
            "2025-06-26 08:27:57,272 EPOCH 5351\n",
            "INFO:__main__:Epoch 5351: total training loss 0.00228\n",
            "2025-06-26 08:27:57,344 Epoch 5351: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5352\n",
            "2025-06-26 08:27:57,346 EPOCH 5352\n",
            "INFO:__main__:Epoch 5352: total training loss 0.00216\n",
            "2025-06-26 08:27:57,417 Epoch 5352: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5353\n",
            "2025-06-26 08:27:57,419 EPOCH 5353\n",
            "INFO:__main__:Epoch 5353: total training loss 0.00222\n",
            "2025-06-26 08:27:57,489 Epoch 5353: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5354\n",
            "2025-06-26 08:27:57,491 EPOCH 5354\n",
            "INFO:__main__:Epoch 5354: total training loss 0.00251\n",
            "2025-06-26 08:27:57,564 Epoch 5354: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5355\n",
            "2025-06-26 08:27:57,566 EPOCH 5355\n",
            "INFO:__main__:Epoch 5355: total training loss 0.00242\n",
            "2025-06-26 08:27:57,645 Epoch 5355: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 5356\n",
            "2025-06-26 08:27:57,647 EPOCH 5356\n",
            "INFO:__main__:Epoch 5356: total training loss 0.00245\n",
            "2025-06-26 08:27:57,720 Epoch 5356: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5357\n",
            "2025-06-26 08:27:57,722 EPOCH 5357\n",
            "INFO:__main__:Epoch 5357: total training loss 0.00231\n",
            "2025-06-26 08:27:57,795 Epoch 5357: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5358\n",
            "2025-06-26 08:27:57,797 EPOCH 5358\n",
            "INFO:__main__:Epoch 5358: total training loss 0.00232\n",
            "2025-06-26 08:27:57,865 Epoch 5358: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5359\n",
            "2025-06-26 08:27:57,867 EPOCH 5359\n",
            "INFO:__main__:Epoch 5359: total training loss 0.00222\n",
            "2025-06-26 08:27:57,939 Epoch 5359: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5360\n",
            "2025-06-26 08:27:57,942 EPOCH 5360\n",
            "INFO:__main__:Epoch 5360: total training loss 0.00197\n",
            "2025-06-26 08:27:58,011 Epoch 5360: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5361\n",
            "2025-06-26 08:27:58,014 EPOCH 5361\n",
            "INFO:__main__:Epoch 5361: total training loss 0.00209\n",
            "2025-06-26 08:27:58,085 Epoch 5361: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5362\n",
            "2025-06-26 08:27:58,087 EPOCH 5362\n",
            "INFO:__main__:Epoch 5362: total training loss 0.00192\n",
            "2025-06-26 08:27:58,157 Epoch 5362: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5363\n",
            "2025-06-26 08:27:58,159 EPOCH 5363\n",
            "INFO:__main__:Epoch 5363: total training loss 0.00203\n",
            "2025-06-26 08:27:58,231 Epoch 5363: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5364\n",
            "2025-06-26 08:27:58,233 EPOCH 5364\n",
            "INFO:__main__:Epoch 5364: total training loss 0.00207\n",
            "2025-06-26 08:27:58,305 Epoch 5364: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5365\n",
            "2025-06-26 08:27:58,308 EPOCH 5365\n",
            "INFO:__main__:Epoch 5365: total training loss 0.00199\n",
            "2025-06-26 08:27:58,376 Epoch 5365: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5366\n",
            "2025-06-26 08:27:58,378 EPOCH 5366\n",
            "INFO:__main__:Epoch 5366: total training loss 0.00189\n",
            "2025-06-26 08:27:58,448 Epoch 5366: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5367\n",
            "2025-06-26 08:27:58,450 EPOCH 5367\n",
            "INFO:__main__:Epoch 5367: total training loss 0.00202\n",
            "2025-06-26 08:27:58,522 Epoch 5367: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5368\n",
            "2025-06-26 08:27:58,524 EPOCH 5368\n",
            "INFO:__main__:Epoch 5368: total training loss 0.00192\n",
            "2025-06-26 08:27:58,599 Epoch 5368: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5369\n",
            "2025-06-26 08:27:58,601 EPOCH 5369\n",
            "INFO:__main__:Epoch 5369: total training loss 0.00196\n",
            "2025-06-26 08:27:58,669 Epoch 5369: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5370\n",
            "2025-06-26 08:27:58,671 EPOCH 5370\n",
            "INFO:__main__:Epoch 5370: total training loss 0.00215\n",
            "2025-06-26 08:27:58,756 Epoch 5370: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5371\n",
            "2025-06-26 08:27:58,758 EPOCH 5371\n",
            "INFO:__main__:Epoch 5371: total training loss 0.00258\n",
            "2025-06-26 08:27:58,827 Epoch 5371: total training loss 0.00258\n",
            "INFO:__main__:EPOCH 5372\n",
            "2025-06-26 08:27:58,829 EPOCH 5372\n",
            "INFO:__main__:Epoch 5372: total training loss 0.00256\n",
            "2025-06-26 08:27:58,900 Epoch 5372: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5373\n",
            "2025-06-26 08:27:58,902 EPOCH 5373\n",
            "INFO:__main__:Epoch 5373: total training loss 0.00232\n",
            "2025-06-26 08:27:58,974 Epoch 5373: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5374\n",
            "2025-06-26 08:27:58,977 EPOCH 5374\n",
            "INFO:__main__:Epoch 5374: total training loss 0.00261\n",
            "2025-06-26 08:27:59,046 Epoch 5374: total training loss 0.00261\n",
            "INFO:__main__:EPOCH 5375\n",
            "2025-06-26 08:27:59,048 EPOCH 5375\n",
            "INFO:__main__:Epoch 5375: total training loss 0.00256\n",
            "2025-06-26 08:27:59,118 Epoch 5375: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5376\n",
            "2025-06-26 08:27:59,120 EPOCH 5376\n",
            "INFO:__main__:Epoch 5376: total training loss 0.00259\n",
            "2025-06-26 08:27:59,193 Epoch 5376: total training loss 0.00259\n",
            "INFO:__main__:EPOCH 5377\n",
            "2025-06-26 08:27:59,195 EPOCH 5377\n",
            "INFO:__main__:Epoch 5377: total training loss 0.00236\n",
            "2025-06-26 08:27:59,264 Epoch 5377: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5378\n",
            "2025-06-26 08:27:59,266 EPOCH 5378\n",
            "INFO:__main__:Epoch 5378: total training loss 0.00247\n",
            "2025-06-26 08:27:59,369 Epoch 5378: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5379\n",
            "2025-06-26 08:27:59,375 EPOCH 5379\n",
            "INFO:__main__:Epoch 5379: total training loss 0.00253\n",
            "2025-06-26 08:27:59,472 Epoch 5379: total training loss 0.00253\n",
            "INFO:__main__:EPOCH 5380\n",
            "2025-06-26 08:27:59,474 EPOCH 5380\n",
            "INFO:__main__:Epoch 5380: total training loss 0.00230\n",
            "2025-06-26 08:27:59,563 Epoch 5380: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5381\n",
            "2025-06-26 08:27:59,567 EPOCH 5381\n",
            "INFO:__main__:Epoch 5381: total training loss 0.00224\n",
            "2025-06-26 08:27:59,650 Epoch 5381: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5382\n",
            "2025-06-26 08:27:59,657 EPOCH 5382\n",
            "INFO:__main__:Epoch 5382: total training loss 0.00213\n",
            "2025-06-26 08:27:59,745 Epoch 5382: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5383\n",
            "2025-06-26 08:27:59,750 EPOCH 5383\n",
            "INFO:__main__:Epoch 5383: total training loss 0.00210\n",
            "2025-06-26 08:27:59,845 Epoch 5383: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5384\n",
            "2025-06-26 08:27:59,847 EPOCH 5384\n",
            "INFO:__main__:Epoch 5384: total training loss 0.00219\n",
            "2025-06-26 08:27:59,940 Epoch 5384: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5385\n",
            "2025-06-26 08:27:59,944 EPOCH 5385\n",
            "INFO:__main__:Epoch 5385: total training loss 0.00205\n",
            "2025-06-26 08:28:00,038 Epoch 5385: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5386\n",
            "2025-06-26 08:28:00,040 EPOCH 5386\n",
            "INFO:__main__:Epoch 5386: total training loss 0.00213\n",
            "2025-06-26 08:28:00,123 Epoch 5386: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5387\n",
            "2025-06-26 08:28:00,125 EPOCH 5387\n",
            "INFO:__main__:Epoch 5387: total training loss 0.00208\n",
            "2025-06-26 08:28:00,215 Epoch 5387: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5388\n",
            "2025-06-26 08:28:00,225 EPOCH 5388\n",
            "INFO:__main__:Epoch 5388: total training loss 0.00202\n",
            "2025-06-26 08:28:00,333 Epoch 5388: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5389\n",
            "2025-06-26 08:28:00,335 EPOCH 5389\n",
            "INFO:__main__:Epoch 5389: total training loss 0.00209\n",
            "2025-06-26 08:28:00,421 Epoch 5389: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5390\n",
            "2025-06-26 08:28:00,427 EPOCH 5390\n",
            "INFO:__main__:Epoch 5390: total training loss 0.00214\n",
            "2025-06-26 08:28:00,501 Epoch 5390: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5391\n",
            "2025-06-26 08:28:00,509 EPOCH 5391\n",
            "INFO:__main__:Epoch 5391: total training loss 0.00203\n",
            "2025-06-26 08:28:00,611 Epoch 5391: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5392\n",
            "2025-06-26 08:28:00,616 EPOCH 5392\n",
            "INFO:__main__:Epoch 5392: total training loss 0.00209\n",
            "2025-06-26 08:28:00,703 Epoch 5392: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5393\n",
            "2025-06-26 08:28:00,707 EPOCH 5393\n",
            "INFO:__main__:Epoch 5393: total training loss 0.00222\n",
            "2025-06-26 08:28:00,794 Epoch 5393: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5394\n",
            "2025-06-26 08:28:00,803 EPOCH 5394\n",
            "INFO:__main__:Epoch 5394: total training loss 0.00217\n",
            "2025-06-26 08:28:00,904 Epoch 5394: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5395\n",
            "2025-06-26 08:28:00,906 EPOCH 5395\n",
            "INFO:__main__:Epoch 5395: total training loss 0.00199\n",
            "2025-06-26 08:28:00,995 Epoch 5395: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5396\n",
            "2025-06-26 08:28:01,000 EPOCH 5396\n",
            "INFO:__main__:Epoch 5396: total training loss 0.00247\n",
            "2025-06-26 08:28:01,102 Epoch 5396: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5397\n",
            "2025-06-26 08:28:01,107 EPOCH 5397\n",
            "INFO:__main__:Epoch 5397: total training loss 0.00223\n",
            "2025-06-26 08:28:01,189 Epoch 5397: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5398\n",
            "2025-06-26 08:28:01,197 EPOCH 5398\n",
            "INFO:__main__:Epoch 5398: total training loss 0.00229\n",
            "2025-06-26 08:28:01,299 Epoch 5398: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5399\n",
            "2025-06-26 08:28:01,301 EPOCH 5399\n",
            "INFO:__main__:Epoch 5399: total training loss 0.00245\n",
            "2025-06-26 08:28:01,398 Epoch 5399: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5400\n",
            "2025-06-26 08:28:01,400 EPOCH 5400\n",
            "INFO:__main__:Epoch 5400: total training loss 0.00280\n",
            "2025-06-26 08:28:01,488 Epoch 5400: total training loss 0.00280\n",
            "INFO:__main__:EPOCH 5401\n",
            "2025-06-26 08:28:01,491 EPOCH 5401\n",
            "INFO:__main__:Epoch 5401: total training loss 0.00254\n",
            "2025-06-26 08:28:01,561 Epoch 5401: total training loss 0.00254\n",
            "INFO:__main__:EPOCH 5402\n",
            "2025-06-26 08:28:01,564 EPOCH 5402\n",
            "INFO:__main__:Epoch 5402: total training loss 0.00256\n",
            "2025-06-26 08:28:01,642 Epoch 5402: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5403\n",
            "2025-06-26 08:28:01,644 EPOCH 5403\n",
            "INFO:__main__:Epoch 5403: total training loss 0.00260\n",
            "2025-06-26 08:28:01,715 Epoch 5403: total training loss 0.00260\n",
            "INFO:__main__:EPOCH 5404\n",
            "2025-06-26 08:28:01,717 EPOCH 5404\n",
            "INFO:__main__:Epoch 5404: total training loss 0.00246\n",
            "2025-06-26 08:28:01,791 Epoch 5404: total training loss 0.00246\n",
            "INFO:__main__:EPOCH 5405\n",
            "2025-06-26 08:28:01,792 EPOCH 5405\n",
            "INFO:__main__:Epoch 5405: total training loss 0.00244\n",
            "2025-06-26 08:28:01,863 Epoch 5405: total training loss 0.00244\n",
            "INFO:__main__:EPOCH 5406\n",
            "2025-06-26 08:28:01,865 EPOCH 5406\n",
            "INFO:__main__:Epoch 5406: total training loss 0.00233\n",
            "2025-06-26 08:28:01,945 Epoch 5406: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5407\n",
            "2025-06-26 08:28:01,947 EPOCH 5407\n",
            "INFO:__main__:Epoch 5407: total training loss 0.00233\n",
            "2025-06-26 08:28:02,028 Epoch 5407: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5408\n",
            "2025-06-26 08:28:02,030 EPOCH 5408\n",
            "INFO:__main__:Epoch 5408: total training loss 0.00222\n",
            "2025-06-26 08:28:02,108 Epoch 5408: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5409\n",
            "2025-06-26 08:28:02,110 EPOCH 5409\n",
            "INFO:__main__:Epoch 5409: total training loss 0.00247\n",
            "2025-06-26 08:28:02,183 Epoch 5409: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5410\n",
            "2025-06-26 08:28:02,186 EPOCH 5410\n",
            "INFO:__main__:Epoch 5410: total training loss 0.00220\n",
            "2025-06-26 08:28:02,259 Epoch 5410: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5411\n",
            "2025-06-26 08:28:02,262 EPOCH 5411\n",
            "INFO:__main__:Epoch 5411: total training loss 0.00224\n",
            "2025-06-26 08:28:02,342 Epoch 5411: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5412\n",
            "2025-06-26 08:28:02,344 EPOCH 5412\n",
            "INFO:__main__:Epoch 5412: total training loss 0.00217\n",
            "2025-06-26 08:28:02,413 Epoch 5412: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5413\n",
            "2025-06-26 08:28:02,415 EPOCH 5413\n",
            "INFO:__main__:Epoch 5413: total training loss 0.00215\n",
            "2025-06-26 08:28:02,498 Epoch 5413: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5414\n",
            "2025-06-26 08:28:02,500 EPOCH 5414\n",
            "INFO:__main__:Epoch 5414: total training loss 0.00211\n",
            "2025-06-26 08:28:02,571 Epoch 5414: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5415\n",
            "2025-06-26 08:28:02,573 EPOCH 5415\n",
            "INFO:__main__:Epoch 5415: total training loss 0.00215\n",
            "2025-06-26 08:28:02,641 Epoch 5415: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5416\n",
            "2025-06-26 08:28:02,643 EPOCH 5416\n",
            "INFO:__main__:Epoch 5416: total training loss 0.00229\n",
            "2025-06-26 08:28:02,713 Epoch 5416: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5417\n",
            "2025-06-26 08:28:02,715 EPOCH 5417\n",
            "INFO:__main__:Epoch 5417: total training loss 0.00219\n",
            "2025-06-26 08:28:02,786 Epoch 5417: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5418\n",
            "2025-06-26 08:28:02,788 EPOCH 5418\n",
            "INFO:__main__:Epoch 5418: total training loss 0.00211\n",
            "2025-06-26 08:28:02,860 Epoch 5418: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5419\n",
            "2025-06-26 08:28:02,862 EPOCH 5419\n",
            "INFO:__main__:Epoch 5419: total training loss 0.00208\n",
            "2025-06-26 08:28:02,933 Epoch 5419: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5420\n",
            "2025-06-26 08:28:02,935 EPOCH 5420\n",
            "INFO:__main__:Epoch 5420: total training loss 0.00209\n",
            "2025-06-26 08:28:03,006 Epoch 5420: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5421\n",
            "2025-06-26 08:28:03,008 EPOCH 5421\n",
            "INFO:__main__:Epoch 5421: total training loss 0.00213\n",
            "2025-06-26 08:28:03,098 Epoch 5421: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5422\n",
            "2025-06-26 08:28:03,100 EPOCH 5422\n",
            "INFO:__main__:Epoch 5422: total training loss 0.00212\n",
            "2025-06-26 08:28:03,178 Epoch 5422: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5423\n",
            "2025-06-26 08:28:03,181 EPOCH 5423\n",
            "INFO:__main__:Epoch 5423: total training loss 0.00228\n",
            "2025-06-26 08:28:03,289 Epoch 5423: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5424\n",
            "2025-06-26 08:28:03,291 EPOCH 5424\n",
            "INFO:__main__:Epoch 5424: total training loss 0.00216\n",
            "2025-06-26 08:28:03,420 Epoch 5424: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5425\n",
            "2025-06-26 08:28:03,424 EPOCH 5425\n",
            "INFO:__main__:Epoch 5425: total training loss 0.00219\n",
            "2025-06-26 08:28:03,527 Epoch 5425: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5426\n",
            "2025-06-26 08:28:03,529 EPOCH 5426\n",
            "INFO:__main__:Epoch 5426: total training loss 0.00219\n",
            "2025-06-26 08:28:03,625 Epoch 5426: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5427\n",
            "2025-06-26 08:28:03,627 EPOCH 5427\n",
            "INFO:__main__:Epoch 5427: total training loss 0.00208\n",
            "2025-06-26 08:28:03,732 Epoch 5427: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5428\n",
            "2025-06-26 08:28:03,737 EPOCH 5428\n",
            "INFO:__main__:Epoch 5428: total training loss 0.00196\n",
            "2025-06-26 08:28:03,836 Epoch 5428: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5429\n",
            "2025-06-26 08:28:03,843 EPOCH 5429\n",
            "INFO:__main__:Epoch 5429: total training loss 0.00203\n",
            "2025-06-26 08:28:03,966 Epoch 5429: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5430\n",
            "2025-06-26 08:28:03,975 EPOCH 5430\n",
            "INFO:__main__:Epoch 5430: total training loss 0.00211\n",
            "2025-06-26 08:28:04,079 Epoch 5430: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5431\n",
            "2025-06-26 08:28:04,082 EPOCH 5431\n",
            "INFO:__main__:Epoch 5431: total training loss 0.00210\n",
            "2025-06-26 08:28:04,192 Epoch 5431: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5432\n",
            "2025-06-26 08:28:04,194 EPOCH 5432\n",
            "INFO:__main__:Epoch 5432: total training loss 0.00203\n",
            "2025-06-26 08:28:04,298 Epoch 5432: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5433\n",
            "2025-06-26 08:28:04,302 EPOCH 5433\n",
            "INFO:__main__:Epoch 5433: total training loss 0.00216\n",
            "2025-06-26 08:28:04,399 Epoch 5433: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5434\n",
            "2025-06-26 08:28:04,405 EPOCH 5434\n",
            "INFO:__main__:Epoch 5434: total training loss 0.00225\n",
            "2025-06-26 08:28:04,505 Epoch 5434: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5435\n",
            "2025-06-26 08:28:04,510 EPOCH 5435\n",
            "INFO:__main__:Epoch 5435: total training loss 0.00235\n",
            "2025-06-26 08:28:04,597 Epoch 5435: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 5436\n",
            "2025-06-26 08:28:04,606 EPOCH 5436\n",
            "INFO:__main__:Epoch 5436: total training loss 0.00200\n",
            "2025-06-26 08:28:04,681 Epoch 5436: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5437\n",
            "2025-06-26 08:28:04,685 EPOCH 5437\n",
            "INFO:__main__:Epoch 5437: total training loss 0.00230\n",
            "2025-06-26 08:28:04,762 Epoch 5437: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5438\n",
            "2025-06-26 08:28:04,764 EPOCH 5438\n",
            "INFO:__main__:Epoch 5438: total training loss 0.00201\n",
            "2025-06-26 08:28:04,836 Epoch 5438: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5439\n",
            "2025-06-26 08:28:04,838 EPOCH 5439\n",
            "INFO:__main__:Epoch 5439: total training loss 0.00207\n",
            "2025-06-26 08:28:04,908 Epoch 5439: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5440\n",
            "2025-06-26 08:28:04,910 EPOCH 5440\n",
            "INFO:__main__:Epoch 5440: total training loss 0.00226\n",
            "2025-06-26 08:28:04,983 Epoch 5440: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5441\n",
            "2025-06-26 08:28:04,985 EPOCH 5441\n",
            "INFO:__main__:Epoch 5441: total training loss 0.00200\n",
            "2025-06-26 08:28:05,059 Epoch 5441: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5442\n",
            "2025-06-26 08:28:05,061 EPOCH 5442\n",
            "INFO:__main__:Epoch 5442: total training loss 0.00229\n",
            "2025-06-26 08:28:05,132 Epoch 5442: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5443\n",
            "2025-06-26 08:28:05,134 EPOCH 5443\n",
            "INFO:__main__:Epoch 5443: total training loss 0.00204\n",
            "2025-06-26 08:28:05,218 Epoch 5443: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5444\n",
            "2025-06-26 08:28:05,220 EPOCH 5444\n",
            "INFO:__main__:Epoch 5444: total training loss 0.00207\n",
            "2025-06-26 08:28:05,299 Epoch 5444: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5445\n",
            "2025-06-26 08:28:05,301 EPOCH 5445\n",
            "INFO:__main__:Epoch 5445: total training loss 0.00222\n",
            "2025-06-26 08:28:05,380 Epoch 5445: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5446\n",
            "2025-06-26 08:28:05,382 EPOCH 5446\n",
            "INFO:__main__:Epoch 5446: total training loss 0.00223\n",
            "2025-06-26 08:28:05,457 Epoch 5446: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5447\n",
            "2025-06-26 08:28:05,458 EPOCH 5447\n",
            "INFO:__main__:Epoch 5447: total training loss 0.00224\n",
            "2025-06-26 08:28:05,532 Epoch 5447: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5448\n",
            "2025-06-26 08:28:05,534 EPOCH 5448\n",
            "INFO:__main__:Epoch 5448: total training loss 0.00216\n",
            "2025-06-26 08:28:05,610 Epoch 5448: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5449\n",
            "2025-06-26 08:28:05,612 EPOCH 5449\n",
            "INFO:__main__:Epoch 5449: total training loss 0.00214\n",
            "2025-06-26 08:28:05,688 Epoch 5449: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5450\n",
            "2025-06-26 08:28:05,690 EPOCH 5450\n",
            "INFO:__main__:Epoch 5450: total training loss 0.00198\n",
            "2025-06-26 08:28:05,765 Epoch 5450: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5451\n",
            "2025-06-26 08:28:05,768 EPOCH 5451\n",
            "INFO:__main__:Epoch 5451: total training loss 0.00198\n",
            "2025-06-26 08:28:05,842 Epoch 5451: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5452\n",
            "2025-06-26 08:28:05,844 EPOCH 5452\n",
            "INFO:__main__:Epoch 5452: total training loss 0.00210\n",
            "2025-06-26 08:28:05,921 Epoch 5452: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5453\n",
            "2025-06-26 08:28:05,926 EPOCH 5453\n",
            "INFO:__main__:Epoch 5453: total training loss 0.00203\n",
            "2025-06-26 08:28:06,008 Epoch 5453: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5454\n",
            "2025-06-26 08:28:06,012 EPOCH 5454\n",
            "INFO:__main__:Epoch 5454: total training loss 0.00206\n",
            "2025-06-26 08:28:06,087 Epoch 5454: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5455\n",
            "2025-06-26 08:28:06,089 EPOCH 5455\n",
            "INFO:__main__:Epoch 5455: total training loss 0.00196\n",
            "2025-06-26 08:28:06,168 Epoch 5455: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5456\n",
            "2025-06-26 08:28:06,170 EPOCH 5456\n",
            "INFO:__main__:Epoch 5456: total training loss 0.00201\n",
            "2025-06-26 08:28:06,259 Epoch 5456: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5457\n",
            "2025-06-26 08:28:06,262 EPOCH 5457\n",
            "INFO:__main__:Epoch 5457: total training loss 0.00208\n",
            "2025-06-26 08:28:06,350 Epoch 5457: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5458\n",
            "2025-06-26 08:28:06,352 EPOCH 5458\n",
            "INFO:__main__:Epoch 5458: total training loss 0.00201\n",
            "2025-06-26 08:28:06,428 Epoch 5458: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5459\n",
            "2025-06-26 08:28:06,430 EPOCH 5459\n",
            "INFO:__main__:Epoch 5459: total training loss 0.00201\n",
            "2025-06-26 08:28:06,503 Epoch 5459: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5460\n",
            "2025-06-26 08:28:06,505 EPOCH 5460\n",
            "INFO:__main__:Epoch 5460: total training loss 0.00228\n",
            "2025-06-26 08:28:06,578 Epoch 5460: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5461\n",
            "2025-06-26 08:28:06,580 EPOCH 5461\n",
            "INFO:__main__:Epoch 5461: total training loss 0.00215\n",
            "2025-06-26 08:28:06,651 Epoch 5461: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5462\n",
            "2025-06-26 08:28:06,653 EPOCH 5462\n",
            "INFO:__main__:Epoch 5462: total training loss 0.00219\n",
            "2025-06-26 08:28:06,729 Epoch 5462: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5463\n",
            "2025-06-26 08:28:06,732 EPOCH 5463\n",
            "INFO:__main__:Epoch 5463: total training loss 0.00213\n",
            "2025-06-26 08:28:06,804 Epoch 5463: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5464\n",
            "2025-06-26 08:28:06,809 EPOCH 5464\n",
            "INFO:__main__:Epoch 5464: total training loss 0.00224\n",
            "2025-06-26 08:28:06,879 Epoch 5464: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5465\n",
            "2025-06-26 08:28:06,882 EPOCH 5465\n",
            "INFO:__main__:Epoch 5465: total training loss 0.00215\n",
            "2025-06-26 08:28:06,950 Epoch 5465: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5466\n",
            "2025-06-26 08:28:06,952 EPOCH 5466\n",
            "INFO:__main__:Epoch 5466: total training loss 0.00227\n",
            "2025-06-26 08:28:07,022 Epoch 5466: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5467\n",
            "2025-06-26 08:28:07,024 EPOCH 5467\n",
            "INFO:__main__:Epoch 5467: total training loss 0.00212\n",
            "2025-06-26 08:28:07,098 Epoch 5467: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5468\n",
            "2025-06-26 08:28:07,100 EPOCH 5468\n",
            "INFO:__main__:Epoch 5468: total training loss 0.00226\n",
            "2025-06-26 08:28:07,169 Epoch 5468: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5469\n",
            "2025-06-26 08:28:07,172 EPOCH 5469\n",
            "INFO:__main__:Epoch 5469: total training loss 0.00220\n",
            "2025-06-26 08:28:07,243 Epoch 5469: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5470\n",
            "2025-06-26 08:28:07,245 EPOCH 5470\n",
            "INFO:__main__:Epoch 5470: total training loss 0.00221\n",
            "2025-06-26 08:28:07,313 Epoch 5470: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5471\n",
            "2025-06-26 08:28:07,315 EPOCH 5471\n",
            "INFO:__main__:Epoch 5471: total training loss 0.00221\n",
            "2025-06-26 08:28:07,404 Epoch 5471: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5472\n",
            "2025-06-26 08:28:07,406 EPOCH 5472\n",
            "INFO:__main__:Epoch 5472: total training loss 0.00197\n",
            "2025-06-26 08:28:07,477 Epoch 5472: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5473\n",
            "2025-06-26 08:28:07,479 EPOCH 5473\n",
            "INFO:__main__:Epoch 5473: total training loss 0.00208\n",
            "2025-06-26 08:28:07,550 Epoch 5473: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5474\n",
            "2025-06-26 08:28:07,552 EPOCH 5474\n",
            "INFO:__main__:Epoch 5474: total training loss 0.00209\n",
            "2025-06-26 08:28:07,623 Epoch 5474: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5475\n",
            "2025-06-26 08:28:07,625 EPOCH 5475\n",
            "INFO:__main__:Epoch 5475: total training loss 0.00195\n",
            "2025-06-26 08:28:07,695 Epoch 5475: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5476\n",
            "2025-06-26 08:28:07,697 EPOCH 5476\n",
            "INFO:__main__:Epoch 5476: total training loss 0.00195\n",
            "2025-06-26 08:28:07,764 Epoch 5476: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5477\n",
            "2025-06-26 08:28:07,766 EPOCH 5477\n",
            "INFO:__main__:Epoch 5477: total training loss 0.00192\n",
            "2025-06-26 08:28:07,835 Epoch 5477: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5478\n",
            "2025-06-26 08:28:07,837 EPOCH 5478\n",
            "INFO:__main__:Epoch 5478: total training loss 0.00195\n",
            "2025-06-26 08:28:07,905 Epoch 5478: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5479\n",
            "2025-06-26 08:28:07,907 EPOCH 5479\n",
            "INFO:__main__:Epoch 5479: total training loss 0.00184\n",
            "2025-06-26 08:28:07,978 Epoch 5479: total training loss 0.00184\n",
            "INFO:__main__:EPOCH 5480\n",
            "2025-06-26 08:28:07,980 EPOCH 5480\n",
            "INFO:__main__:Epoch 5480: total training loss 0.00191\n",
            "2025-06-26 08:28:08,052 Epoch 5480: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5481\n",
            "2025-06-26 08:28:08,054 EPOCH 5481\n",
            "INFO:__main__:Epoch 5481: total training loss 0.00186\n",
            "2025-06-26 08:28:08,124 Epoch 5481: total training loss 0.00186\n",
            "INFO:__main__:EPOCH 5482\n",
            "2025-06-26 08:28:08,126 EPOCH 5482\n",
            "INFO:__main__:Epoch 5482: total training loss 0.00190\n",
            "2025-06-26 08:28:08,198 Epoch 5482: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5483\n",
            "2025-06-26 08:28:08,200 EPOCH 5483\n",
            "INFO:__main__:Epoch 5483: total training loss 0.00188\n",
            "2025-06-26 08:28:08,275 Epoch 5483: total training loss 0.00188\n",
            "INFO:__main__:EPOCH 5484\n",
            "2025-06-26 08:28:08,277 EPOCH 5484\n",
            "INFO:__main__:Epoch 5484: total training loss 0.00180\n",
            "2025-06-26 08:28:08,347 Epoch 5484: total training loss 0.00180\n",
            "INFO:__main__:EPOCH 5485\n",
            "2025-06-26 08:28:08,349 EPOCH 5485\n",
            "INFO:__main__:Epoch 5485: total training loss 0.00196\n",
            "2025-06-26 08:28:08,442 Epoch 5485: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5486\n",
            "2025-06-26 08:28:08,444 EPOCH 5486\n",
            "INFO:__main__:Epoch 5486: total training loss 0.00200\n",
            "2025-06-26 08:28:08,512 Epoch 5486: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5487\n",
            "2025-06-26 08:28:08,514 EPOCH 5487\n",
            "INFO:__main__:Epoch 5487: total training loss 0.00191\n",
            "2025-06-26 08:28:08,586 Epoch 5487: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5488\n",
            "2025-06-26 08:28:08,588 EPOCH 5488\n",
            "INFO:__main__:Epoch 5488: total training loss 0.00212\n",
            "2025-06-26 08:28:08,656 Epoch 5488: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5489\n",
            "2025-06-26 08:28:08,658 EPOCH 5489\n",
            "INFO:__main__:Epoch 5489: total training loss 0.00210\n",
            "2025-06-26 08:28:08,731 Epoch 5489: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5490\n",
            "2025-06-26 08:28:08,732 EPOCH 5490\n",
            "INFO:__main__:Epoch 5490: total training loss 0.00220\n",
            "2025-06-26 08:28:08,802 Epoch 5490: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5491\n",
            "2025-06-26 08:28:08,804 EPOCH 5491\n",
            "INFO:__main__:Epoch 5491: total training loss 0.00230\n",
            "2025-06-26 08:28:08,873 Epoch 5491: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5492\n",
            "2025-06-26 08:28:08,875 EPOCH 5492\n",
            "INFO:__main__:Epoch 5492: total training loss 0.00229\n",
            "2025-06-26 08:28:08,948 Epoch 5492: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5493\n",
            "2025-06-26 08:28:08,950 EPOCH 5493\n",
            "INFO:__main__:Epoch 5493: total training loss 0.00223\n",
            "2025-06-26 08:28:09,019 Epoch 5493: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5494\n",
            "2025-06-26 08:28:09,022 EPOCH 5494\n",
            "INFO:__main__:Epoch 5494: total training loss 0.00231\n",
            "2025-06-26 08:28:09,096 Epoch 5494: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5495\n",
            "2025-06-26 08:28:09,098 EPOCH 5495\n",
            "INFO:__main__:Epoch 5495: total training loss 0.00227\n",
            "2025-06-26 08:28:09,166 Epoch 5495: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5496\n",
            "2025-06-26 08:28:09,168 EPOCH 5496\n",
            "INFO:__main__:Epoch 5496: total training loss 0.00237\n",
            "2025-06-26 08:28:09,240 Epoch 5496: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5497\n",
            "2025-06-26 08:28:09,242 EPOCH 5497\n",
            "INFO:__main__:Epoch 5497: total training loss 0.00207\n",
            "2025-06-26 08:28:09,315 Epoch 5497: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5498\n",
            "2025-06-26 08:28:09,317 EPOCH 5498\n",
            "INFO:__main__:Epoch 5498: total training loss 0.00216\n",
            "2025-06-26 08:28:09,386 Epoch 5498: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5499\n",
            "2025-06-26 08:28:09,388 EPOCH 5499\n",
            "INFO:__main__:Epoch 5499: total training loss 0.00224\n",
            "2025-06-26 08:28:09,467 Epoch 5499: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5500\n",
            "2025-06-26 08:28:09,469 EPOCH 5500\n",
            "INFO:__main__:Epoch 5500 Step:     5500 Batch Loss:     0.002139 Tokens per Sec:  1968679, Lr: 0.001000\n",
            "2025-06-26 08:28:09,543 Epoch 5500 Step:     5500 Batch Loss:     0.002139 Tokens per Sec:  1968679, Lr: 0.001000\n",
            "INFO:__main__:Epoch 5500: total training loss 0.00214\n",
            "2025-06-26 08:28:09,545 Epoch 5500: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5501\n",
            "2025-06-26 08:28:09,550 EPOCH 5501\n",
            "INFO:__main__:Epoch 5501: total training loss 0.00210\n",
            "2025-06-26 08:28:09,626 Epoch 5501: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5502\n",
            "2025-06-26 08:28:09,628 EPOCH 5502\n",
            "INFO:__main__:Epoch 5502: total training loss 0.00232\n",
            "2025-06-26 08:28:09,695 Epoch 5502: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5503\n",
            "2025-06-26 08:28:09,697 EPOCH 5503\n",
            "INFO:__main__:Epoch 5503: total training loss 0.00221\n",
            "2025-06-26 08:28:09,770 Epoch 5503: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5504\n",
            "2025-06-26 08:28:09,772 EPOCH 5504\n",
            "INFO:__main__:Epoch 5504: total training loss 0.00228\n",
            "2025-06-26 08:28:09,843 Epoch 5504: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5505\n",
            "2025-06-26 08:28:09,845 EPOCH 5505\n",
            "INFO:__main__:Epoch 5505: total training loss 0.00227\n",
            "2025-06-26 08:28:09,916 Epoch 5505: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5506\n",
            "2025-06-26 08:28:09,918 EPOCH 5506\n",
            "INFO:__main__:Epoch 5506: total training loss 0.00219\n",
            "2025-06-26 08:28:09,990 Epoch 5506: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5507\n",
            "2025-06-26 08:28:09,992 EPOCH 5507\n",
            "INFO:__main__:Epoch 5507: total training loss 0.00259\n",
            "2025-06-26 08:28:10,066 Epoch 5507: total training loss 0.00259\n",
            "INFO:__main__:EPOCH 5508\n",
            "2025-06-26 08:28:10,068 EPOCH 5508\n",
            "INFO:__main__:Epoch 5508: total training loss 0.00250\n",
            "2025-06-26 08:28:10,139 Epoch 5508: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5509\n",
            "2025-06-26 08:28:10,141 EPOCH 5509\n",
            "INFO:__main__:Epoch 5509: total training loss 0.00225\n",
            "2025-06-26 08:28:10,212 Epoch 5509: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5510\n",
            "2025-06-26 08:28:10,214 EPOCH 5510\n",
            "INFO:__main__:Epoch 5510: total training loss 0.00241\n",
            "2025-06-26 08:28:10,284 Epoch 5510: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5511\n",
            "2025-06-26 08:28:10,286 EPOCH 5511\n",
            "INFO:__main__:Epoch 5511: total training loss 0.00227\n",
            "2025-06-26 08:28:10,358 Epoch 5511: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5512\n",
            "2025-06-26 08:28:10,360 EPOCH 5512\n",
            "INFO:__main__:Epoch 5512: total training loss 0.00218\n",
            "2025-06-26 08:28:10,428 Epoch 5512: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5513\n",
            "2025-06-26 08:28:10,430 EPOCH 5513\n",
            "INFO:__main__:Epoch 5513: total training loss 0.00230\n",
            "2025-06-26 08:28:10,507 Epoch 5513: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5514\n",
            "2025-06-26 08:28:10,510 EPOCH 5514\n",
            "INFO:__main__:Epoch 5514: total training loss 0.00214\n",
            "2025-06-26 08:28:10,589 Epoch 5514: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5515\n",
            "2025-06-26 08:28:10,591 EPOCH 5515\n",
            "INFO:__main__:Epoch 5515: total training loss 0.00208\n",
            "2025-06-26 08:28:10,659 Epoch 5515: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5516\n",
            "2025-06-26 08:28:10,661 EPOCH 5516\n",
            "INFO:__main__:Epoch 5516: total training loss 0.00215\n",
            "2025-06-26 08:28:10,730 Epoch 5516: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5517\n",
            "2025-06-26 08:28:10,732 EPOCH 5517\n",
            "INFO:__main__:Epoch 5517: total training loss 0.00198\n",
            "2025-06-26 08:28:10,804 Epoch 5517: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5518\n",
            "2025-06-26 08:28:10,806 EPOCH 5518\n",
            "INFO:__main__:Epoch 5518: total training loss 0.00208\n",
            "2025-06-26 08:28:10,873 Epoch 5518: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5519\n",
            "2025-06-26 08:28:10,875 EPOCH 5519\n",
            "INFO:__main__:Epoch 5519: total training loss 0.00198\n",
            "2025-06-26 08:28:10,945 Epoch 5519: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5520\n",
            "2025-06-26 08:28:10,946 EPOCH 5520\n",
            "INFO:__main__:Epoch 5520: total training loss 0.00196\n",
            "2025-06-26 08:28:11,020 Epoch 5520: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5521\n",
            "2025-06-26 08:28:11,022 EPOCH 5521\n",
            "INFO:__main__:Epoch 5521: total training loss 0.00212\n",
            "2025-06-26 08:28:11,090 Epoch 5521: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5522\n",
            "2025-06-26 08:28:11,092 EPOCH 5522\n",
            "INFO:__main__:Epoch 5522: total training loss 0.00202\n",
            "2025-06-26 08:28:11,164 Epoch 5522: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5523\n",
            "2025-06-26 08:28:11,166 EPOCH 5523\n",
            "INFO:__main__:Epoch 5523: total training loss 0.00190\n",
            "2025-06-26 08:28:11,245 Epoch 5523: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5524\n",
            "2025-06-26 08:28:11,247 EPOCH 5524\n",
            "INFO:__main__:Epoch 5524: total training loss 0.00212\n",
            "2025-06-26 08:28:11,323 Epoch 5524: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5525\n",
            "2025-06-26 08:28:11,324 EPOCH 5525\n",
            "INFO:__main__:Epoch 5525: total training loss 0.00216\n",
            "2025-06-26 08:28:11,394 Epoch 5525: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5526\n",
            "2025-06-26 08:28:11,396 EPOCH 5526\n",
            "INFO:__main__:Epoch 5526: total training loss 0.00214\n",
            "2025-06-26 08:28:11,470 Epoch 5526: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5527\n",
            "2025-06-26 08:28:11,472 EPOCH 5527\n",
            "INFO:__main__:Epoch 5527: total training loss 0.00224\n",
            "2025-06-26 08:28:11,548 Epoch 5527: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5528\n",
            "2025-06-26 08:28:11,550 EPOCH 5528\n",
            "INFO:__main__:Epoch 5528: total training loss 0.00214\n",
            "2025-06-26 08:28:11,642 Epoch 5528: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5529\n",
            "2025-06-26 08:28:11,644 EPOCH 5529\n",
            "INFO:__main__:Epoch 5529: total training loss 0.00224\n",
            "2025-06-26 08:28:11,709 Epoch 5529: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5530\n",
            "2025-06-26 08:28:11,711 EPOCH 5530\n",
            "INFO:__main__:Epoch 5530: total training loss 0.00221\n",
            "2025-06-26 08:28:11,782 Epoch 5530: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5531\n",
            "2025-06-26 08:28:11,785 EPOCH 5531\n",
            "INFO:__main__:Epoch 5531: total training loss 0.00208\n",
            "2025-06-26 08:28:11,857 Epoch 5531: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5532\n",
            "2025-06-26 08:28:11,859 EPOCH 5532\n",
            "INFO:__main__:Epoch 5532: total training loss 0.00200\n",
            "2025-06-26 08:28:11,933 Epoch 5532: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5533\n",
            "2025-06-26 08:28:11,935 EPOCH 5533\n",
            "INFO:__main__:Epoch 5533: total training loss 0.00205\n",
            "2025-06-26 08:28:12,005 Epoch 5533: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5534\n",
            "2025-06-26 08:28:12,007 EPOCH 5534\n",
            "INFO:__main__:Epoch 5534: total training loss 0.00207\n",
            "2025-06-26 08:28:12,078 Epoch 5534: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5535\n",
            "2025-06-26 08:28:12,081 EPOCH 5535\n",
            "INFO:__main__:Epoch 5535: total training loss 0.00198\n",
            "2025-06-26 08:28:12,154 Epoch 5535: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5536\n",
            "2025-06-26 08:28:12,156 EPOCH 5536\n",
            "INFO:__main__:Epoch 5536: total training loss 0.00222\n",
            "2025-06-26 08:28:12,231 Epoch 5536: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5537\n",
            "2025-06-26 08:28:12,233 EPOCH 5537\n",
            "INFO:__main__:Epoch 5537: total training loss 0.00212\n",
            "2025-06-26 08:28:12,306 Epoch 5537: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5538\n",
            "2025-06-26 08:28:12,309 EPOCH 5538\n",
            "INFO:__main__:Epoch 5538: total training loss 0.00195\n",
            "2025-06-26 08:28:12,378 Epoch 5538: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5539\n",
            "2025-06-26 08:28:12,380 EPOCH 5539\n",
            "INFO:__main__:Epoch 5539: total training loss 0.00215\n",
            "2025-06-26 08:28:12,451 Epoch 5539: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5540\n",
            "2025-06-26 08:28:12,453 EPOCH 5540\n",
            "INFO:__main__:Epoch 5540: total training loss 0.00218\n",
            "2025-06-26 08:28:12,526 Epoch 5540: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5541\n",
            "2025-06-26 08:28:12,529 EPOCH 5541\n",
            "INFO:__main__:Epoch 5541: total training loss 0.00220\n",
            "2025-06-26 08:28:12,604 Epoch 5541: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5542\n",
            "2025-06-26 08:28:12,606 EPOCH 5542\n",
            "INFO:__main__:Epoch 5542: total training loss 0.00223\n",
            "2025-06-26 08:28:12,698 Epoch 5542: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5543\n",
            "2025-06-26 08:28:12,700 EPOCH 5543\n",
            "INFO:__main__:Epoch 5543: total training loss 0.00226\n",
            "2025-06-26 08:28:12,775 Epoch 5543: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5544\n",
            "2025-06-26 08:28:12,777 EPOCH 5544\n",
            "INFO:__main__:Epoch 5544: total training loss 0.00231\n",
            "2025-06-26 08:28:12,849 Epoch 5544: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5545\n",
            "2025-06-26 08:28:12,851 EPOCH 5545\n",
            "INFO:__main__:Epoch 5545: total training loss 0.00239\n",
            "2025-06-26 08:28:12,925 Epoch 5545: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 5546\n",
            "2025-06-26 08:28:12,927 EPOCH 5546\n",
            "INFO:__main__:Epoch 5546: total training loss 0.00242\n",
            "2025-06-26 08:28:12,997 Epoch 5546: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 5547\n",
            "2025-06-26 08:28:12,999 EPOCH 5547\n",
            "INFO:__main__:Epoch 5547: total training loss 0.00255\n",
            "2025-06-26 08:28:13,073 Epoch 5547: total training loss 0.00255\n",
            "INFO:__main__:EPOCH 5548\n",
            "2025-06-26 08:28:13,076 EPOCH 5548\n",
            "INFO:__main__:Epoch 5548: total training loss 0.00229\n",
            "2025-06-26 08:28:13,146 Epoch 5548: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5549\n",
            "2025-06-26 08:28:13,148 EPOCH 5549\n",
            "INFO:__main__:Epoch 5549: total training loss 0.00239\n",
            "2025-06-26 08:28:13,220 Epoch 5549: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 5550\n",
            "2025-06-26 08:28:13,221 EPOCH 5550\n",
            "INFO:__main__:Epoch 5550: total training loss 0.00224\n",
            "2025-06-26 08:28:13,289 Epoch 5550: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5551\n",
            "2025-06-26 08:28:13,291 EPOCH 5551\n",
            "INFO:__main__:Epoch 5551: total training loss 0.00215\n",
            "2025-06-26 08:28:13,363 Epoch 5551: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5552\n",
            "2025-06-26 08:28:13,364 EPOCH 5552\n",
            "INFO:__main__:Epoch 5552: total training loss 0.00228\n",
            "2025-06-26 08:28:13,434 Epoch 5552: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5553\n",
            "2025-06-26 08:28:13,435 EPOCH 5553\n",
            "INFO:__main__:Epoch 5553: total training loss 0.00200\n",
            "2025-06-26 08:28:13,505 Epoch 5553: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5554\n",
            "2025-06-26 08:28:13,507 EPOCH 5554\n",
            "INFO:__main__:Epoch 5554: total training loss 0.00220\n",
            "2025-06-26 08:28:13,577 Epoch 5554: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5555\n",
            "2025-06-26 08:28:13,579 EPOCH 5555\n",
            "INFO:__main__:Epoch 5555: total training loss 0.00206\n",
            "2025-06-26 08:28:13,648 Epoch 5555: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5556\n",
            "2025-06-26 08:28:13,650 EPOCH 5556\n",
            "INFO:__main__:Epoch 5556: total training loss 0.00200\n",
            "2025-06-26 08:28:13,730 Epoch 5556: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5557\n",
            "2025-06-26 08:28:13,732 EPOCH 5557\n",
            "INFO:__main__:Epoch 5557: total training loss 0.00212\n",
            "2025-06-26 08:28:13,805 Epoch 5557: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5558\n",
            "2025-06-26 08:28:13,809 EPOCH 5558\n",
            "INFO:__main__:Epoch 5558: total training loss 0.00176\n",
            "2025-06-26 08:28:13,877 Epoch 5558: total training loss 0.00176\n",
            "INFO:__main__:EPOCH 5559\n",
            "2025-06-26 08:28:13,879 EPOCH 5559\n",
            "INFO:__main__:Epoch 5559: total training loss 0.00205\n",
            "2025-06-26 08:28:13,952 Epoch 5559: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5560\n",
            "2025-06-26 08:28:13,954 EPOCH 5560\n",
            "INFO:__main__:Epoch 5560: total training loss 0.00212\n",
            "2025-06-26 08:28:14,027 Epoch 5560: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5561\n",
            "2025-06-26 08:28:14,029 EPOCH 5561\n",
            "INFO:__main__:Epoch 5561: total training loss 0.00215\n",
            "2025-06-26 08:28:14,099 Epoch 5561: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5562\n",
            "2025-06-26 08:28:14,101 EPOCH 5562\n",
            "INFO:__main__:Epoch 5562: total training loss 0.00196\n",
            "2025-06-26 08:28:14,170 Epoch 5562: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5563\n",
            "2025-06-26 08:28:14,172 EPOCH 5563\n",
            "INFO:__main__:Epoch 5563: total training loss 0.00200\n",
            "2025-06-26 08:28:14,245 Epoch 5563: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5564\n",
            "2025-06-26 08:28:14,247 EPOCH 5564\n",
            "INFO:__main__:Epoch 5564: total training loss 0.00206\n",
            "2025-06-26 08:28:14,315 Epoch 5564: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5565\n",
            "2025-06-26 08:28:14,317 EPOCH 5565\n",
            "INFO:__main__:Epoch 5565: total training loss 0.00191\n",
            "2025-06-26 08:28:14,389 Epoch 5565: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5566\n",
            "2025-06-26 08:28:14,391 EPOCH 5566\n",
            "INFO:__main__:Epoch 5566: total training loss 0.00185\n",
            "2025-06-26 08:28:14,460 Epoch 5566: total training loss 0.00185\n",
            "INFO:__main__:EPOCH 5567\n",
            "2025-06-26 08:28:14,462 EPOCH 5567\n",
            "INFO:__main__:Epoch 5567: total training loss 0.00210\n",
            "2025-06-26 08:28:14,535 Epoch 5567: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5568\n",
            "2025-06-26 08:28:14,537 EPOCH 5568\n",
            "INFO:__main__:Epoch 5568: total training loss 0.00201\n",
            "2025-06-26 08:28:14,608 Epoch 5568: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5569\n",
            "2025-06-26 08:28:14,610 EPOCH 5569\n",
            "INFO:__main__:Epoch 5569: total training loss 0.00197\n",
            "2025-06-26 08:28:14,691 Epoch 5569: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5570\n",
            "2025-06-26 08:28:14,693 EPOCH 5570\n",
            "INFO:__main__:Epoch 5570: total training loss 0.00187\n",
            "2025-06-26 08:28:14,785 Epoch 5570: total training loss 0.00187\n",
            "INFO:__main__:EPOCH 5571\n",
            "2025-06-26 08:28:14,792 EPOCH 5571\n",
            "INFO:__main__:Epoch 5571: total training loss 0.00197\n",
            "2025-06-26 08:28:14,879 Epoch 5571: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5572\n",
            "2025-06-26 08:28:14,881 EPOCH 5572\n",
            "INFO:__main__:Epoch 5572: total training loss 0.00210\n",
            "2025-06-26 08:28:14,977 Epoch 5572: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5573\n",
            "2025-06-26 08:28:14,988 EPOCH 5573\n",
            "INFO:__main__:Epoch 5573: total training loss 0.00198\n",
            "2025-06-26 08:28:15,068 Epoch 5573: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5574\n",
            "2025-06-26 08:28:15,073 EPOCH 5574\n",
            "INFO:__main__:Epoch 5574: total training loss 0.00197\n",
            "2025-06-26 08:28:15,170 Epoch 5574: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5575\n",
            "2025-06-26 08:28:15,172 EPOCH 5575\n",
            "INFO:__main__:Epoch 5575: total training loss 0.00236\n",
            "2025-06-26 08:28:15,266 Epoch 5575: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5576\n",
            "2025-06-26 08:28:15,270 EPOCH 5576\n",
            "INFO:__main__:Epoch 5576: total training loss 0.00228\n",
            "2025-06-26 08:28:15,345 Epoch 5576: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5577\n",
            "2025-06-26 08:28:15,349 EPOCH 5577\n",
            "INFO:__main__:Epoch 5577: total training loss 0.00236\n",
            "2025-06-26 08:28:15,420 Epoch 5577: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5578\n",
            "2025-06-26 08:28:15,427 EPOCH 5578\n",
            "INFO:__main__:Epoch 5578: total training loss 0.00226\n",
            "2025-06-26 08:28:15,520 Epoch 5578: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5579\n",
            "2025-06-26 08:28:15,522 EPOCH 5579\n",
            "INFO:__main__:Epoch 5579: total training loss 0.00221\n",
            "2025-06-26 08:28:15,599 Epoch 5579: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5580\n",
            "2025-06-26 08:28:15,601 EPOCH 5580\n",
            "INFO:__main__:Epoch 5580: total training loss 0.00228\n",
            "2025-06-26 08:28:15,674 Epoch 5580: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5581\n",
            "2025-06-26 08:28:15,680 EPOCH 5581\n",
            "INFO:__main__:Epoch 5581: total training loss 0.00216\n",
            "2025-06-26 08:28:15,758 Epoch 5581: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5582\n",
            "2025-06-26 08:28:15,763 EPOCH 5582\n",
            "INFO:__main__:Epoch 5582: total training loss 0.00234\n",
            "2025-06-26 08:28:15,848 Epoch 5582: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5583\n",
            "2025-06-26 08:28:15,852 EPOCH 5583\n",
            "INFO:__main__:Epoch 5583: total training loss 0.00204\n",
            "2025-06-26 08:28:15,944 Epoch 5583: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5584\n",
            "2025-06-26 08:28:15,946 EPOCH 5584\n",
            "INFO:__main__:Epoch 5584: total training loss 0.00201\n",
            "2025-06-26 08:28:16,023 Epoch 5584: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5585\n",
            "2025-06-26 08:28:16,025 EPOCH 5585\n",
            "INFO:__main__:Epoch 5585: total training loss 0.00209\n",
            "2025-06-26 08:28:16,095 Epoch 5585: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5586\n",
            "2025-06-26 08:28:16,097 EPOCH 5586\n",
            "INFO:__main__:Epoch 5586: total training loss 0.00210\n",
            "2025-06-26 08:28:16,167 Epoch 5586: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5587\n",
            "2025-06-26 08:28:16,169 EPOCH 5587\n",
            "INFO:__main__:Epoch 5587: total training loss 0.00221\n",
            "2025-06-26 08:28:16,246 Epoch 5587: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5588\n",
            "2025-06-26 08:28:16,249 EPOCH 5588\n",
            "INFO:__main__:Epoch 5588: total training loss 0.00222\n",
            "2025-06-26 08:28:16,346 Epoch 5588: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5589\n",
            "2025-06-26 08:28:16,348 EPOCH 5589\n",
            "INFO:__main__:Epoch 5589: total training loss 0.00224\n",
            "2025-06-26 08:28:16,440 Epoch 5589: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5590\n",
            "2025-06-26 08:28:16,446 EPOCH 5590\n",
            "INFO:__main__:Epoch 5590: total training loss 0.00230\n",
            "2025-06-26 08:28:16,550 Epoch 5590: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5591\n",
            "2025-06-26 08:28:16,552 EPOCH 5591\n",
            "INFO:__main__:Epoch 5591: total training loss 0.00227\n",
            "2025-06-26 08:28:16,653 Epoch 5591: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5592\n",
            "2025-06-26 08:28:16,658 EPOCH 5592\n",
            "INFO:__main__:Epoch 5592: total training loss 0.00240\n",
            "2025-06-26 08:28:16,755 Epoch 5592: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5593\n",
            "2025-06-26 08:28:16,757 EPOCH 5593\n",
            "INFO:__main__:Epoch 5593: total training loss 0.00285\n",
            "2025-06-26 08:28:16,851 Epoch 5593: total training loss 0.00285\n",
            "INFO:__main__:EPOCH 5594\n",
            "2025-06-26 08:28:16,854 EPOCH 5594\n",
            "INFO:__main__:Epoch 5594: total training loss 0.00254\n",
            "2025-06-26 08:28:16,932 Epoch 5594: total training loss 0.00254\n",
            "INFO:__main__:EPOCH 5595\n",
            "2025-06-26 08:28:16,935 EPOCH 5595\n",
            "INFO:__main__:Epoch 5595: total training loss 0.00262\n",
            "2025-06-26 08:28:17,028 Epoch 5595: total training loss 0.00262\n",
            "INFO:__main__:EPOCH 5596\n",
            "2025-06-26 08:28:17,030 EPOCH 5596\n",
            "INFO:__main__:Epoch 5596: total training loss 0.00247\n",
            "2025-06-26 08:28:17,142 Epoch 5596: total training loss 0.00247\n",
            "INFO:__main__:EPOCH 5597\n",
            "2025-06-26 08:28:17,144 EPOCH 5597\n",
            "INFO:__main__:Epoch 5597: total training loss 0.00262\n",
            "2025-06-26 08:28:17,234 Epoch 5597: total training loss 0.00262\n",
            "INFO:__main__:EPOCH 5598\n",
            "2025-06-26 08:28:17,236 EPOCH 5598\n",
            "INFO:__main__:Epoch 5598: total training loss 0.00250\n",
            "2025-06-26 08:28:17,310 Epoch 5598: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5599\n",
            "2025-06-26 08:28:17,313 EPOCH 5599\n",
            "INFO:__main__:Epoch 5599: total training loss 0.00251\n",
            "2025-06-26 08:28:17,402 Epoch 5599: total training loss 0.00251\n",
            "INFO:__main__:EPOCH 5600\n",
            "2025-06-26 08:28:17,407 EPOCH 5600\n",
            "INFO:__main__:Epoch 5600: total training loss 0.00272\n",
            "2025-06-26 08:28:17,498 Epoch 5600: total training loss 0.00272\n",
            "INFO:__main__:EPOCH 5601\n",
            "2025-06-26 08:28:17,500 EPOCH 5601\n",
            "INFO:__main__:Epoch 5601: total training loss 0.00239\n",
            "2025-06-26 08:28:17,595 Epoch 5601: total training loss 0.00239\n",
            "INFO:__main__:EPOCH 5602\n",
            "2025-06-26 08:28:17,597 EPOCH 5602\n",
            "INFO:__main__:Epoch 5602: total training loss 0.00242\n",
            "2025-06-26 08:28:17,671 Epoch 5602: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 5603\n",
            "2025-06-26 08:28:17,678 EPOCH 5603\n",
            "INFO:__main__:Epoch 5603: total training loss 0.00221\n",
            "2025-06-26 08:28:17,790 Epoch 5603: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5604\n",
            "2025-06-26 08:28:17,792 EPOCH 5604\n",
            "INFO:__main__:Epoch 5604: total training loss 0.00238\n",
            "2025-06-26 08:28:17,894 Epoch 5604: total training loss 0.00238\n",
            "INFO:__main__:EPOCH 5605\n",
            "2025-06-26 08:28:17,896 EPOCH 5605\n",
            "INFO:__main__:Epoch 5605: total training loss 0.00228\n",
            "2025-06-26 08:28:17,973 Epoch 5605: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5606\n",
            "2025-06-26 08:28:17,975 EPOCH 5606\n",
            "INFO:__main__:Epoch 5606: total training loss 0.00216\n",
            "2025-06-26 08:28:18,057 Epoch 5606: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5607\n",
            "2025-06-26 08:28:18,060 EPOCH 5607\n",
            "INFO:__main__:Epoch 5607: total training loss 0.00219\n",
            "2025-06-26 08:28:18,161 Epoch 5607: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5608\n",
            "2025-06-26 08:28:18,163 EPOCH 5608\n",
            "INFO:__main__:Epoch 5608: total training loss 0.00211\n",
            "2025-06-26 08:28:18,244 Epoch 5608: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5609\n",
            "2025-06-26 08:28:18,246 EPOCH 5609\n",
            "INFO:__main__:Epoch 5609: total training loss 0.00206\n",
            "2025-06-26 08:28:18,321 Epoch 5609: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5610\n",
            "2025-06-26 08:28:18,323 EPOCH 5610\n",
            "INFO:__main__:Epoch 5610: total training loss 0.00206\n",
            "2025-06-26 08:28:18,392 Epoch 5610: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5611\n",
            "2025-06-26 08:28:18,394 EPOCH 5611\n",
            "INFO:__main__:Epoch 5611: total training loss 0.00191\n",
            "2025-06-26 08:28:18,467 Epoch 5611: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5612\n",
            "2025-06-26 08:28:18,473 EPOCH 5612\n",
            "INFO:__main__:Epoch 5612: total training loss 0.00188\n",
            "2025-06-26 08:28:18,558 Epoch 5612: total training loss 0.00188\n",
            "INFO:__main__:EPOCH 5613\n",
            "2025-06-26 08:28:18,560 EPOCH 5613\n",
            "INFO:__main__:Epoch 5613: total training loss 0.00188\n",
            "2025-06-26 08:28:18,629 Epoch 5613: total training loss 0.00188\n",
            "INFO:__main__:EPOCH 5614\n",
            "2025-06-26 08:28:18,631 EPOCH 5614\n",
            "INFO:__main__:Epoch 5614: total training loss 0.00186\n",
            "2025-06-26 08:28:18,701 Epoch 5614: total training loss 0.00186\n",
            "INFO:__main__:EPOCH 5615\n",
            "2025-06-26 08:28:18,703 EPOCH 5615\n",
            "INFO:__main__:Epoch 5615: total training loss 0.00182\n",
            "2025-06-26 08:28:18,773 Epoch 5615: total training loss 0.00182\n",
            "INFO:__main__:EPOCH 5616\n",
            "2025-06-26 08:28:18,775 EPOCH 5616\n",
            "INFO:__main__:Epoch 5616: total training loss 0.00222\n",
            "2025-06-26 08:28:18,851 Epoch 5616: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5617\n",
            "2025-06-26 08:28:18,852 EPOCH 5617\n",
            "INFO:__main__:Epoch 5617: total training loss 0.00204\n",
            "2025-06-26 08:28:18,927 Epoch 5617: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5618\n",
            "2025-06-26 08:28:18,929 EPOCH 5618\n",
            "INFO:__main__:Epoch 5618: total training loss 0.00208\n",
            "2025-06-26 08:28:19,010 Epoch 5618: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5619\n",
            "2025-06-26 08:28:19,013 EPOCH 5619\n",
            "INFO:__main__:Epoch 5619: total training loss 0.00220\n",
            "2025-06-26 08:28:19,109 Epoch 5619: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5620\n",
            "2025-06-26 08:28:19,111 EPOCH 5620\n",
            "INFO:__main__:Epoch 5620: total training loss 0.00203\n",
            "2025-06-26 08:28:19,238 Epoch 5620: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5621\n",
            "2025-06-26 08:28:19,240 EPOCH 5621\n",
            "INFO:__main__:Epoch 5621: total training loss 0.00222\n",
            "2025-06-26 08:28:19,354 Epoch 5621: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5622\n",
            "2025-06-26 08:28:19,358 EPOCH 5622\n",
            "INFO:__main__:Epoch 5622: total training loss 0.00210\n",
            "2025-06-26 08:28:19,459 Epoch 5622: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5623\n",
            "2025-06-26 08:28:19,463 EPOCH 5623\n",
            "INFO:__main__:Epoch 5623: total training loss 0.00211\n",
            "2025-06-26 08:28:19,568 Epoch 5623: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5624\n",
            "2025-06-26 08:28:19,571 EPOCH 5624\n",
            "INFO:__main__:Epoch 5624: total training loss 0.00219\n",
            "2025-06-26 08:28:19,685 Epoch 5624: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5625\n",
            "2025-06-26 08:28:19,687 EPOCH 5625\n",
            "INFO:__main__:Epoch 5625: total training loss 0.00222\n",
            "2025-06-26 08:28:19,809 Epoch 5625: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5626\n",
            "2025-06-26 08:28:19,811 EPOCH 5626\n",
            "INFO:__main__:Epoch 5626: total training loss 0.00222\n",
            "2025-06-26 08:28:19,905 Epoch 5626: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5627\n",
            "2025-06-26 08:28:19,908 EPOCH 5627\n",
            "INFO:__main__:Epoch 5627: total training loss 0.00218\n",
            "2025-06-26 08:28:20,027 Epoch 5627: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5628\n",
            "2025-06-26 08:28:20,033 EPOCH 5628\n",
            "INFO:__main__:Epoch 5628: total training loss 0.00229\n",
            "2025-06-26 08:28:20,132 Epoch 5628: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5629\n",
            "2025-06-26 08:28:20,137 EPOCH 5629\n",
            "INFO:__main__:Epoch 5629: total training loss 0.00229\n",
            "2025-06-26 08:28:20,217 Epoch 5629: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5630\n",
            "2025-06-26 08:28:20,220 EPOCH 5630\n",
            "INFO:__main__:Epoch 5630: total training loss 0.00223\n",
            "2025-06-26 08:28:20,306 Epoch 5630: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5631\n",
            "2025-06-26 08:28:20,308 EPOCH 5631\n",
            "INFO:__main__:Epoch 5631: total training loss 0.00228\n",
            "2025-06-26 08:28:20,379 Epoch 5631: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5632\n",
            "2025-06-26 08:28:20,381 EPOCH 5632\n",
            "INFO:__main__:Epoch 5632: total training loss 0.00217\n",
            "2025-06-26 08:28:20,451 Epoch 5632: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5633\n",
            "2025-06-26 08:28:20,453 EPOCH 5633\n",
            "INFO:__main__:Epoch 5633: total training loss 0.00210\n",
            "2025-06-26 08:28:20,534 Epoch 5633: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5634\n",
            "2025-06-26 08:28:20,535 EPOCH 5634\n",
            "INFO:__main__:Epoch 5634: total training loss 0.00221\n",
            "2025-06-26 08:28:20,609 Epoch 5634: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5635\n",
            "2025-06-26 08:28:20,611 EPOCH 5635\n",
            "INFO:__main__:Epoch 5635: total training loss 0.00222\n",
            "2025-06-26 08:28:20,684 Epoch 5635: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5636\n",
            "2025-06-26 08:28:20,686 EPOCH 5636\n",
            "INFO:__main__:Epoch 5636: total training loss 0.00212\n",
            "2025-06-26 08:28:20,755 Epoch 5636: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5637\n",
            "2025-06-26 08:28:20,759 EPOCH 5637\n",
            "INFO:__main__:Epoch 5637: total training loss 0.00220\n",
            "2025-06-26 08:28:20,831 Epoch 5637: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5638\n",
            "2025-06-26 08:28:20,833 EPOCH 5638\n",
            "INFO:__main__:Epoch 5638: total training loss 0.00212\n",
            "2025-06-26 08:28:20,908 Epoch 5638: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5639\n",
            "2025-06-26 08:28:20,911 EPOCH 5639\n",
            "INFO:__main__:Epoch 5639: total training loss 0.00211\n",
            "2025-06-26 08:28:20,988 Epoch 5639: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5640\n",
            "2025-06-26 08:28:20,990 EPOCH 5640\n",
            "INFO:__main__:Epoch 5640: total training loss 0.00224\n",
            "2025-06-26 08:28:21,060 Epoch 5640: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5641\n",
            "2025-06-26 08:28:21,062 EPOCH 5641\n",
            "INFO:__main__:Epoch 5641: total training loss 0.00192\n",
            "2025-06-26 08:28:21,138 Epoch 5641: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5642\n",
            "2025-06-26 08:28:21,140 EPOCH 5642\n",
            "INFO:__main__:Epoch 5642: total training loss 0.00207\n",
            "2025-06-26 08:28:21,215 Epoch 5642: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5643\n",
            "2025-06-26 08:28:21,217 EPOCH 5643\n",
            "INFO:__main__:Epoch 5643: total training loss 0.00203\n",
            "2025-06-26 08:28:21,299 Epoch 5643: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5644\n",
            "2025-06-26 08:28:21,301 EPOCH 5644\n",
            "INFO:__main__:Epoch 5644: total training loss 0.00197\n",
            "2025-06-26 08:28:21,391 Epoch 5644: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5645\n",
            "2025-06-26 08:28:21,393 EPOCH 5645\n",
            "INFO:__main__:Epoch 5645: total training loss 0.00211\n",
            "2025-06-26 08:28:21,467 Epoch 5645: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5646\n",
            "2025-06-26 08:28:21,469 EPOCH 5646\n",
            "INFO:__main__:Epoch 5646: total training loss 0.00197\n",
            "2025-06-26 08:28:21,549 Epoch 5646: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5647\n",
            "2025-06-26 08:28:21,551 EPOCH 5647\n",
            "INFO:__main__:Epoch 5647: total training loss 0.00196\n",
            "2025-06-26 08:28:21,624 Epoch 5647: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5648\n",
            "2025-06-26 08:28:21,626 EPOCH 5648\n",
            "INFO:__main__:Epoch 5648: total training loss 0.00198\n",
            "2025-06-26 08:28:21,700 Epoch 5648: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5649\n",
            "2025-06-26 08:28:21,703 EPOCH 5649\n",
            "INFO:__main__:Epoch 5649: total training loss 0.00207\n",
            "2025-06-26 08:28:21,777 Epoch 5649: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5650\n",
            "2025-06-26 08:28:21,781 EPOCH 5650\n",
            "INFO:__main__:Epoch 5650: total training loss 0.00205\n",
            "2025-06-26 08:28:21,856 Epoch 5650: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5651\n",
            "2025-06-26 08:28:21,858 EPOCH 5651\n",
            "INFO:__main__:Epoch 5651: total training loss 0.00214\n",
            "2025-06-26 08:28:21,932 Epoch 5651: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5652\n",
            "2025-06-26 08:28:21,934 EPOCH 5652\n",
            "INFO:__main__:Epoch 5652: total training loss 0.00215\n",
            "2025-06-26 08:28:22,005 Epoch 5652: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5653\n",
            "2025-06-26 08:28:22,008 EPOCH 5653\n",
            "INFO:__main__:Epoch 5653: total training loss 0.00212\n",
            "2025-06-26 08:28:22,085 Epoch 5653: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5654\n",
            "2025-06-26 08:28:22,087 EPOCH 5654\n",
            "INFO:__main__:Epoch 5654: total training loss 0.00211\n",
            "2025-06-26 08:28:22,164 Epoch 5654: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5655\n",
            "2025-06-26 08:28:22,166 EPOCH 5655\n",
            "INFO:__main__:Epoch 5655: total training loss 0.00207\n",
            "2025-06-26 08:28:22,240 Epoch 5655: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5656\n",
            "2025-06-26 08:28:22,242 EPOCH 5656\n",
            "INFO:__main__:Epoch 5656: total training loss 0.00220\n",
            "2025-06-26 08:28:22,310 Epoch 5656: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5657\n",
            "2025-06-26 08:28:22,312 EPOCH 5657\n",
            "INFO:__main__:Epoch 5657: total training loss 0.00214\n",
            "2025-06-26 08:28:22,395 Epoch 5657: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5658\n",
            "2025-06-26 08:28:22,402 EPOCH 5658\n",
            "INFO:__main__:Epoch 5658: total training loss 0.00207\n",
            "2025-06-26 08:28:22,482 Epoch 5658: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5659\n",
            "2025-06-26 08:28:22,484 EPOCH 5659\n",
            "INFO:__main__:Epoch 5659: total training loss 0.00219\n",
            "2025-06-26 08:28:22,559 Epoch 5659: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5660\n",
            "2025-06-26 08:28:22,562 EPOCH 5660\n",
            "INFO:__main__:Epoch 5660: total training loss 0.00210\n",
            "2025-06-26 08:28:22,631 Epoch 5660: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5661\n",
            "2025-06-26 08:28:22,633 EPOCH 5661\n",
            "INFO:__main__:Epoch 5661: total training loss 0.00208\n",
            "2025-06-26 08:28:22,706 Epoch 5661: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5662\n",
            "2025-06-26 08:28:22,708 EPOCH 5662\n",
            "INFO:__main__:Epoch 5662: total training loss 0.00207\n",
            "2025-06-26 08:28:22,781 Epoch 5662: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5663\n",
            "2025-06-26 08:28:22,783 EPOCH 5663\n",
            "INFO:__main__:Epoch 5663: total training loss 0.00202\n",
            "2025-06-26 08:28:22,855 Epoch 5663: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5664\n",
            "2025-06-26 08:28:22,857 EPOCH 5664\n",
            "INFO:__main__:Epoch 5664: total training loss 0.00203\n",
            "2025-06-26 08:28:22,930 Epoch 5664: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5665\n",
            "2025-06-26 08:28:22,932 EPOCH 5665\n",
            "INFO:__main__:Epoch 5665: total training loss 0.00207\n",
            "2025-06-26 08:28:23,004 Epoch 5665: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5666\n",
            "2025-06-26 08:28:23,007 EPOCH 5666\n",
            "INFO:__main__:Epoch 5666: total training loss 0.00173\n",
            "2025-06-26 08:28:23,079 Epoch 5666: total training loss 0.00173\n",
            "INFO:__main__:EPOCH 5667\n",
            "2025-06-26 08:28:23,081 EPOCH 5667\n",
            "INFO:__main__:Epoch 5667: total training loss 0.00209\n",
            "2025-06-26 08:28:23,153 Epoch 5667: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5668\n",
            "2025-06-26 08:28:23,155 EPOCH 5668\n",
            "INFO:__main__:Epoch 5668: total training loss 0.00176\n",
            "2025-06-26 08:28:23,228 Epoch 5668: total training loss 0.00176\n",
            "INFO:__main__:EPOCH 5669\n",
            "2025-06-26 08:28:23,230 EPOCH 5669\n",
            "INFO:__main__:Epoch 5669: total training loss 0.00186\n",
            "2025-06-26 08:28:23,305 Epoch 5669: total training loss 0.00186\n",
            "INFO:__main__:EPOCH 5670\n",
            "2025-06-26 08:28:23,307 EPOCH 5670\n",
            "INFO:__main__:Epoch 5670: total training loss 0.00195\n",
            "2025-06-26 08:28:23,378 Epoch 5670: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5671\n",
            "2025-06-26 08:28:23,381 EPOCH 5671\n",
            "INFO:__main__:Epoch 5671: total training loss 0.00184\n",
            "2025-06-26 08:28:23,463 Epoch 5671: total training loss 0.00184\n",
            "INFO:__main__:EPOCH 5672\n",
            "2025-06-26 08:28:23,465 EPOCH 5672\n",
            "INFO:__main__:Epoch 5672: total training loss 0.00193\n",
            "2025-06-26 08:28:23,539 Epoch 5672: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5673\n",
            "2025-06-26 08:28:23,542 EPOCH 5673\n",
            "INFO:__main__:Epoch 5673: total training loss 0.00193\n",
            "2025-06-26 08:28:23,617 Epoch 5673: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5674\n",
            "2025-06-26 08:28:23,618 EPOCH 5674\n",
            "INFO:__main__:Epoch 5674: total training loss 0.00190\n",
            "2025-06-26 08:28:23,691 Epoch 5674: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5675\n",
            "2025-06-26 08:28:23,693 EPOCH 5675\n",
            "INFO:__main__:Epoch 5675: total training loss 0.00215\n",
            "2025-06-26 08:28:23,765 Epoch 5675: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5676\n",
            "2025-06-26 08:28:23,768 EPOCH 5676\n",
            "INFO:__main__:Epoch 5676: total training loss 0.00217\n",
            "2025-06-26 08:28:23,842 Epoch 5676: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5677\n",
            "2025-06-26 08:28:23,844 EPOCH 5677\n",
            "INFO:__main__:Epoch 5677: total training loss 0.00209\n",
            "2025-06-26 08:28:23,916 Epoch 5677: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5678\n",
            "2025-06-26 08:28:23,919 EPOCH 5678\n",
            "INFO:__main__:Epoch 5678: total training loss 0.00197\n",
            "2025-06-26 08:28:23,993 Epoch 5678: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5679\n",
            "2025-06-26 08:28:23,995 EPOCH 5679\n",
            "INFO:__main__:Epoch 5679: total training loss 0.00207\n",
            "2025-06-26 08:28:24,063 Epoch 5679: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5680\n",
            "2025-06-26 08:28:24,065 EPOCH 5680\n",
            "INFO:__main__:Epoch 5680: total training loss 0.00207\n",
            "2025-06-26 08:28:24,140 Epoch 5680: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5681\n",
            "2025-06-26 08:28:24,142 EPOCH 5681\n",
            "INFO:__main__:Epoch 5681: total training loss 0.00221\n",
            "2025-06-26 08:28:24,218 Epoch 5681: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5682\n",
            "2025-06-26 08:28:24,220 EPOCH 5682\n",
            "INFO:__main__:Epoch 5682: total training loss 0.00226\n",
            "2025-06-26 08:28:24,300 Epoch 5682: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5683\n",
            "2025-06-26 08:28:24,302 EPOCH 5683\n",
            "INFO:__main__:Epoch 5683: total training loss 0.00216\n",
            "2025-06-26 08:28:24,388 Epoch 5683: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5684\n",
            "2025-06-26 08:28:24,391 EPOCH 5684\n",
            "INFO:__main__:Epoch 5684: total training loss 0.00231\n",
            "2025-06-26 08:28:24,480 Epoch 5684: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5685\n",
            "2025-06-26 08:28:24,483 EPOCH 5685\n",
            "INFO:__main__:Epoch 5685: total training loss 0.00233\n",
            "2025-06-26 08:28:24,571 Epoch 5685: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5686\n",
            "2025-06-26 08:28:24,573 EPOCH 5686\n",
            "INFO:__main__:Epoch 5686: total training loss 0.00218\n",
            "2025-06-26 08:28:24,645 Epoch 5686: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5687\n",
            "2025-06-26 08:28:24,647 EPOCH 5687\n",
            "INFO:__main__:Epoch 5687: total training loss 0.00200\n",
            "2025-06-26 08:28:24,723 Epoch 5687: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5688\n",
            "2025-06-26 08:28:24,725 EPOCH 5688\n",
            "INFO:__main__:Epoch 5688: total training loss 0.00225\n",
            "2025-06-26 08:28:24,794 Epoch 5688: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5689\n",
            "2025-06-26 08:28:24,796 EPOCH 5689\n",
            "INFO:__main__:Epoch 5689: total training loss 0.00207\n",
            "2025-06-26 08:28:24,867 Epoch 5689: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5690\n",
            "2025-06-26 08:28:24,870 EPOCH 5690\n",
            "INFO:__main__:Epoch 5690: total training loss 0.00217\n",
            "2025-06-26 08:28:24,947 Epoch 5690: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5691\n",
            "2025-06-26 08:28:24,952 EPOCH 5691\n",
            "INFO:__main__:Epoch 5691: total training loss 0.00213\n",
            "2025-06-26 08:28:25,031 Epoch 5691: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5692\n",
            "2025-06-26 08:28:25,035 EPOCH 5692\n",
            "INFO:__main__:Epoch 5692: total training loss 0.00209\n",
            "2025-06-26 08:28:25,107 Epoch 5692: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5693\n",
            "2025-06-26 08:28:25,109 EPOCH 5693\n",
            "INFO:__main__:Epoch 5693: total training loss 0.00198\n",
            "2025-06-26 08:28:25,183 Epoch 5693: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5694\n",
            "2025-06-26 08:28:25,186 EPOCH 5694\n",
            "INFO:__main__:Epoch 5694: total training loss 0.00200\n",
            "2025-06-26 08:28:25,256 Epoch 5694: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5695\n",
            "2025-06-26 08:28:25,258 EPOCH 5695\n",
            "INFO:__main__:Epoch 5695: total training loss 0.00188\n",
            "2025-06-26 08:28:25,332 Epoch 5695: total training loss 0.00188\n",
            "INFO:__main__:EPOCH 5696\n",
            "2025-06-26 08:28:25,334 EPOCH 5696\n",
            "INFO:__main__:Epoch 5696: total training loss 0.00194\n",
            "2025-06-26 08:28:25,405 Epoch 5696: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5697\n",
            "2025-06-26 08:28:25,407 EPOCH 5697\n",
            "INFO:__main__:Epoch 5697: total training loss 0.00201\n",
            "2025-06-26 08:28:25,477 Epoch 5697: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5698\n",
            "2025-06-26 08:28:25,479 EPOCH 5698\n",
            "INFO:__main__:Epoch 5698: total training loss 0.00198\n",
            "2025-06-26 08:28:25,558 Epoch 5698: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5699\n",
            "2025-06-26 08:28:25,560 EPOCH 5699\n",
            "INFO:__main__:Epoch 5699: total training loss 0.00205\n",
            "2025-06-26 08:28:25,640 Epoch 5699: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5700\n",
            "2025-06-26 08:28:25,642 EPOCH 5700\n",
            "INFO:__main__:Epoch 5700: total training loss 0.00194\n",
            "2025-06-26 08:28:25,713 Epoch 5700: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5701\n",
            "2025-06-26 08:28:25,715 EPOCH 5701\n",
            "INFO:__main__:Epoch 5701: total training loss 0.00215\n",
            "2025-06-26 08:28:25,786 Epoch 5701: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5702\n",
            "2025-06-26 08:28:25,789 EPOCH 5702\n",
            "INFO:__main__:Epoch 5702: total training loss 0.00211\n",
            "2025-06-26 08:28:25,860 Epoch 5702: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5703\n",
            "2025-06-26 08:28:25,862 EPOCH 5703\n",
            "INFO:__main__:Epoch 5703: total training loss 0.00213\n",
            "2025-06-26 08:28:25,933 Epoch 5703: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5704\n",
            "2025-06-26 08:28:25,935 EPOCH 5704\n",
            "INFO:__main__:Epoch 5704: total training loss 0.00203\n",
            "2025-06-26 08:28:26,015 Epoch 5704: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5705\n",
            "2025-06-26 08:28:26,018 EPOCH 5705\n",
            "INFO:__main__:Epoch 5705: total training loss 0.00229\n",
            "2025-06-26 08:28:26,089 Epoch 5705: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5706\n",
            "2025-06-26 08:28:26,092 EPOCH 5706\n",
            "INFO:__main__:Epoch 5706: total training loss 0.00225\n",
            "2025-06-26 08:28:26,170 Epoch 5706: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5707\n",
            "2025-06-26 08:28:26,173 EPOCH 5707\n",
            "INFO:__main__:Epoch 5707: total training loss 0.00213\n",
            "2025-06-26 08:28:26,252 Epoch 5707: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5708\n",
            "2025-06-26 08:28:26,254 EPOCH 5708\n",
            "INFO:__main__:Epoch 5708: total training loss 0.00212\n",
            "2025-06-26 08:28:26,328 Epoch 5708: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5709\n",
            "2025-06-26 08:28:26,331 EPOCH 5709\n",
            "INFO:__main__:Epoch 5709: total training loss 0.00214\n",
            "2025-06-26 08:28:26,402 Epoch 5709: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5710\n",
            "2025-06-26 08:28:26,404 EPOCH 5710\n",
            "INFO:__main__:Epoch 5710: total training loss 0.00206\n",
            "2025-06-26 08:28:26,478 Epoch 5710: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5711\n",
            "2025-06-26 08:28:26,480 EPOCH 5711\n",
            "INFO:__main__:Epoch 5711: total training loss 0.00228\n",
            "2025-06-26 08:28:26,555 Epoch 5711: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5712\n",
            "2025-06-26 08:28:26,557 EPOCH 5712\n",
            "INFO:__main__:Epoch 5712: total training loss 0.00196\n",
            "2025-06-26 08:28:26,642 Epoch 5712: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5713\n",
            "2025-06-26 08:28:26,644 EPOCH 5713\n",
            "INFO:__main__:Epoch 5713: total training loss 0.00214\n",
            "2025-06-26 08:28:26,723 Epoch 5713: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5714\n",
            "2025-06-26 08:28:26,725 EPOCH 5714\n",
            "INFO:__main__:Epoch 5714: total training loss 0.00197\n",
            "2025-06-26 08:28:26,795 Epoch 5714: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5715\n",
            "2025-06-26 08:28:26,797 EPOCH 5715\n",
            "INFO:__main__:Epoch 5715: total training loss 0.00196\n",
            "2025-06-26 08:28:26,871 Epoch 5715: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5716\n",
            "2025-06-26 08:28:26,873 EPOCH 5716\n",
            "INFO:__main__:Epoch 5716: total training loss 0.00196\n",
            "2025-06-26 08:28:26,945 Epoch 5716: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5717\n",
            "2025-06-26 08:28:26,947 EPOCH 5717\n",
            "INFO:__main__:Epoch 5717: total training loss 0.00203\n",
            "2025-06-26 08:28:27,019 Epoch 5717: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5718\n",
            "2025-06-26 08:28:27,021 EPOCH 5718\n",
            "INFO:__main__:Epoch 5718: total training loss 0.00216\n",
            "2025-06-26 08:28:27,098 Epoch 5718: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5719\n",
            "2025-06-26 08:28:27,100 EPOCH 5719\n",
            "INFO:__main__:Epoch 5719: total training loss 0.00203\n",
            "2025-06-26 08:28:27,170 Epoch 5719: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5720\n",
            "2025-06-26 08:28:27,172 EPOCH 5720\n",
            "INFO:__main__:Epoch 5720: total training loss 0.00212\n",
            "2025-06-26 08:28:27,244 Epoch 5720: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5721\n",
            "2025-06-26 08:28:27,246 EPOCH 5721\n",
            "INFO:__main__:Epoch 5721: total training loss 0.00177\n",
            "2025-06-26 08:28:27,314 Epoch 5721: total training loss 0.00177\n",
            "INFO:__main__:EPOCH 5722\n",
            "2025-06-26 08:28:27,316 EPOCH 5722\n",
            "INFO:__main__:Epoch 5722: total training loss 0.00229\n",
            "2025-06-26 08:28:27,385 Epoch 5722: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5723\n",
            "2025-06-26 08:28:27,387 EPOCH 5723\n",
            "INFO:__main__:Epoch 5723: total training loss 0.00220\n",
            "2025-06-26 08:28:27,460 Epoch 5723: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5724\n",
            "2025-06-26 08:28:27,463 EPOCH 5724\n",
            "INFO:__main__:Epoch 5724: total training loss 0.00211\n",
            "2025-06-26 08:28:27,536 Epoch 5724: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5725\n",
            "2025-06-26 08:28:27,538 EPOCH 5725\n",
            "INFO:__main__:Epoch 5725: total training loss 0.00227\n",
            "2025-06-26 08:28:27,608 Epoch 5725: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5726\n",
            "2025-06-26 08:28:27,610 EPOCH 5726\n",
            "INFO:__main__:Epoch 5726: total training loss 0.00218\n",
            "2025-06-26 08:28:27,692 Epoch 5726: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5727\n",
            "2025-06-26 08:28:27,694 EPOCH 5727\n",
            "INFO:__main__:Epoch 5727: total training loss 0.00225\n",
            "2025-06-26 08:28:27,766 Epoch 5727: total training loss 0.00225\n",
            "INFO:__main__:EPOCH 5728\n",
            "2025-06-26 08:28:27,768 EPOCH 5728\n",
            "INFO:__main__:Epoch 5728: total training loss 0.00214\n",
            "2025-06-26 08:28:27,838 Epoch 5728: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5729\n",
            "2025-06-26 08:28:27,840 EPOCH 5729\n",
            "INFO:__main__:Epoch 5729: total training loss 0.00234\n",
            "2025-06-26 08:28:27,911 Epoch 5729: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5730\n",
            "2025-06-26 08:28:27,913 EPOCH 5730\n",
            "INFO:__main__:Epoch 5730: total training loss 0.00211\n",
            "2025-06-26 08:28:27,983 Epoch 5730: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5731\n",
            "2025-06-26 08:28:27,986 EPOCH 5731\n",
            "INFO:__main__:Epoch 5731: total training loss 0.00228\n",
            "2025-06-26 08:28:28,057 Epoch 5731: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5732\n",
            "2025-06-26 08:28:28,059 EPOCH 5732\n",
            "INFO:__main__:Epoch 5732: total training loss 0.00203\n",
            "2025-06-26 08:28:28,128 Epoch 5732: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5733\n",
            "2025-06-26 08:28:28,130 EPOCH 5733\n",
            "INFO:__main__:Epoch 5733: total training loss 0.00212\n",
            "2025-06-26 08:28:28,203 Epoch 5733: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5734\n",
            "2025-06-26 08:28:28,205 EPOCH 5734\n",
            "INFO:__main__:Epoch 5734: total training loss 0.00196\n",
            "2025-06-26 08:28:28,275 Epoch 5734: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5735\n",
            "2025-06-26 08:28:28,277 EPOCH 5735\n",
            "INFO:__main__:Epoch 5735: total training loss 0.00202\n",
            "2025-06-26 08:28:28,352 Epoch 5735: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5736\n",
            "2025-06-26 08:28:28,354 EPOCH 5736\n",
            "INFO:__main__:Epoch 5736: total training loss 0.00199\n",
            "2025-06-26 08:28:28,422 Epoch 5736: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5737\n",
            "2025-06-26 08:28:28,424 EPOCH 5737\n",
            "INFO:__main__:Epoch 5737: total training loss 0.00191\n",
            "2025-06-26 08:28:28,495 Epoch 5737: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5738\n",
            "2025-06-26 08:28:28,497 EPOCH 5738\n",
            "INFO:__main__:Epoch 5738: total training loss 0.00211\n",
            "2025-06-26 08:28:28,570 Epoch 5738: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5739\n",
            "2025-06-26 08:28:28,572 EPOCH 5739\n",
            "INFO:__main__:Epoch 5739: total training loss 0.00190\n",
            "2025-06-26 08:28:28,646 Epoch 5739: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5740\n",
            "2025-06-26 08:28:28,647 EPOCH 5740\n",
            "INFO:__main__:Epoch 5740: total training loss 0.00209\n",
            "2025-06-26 08:28:28,738 Epoch 5740: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5741\n",
            "2025-06-26 08:28:28,741 EPOCH 5741\n",
            "INFO:__main__:Epoch 5741: total training loss 0.00209\n",
            "2025-06-26 08:28:28,812 Epoch 5741: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5742\n",
            "2025-06-26 08:28:28,814 EPOCH 5742\n",
            "INFO:__main__:Epoch 5742: total training loss 0.00202\n",
            "2025-06-26 08:28:28,884 Epoch 5742: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5743\n",
            "2025-06-26 08:28:28,887 EPOCH 5743\n",
            "INFO:__main__:Epoch 5743: total training loss 0.00223\n",
            "2025-06-26 08:28:28,959 Epoch 5743: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5744\n",
            "2025-06-26 08:28:28,961 EPOCH 5744\n",
            "INFO:__main__:Epoch 5744: total training loss 0.00200\n",
            "2025-06-26 08:28:29,033 Epoch 5744: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5745\n",
            "2025-06-26 08:28:29,035 EPOCH 5745\n",
            "INFO:__main__:Epoch 5745: total training loss 0.00174\n",
            "2025-06-26 08:28:29,105 Epoch 5745: total training loss 0.00174\n",
            "INFO:__main__:EPOCH 5746\n",
            "2025-06-26 08:28:29,107 EPOCH 5746\n",
            "INFO:__main__:Epoch 5746: total training loss 0.00198\n",
            "2025-06-26 08:28:29,175 Epoch 5746: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5747\n",
            "2025-06-26 08:28:29,177 EPOCH 5747\n",
            "INFO:__main__:Epoch 5747: total training loss 0.00204\n",
            "2025-06-26 08:28:29,252 Epoch 5747: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5748\n",
            "2025-06-26 08:28:29,254 EPOCH 5748\n",
            "INFO:__main__:Epoch 5748: total training loss 0.00200\n",
            "2025-06-26 08:28:29,323 Epoch 5748: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5749\n",
            "2025-06-26 08:28:29,326 EPOCH 5749\n",
            "INFO:__main__:Epoch 5749: total training loss 0.00188\n",
            "2025-06-26 08:28:29,396 Epoch 5749: total training loss 0.00188\n",
            "INFO:__main__:EPOCH 5750\n",
            "2025-06-26 08:28:29,397 EPOCH 5750\n",
            "INFO:__main__:Epoch 5750 Step:     5750 Batch Loss:     0.002071 Tokens per Sec:  2117604, Lr: 0.001000\n",
            "2025-06-26 08:28:29,466 Epoch 5750 Step:     5750 Batch Loss:     0.002071 Tokens per Sec:  2117604, Lr: 0.001000\n",
            "INFO:__main__:Epoch 5750: total training loss 0.00207\n",
            "2025-06-26 08:28:29,468 Epoch 5750: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5751\n",
            "2025-06-26 08:28:29,471 EPOCH 5751\n",
            "INFO:__main__:Epoch 5751: total training loss 0.00195\n",
            "2025-06-26 08:28:29,543 Epoch 5751: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5752\n",
            "2025-06-26 08:28:29,545 EPOCH 5752\n",
            "INFO:__main__:Epoch 5752: total training loss 0.00214\n",
            "2025-06-26 08:28:29,620 Epoch 5752: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5753\n",
            "2025-06-26 08:28:29,622 EPOCH 5753\n",
            "INFO:__main__:Epoch 5753: total training loss 0.00206\n",
            "2025-06-26 08:28:29,693 Epoch 5753: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5754\n",
            "2025-06-26 08:28:29,695 EPOCH 5754\n",
            "INFO:__main__:Epoch 5754: total training loss 0.00206\n",
            "2025-06-26 08:28:29,778 Epoch 5754: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5755\n",
            "2025-06-26 08:28:29,781 EPOCH 5755\n",
            "INFO:__main__:Epoch 5755: total training loss 0.00199\n",
            "2025-06-26 08:28:29,852 Epoch 5755: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5756\n",
            "2025-06-26 08:28:29,854 EPOCH 5756\n",
            "INFO:__main__:Epoch 5756: total training loss 0.00195\n",
            "2025-06-26 08:28:29,929 Epoch 5756: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5757\n",
            "2025-06-26 08:28:29,933 EPOCH 5757\n",
            "INFO:__main__:Epoch 5757: total training loss 0.00223\n",
            "2025-06-26 08:28:30,003 Epoch 5757: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5758\n",
            "2025-06-26 08:28:30,005 EPOCH 5758\n",
            "INFO:__main__:Epoch 5758: total training loss 0.00194\n",
            "2025-06-26 08:28:30,078 Epoch 5758: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5759\n",
            "2025-06-26 08:28:30,080 EPOCH 5759\n",
            "INFO:__main__:Epoch 5759: total training loss 0.00209\n",
            "2025-06-26 08:28:30,152 Epoch 5759: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5760\n",
            "2025-06-26 08:28:30,156 EPOCH 5760\n",
            "INFO:__main__:Epoch 5760: total training loss 0.00203\n",
            "2025-06-26 08:28:30,239 Epoch 5760: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5761\n",
            "2025-06-26 08:28:30,241 EPOCH 5761\n",
            "INFO:__main__:Epoch 5761: total training loss 0.00211\n",
            "2025-06-26 08:28:30,322 Epoch 5761: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5762\n",
            "2025-06-26 08:28:30,324 EPOCH 5762\n",
            "INFO:__main__:Epoch 5762: total training loss 0.00214\n",
            "2025-06-26 08:28:30,420 Epoch 5762: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5763\n",
            "2025-06-26 08:28:30,424 EPOCH 5763\n",
            "INFO:__main__:Epoch 5763: total training loss 0.00230\n",
            "2025-06-26 08:28:30,522 Epoch 5763: total training loss 0.00230\n",
            "INFO:__main__:EPOCH 5764\n",
            "2025-06-26 08:28:30,524 EPOCH 5764\n",
            "INFO:__main__:Epoch 5764: total training loss 0.00218\n",
            "2025-06-26 08:28:30,623 Epoch 5764: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5765\n",
            "2025-06-26 08:28:30,625 EPOCH 5765\n",
            "INFO:__main__:Epoch 5765: total training loss 0.00221\n",
            "2025-06-26 08:28:30,717 Epoch 5765: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5766\n",
            "2025-06-26 08:28:30,720 EPOCH 5766\n",
            "INFO:__main__:Epoch 5766: total training loss 0.00218\n",
            "2025-06-26 08:28:30,797 Epoch 5766: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5767\n",
            "2025-06-26 08:28:30,799 EPOCH 5767\n",
            "INFO:__main__:Epoch 5767: total training loss 0.00215\n",
            "2025-06-26 08:28:30,894 Epoch 5767: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5768\n",
            "2025-06-26 08:28:30,896 EPOCH 5768\n",
            "INFO:__main__:Epoch 5768: total training loss 0.00211\n",
            "2025-06-26 08:28:30,968 Epoch 5768: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5769\n",
            "2025-06-26 08:28:30,970 EPOCH 5769\n",
            "INFO:__main__:Epoch 5769: total training loss 0.00214\n",
            "2025-06-26 08:28:31,041 Epoch 5769: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5770\n",
            "2025-06-26 08:28:31,043 EPOCH 5770\n",
            "INFO:__main__:Epoch 5770: total training loss 0.00208\n",
            "2025-06-26 08:28:31,114 Epoch 5770: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5771\n",
            "2025-06-26 08:28:31,116 EPOCH 5771\n",
            "INFO:__main__:Epoch 5771: total training loss 0.00202\n",
            "2025-06-26 08:28:31,204 Epoch 5771: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5772\n",
            "2025-06-26 08:28:31,206 EPOCH 5772\n",
            "INFO:__main__:Epoch 5772: total training loss 0.00216\n",
            "2025-06-26 08:28:31,284 Epoch 5772: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5773\n",
            "2025-06-26 08:28:31,286 EPOCH 5773\n",
            "INFO:__main__:Epoch 5773: total training loss 0.00219\n",
            "2025-06-26 08:28:31,372 Epoch 5773: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5774\n",
            "2025-06-26 08:28:31,374 EPOCH 5774\n",
            "INFO:__main__:Epoch 5774: total training loss 0.00197\n",
            "2025-06-26 08:28:31,459 Epoch 5774: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5775\n",
            "2025-06-26 08:28:31,461 EPOCH 5775\n",
            "INFO:__main__:Epoch 5775: total training loss 0.00213\n",
            "2025-06-26 08:28:31,555 Epoch 5775: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5776\n",
            "2025-06-26 08:28:31,560 EPOCH 5776\n",
            "INFO:__main__:Epoch 5776: total training loss 0.00191\n",
            "2025-06-26 08:28:31,666 Epoch 5776: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5777\n",
            "2025-06-26 08:28:31,668 EPOCH 5777\n",
            "INFO:__main__:Epoch 5777: total training loss 0.00219\n",
            "2025-06-26 08:28:31,785 Epoch 5777: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5778\n",
            "2025-06-26 08:28:31,789 EPOCH 5778\n",
            "INFO:__main__:Epoch 5778: total training loss 0.00207\n",
            "2025-06-26 08:28:31,877 Epoch 5778: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5779\n",
            "2025-06-26 08:28:31,879 EPOCH 5779\n",
            "INFO:__main__:Epoch 5779: total training loss 0.00221\n",
            "2025-06-26 08:28:31,973 Epoch 5779: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5780\n",
            "2025-06-26 08:28:31,977 EPOCH 5780\n",
            "INFO:__main__:Epoch 5780: total training loss 0.00205\n",
            "2025-06-26 08:28:32,063 Epoch 5780: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5781\n",
            "2025-06-26 08:28:32,065 EPOCH 5781\n",
            "INFO:__main__:Epoch 5781: total training loss 0.00219\n",
            "2025-06-26 08:28:32,156 Epoch 5781: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5782\n",
            "2025-06-26 08:28:32,159 EPOCH 5782\n",
            "INFO:__main__:Epoch 5782: total training loss 0.00222\n",
            "2025-06-26 08:28:32,259 Epoch 5782: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5783\n",
            "2025-06-26 08:28:32,261 EPOCH 5783\n",
            "INFO:__main__:Epoch 5783: total training loss 0.00220\n",
            "2025-06-26 08:28:32,347 Epoch 5783: total training loss 0.00220\n",
            "INFO:__main__:EPOCH 5784\n",
            "2025-06-26 08:28:32,352 EPOCH 5784\n",
            "INFO:__main__:Epoch 5784: total training loss 0.00231\n",
            "2025-06-26 08:28:32,445 Epoch 5784: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5785\n",
            "2025-06-26 08:28:32,449 EPOCH 5785\n",
            "INFO:__main__:Epoch 5785: total training loss 0.00210\n",
            "2025-06-26 08:28:32,524 Epoch 5785: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5786\n",
            "2025-06-26 08:28:32,530 EPOCH 5786\n",
            "INFO:__main__:Epoch 5786: total training loss 0.00224\n",
            "2025-06-26 08:28:32,619 Epoch 5786: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5787\n",
            "2025-06-26 08:28:32,620 EPOCH 5787\n",
            "INFO:__main__:Epoch 5787: total training loss 0.00218\n",
            "2025-06-26 08:28:32,723 Epoch 5787: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5788\n",
            "2025-06-26 08:28:32,725 EPOCH 5788\n",
            "INFO:__main__:Epoch 5788: total training loss 0.00210\n",
            "2025-06-26 08:28:32,833 Epoch 5788: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5789\n",
            "2025-06-26 08:28:32,834 EPOCH 5789\n",
            "INFO:__main__:Epoch 5789: total training loss 0.00218\n",
            "2025-06-26 08:28:32,908 Epoch 5789: total training loss 0.00218\n",
            "INFO:__main__:EPOCH 5790\n",
            "2025-06-26 08:28:32,913 EPOCH 5790\n",
            "INFO:__main__:Epoch 5790: total training loss 0.00256\n",
            "2025-06-26 08:28:33,010 Epoch 5790: total training loss 0.00256\n",
            "INFO:__main__:EPOCH 5791\n",
            "2025-06-26 08:28:33,012 EPOCH 5791\n",
            "INFO:__main__:Epoch 5791: total training loss 0.00222\n",
            "2025-06-26 08:28:33,091 Epoch 5791: total training loss 0.00222\n",
            "INFO:__main__:EPOCH 5792\n",
            "2025-06-26 08:28:33,097 EPOCH 5792\n",
            "INFO:__main__:Epoch 5792: total training loss 0.00227\n",
            "2025-06-26 08:28:33,207 Epoch 5792: total training loss 0.00227\n",
            "INFO:__main__:EPOCH 5793\n",
            "2025-06-26 08:28:33,209 EPOCH 5793\n",
            "INFO:__main__:Epoch 5793: total training loss 0.00212\n",
            "2025-06-26 08:28:33,319 Epoch 5793: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5794\n",
            "2025-06-26 08:28:33,322 EPOCH 5794\n",
            "INFO:__main__:Epoch 5794: total training loss 0.00214\n",
            "2025-06-26 08:28:33,431 Epoch 5794: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5795\n",
            "2025-06-26 08:28:33,433 EPOCH 5795\n",
            "INFO:__main__:Epoch 5795: total training loss 0.00204\n",
            "2025-06-26 08:28:33,528 Epoch 5795: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5796\n",
            "2025-06-26 08:28:33,534 EPOCH 5796\n",
            "INFO:__main__:Epoch 5796: total training loss 0.00209\n",
            "2025-06-26 08:28:33,636 Epoch 5796: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5797\n",
            "2025-06-26 08:28:33,640 EPOCH 5797\n",
            "INFO:__main__:Epoch 5797: total training loss 0.00199\n",
            "2025-06-26 08:28:33,745 Epoch 5797: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5798\n",
            "2025-06-26 08:28:33,749 EPOCH 5798\n",
            "INFO:__main__:Epoch 5798: total training loss 0.00201\n",
            "2025-06-26 08:28:33,822 Epoch 5798: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5799\n",
            "2025-06-26 08:28:33,829 EPOCH 5799\n",
            "INFO:__main__:Epoch 5799: total training loss 0.00203\n",
            "2025-06-26 08:28:33,940 Epoch 5799: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5800\n",
            "2025-06-26 08:28:33,941 EPOCH 5800\n",
            "INFO:__main__:Epoch 5800: total training loss 0.00196\n",
            "2025-06-26 08:28:34,047 Epoch 5800: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5801\n",
            "2025-06-26 08:28:34,050 EPOCH 5801\n",
            "INFO:__main__:Epoch 5801: total training loss 0.00193\n",
            "2025-06-26 08:28:34,173 Epoch 5801: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5802\n",
            "2025-06-26 08:28:34,177 EPOCH 5802\n",
            "INFO:__main__:Epoch 5802: total training loss 0.00201\n",
            "2025-06-26 08:28:34,278 Epoch 5802: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5803\n",
            "2025-06-26 08:28:34,284 EPOCH 5803\n",
            "INFO:__main__:Epoch 5803: total training loss 0.00191\n",
            "2025-06-26 08:28:34,387 Epoch 5803: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5804\n",
            "2025-06-26 08:28:34,389 EPOCH 5804\n",
            "INFO:__main__:Epoch 5804: total training loss 0.00183\n",
            "2025-06-26 08:28:34,474 Epoch 5804: total training loss 0.00183\n",
            "INFO:__main__:EPOCH 5805\n",
            "2025-06-26 08:28:34,480 EPOCH 5805\n",
            "INFO:__main__:Epoch 5805: total training loss 0.00207\n",
            "2025-06-26 08:28:34,589 Epoch 5805: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5806\n",
            "2025-06-26 08:28:34,591 EPOCH 5806\n",
            "INFO:__main__:Epoch 5806: total training loss 0.00206\n",
            "2025-06-26 08:28:34,719 Epoch 5806: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5807\n",
            "2025-06-26 08:28:34,722 EPOCH 5807\n",
            "INFO:__main__:Epoch 5807: total training loss 0.00209\n",
            "2025-06-26 08:28:34,832 Epoch 5807: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5808\n",
            "2025-06-26 08:28:34,833 EPOCH 5808\n",
            "INFO:__main__:Epoch 5808: total training loss 0.00194\n",
            "2025-06-26 08:28:34,945 Epoch 5808: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5809\n",
            "2025-06-26 08:28:34,949 EPOCH 5809\n",
            "INFO:__main__:Epoch 5809: total training loss 0.00204\n",
            "2025-06-26 08:28:35,044 Epoch 5809: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5810\n",
            "2025-06-26 08:28:35,046 EPOCH 5810\n",
            "INFO:__main__:Epoch 5810: total training loss 0.00214\n",
            "2025-06-26 08:28:35,177 Epoch 5810: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5811\n",
            "2025-06-26 08:28:35,180 EPOCH 5811\n",
            "INFO:__main__:Epoch 5811: total training loss 0.00207\n",
            "2025-06-26 08:28:35,278 Epoch 5811: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5812\n",
            "2025-06-26 08:28:35,285 EPOCH 5812\n",
            "INFO:__main__:Epoch 5812: total training loss 0.00207\n",
            "2025-06-26 08:28:35,405 Epoch 5812: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5813\n",
            "2025-06-26 08:28:35,408 EPOCH 5813\n",
            "INFO:__main__:Epoch 5813: total training loss 0.00216\n",
            "2025-06-26 08:28:35,488 Epoch 5813: total training loss 0.00216\n",
            "INFO:__main__:EPOCH 5814\n",
            "2025-06-26 08:28:35,490 EPOCH 5814\n",
            "INFO:__main__:Epoch 5814: total training loss 0.00198\n",
            "2025-06-26 08:28:35,570 Epoch 5814: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5815\n",
            "2025-06-26 08:28:35,572 EPOCH 5815\n",
            "INFO:__main__:Epoch 5815: total training loss 0.00217\n",
            "2025-06-26 08:28:35,651 Epoch 5815: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5816\n",
            "2025-06-26 08:28:35,653 EPOCH 5816\n",
            "INFO:__main__:Epoch 5816: total training loss 0.00232\n",
            "2025-06-26 08:28:35,727 Epoch 5816: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5817\n",
            "2025-06-26 08:28:35,729 EPOCH 5817\n",
            "INFO:__main__:Epoch 5817: total training loss 0.00191\n",
            "2025-06-26 08:28:35,807 Epoch 5817: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5818\n",
            "2025-06-26 08:28:35,810 EPOCH 5818\n",
            "INFO:__main__:Epoch 5818: total training loss 0.00209\n",
            "2025-06-26 08:28:35,884 Epoch 5818: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5819\n",
            "2025-06-26 08:28:35,885 EPOCH 5819\n",
            "INFO:__main__:Epoch 5819: total training loss 0.00232\n",
            "2025-06-26 08:28:35,958 Epoch 5819: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5820\n",
            "2025-06-26 08:28:35,960 EPOCH 5820\n",
            "INFO:__main__:Epoch 5820: total training loss 0.00194\n",
            "2025-06-26 08:28:36,036 Epoch 5820: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5821\n",
            "2025-06-26 08:28:36,038 EPOCH 5821\n",
            "INFO:__main__:Epoch 5821: total training loss 0.00221\n",
            "2025-06-26 08:28:36,109 Epoch 5821: total training loss 0.00221\n",
            "INFO:__main__:EPOCH 5822\n",
            "2025-06-26 08:28:36,111 EPOCH 5822\n",
            "INFO:__main__:Epoch 5822: total training loss 0.00210\n",
            "2025-06-26 08:28:36,182 Epoch 5822: total training loss 0.00210\n",
            "INFO:__main__:EPOCH 5823\n",
            "2025-06-26 08:28:36,186 EPOCH 5823\n",
            "INFO:__main__:Epoch 5823: total training loss 0.00223\n",
            "2025-06-26 08:28:36,277 Epoch 5823: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5824\n",
            "2025-06-26 08:28:36,279 EPOCH 5824\n",
            "INFO:__main__:Epoch 5824: total training loss 0.00223\n",
            "2025-06-26 08:28:36,352 Epoch 5824: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5825\n",
            "2025-06-26 08:28:36,353 EPOCH 5825\n",
            "INFO:__main__:Epoch 5825: total training loss 0.00235\n",
            "2025-06-26 08:28:36,428 Epoch 5825: total training loss 0.00235\n",
            "INFO:__main__:EPOCH 5826\n",
            "2025-06-26 08:28:36,430 EPOCH 5826\n",
            "INFO:__main__:Epoch 5826: total training loss 0.00223\n",
            "2025-06-26 08:28:36,503 Epoch 5826: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5827\n",
            "2025-06-26 08:28:36,505 EPOCH 5827\n",
            "INFO:__main__:Epoch 5827: total training loss 0.00226\n",
            "2025-06-26 08:28:36,581 Epoch 5827: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5828\n",
            "2025-06-26 08:28:36,583 EPOCH 5828\n",
            "INFO:__main__:Epoch 5828: total training loss 0.00217\n",
            "2025-06-26 08:28:36,652 Epoch 5828: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5829\n",
            "2025-06-26 08:28:36,656 EPOCH 5829\n",
            "INFO:__main__:Epoch 5829: total training loss 0.00217\n",
            "2025-06-26 08:28:36,724 Epoch 5829: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5830\n",
            "2025-06-26 08:28:36,726 EPOCH 5830\n",
            "INFO:__main__:Epoch 5830: total training loss 0.00194\n",
            "2025-06-26 08:28:36,798 Epoch 5830: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5831\n",
            "2025-06-26 08:28:36,800 EPOCH 5831\n",
            "INFO:__main__:Epoch 5831: total training loss 0.00212\n",
            "2025-06-26 08:28:36,873 Epoch 5831: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5832\n",
            "2025-06-26 08:28:36,876 EPOCH 5832\n",
            "INFO:__main__:Epoch 5832: total training loss 0.00202\n",
            "2025-06-26 08:28:36,946 Epoch 5832: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5833\n",
            "2025-06-26 08:28:36,950 EPOCH 5833\n",
            "INFO:__main__:Epoch 5833: total training loss 0.00196\n",
            "2025-06-26 08:28:37,021 Epoch 5833: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5834\n",
            "2025-06-26 08:28:37,023 EPOCH 5834\n",
            "INFO:__main__:Epoch 5834: total training loss 0.00194\n",
            "2025-06-26 08:28:37,099 Epoch 5834: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5835\n",
            "2025-06-26 08:28:37,101 EPOCH 5835\n",
            "INFO:__main__:Epoch 5835: total training loss 0.00205\n",
            "2025-06-26 08:28:37,171 Epoch 5835: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5836\n",
            "2025-06-26 08:28:37,173 EPOCH 5836\n",
            "INFO:__main__:Epoch 5836: total training loss 0.00207\n",
            "2025-06-26 08:28:37,243 Epoch 5836: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5837\n",
            "2025-06-26 08:28:37,245 EPOCH 5837\n",
            "INFO:__main__:Epoch 5837: total training loss 0.00209\n",
            "2025-06-26 08:28:37,334 Epoch 5837: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5838\n",
            "2025-06-26 08:28:37,336 EPOCH 5838\n",
            "INFO:__main__:Epoch 5838: total training loss 0.00193\n",
            "2025-06-26 08:28:37,405 Epoch 5838: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5839\n",
            "2025-06-26 08:28:37,407 EPOCH 5839\n",
            "INFO:__main__:Epoch 5839: total training loss 0.00192\n",
            "2025-06-26 08:28:37,479 Epoch 5839: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5840\n",
            "2025-06-26 08:28:37,482 EPOCH 5840\n",
            "INFO:__main__:Epoch 5840: total training loss 0.00192\n",
            "2025-06-26 08:28:37,551 Epoch 5840: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5841\n",
            "2025-06-26 08:28:37,553 EPOCH 5841\n",
            "INFO:__main__:Epoch 5841: total training loss 0.00201\n",
            "2025-06-26 08:28:37,625 Epoch 5841: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5842\n",
            "2025-06-26 08:28:37,627 EPOCH 5842\n",
            "INFO:__main__:Epoch 5842: total training loss 0.00206\n",
            "2025-06-26 08:28:37,698 Epoch 5842: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5843\n",
            "2025-06-26 08:28:37,700 EPOCH 5843\n",
            "INFO:__main__:Epoch 5843: total training loss 0.00190\n",
            "2025-06-26 08:28:37,769 Epoch 5843: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5844\n",
            "2025-06-26 08:28:37,771 EPOCH 5844\n",
            "INFO:__main__:Epoch 5844: total training loss 0.00198\n",
            "2025-06-26 08:28:37,843 Epoch 5844: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5845\n",
            "2025-06-26 08:28:37,845 EPOCH 5845\n",
            "INFO:__main__:Epoch 5845: total training loss 0.00212\n",
            "2025-06-26 08:28:37,920 Epoch 5845: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5846\n",
            "2025-06-26 08:28:37,922 EPOCH 5846\n",
            "INFO:__main__:Epoch 5846: total training loss 0.00178\n",
            "2025-06-26 08:28:37,992 Epoch 5846: total training loss 0.00178\n",
            "INFO:__main__:EPOCH 5847\n",
            "2025-06-26 08:28:37,994 EPOCH 5847\n",
            "INFO:__main__:Epoch 5847: total training loss 0.00203\n",
            "2025-06-26 08:28:38,062 Epoch 5847: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5848\n",
            "2025-06-26 08:28:38,063 EPOCH 5848\n",
            "INFO:__main__:Epoch 5848: total training loss 0.00195\n",
            "2025-06-26 08:28:38,131 Epoch 5848: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5849\n",
            "2025-06-26 08:28:38,134 EPOCH 5849\n",
            "INFO:__main__:Epoch 5849: total training loss 0.00217\n",
            "2025-06-26 08:28:38,208 Epoch 5849: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5850\n",
            "2025-06-26 08:28:38,210 EPOCH 5850\n",
            "INFO:__main__:Epoch 5850: total training loss 0.00201\n",
            "2025-06-26 08:28:38,287 Epoch 5850: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5851\n",
            "2025-06-26 08:28:38,292 EPOCH 5851\n",
            "INFO:__main__:Epoch 5851: total training loss 0.00200\n",
            "2025-06-26 08:28:38,382 Epoch 5851: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5852\n",
            "2025-06-26 08:28:38,384 EPOCH 5852\n",
            "INFO:__main__:Epoch 5852: total training loss 0.00199\n",
            "2025-06-26 08:28:38,454 Epoch 5852: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5853\n",
            "2025-06-26 08:28:38,456 EPOCH 5853\n",
            "INFO:__main__:Epoch 5853: total training loss 0.00197\n",
            "2025-06-26 08:28:38,531 Epoch 5853: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5854\n",
            "2025-06-26 08:28:38,534 EPOCH 5854\n",
            "INFO:__main__:Epoch 5854: total training loss 0.00211\n",
            "2025-06-26 08:28:38,606 Epoch 5854: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5855\n",
            "2025-06-26 08:28:38,608 EPOCH 5855\n",
            "INFO:__main__:Epoch 5855: total training loss 0.00200\n",
            "2025-06-26 08:28:38,674 Epoch 5855: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5856\n",
            "2025-06-26 08:28:38,675 EPOCH 5856\n",
            "INFO:__main__:Epoch 5856: total training loss 0.00200\n",
            "2025-06-26 08:28:38,743 Epoch 5856: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5857\n",
            "2025-06-26 08:28:38,746 EPOCH 5857\n",
            "INFO:__main__:Epoch 5857: total training loss 0.00228\n",
            "2025-06-26 08:28:38,818 Epoch 5857: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5858\n",
            "2025-06-26 08:28:38,820 EPOCH 5858\n",
            "INFO:__main__:Epoch 5858: total training loss 0.00194\n",
            "2025-06-26 08:28:38,891 Epoch 5858: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5859\n",
            "2025-06-26 08:28:38,893 EPOCH 5859\n",
            "INFO:__main__:Epoch 5859: total training loss 0.00198\n",
            "2025-06-26 08:28:38,963 Epoch 5859: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5860\n",
            "2025-06-26 08:28:38,965 EPOCH 5860\n",
            "INFO:__main__:Epoch 5860: total training loss 0.00202\n",
            "2025-06-26 08:28:39,039 Epoch 5860: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5861\n",
            "2025-06-26 08:28:39,041 EPOCH 5861\n",
            "INFO:__main__:Epoch 5861: total training loss 0.00187\n",
            "2025-06-26 08:28:39,114 Epoch 5861: total training loss 0.00187\n",
            "INFO:__main__:EPOCH 5862\n",
            "2025-06-26 08:28:39,117 EPOCH 5862\n",
            "INFO:__main__:Epoch 5862: total training loss 0.00201\n",
            "2025-06-26 08:28:39,186 Epoch 5862: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5863\n",
            "2025-06-26 08:28:39,188 EPOCH 5863\n",
            "INFO:__main__:Epoch 5863: total training loss 0.00176\n",
            "2025-06-26 08:28:39,261 Epoch 5863: total training loss 0.00176\n",
            "INFO:__main__:EPOCH 5864\n",
            "2025-06-26 08:28:39,263 EPOCH 5864\n",
            "INFO:__main__:Epoch 5864: total training loss 0.00189\n",
            "2025-06-26 08:28:39,334 Epoch 5864: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5865\n",
            "2025-06-26 08:28:39,340 EPOCH 5865\n",
            "INFO:__main__:Epoch 5865: total training loss 0.00183\n",
            "2025-06-26 08:28:39,425 Epoch 5865: total training loss 0.00183\n",
            "INFO:__main__:EPOCH 5866\n",
            "2025-06-26 08:28:39,427 EPOCH 5866\n",
            "INFO:__main__:Epoch 5866: total training loss 0.00191\n",
            "2025-06-26 08:28:39,503 Epoch 5866: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5867\n",
            "2025-06-26 08:28:39,505 EPOCH 5867\n",
            "INFO:__main__:Epoch 5867: total training loss 0.00197\n",
            "2025-06-26 08:28:39,579 Epoch 5867: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5868\n",
            "2025-06-26 08:28:39,581 EPOCH 5868\n",
            "INFO:__main__:Epoch 5868: total training loss 0.00182\n",
            "2025-06-26 08:28:39,653 Epoch 5868: total training loss 0.00182\n",
            "INFO:__main__:EPOCH 5869\n",
            "2025-06-26 08:28:39,655 EPOCH 5869\n",
            "INFO:__main__:Epoch 5869: total training loss 0.00200\n",
            "2025-06-26 08:28:39,731 Epoch 5869: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5870\n",
            "2025-06-26 08:28:39,733 EPOCH 5870\n",
            "INFO:__main__:Epoch 5870: total training loss 0.00199\n",
            "2025-06-26 08:28:39,805 Epoch 5870: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5871\n",
            "2025-06-26 08:28:39,807 EPOCH 5871\n",
            "INFO:__main__:Epoch 5871: total training loss 0.00213\n",
            "2025-06-26 08:28:39,884 Epoch 5871: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5872\n",
            "2025-06-26 08:28:39,886 EPOCH 5872\n",
            "INFO:__main__:Epoch 5872: total training loss 0.00206\n",
            "2025-06-26 08:28:39,959 Epoch 5872: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5873\n",
            "2025-06-26 08:28:39,961 EPOCH 5873\n",
            "INFO:__main__:Epoch 5873: total training loss 0.00229\n",
            "2025-06-26 08:28:40,032 Epoch 5873: total training loss 0.00229\n",
            "INFO:__main__:EPOCH 5874\n",
            "2025-06-26 08:28:40,034 EPOCH 5874\n",
            "INFO:__main__:Epoch 5874: total training loss 0.00228\n",
            "2025-06-26 08:28:40,104 Epoch 5874: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5875\n",
            "2025-06-26 08:28:40,106 EPOCH 5875\n",
            "INFO:__main__:Epoch 5875: total training loss 0.00233\n",
            "2025-06-26 08:28:40,175 Epoch 5875: total training loss 0.00233\n",
            "INFO:__main__:EPOCH 5876\n",
            "2025-06-26 08:28:40,177 EPOCH 5876\n",
            "INFO:__main__:Epoch 5876: total training loss 0.00245\n",
            "2025-06-26 08:28:40,249 Epoch 5876: total training loss 0.00245\n",
            "INFO:__main__:EPOCH 5877\n",
            "2025-06-26 08:28:40,251 EPOCH 5877\n",
            "INFO:__main__:Epoch 5877: total training loss 0.00287\n",
            "2025-06-26 08:28:40,326 Epoch 5877: total training loss 0.00287\n",
            "INFO:__main__:EPOCH 5878\n",
            "2025-06-26 08:28:40,328 EPOCH 5878\n",
            "INFO:__main__:Epoch 5878: total training loss 0.00266\n",
            "2025-06-26 08:28:40,407 Epoch 5878: total training loss 0.00266\n",
            "INFO:__main__:EPOCH 5879\n",
            "2025-06-26 08:28:40,410 EPOCH 5879\n",
            "INFO:__main__:Epoch 5879: total training loss 0.00277\n",
            "2025-06-26 08:28:40,481 Epoch 5879: total training loss 0.00277\n",
            "INFO:__main__:EPOCH 5880\n",
            "2025-06-26 08:28:40,483 EPOCH 5880\n",
            "INFO:__main__:Epoch 5880: total training loss 0.00232\n",
            "2025-06-26 08:28:40,554 Epoch 5880: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5881\n",
            "2025-06-26 08:28:40,556 EPOCH 5881\n",
            "INFO:__main__:Epoch 5881: total training loss 0.00258\n",
            "2025-06-26 08:28:40,630 Epoch 5881: total training loss 0.00258\n",
            "INFO:__main__:EPOCH 5882\n",
            "2025-06-26 08:28:40,632 EPOCH 5882\n",
            "INFO:__main__:Epoch 5882: total training loss 0.00250\n",
            "2025-06-26 08:28:40,704 Epoch 5882: total training loss 0.00250\n",
            "INFO:__main__:EPOCH 5883\n",
            "2025-06-26 08:28:40,705 EPOCH 5883\n",
            "INFO:__main__:Epoch 5883: total training loss 0.00232\n",
            "2025-06-26 08:28:40,780 Epoch 5883: total training loss 0.00232\n",
            "INFO:__main__:EPOCH 5884\n",
            "2025-06-26 08:28:40,783 EPOCH 5884\n",
            "INFO:__main__:Epoch 5884: total training loss 0.00237\n",
            "2025-06-26 08:28:40,856 Epoch 5884: total training loss 0.00237\n",
            "INFO:__main__:EPOCH 5885\n",
            "2025-06-26 08:28:40,857 EPOCH 5885\n",
            "INFO:__main__:Epoch 5885: total training loss 0.00234\n",
            "2025-06-26 08:28:40,929 Epoch 5885: total training loss 0.00234\n",
            "INFO:__main__:EPOCH 5886\n",
            "2025-06-26 08:28:40,931 EPOCH 5886\n",
            "INFO:__main__:Epoch 5886: total training loss 0.00240\n",
            "2025-06-26 08:28:41,001 Epoch 5886: total training loss 0.00240\n",
            "INFO:__main__:EPOCH 5887\n",
            "2025-06-26 08:28:41,003 EPOCH 5887\n",
            "INFO:__main__:Epoch 5887: total training loss 0.00242\n",
            "2025-06-26 08:28:41,075 Epoch 5887: total training loss 0.00242\n",
            "INFO:__main__:EPOCH 5888\n",
            "2025-06-26 08:28:41,076 EPOCH 5888\n",
            "INFO:__main__:Epoch 5888: total training loss 0.00223\n",
            "2025-06-26 08:28:41,145 Epoch 5888: total training loss 0.00223\n",
            "INFO:__main__:EPOCH 5889\n",
            "2025-06-26 08:28:41,146 EPOCH 5889\n",
            "INFO:__main__:Epoch 5889: total training loss 0.00236\n",
            "2025-06-26 08:28:41,219 Epoch 5889: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5890\n",
            "2025-06-26 08:28:41,221 EPOCH 5890\n",
            "INFO:__main__:Epoch 5890: total training loss 0.00236\n",
            "2025-06-26 08:28:41,290 Epoch 5890: total training loss 0.00236\n",
            "INFO:__main__:EPOCH 5891\n",
            "2025-06-26 08:28:41,293 EPOCH 5891\n",
            "INFO:__main__:Epoch 5891: total training loss 0.00241\n",
            "2025-06-26 08:28:41,364 Epoch 5891: total training loss 0.00241\n",
            "INFO:__main__:EPOCH 5892\n",
            "2025-06-26 08:28:41,366 EPOCH 5892\n",
            "INFO:__main__:Epoch 5892: total training loss 0.00224\n",
            "2025-06-26 08:28:41,450 Epoch 5892: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5893\n",
            "2025-06-26 08:28:41,452 EPOCH 5893\n",
            "INFO:__main__:Epoch 5893: total training loss 0.00231\n",
            "2025-06-26 08:28:41,526 Epoch 5893: total training loss 0.00231\n",
            "INFO:__main__:EPOCH 5894\n",
            "2025-06-26 08:28:41,528 EPOCH 5894\n",
            "INFO:__main__:Epoch 5894: total training loss 0.00214\n",
            "2025-06-26 08:28:41,605 Epoch 5894: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5895\n",
            "2025-06-26 08:28:41,607 EPOCH 5895\n",
            "INFO:__main__:Epoch 5895: total training loss 0.00213\n",
            "2025-06-26 08:28:41,680 Epoch 5895: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5896\n",
            "2025-06-26 08:28:41,681 EPOCH 5896\n",
            "INFO:__main__:Epoch 5896: total training loss 0.00213\n",
            "2025-06-26 08:28:41,746 Epoch 5896: total training loss 0.00213\n",
            "INFO:__main__:EPOCH 5897\n",
            "2025-06-26 08:28:41,750 EPOCH 5897\n",
            "INFO:__main__:Epoch 5897: total training loss 0.00226\n",
            "2025-06-26 08:28:41,823 Epoch 5897: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5898\n",
            "2025-06-26 08:28:41,825 EPOCH 5898\n",
            "INFO:__main__:Epoch 5898: total training loss 0.00202\n",
            "2025-06-26 08:28:41,898 Epoch 5898: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5899\n",
            "2025-06-26 08:28:41,900 EPOCH 5899\n",
            "INFO:__main__:Epoch 5899: total training loss 0.00201\n",
            "2025-06-26 08:28:41,973 Epoch 5899: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5900\n",
            "2025-06-26 08:28:41,975 EPOCH 5900\n",
            "INFO:__main__:Epoch 5900: total training loss 0.00198\n",
            "2025-06-26 08:28:42,047 Epoch 5900: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5901\n",
            "2025-06-26 08:28:42,049 EPOCH 5901\n",
            "INFO:__main__:Epoch 5901: total training loss 0.00199\n",
            "2025-06-26 08:28:42,124 Epoch 5901: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5902\n",
            "2025-06-26 08:28:42,126 EPOCH 5902\n",
            "INFO:__main__:Epoch 5902: total training loss 0.00194\n",
            "2025-06-26 08:28:42,198 Epoch 5902: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5903\n",
            "2025-06-26 08:28:42,200 EPOCH 5903\n",
            "INFO:__main__:Epoch 5903: total training loss 0.00194\n",
            "2025-06-26 08:28:42,268 Epoch 5903: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5904\n",
            "2025-06-26 08:28:42,270 EPOCH 5904\n",
            "INFO:__main__:Epoch 5904: total training loss 0.00202\n",
            "2025-06-26 08:28:42,343 Epoch 5904: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5905\n",
            "2025-06-26 08:28:42,345 EPOCH 5905\n",
            "INFO:__main__:Epoch 5905: total training loss 0.00192\n",
            "2025-06-26 08:28:42,416 Epoch 5905: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5906\n",
            "2025-06-26 08:28:42,418 EPOCH 5906\n",
            "INFO:__main__:Epoch 5906: total training loss 0.00214\n",
            "2025-06-26 08:28:42,503 Epoch 5906: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5907\n",
            "2025-06-26 08:28:42,504 EPOCH 5907\n",
            "INFO:__main__:Epoch 5907: total training loss 0.00196\n",
            "2025-06-26 08:28:42,579 Epoch 5907: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5908\n",
            "2025-06-26 08:28:42,581 EPOCH 5908\n",
            "INFO:__main__:Epoch 5908: total training loss 0.00204\n",
            "2025-06-26 08:28:42,650 Epoch 5908: total training loss 0.00204\n",
            "INFO:__main__:EPOCH 5909\n",
            "2025-06-26 08:28:42,652 EPOCH 5909\n",
            "INFO:__main__:Epoch 5909: total training loss 0.00195\n",
            "2025-06-26 08:28:42,723 Epoch 5909: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5910\n",
            "2025-06-26 08:28:42,725 EPOCH 5910\n",
            "INFO:__main__:Epoch 5910: total training loss 0.00193\n",
            "2025-06-26 08:28:42,793 Epoch 5910: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5911\n",
            "2025-06-26 08:28:42,794 EPOCH 5911\n",
            "INFO:__main__:Epoch 5911: total training loss 0.00192\n",
            "2025-06-26 08:28:42,861 Epoch 5911: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5912\n",
            "2025-06-26 08:28:42,863 EPOCH 5912\n",
            "INFO:__main__:Epoch 5912: total training loss 0.00179\n",
            "2025-06-26 08:28:42,934 Epoch 5912: total training loss 0.00179\n",
            "INFO:__main__:EPOCH 5913\n",
            "2025-06-26 08:28:42,936 EPOCH 5913\n",
            "INFO:__main__:Epoch 5913: total training loss 0.00200\n",
            "2025-06-26 08:28:43,006 Epoch 5913: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5914\n",
            "2025-06-26 08:28:43,008 EPOCH 5914\n",
            "INFO:__main__:Epoch 5914: total training loss 0.00184\n",
            "2025-06-26 08:28:43,079 Epoch 5914: total training loss 0.00184\n",
            "INFO:__main__:EPOCH 5915\n",
            "2025-06-26 08:28:43,081 EPOCH 5915\n",
            "INFO:__main__:Epoch 5915: total training loss 0.00197\n",
            "2025-06-26 08:28:43,152 Epoch 5915: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5916\n",
            "2025-06-26 08:28:43,154 EPOCH 5916\n",
            "INFO:__main__:Epoch 5916: total training loss 0.00197\n",
            "2025-06-26 08:28:43,228 Epoch 5916: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5917\n",
            "2025-06-26 08:28:43,230 EPOCH 5917\n",
            "INFO:__main__:Epoch 5917: total training loss 0.00191\n",
            "2025-06-26 08:28:43,303 Epoch 5917: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5918\n",
            "2025-06-26 08:28:43,305 EPOCH 5918\n",
            "INFO:__main__:Epoch 5918: total training loss 0.00198\n",
            "2025-06-26 08:28:43,380 Epoch 5918: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5919\n",
            "2025-06-26 08:28:43,382 EPOCH 5919\n",
            "INFO:__main__:Epoch 5919: total training loss 0.00209\n",
            "2025-06-26 08:28:43,451 Epoch 5919: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5920\n",
            "2025-06-26 08:28:43,453 EPOCH 5920\n",
            "INFO:__main__:Epoch 5920: total training loss 0.00197\n",
            "2025-06-26 08:28:43,537 Epoch 5920: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5921\n",
            "2025-06-26 08:28:43,542 EPOCH 5921\n",
            "INFO:__main__:Epoch 5921: total training loss 0.00199\n",
            "2025-06-26 08:28:43,616 Epoch 5921: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5922\n",
            "2025-06-26 08:28:43,618 EPOCH 5922\n",
            "INFO:__main__:Epoch 5922: total training loss 0.00209\n",
            "2025-06-26 08:28:43,684 Epoch 5922: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5923\n",
            "2025-06-26 08:28:43,686 EPOCH 5923\n",
            "INFO:__main__:Epoch 5923: total training loss 0.00202\n",
            "2025-06-26 08:28:43,755 Epoch 5923: total training loss 0.00202\n",
            "INFO:__main__:EPOCH 5924\n",
            "2025-06-26 08:28:43,757 EPOCH 5924\n",
            "INFO:__main__:Epoch 5924: total training loss 0.00201\n",
            "2025-06-26 08:28:43,827 Epoch 5924: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5925\n",
            "2025-06-26 08:28:43,828 EPOCH 5925\n",
            "INFO:__main__:Epoch 5925: total training loss 0.00203\n",
            "2025-06-26 08:28:43,898 Epoch 5925: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5926\n",
            "2025-06-26 08:28:43,900 EPOCH 5926\n",
            "INFO:__main__:Epoch 5926: total training loss 0.00207\n",
            "2025-06-26 08:28:43,970 Epoch 5926: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5927\n",
            "2025-06-26 08:28:43,972 EPOCH 5927\n",
            "INFO:__main__:Epoch 5927: total training loss 0.00198\n",
            "2025-06-26 08:28:44,039 Epoch 5927: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5928\n",
            "2025-06-26 08:28:44,041 EPOCH 5928\n",
            "INFO:__main__:Epoch 5928: total training loss 0.00211\n",
            "2025-06-26 08:28:44,111 Epoch 5928: total training loss 0.00211\n",
            "INFO:__main__:EPOCH 5929\n",
            "2025-06-26 08:28:44,114 EPOCH 5929\n",
            "INFO:__main__:Epoch 5929: total training loss 0.00197\n",
            "2025-06-26 08:28:44,188 Epoch 5929: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5930\n",
            "2025-06-26 08:28:44,190 EPOCH 5930\n",
            "INFO:__main__:Epoch 5930: total training loss 0.00192\n",
            "2025-06-26 08:28:44,261 Epoch 5930: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5931\n",
            "2025-06-26 08:28:44,263 EPOCH 5931\n",
            "INFO:__main__:Epoch 5931: total training loss 0.00208\n",
            "2025-06-26 08:28:44,332 Epoch 5931: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 5932\n",
            "2025-06-26 08:28:44,333 EPOCH 5932\n",
            "INFO:__main__:Epoch 5932: total training loss 0.00191\n",
            "2025-06-26 08:28:44,402 Epoch 5932: total training loss 0.00191\n",
            "INFO:__main__:EPOCH 5933\n",
            "2025-06-26 08:28:44,404 EPOCH 5933\n",
            "INFO:__main__:Epoch 5933: total training loss 0.00187\n",
            "2025-06-26 08:28:44,473 Epoch 5933: total training loss 0.00187\n",
            "INFO:__main__:EPOCH 5934\n",
            "2025-06-26 08:28:44,475 EPOCH 5934\n",
            "INFO:__main__:Epoch 5934: total training loss 0.00184\n",
            "2025-06-26 08:28:44,546 Epoch 5934: total training loss 0.00184\n",
            "INFO:__main__:EPOCH 5935\n",
            "2025-06-26 08:28:44,548 EPOCH 5935\n",
            "INFO:__main__:Epoch 5935: total training loss 0.00185\n",
            "2025-06-26 08:28:44,631 Epoch 5935: total training loss 0.00185\n",
            "INFO:__main__:EPOCH 5936\n",
            "2025-06-26 08:28:44,633 EPOCH 5936\n",
            "INFO:__main__:Epoch 5936: total training loss 0.00186\n",
            "2025-06-26 08:28:44,705 Epoch 5936: total training loss 0.00186\n",
            "INFO:__main__:EPOCH 5937\n",
            "2025-06-26 08:28:44,707 EPOCH 5937\n",
            "INFO:__main__:Epoch 5937: total training loss 0.00182\n",
            "2025-06-26 08:28:44,780 Epoch 5937: total training loss 0.00182\n",
            "INFO:__main__:EPOCH 5938\n",
            "2025-06-26 08:28:44,782 EPOCH 5938\n",
            "INFO:__main__:Epoch 5938: total training loss 0.00194\n",
            "2025-06-26 08:28:44,852 Epoch 5938: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5939\n",
            "2025-06-26 08:28:44,854 EPOCH 5939\n",
            "INFO:__main__:Epoch 5939: total training loss 0.00178\n",
            "2025-06-26 08:28:44,924 Epoch 5939: total training loss 0.00178\n",
            "INFO:__main__:EPOCH 5940\n",
            "2025-06-26 08:28:44,925 EPOCH 5940\n",
            "INFO:__main__:Epoch 5940: total training loss 0.00194\n",
            "2025-06-26 08:28:44,998 Epoch 5940: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5941\n",
            "2025-06-26 08:28:44,999 EPOCH 5941\n",
            "INFO:__main__:Epoch 5941: total training loss 0.00182\n",
            "2025-06-26 08:28:45,074 Epoch 5941: total training loss 0.00182\n",
            "INFO:__main__:EPOCH 5942\n",
            "2025-06-26 08:28:45,076 EPOCH 5942\n",
            "INFO:__main__:Epoch 5942: total training loss 0.00199\n",
            "2025-06-26 08:28:45,144 Epoch 5942: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5943\n",
            "2025-06-26 08:28:45,146 EPOCH 5943\n",
            "INFO:__main__:Epoch 5943: total training loss 0.00192\n",
            "2025-06-26 08:28:45,219 Epoch 5943: total training loss 0.00192\n",
            "INFO:__main__:EPOCH 5944\n",
            "2025-06-26 08:28:45,221 EPOCH 5944\n",
            "INFO:__main__:Epoch 5944: total training loss 0.00205\n",
            "2025-06-26 08:28:45,290 Epoch 5944: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5945\n",
            "2025-06-26 08:28:45,292 EPOCH 5945\n",
            "INFO:__main__:Epoch 5945: total training loss 0.00207\n",
            "2025-06-26 08:28:45,363 Epoch 5945: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5946\n",
            "2025-06-26 08:28:45,365 EPOCH 5946\n",
            "INFO:__main__:Epoch 5946: total training loss 0.00214\n",
            "2025-06-26 08:28:45,440 Epoch 5946: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5947\n",
            "2025-06-26 08:28:45,442 EPOCH 5947\n",
            "INFO:__main__:Epoch 5947: total training loss 0.00207\n",
            "2025-06-26 08:28:45,525 Epoch 5947: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5948\n",
            "2025-06-26 08:28:45,527 EPOCH 5948\n",
            "INFO:__main__:Epoch 5948: total training loss 0.00217\n",
            "2025-06-26 08:28:45,635 Epoch 5948: total training loss 0.00217\n",
            "INFO:__main__:EPOCH 5949\n",
            "2025-06-26 08:28:45,638 EPOCH 5949\n",
            "INFO:__main__:Epoch 5949: total training loss 0.00209\n",
            "2025-06-26 08:28:45,747 Epoch 5949: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5950\n",
            "2025-06-26 08:28:45,750 EPOCH 5950\n",
            "INFO:__main__:Epoch 5950: total training loss 0.00214\n",
            "2025-06-26 08:28:45,848 Epoch 5950: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5951\n",
            "2025-06-26 08:28:45,850 EPOCH 5951\n",
            "INFO:__main__:Epoch 5951: total training loss 0.00224\n",
            "2025-06-26 08:28:45,964 Epoch 5951: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5952\n",
            "2025-06-26 08:28:45,968 EPOCH 5952\n",
            "INFO:__main__:Epoch 5952: total training loss 0.00228\n",
            "2025-06-26 08:28:46,071 Epoch 5952: total training loss 0.00228\n",
            "INFO:__main__:EPOCH 5953\n",
            "2025-06-26 08:28:46,076 EPOCH 5953\n",
            "INFO:__main__:Epoch 5953: total training loss 0.00219\n",
            "2025-06-26 08:28:46,150 Epoch 5953: total training loss 0.00219\n",
            "INFO:__main__:EPOCH 5954\n",
            "2025-06-26 08:28:46,158 EPOCH 5954\n",
            "INFO:__main__:Epoch 5954: total training loss 0.00215\n",
            "2025-06-26 08:28:46,237 Epoch 5954: total training loss 0.00215\n",
            "INFO:__main__:EPOCH 5955\n",
            "2025-06-26 08:28:46,241 EPOCH 5955\n",
            "INFO:__main__:Epoch 5955: total training loss 0.00224\n",
            "2025-06-26 08:28:46,335 Epoch 5955: total training loss 0.00224\n",
            "INFO:__main__:EPOCH 5956\n",
            "2025-06-26 08:28:46,342 EPOCH 5956\n",
            "INFO:__main__:Epoch 5956: total training loss 0.00207\n",
            "2025-06-26 08:28:46,445 Epoch 5956: total training loss 0.00207\n",
            "INFO:__main__:EPOCH 5957\n",
            "2025-06-26 08:28:46,451 EPOCH 5957\n",
            "INFO:__main__:Epoch 5957: total training loss 0.00196\n",
            "2025-06-26 08:28:46,533 Epoch 5957: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5958\n",
            "2025-06-26 08:28:46,535 EPOCH 5958\n",
            "INFO:__main__:Epoch 5958: total training loss 0.00209\n",
            "2025-06-26 08:28:46,645 Epoch 5958: total training loss 0.00209\n",
            "INFO:__main__:EPOCH 5959\n",
            "2025-06-26 08:28:46,647 EPOCH 5959\n",
            "INFO:__main__:Epoch 5959: total training loss 0.00197\n",
            "2025-06-26 08:28:46,754 Epoch 5959: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5960\n",
            "2025-06-26 08:28:46,759 EPOCH 5960\n",
            "INFO:__main__:Epoch 5960: total training loss 0.00201\n",
            "2025-06-26 08:28:46,859 Epoch 5960: total training loss 0.00201\n",
            "INFO:__main__:EPOCH 5961\n",
            "2025-06-26 08:28:46,860 EPOCH 5961\n",
            "INFO:__main__:Epoch 5961: total training loss 0.00195\n",
            "2025-06-26 08:28:46,940 Epoch 5961: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5962\n",
            "2025-06-26 08:28:46,945 EPOCH 5962\n",
            "INFO:__main__:Epoch 5962: total training loss 0.00203\n",
            "2025-06-26 08:28:47,029 Epoch 5962: total training loss 0.00203\n",
            "INFO:__main__:EPOCH 5963\n",
            "2025-06-26 08:28:47,038 EPOCH 5963\n",
            "INFO:__main__:Epoch 5963: total training loss 0.00178\n",
            "2025-06-26 08:28:47,116 Epoch 5963: total training loss 0.00178\n",
            "INFO:__main__:EPOCH 5964\n",
            "2025-06-26 08:28:47,120 EPOCH 5964\n",
            "INFO:__main__:Epoch 5964: total training loss 0.00189\n",
            "2025-06-26 08:28:47,207 Epoch 5964: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5965\n",
            "2025-06-26 08:28:47,212 EPOCH 5965\n",
            "INFO:__main__:Epoch 5965: total training loss 0.00179\n",
            "2025-06-26 08:28:47,299 Epoch 5965: total training loss 0.00179\n",
            "INFO:__main__:EPOCH 5966\n",
            "2025-06-26 08:28:47,306 EPOCH 5966\n",
            "INFO:__main__:Epoch 5966: total training loss 0.00193\n",
            "2025-06-26 08:28:47,406 Epoch 5966: total training loss 0.00193\n",
            "INFO:__main__:EPOCH 5967\n",
            "2025-06-26 08:28:47,408 EPOCH 5967\n",
            "INFO:__main__:Epoch 5967: total training loss 0.00189\n",
            "2025-06-26 08:28:47,494 Epoch 5967: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5968\n",
            "2025-06-26 08:28:47,499 EPOCH 5968\n",
            "INFO:__main__:Epoch 5968: total training loss 0.00182\n",
            "2025-06-26 08:28:47,583 Epoch 5968: total training loss 0.00182\n",
            "INFO:__main__:EPOCH 5969\n",
            "2025-06-26 08:28:47,590 EPOCH 5969\n",
            "INFO:__main__:Epoch 5969: total training loss 0.00181\n",
            "2025-06-26 08:28:47,669 Epoch 5969: total training loss 0.00181\n",
            "INFO:__main__:EPOCH 5970\n",
            "2025-06-26 08:28:47,672 EPOCH 5970\n",
            "INFO:__main__:Epoch 5970: total training loss 0.00174\n",
            "2025-06-26 08:28:47,749 Epoch 5970: total training loss 0.00174\n",
            "INFO:__main__:EPOCH 5971\n",
            "2025-06-26 08:28:47,752 EPOCH 5971\n",
            "INFO:__main__:Epoch 5971: total training loss 0.00195\n",
            "2025-06-26 08:28:47,841 Epoch 5971: total training loss 0.00195\n",
            "INFO:__main__:EPOCH 5972\n",
            "2025-06-26 08:28:47,845 EPOCH 5972\n",
            "INFO:__main__:Epoch 5972: total training loss 0.00197\n",
            "2025-06-26 08:28:47,929 Epoch 5972: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5973\n",
            "2025-06-26 08:28:47,935 EPOCH 5973\n",
            "INFO:__main__:Epoch 5973: total training loss 0.00200\n",
            "2025-06-26 08:28:48,023 Epoch 5973: total training loss 0.00200\n",
            "INFO:__main__:EPOCH 5974\n",
            "2025-06-26 08:28:48,029 EPOCH 5974\n",
            "INFO:__main__:Epoch 5974: total training loss 0.00185\n",
            "2025-06-26 08:28:48,115 Epoch 5974: total training loss 0.00185\n",
            "INFO:__main__:EPOCH 5975\n",
            "2025-06-26 08:28:48,118 EPOCH 5975\n",
            "INFO:__main__:Epoch 5975: total training loss 0.00212\n",
            "2025-06-26 08:28:48,203 Epoch 5975: total training loss 0.00212\n",
            "INFO:__main__:EPOCH 5976\n",
            "2025-06-26 08:28:48,207 EPOCH 5976\n",
            "INFO:__main__:Epoch 5976: total training loss 0.00198\n",
            "2025-06-26 08:28:48,338 Epoch 5976: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5977\n",
            "2025-06-26 08:28:48,339 EPOCH 5977\n",
            "INFO:__main__:Epoch 5977: total training loss 0.00198\n",
            "2025-06-26 08:28:48,460 Epoch 5977: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5978\n",
            "2025-06-26 08:28:48,461 EPOCH 5978\n",
            "INFO:__main__:Epoch 5978: total training loss 0.00206\n",
            "2025-06-26 08:28:48,572 Epoch 5978: total training loss 0.00206\n",
            "INFO:__main__:EPOCH 5979\n",
            "2025-06-26 08:28:48,583 EPOCH 5979\n",
            "INFO:__main__:Epoch 5979: total training loss 0.00190\n",
            "2025-06-26 08:28:48,685 Epoch 5979: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5980\n",
            "2025-06-26 08:28:48,694 EPOCH 5980\n",
            "INFO:__main__:Epoch 5980: total training loss 0.00189\n",
            "2025-06-26 08:28:48,766 Epoch 5980: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5981\n",
            "2025-06-26 08:28:48,770 EPOCH 5981\n",
            "INFO:__main__:Epoch 5981: total training loss 0.00189\n",
            "2025-06-26 08:28:48,844 Epoch 5981: total training loss 0.00189\n",
            "INFO:__main__:EPOCH 5982\n",
            "2025-06-26 08:28:48,848 EPOCH 5982\n",
            "INFO:__main__:Epoch 5982: total training loss 0.00197\n",
            "2025-06-26 08:28:48,939 Epoch 5982: total training loss 0.00197\n",
            "INFO:__main__:EPOCH 5983\n",
            "2025-06-26 08:28:48,945 EPOCH 5983\n",
            "INFO:__main__:Epoch 5983: total training loss 0.00176\n",
            "2025-06-26 08:28:49,026 Epoch 5983: total training loss 0.00176\n",
            "INFO:__main__:EPOCH 5984\n",
            "2025-06-26 08:28:49,032 EPOCH 5984\n",
            "INFO:__main__:Epoch 5984: total training loss 0.00190\n",
            "2025-06-26 08:28:49,115 Epoch 5984: total training loss 0.00190\n",
            "INFO:__main__:EPOCH 5985\n",
            "2025-06-26 08:28:49,119 EPOCH 5985\n",
            "INFO:__main__:Epoch 5985: total training loss 0.00164\n",
            "2025-06-26 08:28:49,199 Epoch 5985: total training loss 0.00164\n",
            "INFO:__main__:EPOCH 5986\n",
            "2025-06-26 08:28:49,204 EPOCH 5986\n",
            "INFO:__main__:Epoch 5986: total training loss 0.00179\n",
            "2025-06-26 08:28:49,303 Epoch 5986: total training loss 0.00179\n",
            "INFO:__main__:EPOCH 5987\n",
            "2025-06-26 08:28:49,305 EPOCH 5987\n",
            "INFO:__main__:Epoch 5987: total training loss 0.00169\n",
            "2025-06-26 08:28:49,415 Epoch 5987: total training loss 0.00169\n",
            "INFO:__main__:EPOCH 5988\n",
            "2025-06-26 08:28:49,417 EPOCH 5988\n",
            "INFO:__main__:Epoch 5988: total training loss 0.00169\n",
            "2025-06-26 08:28:49,510 Epoch 5988: total training loss 0.00169\n",
            "INFO:__main__:EPOCH 5989\n",
            "2025-06-26 08:28:49,514 EPOCH 5989\n",
            "INFO:__main__:Epoch 5989: total training loss 0.00177\n",
            "2025-06-26 08:28:49,621 Epoch 5989: total training loss 0.00177\n",
            "INFO:__main__:EPOCH 5990\n",
            "2025-06-26 08:28:49,623 EPOCH 5990\n",
            "INFO:__main__:Epoch 5990: total training loss 0.00167\n",
            "2025-06-26 08:28:49,719 Epoch 5990: total training loss 0.00167\n",
            "INFO:__main__:EPOCH 5991\n",
            "2025-06-26 08:28:49,725 EPOCH 5991\n",
            "INFO:__main__:Epoch 5991: total training loss 0.00196\n",
            "2025-06-26 08:28:49,802 Epoch 5991: total training loss 0.00196\n",
            "INFO:__main__:EPOCH 5992\n",
            "2025-06-26 08:28:49,808 EPOCH 5992\n",
            "INFO:__main__:Epoch 5992: total training loss 0.00199\n",
            "2025-06-26 08:28:49,929 Epoch 5992: total training loss 0.00199\n",
            "INFO:__main__:EPOCH 5993\n",
            "2025-06-26 08:28:49,933 EPOCH 5993\n",
            "INFO:__main__:Epoch 5993: total training loss 0.00205\n",
            "2025-06-26 08:28:50,037 Epoch 5993: total training loss 0.00205\n",
            "INFO:__main__:EPOCH 5994\n",
            "2025-06-26 08:28:50,042 EPOCH 5994\n",
            "INFO:__main__:Epoch 5994: total training loss 0.00198\n",
            "2025-06-26 08:28:50,145 Epoch 5994: total training loss 0.00198\n",
            "INFO:__main__:EPOCH 5995\n",
            "2025-06-26 08:28:50,146 EPOCH 5995\n",
            "INFO:__main__:Epoch 5995: total training loss 0.00187\n",
            "2025-06-26 08:28:50,238 Epoch 5995: total training loss 0.00187\n",
            "INFO:__main__:EPOCH 5996\n",
            "2025-06-26 08:28:50,240 EPOCH 5996\n",
            "INFO:__main__:Epoch 5996: total training loss 0.00214\n",
            "2025-06-26 08:28:50,371 Epoch 5996: total training loss 0.00214\n",
            "INFO:__main__:EPOCH 5997\n",
            "2025-06-26 08:28:50,373 EPOCH 5997\n",
            "INFO:__main__:Epoch 5997: total training loss 0.00194\n",
            "2025-06-26 08:28:50,476 Epoch 5997: total training loss 0.00194\n",
            "INFO:__main__:EPOCH 5998\n",
            "2025-06-26 08:28:50,478 EPOCH 5998\n",
            "INFO:__main__:Epoch 5998: total training loss 0.00226\n",
            "2025-06-26 08:28:50,564 Epoch 5998: total training loss 0.00226\n",
            "INFO:__main__:EPOCH 5999\n",
            "2025-06-26 08:28:50,566 EPOCH 5999\n",
            "INFO:__main__:Epoch 5999: total training loss 0.00208\n",
            "2025-06-26 08:28:50,650 Epoch 5999: total training loss 0.00208\n",
            "INFO:__main__:EPOCH 6000\n",
            "2025-06-26 08:28:50,652 EPOCH 6000\n",
            "INFO:__main__:Epoch 6000 Step:     6000 Batch Loss:     0.002007 Tokens per Sec:  1907799, Lr: 0.001000\n",
            "2025-06-26 08:28:50,727 Epoch 6000 Step:     6000 Batch Loss:     0.002007 Tokens per Sec:  1907799, Lr: 0.001000\n",
            "INFO:__main__:Hooray! New best validation result [dtw]!\n",
            "2025-06-26 08:28:51,387 Hooray! New best validation result [dtw]!\n",
            "INFO:__main__:Saving new checkpoint.\n",
            "2025-06-26 08:28:51,389 Saving new checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev/11August_2010_Wednesday_tagesschau-2    dtw: 14.61\n",
            "dev/11August_2010_Wednesday_tagesschau-3    dtw: 11.11\n",
            "dev/11August_2010_Wednesday_tagesschau-8    dtw: 13.51\n",
            "dev/25October_2010_Monday_tagesschau-22    dtw: 15.79\n",
            "dev/05May_2011_Thursday_tagesschau-25    dtw: 10.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 14754\n",
            "2025-06-26 08:42:24,069 EPOCH 14754\n",
            "INFO:__main__:Epoch 14754: total training loss 0.00090\n",
            "2025-06-26 08:42:24,165 Epoch 14754: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14755\n",
            "2025-06-26 08:42:24,167 EPOCH 14755\n",
            "INFO:__main__:Epoch 14755: total training loss 0.00101\n",
            "2025-06-26 08:42:24,249 Epoch 14755: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14756\n",
            "2025-06-26 08:42:24,252 EPOCH 14756\n",
            "INFO:__main__:Epoch 14756: total training loss 0.00099\n",
            "2025-06-26 08:42:24,343 Epoch 14756: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14757\n",
            "2025-06-26 08:42:24,352 EPOCH 14757\n",
            "INFO:__main__:Epoch 14757: total training loss 0.00100\n",
            "2025-06-26 08:42:24,440 Epoch 14757: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14758\n",
            "2025-06-26 08:42:24,443 EPOCH 14758\n",
            "INFO:__main__:Epoch 14758: total training loss 0.00103\n",
            "2025-06-26 08:42:24,538 Epoch 14758: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14759\n",
            "2025-06-26 08:42:24,540 EPOCH 14759\n",
            "INFO:__main__:Epoch 14759: total training loss 0.00098\n",
            "2025-06-26 08:42:24,623 Epoch 14759: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14760\n",
            "2025-06-26 08:42:24,625 EPOCH 14760\n",
            "INFO:__main__:Epoch 14760: total training loss 0.00095\n",
            "2025-06-26 08:42:24,714 Epoch 14760: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14761\n",
            "2025-06-26 08:42:24,718 EPOCH 14761\n",
            "INFO:__main__:Epoch 14761: total training loss 0.00097\n",
            "2025-06-26 08:42:24,818 Epoch 14761: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14762\n",
            "2025-06-26 08:42:24,821 EPOCH 14762\n",
            "INFO:__main__:Epoch 14762: total training loss 0.00099\n",
            "2025-06-26 08:42:24,909 Epoch 14762: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14763\n",
            "2025-06-26 08:42:24,910 EPOCH 14763\n",
            "INFO:__main__:Epoch 14763: total training loss 0.00097\n",
            "2025-06-26 08:42:25,000 Epoch 14763: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14764\n",
            "2025-06-26 08:42:25,004 EPOCH 14764\n",
            "INFO:__main__:Epoch 14764: total training loss 0.00096\n",
            "2025-06-26 08:42:25,092 Epoch 14764: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14765\n",
            "2025-06-26 08:42:25,094 EPOCH 14765\n",
            "INFO:__main__:Epoch 14765: total training loss 0.00094\n",
            "2025-06-26 08:42:25,177 Epoch 14765: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14766\n",
            "2025-06-26 08:42:25,182 EPOCH 14766\n",
            "INFO:__main__:Epoch 14766: total training loss 0.00091\n",
            "2025-06-26 08:42:25,294 Epoch 14766: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14767\n",
            "2025-06-26 08:42:25,295 EPOCH 14767\n",
            "INFO:__main__:Epoch 14767: total training loss 0.00091\n",
            "2025-06-26 08:42:25,373 Epoch 14767: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14768\n",
            "2025-06-26 08:42:25,379 EPOCH 14768\n",
            "INFO:__main__:Epoch 14768: total training loss 0.00095\n",
            "2025-06-26 08:42:25,486 Epoch 14768: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14769\n",
            "2025-06-26 08:42:25,495 EPOCH 14769\n",
            "INFO:__main__:Epoch 14769: total training loss 0.00092\n",
            "2025-06-26 08:42:25,576 Epoch 14769: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14770\n",
            "2025-06-26 08:42:25,581 EPOCH 14770\n",
            "INFO:__main__:Epoch 14770: total training loss 0.00090\n",
            "2025-06-26 08:42:25,663 Epoch 14770: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14771\n",
            "2025-06-26 08:42:25,665 EPOCH 14771\n",
            "INFO:__main__:Epoch 14771: total training loss 0.00089\n",
            "2025-06-26 08:42:25,736 Epoch 14771: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14772\n",
            "2025-06-26 08:42:25,738 EPOCH 14772\n",
            "INFO:__main__:Epoch 14772: total training loss 0.00091\n",
            "2025-06-26 08:42:25,809 Epoch 14772: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14773\n",
            "2025-06-26 08:42:25,811 EPOCH 14773\n",
            "INFO:__main__:Epoch 14773: total training loss 0.00096\n",
            "2025-06-26 08:42:25,882 Epoch 14773: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14774\n",
            "2025-06-26 08:42:25,884 EPOCH 14774\n",
            "INFO:__main__:Epoch 14774: total training loss 0.00091\n",
            "2025-06-26 08:42:25,955 Epoch 14774: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14775\n",
            "2025-06-26 08:42:25,958 EPOCH 14775\n",
            "INFO:__main__:Epoch 14775: total training loss 0.00095\n",
            "2025-06-26 08:42:26,026 Epoch 14775: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14776\n",
            "2025-06-26 08:42:26,028 EPOCH 14776\n",
            "INFO:__main__:Epoch 14776: total training loss 0.00097\n",
            "2025-06-26 08:42:26,118 Epoch 14776: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14777\n",
            "2025-06-26 08:42:26,121 EPOCH 14777\n",
            "INFO:__main__:Epoch 14777: total training loss 0.00101\n",
            "2025-06-26 08:42:26,193 Epoch 14777: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14778\n",
            "2025-06-26 08:42:26,195 EPOCH 14778\n",
            "INFO:__main__:Epoch 14778: total training loss 0.00099\n",
            "2025-06-26 08:42:26,264 Epoch 14778: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14779\n",
            "2025-06-26 08:42:26,266 EPOCH 14779\n",
            "INFO:__main__:Epoch 14779: total training loss 0.00099\n",
            "2025-06-26 08:42:26,346 Epoch 14779: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14780\n",
            "2025-06-26 08:42:26,348 EPOCH 14780\n",
            "INFO:__main__:Epoch 14780: total training loss 0.00105\n",
            "2025-06-26 08:42:26,439 Epoch 14780: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 14781\n",
            "2025-06-26 08:42:26,446 EPOCH 14781\n",
            "INFO:__main__:Epoch 14781: total training loss 0.00104\n",
            "2025-06-26 08:42:26,558 Epoch 14781: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14782\n",
            "2025-06-26 08:42:26,563 EPOCH 14782\n",
            "INFO:__main__:Epoch 14782: total training loss 0.00094\n",
            "2025-06-26 08:42:26,673 Epoch 14782: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14783\n",
            "2025-06-26 08:42:26,677 EPOCH 14783\n",
            "INFO:__main__:Epoch 14783: total training loss 0.00098\n",
            "2025-06-26 08:42:26,759 Epoch 14783: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14784\n",
            "2025-06-26 08:42:26,768 EPOCH 14784\n",
            "INFO:__main__:Epoch 14784: total training loss 0.00104\n",
            "2025-06-26 08:42:26,865 Epoch 14784: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14785\n",
            "2025-06-26 08:42:26,870 EPOCH 14785\n",
            "INFO:__main__:Epoch 14785: total training loss 0.00095\n",
            "2025-06-26 08:42:26,966 Epoch 14785: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14786\n",
            "2025-06-26 08:42:26,969 EPOCH 14786\n",
            "INFO:__main__:Epoch 14786: total training loss 0.00094\n",
            "2025-06-26 08:42:27,052 Epoch 14786: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14787\n",
            "2025-06-26 08:42:27,058 EPOCH 14787\n",
            "INFO:__main__:Epoch 14787: total training loss 0.00095\n",
            "2025-06-26 08:42:27,182 Epoch 14787: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14788\n",
            "2025-06-26 08:42:27,184 EPOCH 14788\n",
            "INFO:__main__:Epoch 14788: total training loss 0.00099\n",
            "2025-06-26 08:42:27,326 Epoch 14788: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14789\n",
            "2025-06-26 08:42:27,331 EPOCH 14789\n",
            "INFO:__main__:Epoch 14789: total training loss 0.00099\n",
            "2025-06-26 08:42:27,459 Epoch 14789: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14790\n",
            "2025-06-26 08:42:27,462 EPOCH 14790\n",
            "INFO:__main__:Epoch 14790: total training loss 0.00101\n",
            "2025-06-26 08:42:27,576 Epoch 14790: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14791\n",
            "2025-06-26 08:42:27,579 EPOCH 14791\n",
            "INFO:__main__:Epoch 14791: total training loss 0.00098\n",
            "2025-06-26 08:42:27,708 Epoch 14791: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14792\n",
            "2025-06-26 08:42:27,709 EPOCH 14792\n",
            "INFO:__main__:Epoch 14792: total training loss 0.00101\n",
            "2025-06-26 08:42:27,795 Epoch 14792: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14793\n",
            "2025-06-26 08:42:27,799 EPOCH 14793\n",
            "INFO:__main__:Epoch 14793: total training loss 0.00099\n",
            "2025-06-26 08:42:27,872 Epoch 14793: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14794\n",
            "2025-06-26 08:42:27,874 EPOCH 14794\n",
            "INFO:__main__:Epoch 14794: total training loss 0.00106\n",
            "2025-06-26 08:42:27,947 Epoch 14794: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 14795\n",
            "2025-06-26 08:42:27,949 EPOCH 14795\n",
            "INFO:__main__:Epoch 14795: total training loss 0.00111\n",
            "2025-06-26 08:42:28,026 Epoch 14795: total training loss 0.00111\n",
            "INFO:__main__:EPOCH 14796\n",
            "2025-06-26 08:42:28,028 EPOCH 14796\n",
            "INFO:__main__:Epoch 14796: total training loss 0.00103\n",
            "2025-06-26 08:42:28,109 Epoch 14796: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14797\n",
            "2025-06-26 08:42:28,111 EPOCH 14797\n",
            "INFO:__main__:Epoch 14797: total training loss 0.00102\n",
            "2025-06-26 08:42:28,184 Epoch 14797: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 14798\n",
            "2025-06-26 08:42:28,190 EPOCH 14798\n",
            "INFO:__main__:Epoch 14798: total training loss 0.00107\n",
            "2025-06-26 08:42:28,270 Epoch 14798: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 14799\n",
            "2025-06-26 08:42:28,273 EPOCH 14799\n",
            "INFO:__main__:Epoch 14799: total training loss 0.00108\n",
            "2025-06-26 08:42:28,348 Epoch 14799: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 14800\n",
            "2025-06-26 08:42:28,350 EPOCH 14800\n",
            "INFO:__main__:Epoch 14800: total training loss 0.00112\n",
            "2025-06-26 08:42:28,417 Epoch 14800: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 14801\n",
            "2025-06-26 08:42:28,418 EPOCH 14801\n",
            "INFO:__main__:Epoch 14801: total training loss 0.00104\n",
            "2025-06-26 08:42:28,490 Epoch 14801: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14802\n",
            "2025-06-26 08:42:28,492 EPOCH 14802\n",
            "INFO:__main__:Epoch 14802: total training loss 0.00108\n",
            "2025-06-26 08:42:28,578 Epoch 14802: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 14803\n",
            "2025-06-26 08:42:28,579 EPOCH 14803\n",
            "INFO:__main__:Epoch 14803: total training loss 0.00101\n",
            "2025-06-26 08:42:28,648 Epoch 14803: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14804\n",
            "2025-06-26 08:42:28,650 EPOCH 14804\n",
            "INFO:__main__:Epoch 14804: total training loss 0.00099\n",
            "2025-06-26 08:42:28,719 Epoch 14804: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14805\n",
            "2025-06-26 08:42:28,721 EPOCH 14805\n",
            "INFO:__main__:Epoch 14805: total training loss 0.00103\n",
            "2025-06-26 08:42:28,793 Epoch 14805: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14806\n",
            "2025-06-26 08:42:28,795 EPOCH 14806\n",
            "INFO:__main__:Epoch 14806: total training loss 0.00103\n",
            "2025-06-26 08:42:28,864 Epoch 14806: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14807\n",
            "2025-06-26 08:42:28,866 EPOCH 14807\n",
            "INFO:__main__:Epoch 14807: total training loss 0.00100\n",
            "2025-06-26 08:42:28,943 Epoch 14807: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14808\n",
            "2025-06-26 08:42:28,945 EPOCH 14808\n",
            "INFO:__main__:Epoch 14808: total training loss 0.00098\n",
            "2025-06-26 08:42:29,021 Epoch 14808: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14809\n",
            "2025-06-26 08:42:29,023 EPOCH 14809\n",
            "INFO:__main__:Epoch 14809: total training loss 0.00091\n",
            "2025-06-26 08:42:29,101 Epoch 14809: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14810\n",
            "2025-06-26 08:42:29,104 EPOCH 14810\n",
            "INFO:__main__:Epoch 14810: total training loss 0.00093\n",
            "2025-06-26 08:42:29,181 Epoch 14810: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14811\n",
            "2025-06-26 08:42:29,184 EPOCH 14811\n",
            "INFO:__main__:Epoch 14811: total training loss 0.00092\n",
            "2025-06-26 08:42:29,267 Epoch 14811: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14812\n",
            "2025-06-26 08:42:29,269 EPOCH 14812\n",
            "INFO:__main__:Epoch 14812: total training loss 0.00088\n",
            "2025-06-26 08:42:29,363 Epoch 14812: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 14813\n",
            "2025-06-26 08:42:29,365 EPOCH 14813\n",
            "INFO:__main__:Epoch 14813: total training loss 0.00089\n",
            "2025-06-26 08:42:29,433 Epoch 14813: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14814\n",
            "2025-06-26 08:42:29,435 EPOCH 14814\n",
            "INFO:__main__:Epoch 14814: total training loss 0.00090\n",
            "2025-06-26 08:42:29,513 Epoch 14814: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14815\n",
            "2025-06-26 08:42:29,515 EPOCH 14815\n",
            "INFO:__main__:Epoch 14815: total training loss 0.00090\n",
            "2025-06-26 08:42:29,587 Epoch 14815: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14816\n",
            "2025-06-26 08:42:29,589 EPOCH 14816\n",
            "INFO:__main__:Epoch 14816: total training loss 0.00089\n",
            "2025-06-26 08:42:29,658 Epoch 14816: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14817\n",
            "2025-06-26 08:42:29,660 EPOCH 14817\n",
            "INFO:__main__:Epoch 14817: total training loss 0.00089\n",
            "2025-06-26 08:42:29,736 Epoch 14817: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14818\n",
            "2025-06-26 08:42:29,738 EPOCH 14818\n",
            "INFO:__main__:Epoch 14818: total training loss 0.00093\n",
            "2025-06-26 08:42:29,825 Epoch 14818: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14819\n",
            "2025-06-26 08:42:29,826 EPOCH 14819\n",
            "INFO:__main__:Epoch 14819: total training loss 0.00095\n",
            "2025-06-26 08:42:29,902 Epoch 14819: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14820\n",
            "2025-06-26 08:42:29,904 EPOCH 14820\n",
            "INFO:__main__:Epoch 14820: total training loss 0.00099\n",
            "2025-06-26 08:42:29,979 Epoch 14820: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14821\n",
            "2025-06-26 08:42:29,981 EPOCH 14821\n",
            "INFO:__main__:Epoch 14821: total training loss 0.00092\n",
            "2025-06-26 08:42:30,053 Epoch 14821: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14822\n",
            "2025-06-26 08:42:30,055 EPOCH 14822\n",
            "INFO:__main__:Epoch 14822: total training loss 0.00094\n",
            "2025-06-26 08:42:30,140 Epoch 14822: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14823\n",
            "2025-06-26 08:42:30,142 EPOCH 14823\n",
            "INFO:__main__:Epoch 14823: total training loss 0.00108\n",
            "2025-06-26 08:42:30,227 Epoch 14823: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 14824\n",
            "2025-06-26 08:42:30,229 EPOCH 14824\n",
            "INFO:__main__:Epoch 14824: total training loss 0.00107\n",
            "2025-06-26 08:42:30,307 Epoch 14824: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 14825\n",
            "2025-06-26 08:42:30,310 EPOCH 14825\n",
            "INFO:__main__:Epoch 14825: total training loss 0.00110\n",
            "2025-06-26 08:42:30,402 Epoch 14825: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 14826\n",
            "2025-06-26 08:42:30,404 EPOCH 14826\n",
            "INFO:__main__:Epoch 14826: total training loss 0.00103\n",
            "2025-06-26 08:42:30,481 Epoch 14826: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14827\n",
            "2025-06-26 08:42:30,483 EPOCH 14827\n",
            "INFO:__main__:Epoch 14827: total training loss 0.00103\n",
            "2025-06-26 08:42:30,556 Epoch 14827: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14828\n",
            "2025-06-26 08:42:30,559 EPOCH 14828\n",
            "INFO:__main__:Epoch 14828: total training loss 0.00094\n",
            "2025-06-26 08:42:30,631 Epoch 14828: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14829\n",
            "2025-06-26 08:42:30,633 EPOCH 14829\n",
            "INFO:__main__:Epoch 14829: total training loss 0.00096\n",
            "2025-06-26 08:42:30,711 Epoch 14829: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14830\n",
            "2025-06-26 08:42:30,713 EPOCH 14830\n",
            "INFO:__main__:Epoch 14830: total training loss 0.00096\n",
            "2025-06-26 08:42:30,785 Epoch 14830: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14831\n",
            "2025-06-26 08:42:30,787 EPOCH 14831\n",
            "INFO:__main__:Epoch 14831: total training loss 0.00102\n",
            "2025-06-26 08:42:30,862 Epoch 14831: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 14832\n",
            "2025-06-26 08:42:30,864 EPOCH 14832\n",
            "INFO:__main__:Epoch 14832: total training loss 0.00099\n",
            "2025-06-26 08:42:30,936 Epoch 14832: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14833\n",
            "2025-06-26 08:42:30,938 EPOCH 14833\n",
            "INFO:__main__:Epoch 14833: total training loss 0.00104\n",
            "2025-06-26 08:42:31,008 Epoch 14833: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14834\n",
            "2025-06-26 08:42:31,010 EPOCH 14834\n",
            "INFO:__main__:Epoch 14834: total training loss 0.00105\n",
            "2025-06-26 08:42:31,085 Epoch 14834: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 14835\n",
            "2025-06-26 08:42:31,087 EPOCH 14835\n",
            "INFO:__main__:Epoch 14835: total training loss 0.00100\n",
            "2025-06-26 08:42:31,159 Epoch 14835: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14836\n",
            "2025-06-26 08:42:31,161 EPOCH 14836\n",
            "INFO:__main__:Epoch 14836: total training loss 0.00101\n",
            "2025-06-26 08:42:31,244 Epoch 14836: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14837\n",
            "2025-06-26 08:42:31,246 EPOCH 14837\n",
            "INFO:__main__:Epoch 14837: total training loss 0.00099\n",
            "2025-06-26 08:42:31,320 Epoch 14837: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14838\n",
            "2025-06-26 08:42:31,322 EPOCH 14838\n",
            "INFO:__main__:Epoch 14838: total training loss 0.00092\n",
            "2025-06-26 08:42:31,395 Epoch 14838: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14839\n",
            "2025-06-26 08:42:31,398 EPOCH 14839\n",
            "INFO:__main__:Epoch 14839: total training loss 0.00099\n",
            "2025-06-26 08:42:31,492 Epoch 14839: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14840\n",
            "2025-06-26 08:42:31,495 EPOCH 14840\n",
            "INFO:__main__:Epoch 14840: total training loss 0.00091\n",
            "2025-06-26 08:42:31,567 Epoch 14840: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14841\n",
            "2025-06-26 08:42:31,569 EPOCH 14841\n",
            "INFO:__main__:Epoch 14841: total training loss 0.00087\n",
            "2025-06-26 08:42:31,641 Epoch 14841: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 14842\n",
            "2025-06-26 08:42:31,643 EPOCH 14842\n",
            "INFO:__main__:Epoch 14842: total training loss 0.00093\n",
            "2025-06-26 08:42:31,726 Epoch 14842: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14843\n",
            "2025-06-26 08:42:31,730 EPOCH 14843\n",
            "INFO:__main__:Epoch 14843: total training loss 0.00091\n",
            "2025-06-26 08:42:31,813 Epoch 14843: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14844\n",
            "2025-06-26 08:42:31,815 EPOCH 14844\n",
            "INFO:__main__:Epoch 14844: total training loss 0.00094\n",
            "2025-06-26 08:42:31,890 Epoch 14844: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14845\n",
            "2025-06-26 08:42:31,895 EPOCH 14845\n",
            "INFO:__main__:Epoch 14845: total training loss 0.00096\n",
            "2025-06-26 08:42:31,981 Epoch 14845: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14846\n",
            "2025-06-26 08:42:31,983 EPOCH 14846\n",
            "INFO:__main__:Epoch 14846: total training loss 0.00091\n",
            "2025-06-26 08:42:32,056 Epoch 14846: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14847\n",
            "2025-06-26 08:42:32,058 EPOCH 14847\n",
            "INFO:__main__:Epoch 14847: total training loss 0.00090\n",
            "2025-06-26 08:42:32,132 Epoch 14847: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14848\n",
            "2025-06-26 08:42:32,134 EPOCH 14848\n",
            "INFO:__main__:Epoch 14848: total training loss 0.00096\n",
            "2025-06-26 08:42:32,208 Epoch 14848: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14849\n",
            "2025-06-26 08:42:32,210 EPOCH 14849\n",
            "INFO:__main__:Epoch 14849: total training loss 0.00094\n",
            "2025-06-26 08:42:32,289 Epoch 14849: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14850\n",
            "2025-06-26 08:42:32,291 EPOCH 14850\n",
            "INFO:__main__:Epoch 14850: total training loss 0.00093\n",
            "2025-06-26 08:42:32,368 Epoch 14850: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14851\n",
            "2025-06-26 08:42:32,370 EPOCH 14851\n",
            "INFO:__main__:Epoch 14851: total training loss 0.00092\n",
            "2025-06-26 08:42:32,444 Epoch 14851: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14852\n",
            "2025-06-26 08:42:32,446 EPOCH 14852\n",
            "INFO:__main__:Epoch 14852: total training loss 0.00096\n",
            "2025-06-26 08:42:32,529 Epoch 14852: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14853\n",
            "2025-06-26 08:42:32,532 EPOCH 14853\n",
            "INFO:__main__:Epoch 14853: total training loss 0.00096\n",
            "2025-06-26 08:42:32,609 Epoch 14853: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14854\n",
            "2025-06-26 08:42:32,611 EPOCH 14854\n",
            "INFO:__main__:Epoch 14854: total training loss 0.00095\n",
            "2025-06-26 08:42:32,681 Epoch 14854: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14855\n",
            "2025-06-26 08:42:32,683 EPOCH 14855\n",
            "INFO:__main__:Epoch 14855: total training loss 0.00097\n",
            "2025-06-26 08:42:32,766 Epoch 14855: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14856\n",
            "2025-06-26 08:42:32,769 EPOCH 14856\n",
            "INFO:__main__:Epoch 14856: total training loss 0.00097\n",
            "2025-06-26 08:42:32,844 Epoch 14856: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14857\n",
            "2025-06-26 08:42:32,846 EPOCH 14857\n",
            "INFO:__main__:Epoch 14857: total training loss 0.00100\n",
            "2025-06-26 08:42:32,927 Epoch 14857: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14858\n",
            "2025-06-26 08:42:32,930 EPOCH 14858\n",
            "INFO:__main__:Epoch 14858: total training loss 0.00092\n",
            "2025-06-26 08:42:33,000 Epoch 14858: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14859\n",
            "2025-06-26 08:42:33,002 EPOCH 14859\n",
            "INFO:__main__:Epoch 14859: total training loss 0.00090\n",
            "2025-06-26 08:42:33,082 Epoch 14859: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14860\n",
            "2025-06-26 08:42:33,084 EPOCH 14860\n",
            "INFO:__main__:Epoch 14860: total training loss 0.00093\n",
            "2025-06-26 08:42:33,153 Epoch 14860: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14861\n",
            "2025-06-26 08:42:33,155 EPOCH 14861\n",
            "INFO:__main__:Epoch 14861: total training loss 0.00094\n",
            "2025-06-26 08:42:33,238 Epoch 14861: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14862\n",
            "2025-06-26 08:42:33,240 EPOCH 14862\n",
            "INFO:__main__:Epoch 14862: total training loss 0.00093\n",
            "2025-06-26 08:42:33,321 Epoch 14862: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14863\n",
            "2025-06-26 08:42:33,323 EPOCH 14863\n",
            "INFO:__main__:Epoch 14863: total training loss 0.00097\n",
            "2025-06-26 08:42:33,398 Epoch 14863: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14864\n",
            "2025-06-26 08:42:33,400 EPOCH 14864\n",
            "INFO:__main__:Epoch 14864: total training loss 0.00092\n",
            "2025-06-26 08:42:33,485 Epoch 14864: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14865\n",
            "2025-06-26 08:42:33,489 EPOCH 14865\n",
            "INFO:__main__:Epoch 14865: total training loss 0.00094\n",
            "2025-06-26 08:42:33,573 Epoch 14865: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14866\n",
            "2025-06-26 08:42:33,575 EPOCH 14866\n",
            "INFO:__main__:Epoch 14866: total training loss 0.00096\n",
            "2025-06-26 08:42:33,670 Epoch 14866: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14867\n",
            "2025-06-26 08:42:33,672 EPOCH 14867\n",
            "INFO:__main__:Epoch 14867: total training loss 0.00092\n",
            "2025-06-26 08:42:33,749 Epoch 14867: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14868\n",
            "2025-06-26 08:42:33,751 EPOCH 14868\n",
            "INFO:__main__:Epoch 14868: total training loss 0.00096\n",
            "2025-06-26 08:42:33,822 Epoch 14868: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14869\n",
            "2025-06-26 08:42:33,824 EPOCH 14869\n",
            "INFO:__main__:Epoch 14869: total training loss 0.00093\n",
            "2025-06-26 08:42:33,898 Epoch 14869: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14870\n",
            "2025-06-26 08:42:33,901 EPOCH 14870\n",
            "INFO:__main__:Epoch 14870: total training loss 0.00092\n",
            "2025-06-26 08:42:33,974 Epoch 14870: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14871\n",
            "2025-06-26 08:42:33,976 EPOCH 14871\n",
            "INFO:__main__:Epoch 14871: total training loss 0.00103\n",
            "2025-06-26 08:42:34,062 Epoch 14871: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14872\n",
            "2025-06-26 08:42:34,064 EPOCH 14872\n",
            "INFO:__main__:Epoch 14872: total training loss 0.00101\n",
            "2025-06-26 08:42:34,141 Epoch 14872: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14873\n",
            "2025-06-26 08:42:34,143 EPOCH 14873\n",
            "INFO:__main__:Epoch 14873: total training loss 0.00099\n",
            "2025-06-26 08:42:34,215 Epoch 14873: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14874\n",
            "2025-06-26 08:42:34,218 EPOCH 14874\n",
            "INFO:__main__:Epoch 14874: total training loss 0.00098\n",
            "2025-06-26 08:42:34,300 Epoch 14874: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14875\n",
            "2025-06-26 08:42:34,302 EPOCH 14875\n",
            "INFO:__main__:Epoch 14875: total training loss 0.00099\n",
            "2025-06-26 08:42:34,374 Epoch 14875: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14876\n",
            "2025-06-26 08:42:34,376 EPOCH 14876\n",
            "INFO:__main__:Epoch 14876: total training loss 0.00102\n",
            "2025-06-26 08:42:34,447 Epoch 14876: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 14877\n",
            "2025-06-26 08:42:34,449 EPOCH 14877\n",
            "INFO:__main__:Epoch 14877: total training loss 0.00102\n",
            "2025-06-26 08:42:34,525 Epoch 14877: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 14878\n",
            "2025-06-26 08:42:34,527 EPOCH 14878\n",
            "INFO:__main__:Epoch 14878: total training loss 0.00097\n",
            "2025-06-26 08:42:34,599 Epoch 14878: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14879\n",
            "2025-06-26 08:42:34,601 EPOCH 14879\n",
            "INFO:__main__:Epoch 14879: total training loss 0.00100\n",
            "2025-06-26 08:42:34,698 Epoch 14879: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14880\n",
            "2025-06-26 08:42:34,702 EPOCH 14880\n",
            "INFO:__main__:Epoch 14880: total training loss 0.00096\n",
            "2025-06-26 08:42:34,778 Epoch 14880: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14881\n",
            "2025-06-26 08:42:34,781 EPOCH 14881\n",
            "INFO:__main__:Epoch 14881: total training loss 0.00097\n",
            "2025-06-26 08:42:34,859 Epoch 14881: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14882\n",
            "2025-06-26 08:42:34,861 EPOCH 14882\n",
            "INFO:__main__:Epoch 14882: total training loss 0.00096\n",
            "2025-06-26 08:42:34,935 Epoch 14882: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14883\n",
            "2025-06-26 08:42:34,937 EPOCH 14883\n",
            "INFO:__main__:Epoch 14883: total training loss 0.00090\n",
            "2025-06-26 08:42:35,007 Epoch 14883: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14884\n",
            "2025-06-26 08:42:35,009 EPOCH 14884\n",
            "INFO:__main__:Epoch 14884: total training loss 0.00093\n",
            "2025-06-26 08:42:35,087 Epoch 14884: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14885\n",
            "2025-06-26 08:42:35,089 EPOCH 14885\n",
            "INFO:__main__:Epoch 14885: total training loss 0.00091\n",
            "2025-06-26 08:42:35,158 Epoch 14885: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14886\n",
            "2025-06-26 08:42:35,160 EPOCH 14886\n",
            "INFO:__main__:Epoch 14886: total training loss 0.00092\n",
            "2025-06-26 08:42:35,243 Epoch 14886: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14887\n",
            "2025-06-26 08:42:35,245 EPOCH 14887\n",
            "INFO:__main__:Epoch 14887: total training loss 0.00090\n",
            "2025-06-26 08:42:35,316 Epoch 14887: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14888\n",
            "2025-06-26 08:42:35,319 EPOCH 14888\n",
            "INFO:__main__:Epoch 14888: total training loss 0.00091\n",
            "2025-06-26 08:42:35,395 Epoch 14888: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14889\n",
            "2025-06-26 08:42:35,397 EPOCH 14889\n",
            "INFO:__main__:Epoch 14889: total training loss 0.00094\n",
            "2025-06-26 08:42:35,466 Epoch 14889: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14890\n",
            "2025-06-26 08:42:35,469 EPOCH 14890\n",
            "INFO:__main__:Epoch 14890: total training loss 0.00094\n",
            "2025-06-26 08:42:35,551 Epoch 14890: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14891\n",
            "2025-06-26 08:42:35,553 EPOCH 14891\n",
            "INFO:__main__:Epoch 14891: total training loss 0.00094\n",
            "2025-06-26 08:42:35,626 Epoch 14891: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14892\n",
            "2025-06-26 08:42:35,628 EPOCH 14892\n",
            "INFO:__main__:Epoch 14892: total training loss 0.00086\n",
            "2025-06-26 08:42:35,702 Epoch 14892: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 14893\n",
            "2025-06-26 08:42:35,705 EPOCH 14893\n",
            "INFO:__main__:Epoch 14893: total training loss 0.00091\n",
            "2025-06-26 08:42:35,798 Epoch 14893: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14894\n",
            "2025-06-26 08:42:35,800 EPOCH 14894\n",
            "INFO:__main__:Epoch 14894: total training loss 0.00096\n",
            "2025-06-26 08:42:35,873 Epoch 14894: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14895\n",
            "2025-06-26 08:42:35,875 EPOCH 14895\n",
            "INFO:__main__:Epoch 14895: total training loss 0.00099\n",
            "2025-06-26 08:42:35,950 Epoch 14895: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14896\n",
            "2025-06-26 08:42:35,953 EPOCH 14896\n",
            "INFO:__main__:Epoch 14896: total training loss 0.00094\n",
            "2025-06-26 08:42:36,043 Epoch 14896: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14897\n",
            "2025-06-26 08:42:36,046 EPOCH 14897\n",
            "INFO:__main__:Epoch 14897: total training loss 0.00096\n",
            "2025-06-26 08:42:36,131 Epoch 14897: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14898\n",
            "2025-06-26 08:42:36,137 EPOCH 14898\n",
            "INFO:__main__:Epoch 14898: total training loss 0.00103\n",
            "2025-06-26 08:42:36,218 Epoch 14898: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14899\n",
            "2025-06-26 08:42:36,220 EPOCH 14899\n",
            "INFO:__main__:Epoch 14899: total training loss 0.00103\n",
            "2025-06-26 08:42:36,296 Epoch 14899: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14900\n",
            "2025-06-26 08:42:36,298 EPOCH 14900\n",
            "INFO:__main__:Epoch 14900: total training loss 0.00104\n",
            "2025-06-26 08:42:36,373 Epoch 14900: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14901\n",
            "2025-06-26 08:42:36,377 EPOCH 14901\n",
            "INFO:__main__:Epoch 14901: total training loss 0.00099\n",
            "2025-06-26 08:42:36,466 Epoch 14901: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14902\n",
            "2025-06-26 08:42:36,470 EPOCH 14902\n",
            "INFO:__main__:Epoch 14902: total training loss 0.00090\n",
            "2025-06-26 08:42:36,558 Epoch 14902: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14903\n",
            "2025-06-26 08:42:36,562 EPOCH 14903\n",
            "INFO:__main__:Epoch 14903: total training loss 0.00094\n",
            "2025-06-26 08:42:36,636 Epoch 14903: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14904\n",
            "2025-06-26 08:42:36,639 EPOCH 14904\n",
            "INFO:__main__:Epoch 14904: total training loss 0.00099\n",
            "2025-06-26 08:42:36,713 Epoch 14904: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14905\n",
            "2025-06-26 08:42:36,716 EPOCH 14905\n",
            "INFO:__main__:Epoch 14905: total training loss 0.00092\n",
            "2025-06-26 08:42:36,804 Epoch 14905: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14906\n",
            "2025-06-26 08:42:36,806 EPOCH 14906\n",
            "INFO:__main__:Epoch 14906: total training loss 0.00099\n",
            "2025-06-26 08:42:36,885 Epoch 14906: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14907\n",
            "2025-06-26 08:42:36,887 EPOCH 14907\n",
            "INFO:__main__:Epoch 14907: total training loss 0.00113\n",
            "2025-06-26 08:42:36,970 Epoch 14907: total training loss 0.00113\n",
            "INFO:__main__:EPOCH 14908\n",
            "2025-06-26 08:42:36,975 EPOCH 14908\n",
            "INFO:__main__:Epoch 14908: total training loss 0.00104\n",
            "2025-06-26 08:42:37,055 Epoch 14908: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14909\n",
            "2025-06-26 08:42:37,059 EPOCH 14909\n",
            "INFO:__main__:Epoch 14909: total training loss 0.00099\n",
            "2025-06-26 08:42:37,130 Epoch 14909: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14910\n",
            "2025-06-26 08:42:37,135 EPOCH 14910\n",
            "INFO:__main__:Epoch 14910: total training loss 0.00096\n",
            "2025-06-26 08:42:37,224 Epoch 14910: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14911\n",
            "2025-06-26 08:42:37,226 EPOCH 14911\n",
            "INFO:__main__:Epoch 14911: total training loss 0.00096\n",
            "2025-06-26 08:42:37,308 Epoch 14911: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14912\n",
            "2025-06-26 08:42:37,313 EPOCH 14912\n",
            "INFO:__main__:Epoch 14912: total training loss 0.00097\n",
            "2025-06-26 08:42:37,386 Epoch 14912: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14913\n",
            "2025-06-26 08:42:37,389 EPOCH 14913\n",
            "INFO:__main__:Epoch 14913: total training loss 0.00098\n",
            "2025-06-26 08:42:37,461 Epoch 14913: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14914\n",
            "2025-06-26 08:42:37,463 EPOCH 14914\n",
            "INFO:__main__:Epoch 14914: total training loss 0.00100\n",
            "2025-06-26 08:42:37,540 Epoch 14914: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14915\n",
            "2025-06-26 08:42:37,542 EPOCH 14915\n",
            "INFO:__main__:Epoch 14915: total training loss 0.00095\n",
            "2025-06-26 08:42:37,624 Epoch 14915: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14916\n",
            "2025-06-26 08:42:37,627 EPOCH 14916\n",
            "INFO:__main__:Epoch 14916: total training loss 0.00094\n",
            "2025-06-26 08:42:37,698 Epoch 14916: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14917\n",
            "2025-06-26 08:42:37,701 EPOCH 14917\n",
            "INFO:__main__:Epoch 14917: total training loss 0.00099\n",
            "2025-06-26 08:42:37,787 Epoch 14917: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 14918\n",
            "2025-06-26 08:42:37,790 EPOCH 14918\n",
            "INFO:__main__:Epoch 14918: total training loss 0.00093\n",
            "2025-06-26 08:42:37,883 Epoch 14918: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14919\n",
            "2025-06-26 08:42:37,886 EPOCH 14919\n",
            "INFO:__main__:Epoch 14919: total training loss 0.00094\n",
            "2025-06-26 08:42:37,972 Epoch 14919: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14920\n",
            "2025-06-26 08:42:37,974 EPOCH 14920\n",
            "INFO:__main__:Epoch 14920: total training loss 0.00089\n",
            "2025-06-26 08:42:38,063 Epoch 14920: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14921\n",
            "2025-06-26 08:42:38,065 EPOCH 14921\n",
            "INFO:__main__:Epoch 14921: total training loss 0.00096\n",
            "2025-06-26 08:42:38,144 Epoch 14921: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14922\n",
            "2025-06-26 08:42:38,147 EPOCH 14922\n",
            "INFO:__main__:Epoch 14922: total training loss 0.00089\n",
            "2025-06-26 08:42:38,226 Epoch 14922: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14923\n",
            "2025-06-26 08:42:38,228 EPOCH 14923\n",
            "INFO:__main__:Epoch 14923: total training loss 0.00089\n",
            "2025-06-26 08:42:38,329 Epoch 14923: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14924\n",
            "2025-06-26 08:42:38,331 EPOCH 14924\n",
            "INFO:__main__:Epoch 14924: total training loss 0.00091\n",
            "2025-06-26 08:42:38,443 Epoch 14924: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14925\n",
            "2025-06-26 08:42:38,445 EPOCH 14925\n",
            "INFO:__main__:Epoch 14925: total training loss 0.00092\n",
            "2025-06-26 08:42:38,548 Epoch 14925: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14926\n",
            "2025-06-26 08:42:38,552 EPOCH 14926\n",
            "INFO:__main__:Epoch 14926: total training loss 0.00089\n",
            "2025-06-26 08:42:38,650 Epoch 14926: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14927\n",
            "2025-06-26 08:42:38,652 EPOCH 14927\n",
            "INFO:__main__:Epoch 14927: total training loss 0.00089\n",
            "2025-06-26 08:42:38,766 Epoch 14927: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14928\n",
            "2025-06-26 08:42:38,767 EPOCH 14928\n",
            "INFO:__main__:Epoch 14928: total training loss 0.00091\n",
            "2025-06-26 08:42:38,875 Epoch 14928: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14929\n",
            "2025-06-26 08:42:38,879 EPOCH 14929\n",
            "INFO:__main__:Epoch 14929: total training loss 0.00095\n",
            "2025-06-26 08:42:39,000 Epoch 14929: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14930\n",
            "2025-06-26 08:42:39,006 EPOCH 14930\n",
            "INFO:__main__:Epoch 14930: total training loss 0.00090\n",
            "2025-06-26 08:42:39,110 Epoch 14930: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14931\n",
            "2025-06-26 08:42:39,114 EPOCH 14931\n",
            "INFO:__main__:Epoch 14931: total training loss 0.00098\n",
            "2025-06-26 08:42:39,185 Epoch 14931: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14932\n",
            "2025-06-26 08:42:39,190 EPOCH 14932\n",
            "INFO:__main__:Epoch 14932: total training loss 0.00104\n",
            "2025-06-26 08:42:39,268 Epoch 14932: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14933\n",
            "2025-06-26 08:42:39,274 EPOCH 14933\n",
            "INFO:__main__:Epoch 14933: total training loss 0.00113\n",
            "2025-06-26 08:42:39,354 Epoch 14933: total training loss 0.00113\n",
            "INFO:__main__:EPOCH 14934\n",
            "2025-06-26 08:42:39,359 EPOCH 14934\n",
            "INFO:__main__:Epoch 14934: total training loss 0.00108\n",
            "2025-06-26 08:42:39,456 Epoch 14934: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 14935\n",
            "2025-06-26 08:42:39,461 EPOCH 14935\n",
            "INFO:__main__:Epoch 14935: total training loss 0.00101\n",
            "2025-06-26 08:42:39,570 Epoch 14935: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14936\n",
            "2025-06-26 08:42:39,575 EPOCH 14936\n",
            "INFO:__main__:Epoch 14936: total training loss 0.00100\n",
            "2025-06-26 08:42:39,683 Epoch 14936: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14937\n",
            "2025-06-26 08:42:39,690 EPOCH 14937\n",
            "INFO:__main__:Epoch 14937: total training loss 0.00103\n",
            "2025-06-26 08:42:39,798 Epoch 14937: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14938\n",
            "2025-06-26 08:42:39,804 EPOCH 14938\n",
            "INFO:__main__:Epoch 14938: total training loss 0.00101\n",
            "2025-06-26 08:42:39,924 Epoch 14938: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14939\n",
            "2025-06-26 08:42:39,927 EPOCH 14939\n",
            "INFO:__main__:Epoch 14939: total training loss 0.00105\n",
            "2025-06-26 08:42:40,023 Epoch 14939: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 14940\n",
            "2025-06-26 08:42:40,025 EPOCH 14940\n",
            "INFO:__main__:Epoch 14940: total training loss 0.00097\n",
            "2025-06-26 08:42:40,115 Epoch 14940: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14941\n",
            "2025-06-26 08:42:40,120 EPOCH 14941\n",
            "INFO:__main__:Epoch 14941: total training loss 0.00110\n",
            "2025-06-26 08:42:40,215 Epoch 14941: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 14942\n",
            "2025-06-26 08:42:40,219 EPOCH 14942\n",
            "INFO:__main__:Epoch 14942: total training loss 0.00103\n",
            "2025-06-26 08:42:40,332 Epoch 14942: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14943\n",
            "2025-06-26 08:42:40,338 EPOCH 14943\n",
            "INFO:__main__:Epoch 14943: total training loss 0.00097\n",
            "2025-06-26 08:42:40,412 Epoch 14943: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14944\n",
            "2025-06-26 08:42:40,418 EPOCH 14944\n",
            "INFO:__main__:Epoch 14944: total training loss 0.00097\n",
            "2025-06-26 08:42:40,506 Epoch 14944: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14945\n",
            "2025-06-26 08:42:40,513 EPOCH 14945\n",
            "INFO:__main__:Epoch 14945: total training loss 0.00098\n",
            "2025-06-26 08:42:40,585 Epoch 14945: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14946\n",
            "2025-06-26 08:42:40,590 EPOCH 14946\n",
            "INFO:__main__:Epoch 14946: total training loss 0.00092\n",
            "2025-06-26 08:42:40,664 Epoch 14946: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14947\n",
            "2025-06-26 08:42:40,670 EPOCH 14947\n",
            "INFO:__main__:Epoch 14947: total training loss 0.00096\n",
            "2025-06-26 08:42:40,766 Epoch 14947: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14948\n",
            "2025-06-26 08:42:40,768 EPOCH 14948\n",
            "INFO:__main__:Epoch 14948: total training loss 0.00097\n",
            "2025-06-26 08:42:40,867 Epoch 14948: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14949\n",
            "2025-06-26 08:42:40,875 EPOCH 14949\n",
            "INFO:__main__:Epoch 14949: total training loss 0.00092\n",
            "2025-06-26 08:42:41,001 Epoch 14949: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14950\n",
            "2025-06-26 08:42:41,005 EPOCH 14950\n",
            "INFO:__main__:Epoch 14950: total training loss 0.00090\n",
            "2025-06-26 08:42:41,121 Epoch 14950: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14951\n",
            "2025-06-26 08:42:41,125 EPOCH 14951\n",
            "INFO:__main__:Epoch 14951: total training loss 0.00087\n",
            "2025-06-26 08:42:41,245 Epoch 14951: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 14952\n",
            "2025-06-26 08:42:41,247 EPOCH 14952\n",
            "INFO:__main__:Epoch 14952: total training loss 0.00091\n",
            "2025-06-26 08:42:41,369 Epoch 14952: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14953\n",
            "2025-06-26 08:42:41,371 EPOCH 14953\n",
            "INFO:__main__:Epoch 14953: total training loss 0.00089\n",
            "2025-06-26 08:42:41,470 Epoch 14953: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14954\n",
            "2025-06-26 08:42:41,472 EPOCH 14954\n",
            "INFO:__main__:Epoch 14954: total training loss 0.00091\n",
            "2025-06-26 08:42:41,588 Epoch 14954: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14955\n",
            "2025-06-26 08:42:41,592 EPOCH 14955\n",
            "INFO:__main__:Epoch 14955: total training loss 0.00095\n",
            "2025-06-26 08:42:41,702 Epoch 14955: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14956\n",
            "2025-06-26 08:42:41,706 EPOCH 14956\n",
            "INFO:__main__:Epoch 14956: total training loss 0.00090\n",
            "2025-06-26 08:42:41,824 Epoch 14956: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14957\n",
            "2025-06-26 08:42:41,828 EPOCH 14957\n",
            "INFO:__main__:Epoch 14957: total training loss 0.00091\n",
            "2025-06-26 08:42:41,933 Epoch 14957: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14958\n",
            "2025-06-26 08:42:41,937 EPOCH 14958\n",
            "INFO:__main__:Epoch 14958: total training loss 0.00093\n",
            "2025-06-26 08:42:42,017 Epoch 14958: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 14959\n",
            "2025-06-26 08:42:42,021 EPOCH 14959\n",
            "INFO:__main__:Epoch 14959: total training loss 0.00098\n",
            "2025-06-26 08:42:42,110 Epoch 14959: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14960\n",
            "2025-06-26 08:42:42,116 EPOCH 14960\n",
            "INFO:__main__:Epoch 14960: total training loss 0.00094\n",
            "2025-06-26 08:42:42,214 Epoch 14960: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14961\n",
            "2025-06-26 08:42:42,216 EPOCH 14961\n",
            "INFO:__main__:Epoch 14961: total training loss 0.00092\n",
            "2025-06-26 08:42:42,308 Epoch 14961: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14962\n",
            "2025-06-26 08:42:42,311 EPOCH 14962\n",
            "INFO:__main__:Epoch 14962: total training loss 0.00092\n",
            "2025-06-26 08:42:42,384 Epoch 14962: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 14963\n",
            "2025-06-26 08:42:42,390 EPOCH 14963\n",
            "INFO:__main__:Epoch 14963: total training loss 0.00102\n",
            "2025-06-26 08:42:42,474 Epoch 14963: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 14964\n",
            "2025-06-26 08:42:42,482 EPOCH 14964\n",
            "INFO:__main__:Epoch 14964: total training loss 0.00118\n",
            "2025-06-26 08:42:42,581 Epoch 14964: total training loss 0.00118\n",
            "INFO:__main__:EPOCH 14965\n",
            "2025-06-26 08:42:42,589 EPOCH 14965\n",
            "INFO:__main__:Epoch 14965: total training loss 0.00112\n",
            "2025-06-26 08:42:42,679 Epoch 14965: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 14966\n",
            "2025-06-26 08:42:42,686 EPOCH 14966\n",
            "INFO:__main__:Epoch 14966: total training loss 0.00109\n",
            "2025-06-26 08:42:42,781 Epoch 14966: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 14967\n",
            "2025-06-26 08:42:42,784 EPOCH 14967\n",
            "INFO:__main__:Epoch 14967: total training loss 0.00098\n",
            "2025-06-26 08:42:42,885 Epoch 14967: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14968\n",
            "2025-06-26 08:42:42,892 EPOCH 14968\n",
            "INFO:__main__:Epoch 14968: total training loss 0.00103\n",
            "2025-06-26 08:42:42,961 Epoch 14968: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14969\n",
            "2025-06-26 08:42:42,965 EPOCH 14969\n",
            "INFO:__main__:Epoch 14969: total training loss 0.00103\n",
            "2025-06-26 08:42:43,041 Epoch 14969: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 14970\n",
            "2025-06-26 08:42:43,045 EPOCH 14970\n",
            "INFO:__main__:Epoch 14970: total training loss 0.00104\n",
            "2025-06-26 08:42:43,118 Epoch 14970: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 14971\n",
            "2025-06-26 08:42:43,120 EPOCH 14971\n",
            "INFO:__main__:Epoch 14971: total training loss 0.00097\n",
            "2025-06-26 08:42:43,197 Epoch 14971: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14972\n",
            "2025-06-26 08:42:43,199 EPOCH 14972\n",
            "INFO:__main__:Epoch 14972: total training loss 0.00094\n",
            "2025-06-26 08:42:43,276 Epoch 14972: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14973\n",
            "2025-06-26 08:42:43,278 EPOCH 14973\n",
            "INFO:__main__:Epoch 14973: total training loss 0.00096\n",
            "2025-06-26 08:42:43,389 Epoch 14973: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 14974\n",
            "2025-06-26 08:42:43,395 EPOCH 14974\n",
            "INFO:__main__:Epoch 14974: total training loss 0.00091\n",
            "2025-06-26 08:42:43,476 Epoch 14974: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14975\n",
            "2025-06-26 08:42:43,478 EPOCH 14975\n",
            "INFO:__main__:Epoch 14975: total training loss 0.00095\n",
            "2025-06-26 08:42:43,561 Epoch 14975: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 14976\n",
            "2025-06-26 08:42:43,563 EPOCH 14976\n",
            "INFO:__main__:Epoch 14976: total training loss 0.00089\n",
            "2025-06-26 08:42:43,642 Epoch 14976: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14977\n",
            "2025-06-26 08:42:43,644 EPOCH 14977\n",
            "INFO:__main__:Epoch 14977: total training loss 0.00087\n",
            "2025-06-26 08:42:43,723 Epoch 14977: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 14978\n",
            "2025-06-26 08:42:43,725 EPOCH 14978\n",
            "INFO:__main__:Epoch 14978: total training loss 0.00088\n",
            "2025-06-26 08:42:43,800 Epoch 14978: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 14979\n",
            "2025-06-26 08:42:43,802 EPOCH 14979\n",
            "INFO:__main__:Epoch 14979: total training loss 0.00091\n",
            "2025-06-26 08:42:43,884 Epoch 14979: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14980\n",
            "2025-06-26 08:42:43,886 EPOCH 14980\n",
            "INFO:__main__:Epoch 14980: total training loss 0.00089\n",
            "2025-06-26 08:42:43,976 Epoch 14980: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 14981\n",
            "2025-06-26 08:42:43,978 EPOCH 14981\n",
            "INFO:__main__:Epoch 14981: total training loss 0.00085\n",
            "2025-06-26 08:42:44,050 Epoch 14981: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 14982\n",
            "2025-06-26 08:42:44,052 EPOCH 14982\n",
            "INFO:__main__:Epoch 14982: total training loss 0.00091\n",
            "2025-06-26 08:42:44,125 Epoch 14982: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14983\n",
            "2025-06-26 08:42:44,127 EPOCH 14983\n",
            "INFO:__main__:Epoch 14983: total training loss 0.00094\n",
            "2025-06-26 08:42:44,200 Epoch 14983: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 14984\n",
            "2025-06-26 08:42:44,202 EPOCH 14984\n",
            "INFO:__main__:Epoch 14984: total training loss 0.00091\n",
            "2025-06-26 08:42:44,285 Epoch 14984: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14985\n",
            "2025-06-26 08:42:44,287 EPOCH 14985\n",
            "INFO:__main__:Epoch 14985: total training loss 0.00090\n",
            "2025-06-26 08:42:44,363 Epoch 14985: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 14986\n",
            "2025-06-26 08:42:44,365 EPOCH 14986\n",
            "INFO:__main__:Epoch 14986: total training loss 0.00091\n",
            "2025-06-26 08:42:44,456 Epoch 14986: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 14987\n",
            "2025-06-26 08:42:44,458 EPOCH 14987\n",
            "INFO:__main__:Epoch 14987: total training loss 0.00098\n",
            "2025-06-26 08:42:44,533 Epoch 14987: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 14988\n",
            "2025-06-26 08:42:44,536 EPOCH 14988\n",
            "INFO:__main__:Epoch 14988: total training loss 0.00105\n",
            "2025-06-26 08:42:44,626 Epoch 14988: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 14989\n",
            "2025-06-26 08:42:44,628 EPOCH 14989\n",
            "INFO:__main__:Epoch 14989: total training loss 0.00107\n",
            "2025-06-26 08:42:44,697 Epoch 14989: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 14990\n",
            "2025-06-26 08:42:44,699 EPOCH 14990\n",
            "INFO:__main__:Epoch 14990: total training loss 0.00108\n",
            "2025-06-26 08:42:44,770 Epoch 14990: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 14991\n",
            "2025-06-26 08:42:44,773 EPOCH 14991\n",
            "INFO:__main__:Epoch 14991: total training loss 0.00106\n",
            "2025-06-26 08:42:44,848 Epoch 14991: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 14992\n",
            "2025-06-26 08:42:44,850 EPOCH 14992\n",
            "INFO:__main__:Epoch 14992: total training loss 0.00110\n",
            "2025-06-26 08:42:44,922 Epoch 14992: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 14993\n",
            "2025-06-26 08:42:44,924 EPOCH 14993\n",
            "INFO:__main__:Epoch 14993: total training loss 0.00106\n",
            "2025-06-26 08:42:44,992 Epoch 14993: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 14994\n",
            "2025-06-26 08:42:44,994 EPOCH 14994\n",
            "INFO:__main__:Epoch 14994: total training loss 0.00100\n",
            "2025-06-26 08:42:45,067 Epoch 14994: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14995\n",
            "2025-06-26 08:42:45,069 EPOCH 14995\n",
            "INFO:__main__:Epoch 14995: total training loss 0.00105\n",
            "2025-06-26 08:42:45,144 Epoch 14995: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 14996\n",
            "2025-06-26 08:42:45,146 EPOCH 14996\n",
            "INFO:__main__:Epoch 14996: total training loss 0.00101\n",
            "2025-06-26 08:42:45,233 Epoch 14996: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 14997\n",
            "2025-06-26 08:42:45,235 EPOCH 14997\n",
            "INFO:__main__:Epoch 14997: total training loss 0.00100\n",
            "2025-06-26 08:42:45,305 Epoch 14997: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 14998\n",
            "2025-06-26 08:42:45,307 EPOCH 14998\n",
            "INFO:__main__:Epoch 14998: total training loss 0.00097\n",
            "2025-06-26 08:42:45,377 Epoch 14998: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 14999\n",
            "2025-06-26 08:42:45,379 EPOCH 14999\n",
            "INFO:__main__:Epoch 14999: total training loss 0.00096\n",
            "2025-06-26 08:42:45,448 Epoch 14999: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15000\n",
            "2025-06-26 08:42:45,450 EPOCH 15000\n",
            "INFO:__main__:Epoch 15000 Step:    15000 Batch Loss:     0.000960 Tokens per Sec:  1769127, Lr: 0.001000\n",
            "2025-06-26 08:42:45,532 Epoch 15000 Step:    15000 Batch Loss:     0.000960 Tokens per Sec:  1769127, Lr: 0.001000\n",
            "INFO:__main__:Epoch 15000: total training loss 0.00096\n",
            "2025-06-26 08:42:45,534 Epoch 15000: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15001\n",
            "2025-06-26 08:42:45,536 EPOCH 15001\n",
            "INFO:__main__:Epoch 15001: total training loss 0.00091\n",
            "2025-06-26 08:42:45,611 Epoch 15001: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15002\n",
            "2025-06-26 08:42:45,613 EPOCH 15002\n",
            "INFO:__main__:Epoch 15002: total training loss 0.00089\n",
            "2025-06-26 08:42:45,685 Epoch 15002: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15003\n",
            "2025-06-26 08:42:45,688 EPOCH 15003\n",
            "INFO:__main__:Epoch 15003: total training loss 0.00096\n",
            "2025-06-26 08:42:45,763 Epoch 15003: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15004\n",
            "2025-06-26 08:42:45,765 EPOCH 15004\n",
            "INFO:__main__:Epoch 15004: total training loss 0.00094\n",
            "2025-06-26 08:42:45,840 Epoch 15004: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15005\n",
            "2025-06-26 08:42:45,843 EPOCH 15005\n",
            "INFO:__main__:Epoch 15005: total training loss 0.00093\n",
            "2025-06-26 08:42:45,914 Epoch 15005: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15006\n",
            "2025-06-26 08:42:45,916 EPOCH 15006\n",
            "INFO:__main__:Epoch 15006: total training loss 0.00090\n",
            "2025-06-26 08:42:45,986 Epoch 15006: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15007\n",
            "2025-06-26 08:42:45,988 EPOCH 15007\n",
            "INFO:__main__:Epoch 15007: total training loss 0.00092\n",
            "2025-06-26 08:42:46,058 Epoch 15007: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15008\n",
            "2025-06-26 08:42:46,060 EPOCH 15008\n",
            "INFO:__main__:Epoch 15008: total training loss 0.00094\n",
            "2025-06-26 08:42:46,128 Epoch 15008: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15009\n",
            "2025-06-26 08:42:46,130 EPOCH 15009\n",
            "INFO:__main__:Epoch 15009: total training loss 0.00095\n",
            "2025-06-26 08:42:46,201 Epoch 15009: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15010\n",
            "2025-06-26 08:42:46,203 EPOCH 15010\n",
            "INFO:__main__:Epoch 15010: total training loss 0.00094\n",
            "2025-06-26 08:42:46,272 Epoch 15010: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15011\n",
            "2025-06-26 08:42:46,274 EPOCH 15011\n",
            "INFO:__main__:Epoch 15011: total training loss 0.00097\n",
            "2025-06-26 08:42:46,346 Epoch 15011: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15012\n",
            "2025-06-26 08:42:46,348 EPOCH 15012\n",
            "INFO:__main__:Epoch 15012: total training loss 0.00094\n",
            "2025-06-26 08:42:46,425 Epoch 15012: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15013\n",
            "2025-06-26 08:42:46,427 EPOCH 15013\n",
            "INFO:__main__:Epoch 15013: total training loss 0.00100\n",
            "2025-06-26 08:42:46,499 Epoch 15013: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15014\n",
            "2025-06-26 08:42:46,501 EPOCH 15014\n",
            "INFO:__main__:Epoch 15014: total training loss 0.00102\n",
            "2025-06-26 08:42:46,595 Epoch 15014: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15015\n",
            "2025-06-26 08:42:46,597 EPOCH 15015\n",
            "INFO:__main__:Epoch 15015: total training loss 0.00093\n",
            "2025-06-26 08:42:46,679 Epoch 15015: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15016\n",
            "2025-06-26 08:42:46,681 EPOCH 15016\n",
            "INFO:__main__:Epoch 15016: total training loss 0.00091\n",
            "2025-06-26 08:42:46,752 Epoch 15016: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15017\n",
            "2025-06-26 08:42:46,755 EPOCH 15017\n",
            "INFO:__main__:Epoch 15017: total training loss 0.00091\n",
            "2025-06-26 08:42:46,826 Epoch 15017: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15018\n",
            "2025-06-26 08:42:46,829 EPOCH 15018\n",
            "INFO:__main__:Epoch 15018: total training loss 0.00095\n",
            "2025-06-26 08:42:46,899 Epoch 15018: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15019\n",
            "2025-06-26 08:42:46,901 EPOCH 15019\n",
            "INFO:__main__:Epoch 15019: total training loss 0.00095\n",
            "2025-06-26 08:42:46,975 Epoch 15019: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15020\n",
            "2025-06-26 08:42:46,977 EPOCH 15020\n",
            "INFO:__main__:Epoch 15020: total training loss 0.00101\n",
            "2025-06-26 08:42:47,046 Epoch 15020: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15021\n",
            "2025-06-26 08:42:47,048 EPOCH 15021\n",
            "INFO:__main__:Epoch 15021: total training loss 0.00104\n",
            "2025-06-26 08:42:47,119 Epoch 15021: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15022\n",
            "2025-06-26 08:42:47,121 EPOCH 15022\n",
            "INFO:__main__:Epoch 15022: total training loss 0.00102\n",
            "2025-06-26 08:42:47,202 Epoch 15022: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15023\n",
            "2025-06-26 08:42:47,204 EPOCH 15023\n",
            "INFO:__main__:Epoch 15023: total training loss 0.00096\n",
            "2025-06-26 08:42:47,293 Epoch 15023: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15024\n",
            "2025-06-26 08:42:47,295 EPOCH 15024\n",
            "INFO:__main__:Epoch 15024: total training loss 0.00096\n",
            "2025-06-26 08:42:47,373 Epoch 15024: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15025\n",
            "2025-06-26 08:42:47,377 EPOCH 15025\n",
            "INFO:__main__:Epoch 15025: total training loss 0.00096\n",
            "2025-06-26 08:42:47,449 Epoch 15025: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15026\n",
            "2025-06-26 08:42:47,452 EPOCH 15026\n",
            "INFO:__main__:Epoch 15026: total training loss 0.00094\n",
            "2025-06-26 08:42:47,527 Epoch 15026: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15027\n",
            "2025-06-26 08:42:47,531 EPOCH 15027\n",
            "INFO:__main__:Epoch 15027: total training loss 0.00092\n",
            "2025-06-26 08:42:47,621 Epoch 15027: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15028\n",
            "2025-06-26 08:42:47,623 EPOCH 15028\n",
            "INFO:__main__:Epoch 15028: total training loss 0.00097\n",
            "2025-06-26 08:42:47,713 Epoch 15028: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15029\n",
            "2025-06-26 08:42:47,717 EPOCH 15029\n",
            "INFO:__main__:Epoch 15029: total training loss 0.00092\n",
            "2025-06-26 08:42:47,797 Epoch 15029: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15030\n",
            "2025-06-26 08:42:47,799 EPOCH 15030\n",
            "INFO:__main__:Epoch 15030: total training loss 0.00089\n",
            "2025-06-26 08:42:47,871 Epoch 15030: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15031\n",
            "2025-06-26 08:42:47,873 EPOCH 15031\n",
            "INFO:__main__:Epoch 15031: total training loss 0.00087\n",
            "2025-06-26 08:42:47,947 Epoch 15031: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15032\n",
            "2025-06-26 08:42:47,949 EPOCH 15032\n",
            "INFO:__main__:Epoch 15032: total training loss 0.00088\n",
            "2025-06-26 08:42:48,018 Epoch 15032: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15033\n",
            "2025-06-26 08:42:48,020 EPOCH 15033\n",
            "INFO:__main__:Epoch 15033: total training loss 0.00091\n",
            "2025-06-26 08:42:48,104 Epoch 15033: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15034\n",
            "2025-06-26 08:42:48,106 EPOCH 15034\n",
            "INFO:__main__:Epoch 15034: total training loss 0.00090\n",
            "2025-06-26 08:42:48,185 Epoch 15034: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15035\n",
            "2025-06-26 08:42:48,187 EPOCH 15035\n",
            "INFO:__main__:Epoch 15035: total training loss 0.00090\n",
            "2025-06-26 08:42:48,262 Epoch 15035: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15036\n",
            "2025-06-26 08:42:48,264 EPOCH 15036\n",
            "INFO:__main__:Epoch 15036: total training loss 0.00088\n",
            "2025-06-26 08:42:48,335 Epoch 15036: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15037\n",
            "2025-06-26 08:42:48,337 EPOCH 15037\n",
            "INFO:__main__:Epoch 15037: total training loss 0.00087\n",
            "2025-06-26 08:42:48,408 Epoch 15037: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15038\n",
            "2025-06-26 08:42:48,410 EPOCH 15038\n",
            "INFO:__main__:Epoch 15038: total training loss 0.00086\n",
            "2025-06-26 08:42:48,486 Epoch 15038: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15039\n",
            "2025-06-26 08:42:48,491 EPOCH 15039\n",
            "INFO:__main__:Epoch 15039: total training loss 0.00092\n",
            "2025-06-26 08:42:48,564 Epoch 15039: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15040\n",
            "2025-06-26 08:42:48,567 EPOCH 15040\n",
            "INFO:__main__:Epoch 15040: total training loss 0.00093\n",
            "2025-06-26 08:42:48,642 Epoch 15040: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15041\n",
            "2025-06-26 08:42:48,644 EPOCH 15041\n",
            "INFO:__main__:Epoch 15041: total training loss 0.00091\n",
            "2025-06-26 08:42:48,737 Epoch 15041: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15042\n",
            "2025-06-26 08:42:48,739 EPOCH 15042\n",
            "INFO:__main__:Epoch 15042: total training loss 0.00096\n",
            "2025-06-26 08:42:48,821 Epoch 15042: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15043\n",
            "2025-06-26 08:42:48,823 EPOCH 15043\n",
            "INFO:__main__:Epoch 15043: total training loss 0.00101\n",
            "2025-06-26 08:42:48,899 Epoch 15043: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15044\n",
            "2025-06-26 08:42:48,902 EPOCH 15044\n",
            "INFO:__main__:Epoch 15044: total training loss 0.00093\n",
            "2025-06-26 08:42:48,975 Epoch 15044: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15045\n",
            "2025-06-26 08:42:48,979 EPOCH 15045\n",
            "INFO:__main__:Epoch 15045: total training loss 0.00092\n",
            "2025-06-26 08:42:49,052 Epoch 15045: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15046\n",
            "2025-06-26 08:42:49,057 EPOCH 15046\n",
            "INFO:__main__:Epoch 15046: total training loss 0.00098\n",
            "2025-06-26 08:42:49,136 Epoch 15046: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15047\n",
            "2025-06-26 08:42:49,138 EPOCH 15047\n",
            "INFO:__main__:Epoch 15047: total training loss 0.00103\n",
            "2025-06-26 08:42:49,220 Epoch 15047: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15048\n",
            "2025-06-26 08:42:49,225 EPOCH 15048\n",
            "INFO:__main__:Epoch 15048: total training loss 0.00094\n",
            "2025-06-26 08:42:49,295 Epoch 15048: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15049\n",
            "2025-06-26 08:42:49,297 EPOCH 15049\n",
            "INFO:__main__:Epoch 15049: total training loss 0.00098\n",
            "2025-06-26 08:42:49,386 Epoch 15049: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15050\n",
            "2025-06-26 08:42:49,388 EPOCH 15050\n",
            "INFO:__main__:Epoch 15050: total training loss 0.00095\n",
            "2025-06-26 08:42:49,462 Epoch 15050: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15051\n",
            "2025-06-26 08:42:49,465 EPOCH 15051\n",
            "INFO:__main__:Epoch 15051: total training loss 0.00104\n",
            "2025-06-26 08:42:49,556 Epoch 15051: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15052\n",
            "2025-06-26 08:42:49,561 EPOCH 15052\n",
            "INFO:__main__:Epoch 15052: total training loss 0.00100\n",
            "2025-06-26 08:42:49,639 Epoch 15052: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15053\n",
            "2025-06-26 08:42:49,641 EPOCH 15053\n",
            "INFO:__main__:Epoch 15053: total training loss 0.00100\n",
            "2025-06-26 08:42:49,720 Epoch 15053: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15054\n",
            "2025-06-26 08:42:49,725 EPOCH 15054\n",
            "INFO:__main__:Epoch 15054: total training loss 0.00113\n",
            "2025-06-26 08:42:49,821 Epoch 15054: total training loss 0.00113\n",
            "INFO:__main__:EPOCH 15055\n",
            "2025-06-26 08:42:49,824 EPOCH 15055\n",
            "INFO:__main__:Epoch 15055: total training loss 0.00103\n",
            "2025-06-26 08:42:49,899 Epoch 15055: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15056\n",
            "2025-06-26 08:42:49,901 EPOCH 15056\n",
            "INFO:__main__:Epoch 15056: total training loss 0.00097\n",
            "2025-06-26 08:42:49,983 Epoch 15056: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15057\n",
            "2025-06-26 08:42:49,987 EPOCH 15057\n",
            "INFO:__main__:Epoch 15057: total training loss 0.00105\n",
            "2025-06-26 08:42:50,076 Epoch 15057: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15058\n",
            "2025-06-26 08:42:50,078 EPOCH 15058\n",
            "INFO:__main__:Epoch 15058: total training loss 0.00100\n",
            "2025-06-26 08:42:50,152 Epoch 15058: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15059\n",
            "2025-06-26 08:42:50,154 EPOCH 15059\n",
            "INFO:__main__:Epoch 15059: total training loss 0.00099\n",
            "2025-06-26 08:42:50,227 Epoch 15059: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15060\n",
            "2025-06-26 08:42:50,229 EPOCH 15060\n",
            "INFO:__main__:Epoch 15060: total training loss 0.00105\n",
            "2025-06-26 08:42:50,300 Epoch 15060: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15061\n",
            "2025-06-26 08:42:50,302 EPOCH 15061\n",
            "INFO:__main__:Epoch 15061: total training loss 0.00099\n",
            "2025-06-26 08:42:50,371 Epoch 15061: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15062\n",
            "2025-06-26 08:42:50,374 EPOCH 15062\n",
            "INFO:__main__:Epoch 15062: total training loss 0.00095\n",
            "2025-06-26 08:42:50,445 Epoch 15062: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15063\n",
            "2025-06-26 08:42:50,448 EPOCH 15063\n",
            "INFO:__main__:Epoch 15063: total training loss 0.00099\n",
            "2025-06-26 08:42:50,517 Epoch 15063: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15064\n",
            "2025-06-26 08:42:50,519 EPOCH 15064\n",
            "INFO:__main__:Epoch 15064: total training loss 0.00093\n",
            "2025-06-26 08:42:50,593 Epoch 15064: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15065\n",
            "2025-06-26 08:42:50,595 EPOCH 15065\n",
            "INFO:__main__:Epoch 15065: total training loss 0.00093\n",
            "2025-06-26 08:42:50,666 Epoch 15065: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15066\n",
            "2025-06-26 08:42:50,668 EPOCH 15066\n",
            "INFO:__main__:Epoch 15066: total training loss 0.00094\n",
            "2025-06-26 08:42:50,743 Epoch 15066: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15067\n",
            "2025-06-26 08:42:50,745 EPOCH 15067\n",
            "INFO:__main__:Epoch 15067: total training loss 0.00092\n",
            "2025-06-26 08:42:50,820 Epoch 15067: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15068\n",
            "2025-06-26 08:42:50,822 EPOCH 15068\n",
            "INFO:__main__:Epoch 15068: total training loss 0.00089\n",
            "2025-06-26 08:42:50,911 Epoch 15068: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15069\n",
            "2025-06-26 08:42:50,913 EPOCH 15069\n",
            "INFO:__main__:Epoch 15069: total training loss 0.00086\n",
            "2025-06-26 08:42:50,984 Epoch 15069: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15070\n",
            "2025-06-26 08:42:50,986 EPOCH 15070\n",
            "INFO:__main__:Epoch 15070: total training loss 0.00084\n",
            "2025-06-26 08:42:51,057 Epoch 15070: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15071\n",
            "2025-06-26 08:42:51,060 EPOCH 15071\n",
            "INFO:__main__:Epoch 15071: total training loss 0.00091\n",
            "2025-06-26 08:42:51,131 Epoch 15071: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15072\n",
            "2025-06-26 08:42:51,133 EPOCH 15072\n",
            "INFO:__main__:Epoch 15072: total training loss 0.00088\n",
            "2025-06-26 08:42:51,205 Epoch 15072: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15073\n",
            "2025-06-26 08:42:51,207 EPOCH 15073\n",
            "INFO:__main__:Epoch 15073: total training loss 0.00087\n",
            "2025-06-26 08:42:51,287 Epoch 15073: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15074\n",
            "2025-06-26 08:42:51,289 EPOCH 15074\n",
            "INFO:__main__:Epoch 15074: total training loss 0.00085\n",
            "2025-06-26 08:42:51,362 Epoch 15074: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15075\n",
            "2025-06-26 08:42:51,365 EPOCH 15075\n",
            "INFO:__main__:Epoch 15075: total training loss 0.00088\n",
            "2025-06-26 08:42:51,444 Epoch 15075: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15076\n",
            "2025-06-26 08:42:51,446 EPOCH 15076\n",
            "INFO:__main__:Epoch 15076: total training loss 0.00086\n",
            "2025-06-26 08:42:51,515 Epoch 15076: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15077\n",
            "2025-06-26 08:42:51,522 EPOCH 15077\n",
            "INFO:__main__:Epoch 15077: total training loss 0.00091\n",
            "2025-06-26 08:42:51,601 Epoch 15077: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15078\n",
            "2025-06-26 08:42:51,603 EPOCH 15078\n",
            "INFO:__main__:Epoch 15078: total training loss 0.00095\n",
            "2025-06-26 08:42:51,690 Epoch 15078: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15079\n",
            "2025-06-26 08:42:51,692 EPOCH 15079\n",
            "INFO:__main__:Epoch 15079: total training loss 0.00104\n",
            "2025-06-26 08:42:51,768 Epoch 15079: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15080\n",
            "2025-06-26 08:42:51,770 EPOCH 15080\n",
            "INFO:__main__:Epoch 15080: total training loss 0.00095\n",
            "2025-06-26 08:42:51,843 Epoch 15080: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15081\n",
            "2025-06-26 08:42:51,845 EPOCH 15081\n",
            "INFO:__main__:Epoch 15081: total training loss 0.00090\n",
            "2025-06-26 08:42:51,934 Epoch 15081: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15082\n",
            "2025-06-26 08:42:51,936 EPOCH 15082\n",
            "INFO:__main__:Epoch 15082: total training loss 0.00089\n",
            "2025-06-26 08:42:52,022 Epoch 15082: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15083\n",
            "2025-06-26 08:42:52,026 EPOCH 15083\n",
            "INFO:__main__:Epoch 15083: total training loss 0.00097\n",
            "2025-06-26 08:42:52,099 Epoch 15083: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15084\n",
            "2025-06-26 08:42:52,103 EPOCH 15084\n",
            "INFO:__main__:Epoch 15084: total training loss 0.00091\n",
            "2025-06-26 08:42:52,196 Epoch 15084: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15085\n",
            "2025-06-26 08:42:52,198 EPOCH 15085\n",
            "INFO:__main__:Epoch 15085: total training loss 0.00097\n",
            "2025-06-26 08:42:52,294 Epoch 15085: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15086\n",
            "2025-06-26 08:42:52,296 EPOCH 15086\n",
            "INFO:__main__:Epoch 15086: total training loss 0.00092\n",
            "2025-06-26 08:42:52,368 Epoch 15086: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15087\n",
            "2025-06-26 08:42:52,370 EPOCH 15087\n",
            "INFO:__main__:Epoch 15087: total training loss 0.00087\n",
            "2025-06-26 08:42:52,455 Epoch 15087: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15088\n",
            "2025-06-26 08:42:52,457 EPOCH 15088\n",
            "INFO:__main__:Epoch 15088: total training loss 0.00093\n",
            "2025-06-26 08:42:52,535 Epoch 15088: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15089\n",
            "2025-06-26 08:42:52,537 EPOCH 15089\n",
            "INFO:__main__:Epoch 15089: total training loss 0.00092\n",
            "2025-06-26 08:42:52,619 Epoch 15089: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15090\n",
            "2025-06-26 08:42:52,621 EPOCH 15090\n",
            "INFO:__main__:Epoch 15090: total training loss 0.00103\n",
            "2025-06-26 08:42:52,692 Epoch 15090: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15091\n",
            "2025-06-26 08:42:52,697 EPOCH 15091\n",
            "INFO:__main__:Epoch 15091: total training loss 0.00099\n",
            "2025-06-26 08:42:52,785 Epoch 15091: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15092\n",
            "2025-06-26 08:42:52,787 EPOCH 15092\n",
            "INFO:__main__:Epoch 15092: total training loss 0.00105\n",
            "2025-06-26 08:42:52,863 Epoch 15092: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15093\n",
            "2025-06-26 08:42:52,865 EPOCH 15093\n",
            "INFO:__main__:Epoch 15093: total training loss 0.00107\n",
            "2025-06-26 08:42:52,962 Epoch 15093: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15094\n",
            "2025-06-26 08:42:52,966 EPOCH 15094\n",
            "INFO:__main__:Epoch 15094: total training loss 0.00109\n",
            "2025-06-26 08:42:53,065 Epoch 15094: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15095\n",
            "2025-06-26 08:42:53,067 EPOCH 15095\n",
            "INFO:__main__:Epoch 15095: total training loss 0.00123\n",
            "2025-06-26 08:42:53,159 Epoch 15095: total training loss 0.00123\n",
            "INFO:__main__:EPOCH 15096\n",
            "2025-06-26 08:42:53,165 EPOCH 15096\n",
            "INFO:__main__:Epoch 15096: total training loss 0.00115\n",
            "2025-06-26 08:42:53,257 Epoch 15096: total training loss 0.00115\n",
            "INFO:__main__:EPOCH 15097\n",
            "2025-06-26 08:42:53,261 EPOCH 15097\n",
            "INFO:__main__:Epoch 15097: total training loss 0.00104\n",
            "2025-06-26 08:42:53,347 Epoch 15097: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15098\n",
            "2025-06-26 08:42:53,349 EPOCH 15098\n",
            "INFO:__main__:Epoch 15098: total training loss 0.00108\n",
            "2025-06-26 08:42:53,428 Epoch 15098: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 15099\n",
            "2025-06-26 08:42:53,435 EPOCH 15099\n",
            "INFO:__main__:Epoch 15099: total training loss 0.00107\n",
            "2025-06-26 08:42:53,527 Epoch 15099: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15100\n",
            "2025-06-26 08:42:53,529 EPOCH 15100\n",
            "INFO:__main__:Epoch 15100: total training loss 0.00100\n",
            "2025-06-26 08:42:53,624 Epoch 15100: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15101\n",
            "2025-06-26 08:42:53,628 EPOCH 15101\n",
            "INFO:__main__:Epoch 15101: total training loss 0.00099\n",
            "2025-06-26 08:42:53,713 Epoch 15101: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15102\n",
            "2025-06-26 08:42:53,719 EPOCH 15102\n",
            "INFO:__main__:Epoch 15102: total training loss 0.00095\n",
            "2025-06-26 08:42:53,800 Epoch 15102: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15103\n",
            "2025-06-26 08:42:53,808 EPOCH 15103\n",
            "INFO:__main__:Epoch 15103: total training loss 0.00094\n",
            "2025-06-26 08:42:53,889 Epoch 15103: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15104\n",
            "2025-06-26 08:42:53,894 EPOCH 15104\n",
            "INFO:__main__:Epoch 15104: total training loss 0.00098\n",
            "2025-06-26 08:42:53,980 Epoch 15104: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15105\n",
            "2025-06-26 08:42:53,982 EPOCH 15105\n",
            "INFO:__main__:Epoch 15105: total training loss 0.00090\n",
            "2025-06-26 08:42:54,068 Epoch 15105: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15106\n",
            "2025-06-26 08:42:54,078 EPOCH 15106\n",
            "INFO:__main__:Epoch 15106: total training loss 0.00093\n",
            "2025-06-26 08:42:54,166 Epoch 15106: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15107\n",
            "2025-06-26 08:42:54,171 EPOCH 15107\n",
            "INFO:__main__:Epoch 15107: total training loss 0.00092\n",
            "2025-06-26 08:42:54,281 Epoch 15107: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15108\n",
            "2025-06-26 08:42:54,282 EPOCH 15108\n",
            "INFO:__main__:Epoch 15108: total training loss 0.00090\n",
            "2025-06-26 08:42:54,402 Epoch 15108: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15109\n",
            "2025-06-26 08:42:54,404 EPOCH 15109\n",
            "INFO:__main__:Epoch 15109: total training loss 0.00091\n",
            "2025-06-26 08:42:54,518 Epoch 15109: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15110\n",
            "2025-06-26 08:42:54,520 EPOCH 15110\n",
            "INFO:__main__:Epoch 15110: total training loss 0.00092\n",
            "2025-06-26 08:42:54,632 Epoch 15110: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15111\n",
            "2025-06-26 08:42:54,634 EPOCH 15111\n",
            "INFO:__main__:Epoch 15111: total training loss 0.00095\n",
            "2025-06-26 08:42:54,705 Epoch 15111: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15112\n",
            "2025-06-26 08:42:54,708 EPOCH 15112\n",
            "INFO:__main__:Epoch 15112: total training loss 0.00094\n",
            "2025-06-26 08:42:54,801 Epoch 15112: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15113\n",
            "2025-06-26 08:42:54,804 EPOCH 15113\n",
            "INFO:__main__:Epoch 15113: total training loss 0.00095\n",
            "2025-06-26 08:42:54,903 Epoch 15113: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15114\n",
            "2025-06-26 08:42:54,905 EPOCH 15114\n",
            "INFO:__main__:Epoch 15114: total training loss 0.00091\n",
            "2025-06-26 08:42:55,009 Epoch 15114: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15115\n",
            "2025-06-26 08:42:55,011 EPOCH 15115\n",
            "INFO:__main__:Epoch 15115: total training loss 0.00091\n",
            "2025-06-26 08:42:55,104 Epoch 15115: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15116\n",
            "2025-06-26 08:42:55,106 EPOCH 15116\n",
            "INFO:__main__:Epoch 15116: total training loss 0.00089\n",
            "2025-06-26 08:42:55,196 Epoch 15116: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15117\n",
            "2025-06-26 08:42:55,198 EPOCH 15117\n",
            "INFO:__main__:Epoch 15117: total training loss 0.00086\n",
            "2025-06-26 08:42:55,287 Epoch 15117: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15118\n",
            "2025-06-26 08:42:55,290 EPOCH 15118\n",
            "INFO:__main__:Epoch 15118: total training loss 0.00086\n",
            "2025-06-26 08:42:55,361 Epoch 15118: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15119\n",
            "2025-06-26 08:42:55,363 EPOCH 15119\n",
            "INFO:__main__:Epoch 15119: total training loss 0.00085\n",
            "2025-06-26 08:42:55,445 Epoch 15119: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15120\n",
            "2025-06-26 08:42:55,447 EPOCH 15120\n",
            "INFO:__main__:Epoch 15120: total training loss 0.00084\n",
            "2025-06-26 08:42:55,520 Epoch 15120: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15121\n",
            "2025-06-26 08:42:55,522 EPOCH 15121\n",
            "INFO:__main__:Epoch 15121: total training loss 0.00090\n",
            "2025-06-26 08:42:55,605 Epoch 15121: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15122\n",
            "2025-06-26 08:42:55,608 EPOCH 15122\n",
            "INFO:__main__:Epoch 15122: total training loss 0.00091\n",
            "2025-06-26 08:42:55,679 Epoch 15122: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15123\n",
            "2025-06-26 08:42:55,682 EPOCH 15123\n",
            "INFO:__main__:Epoch 15123: total training loss 0.00088\n",
            "2025-06-26 08:42:55,754 Epoch 15123: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15124\n",
            "2025-06-26 08:42:55,756 EPOCH 15124\n",
            "INFO:__main__:Epoch 15124: total training loss 0.00096\n",
            "2025-06-26 08:42:55,829 Epoch 15124: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15125\n",
            "2025-06-26 08:42:55,831 EPOCH 15125\n",
            "INFO:__main__:Epoch 15125: total training loss 0.00107\n",
            "2025-06-26 08:42:55,908 Epoch 15125: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15126\n",
            "2025-06-26 08:42:55,911 EPOCH 15126\n",
            "INFO:__main__:Epoch 15126: total training loss 0.00105\n",
            "2025-06-26 08:42:55,982 Epoch 15126: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15127\n",
            "2025-06-26 08:42:55,985 EPOCH 15127\n",
            "INFO:__main__:Epoch 15127: total training loss 0.00103\n",
            "2025-06-26 08:42:56,060 Epoch 15127: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15128\n",
            "2025-06-26 08:42:56,062 EPOCH 15128\n",
            "INFO:__main__:Epoch 15128: total training loss 0.00099\n",
            "2025-06-26 08:42:56,145 Epoch 15128: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15129\n",
            "2025-06-26 08:42:56,147 EPOCH 15129\n",
            "INFO:__main__:Epoch 15129: total training loss 0.00095\n",
            "2025-06-26 08:42:56,242 Epoch 15129: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15130\n",
            "2025-06-26 08:42:56,244 EPOCH 15130\n",
            "INFO:__main__:Epoch 15130: total training loss 0.00097\n",
            "2025-06-26 08:42:56,319 Epoch 15130: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15131\n",
            "2025-06-26 08:42:56,321 EPOCH 15131\n",
            "INFO:__main__:Epoch 15131: total training loss 0.00098\n",
            "2025-06-26 08:42:56,395 Epoch 15131: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15132\n",
            "2025-06-26 08:42:56,397 EPOCH 15132\n",
            "INFO:__main__:Epoch 15132: total training loss 0.00102\n",
            "2025-06-26 08:42:56,507 Epoch 15132: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15133\n",
            "2025-06-26 08:42:56,508 EPOCH 15133\n",
            "INFO:__main__:Epoch 15133: total training loss 0.00105\n",
            "2025-06-26 08:42:56,621 Epoch 15133: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15134\n",
            "2025-06-26 08:42:56,622 EPOCH 15134\n",
            "INFO:__main__:Epoch 15134: total training loss 0.00095\n",
            "2025-06-26 08:42:56,735 Epoch 15134: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15135\n",
            "2025-06-26 08:42:56,737 EPOCH 15135\n",
            "INFO:__main__:Epoch 15135: total training loss 0.00102\n",
            "2025-06-26 08:42:56,854 Epoch 15135: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15136\n",
            "2025-06-26 08:42:56,858 EPOCH 15136\n",
            "INFO:__main__:Epoch 15136: total training loss 0.00098\n",
            "2025-06-26 08:42:56,972 Epoch 15136: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15137\n",
            "2025-06-26 08:42:56,973 EPOCH 15137\n",
            "INFO:__main__:Epoch 15137: total training loss 0.00101\n",
            "2025-06-26 08:42:57,078 Epoch 15137: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15138\n",
            "2025-06-26 08:42:57,084 EPOCH 15138\n",
            "INFO:__main__:Epoch 15138: total training loss 0.00100\n",
            "2025-06-26 08:42:57,202 Epoch 15138: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15139\n",
            "2025-06-26 08:42:57,203 EPOCH 15139\n",
            "INFO:__main__:Epoch 15139: total training loss 0.00098\n",
            "2025-06-26 08:42:57,324 Epoch 15139: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15140\n",
            "2025-06-26 08:42:57,326 EPOCH 15140\n",
            "INFO:__main__:Epoch 15140: total training loss 0.00098\n",
            "2025-06-26 08:42:57,450 Epoch 15140: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15141\n",
            "2025-06-26 08:42:57,452 EPOCH 15141\n",
            "INFO:__main__:Epoch 15141: total training loss 0.00092\n",
            "2025-06-26 08:42:57,564 Epoch 15141: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15142\n",
            "2025-06-26 08:42:57,567 EPOCH 15142\n",
            "INFO:__main__:Epoch 15142: total training loss 0.00100\n",
            "2025-06-26 08:42:57,694 Epoch 15142: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15143\n",
            "2025-06-26 08:42:57,697 EPOCH 15143\n",
            "INFO:__main__:Epoch 15143: total training loss 0.00096\n",
            "2025-06-26 08:42:57,810 Epoch 15143: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15144\n",
            "2025-06-26 08:42:57,813 EPOCH 15144\n",
            "INFO:__main__:Epoch 15144: total training loss 0.00087\n",
            "2025-06-26 08:42:57,910 Epoch 15144: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15145\n",
            "2025-06-26 08:42:57,913 EPOCH 15145\n",
            "INFO:__main__:Epoch 15145: total training loss 0.00093\n",
            "2025-06-26 08:42:58,015 Epoch 15145: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15146\n",
            "2025-06-26 08:42:58,023 EPOCH 15146\n",
            "INFO:__main__:Epoch 15146: total training loss 0.00091\n",
            "2025-06-26 08:42:58,155 Epoch 15146: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15147\n",
            "2025-06-26 08:42:58,159 EPOCH 15147\n",
            "INFO:__main__:Epoch 15147: total training loss 0.00090\n",
            "2025-06-26 08:42:58,296 Epoch 15147: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15148\n",
            "2025-06-26 08:42:58,298 EPOCH 15148\n",
            "INFO:__main__:Epoch 15148: total training loss 0.00087\n",
            "2025-06-26 08:42:58,420 Epoch 15148: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15149\n",
            "2025-06-26 08:42:58,422 EPOCH 15149\n",
            "INFO:__main__:Epoch 15149: total training loss 0.00087\n",
            "2025-06-26 08:42:58,542 Epoch 15149: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15150\n",
            "2025-06-26 08:42:58,549 EPOCH 15150\n",
            "INFO:__main__:Epoch 15150: total training loss 0.00086\n",
            "2025-06-26 08:42:58,658 Epoch 15150: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15151\n",
            "2025-06-26 08:42:58,660 EPOCH 15151\n",
            "INFO:__main__:Epoch 15151: total training loss 0.00090\n",
            "2025-06-26 08:42:58,738 Epoch 15151: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15152\n",
            "2025-06-26 08:42:58,740 EPOCH 15152\n",
            "INFO:__main__:Epoch 15152: total training loss 0.00093\n",
            "2025-06-26 08:42:58,812 Epoch 15152: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15153\n",
            "2025-06-26 08:42:58,814 EPOCH 15153\n",
            "INFO:__main__:Epoch 15153: total training loss 0.00086\n",
            "2025-06-26 08:42:58,885 Epoch 15153: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15154\n",
            "2025-06-26 08:42:58,887 EPOCH 15154\n",
            "INFO:__main__:Epoch 15154: total training loss 0.00093\n",
            "2025-06-26 08:42:58,970 Epoch 15154: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15155\n",
            "2025-06-26 08:42:58,972 EPOCH 15155\n",
            "INFO:__main__:Epoch 15155: total training loss 0.00097\n",
            "2025-06-26 08:42:59,048 Epoch 15155: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15156\n",
            "2025-06-26 08:42:59,051 EPOCH 15156\n",
            "INFO:__main__:Epoch 15156: total training loss 0.00100\n",
            "2025-06-26 08:42:59,126 Epoch 15156: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15157\n",
            "2025-06-26 08:42:59,127 EPOCH 15157\n",
            "INFO:__main__:Epoch 15157: total training loss 0.00110\n",
            "2025-06-26 08:42:59,199 Epoch 15157: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 15158\n",
            "2025-06-26 08:42:59,201 EPOCH 15158\n",
            "INFO:__main__:Epoch 15158: total training loss 0.00109\n",
            "2025-06-26 08:42:59,269 Epoch 15158: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15159\n",
            "2025-06-26 08:42:59,271 EPOCH 15159\n",
            "INFO:__main__:Epoch 15159: total training loss 0.00105\n",
            "2025-06-26 08:42:59,340 Epoch 15159: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15160\n",
            "2025-06-26 08:42:59,342 EPOCH 15160\n",
            "INFO:__main__:Epoch 15160: total training loss 0.00103\n",
            "2025-06-26 08:42:59,411 Epoch 15160: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15161\n",
            "2025-06-26 08:42:59,414 EPOCH 15161\n",
            "INFO:__main__:Epoch 15161: total training loss 0.00106\n",
            "2025-06-26 08:42:59,499 Epoch 15161: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15162\n",
            "2025-06-26 08:42:59,501 EPOCH 15162\n",
            "INFO:__main__:Epoch 15162: total training loss 0.00118\n",
            "2025-06-26 08:42:59,580 Epoch 15162: total training loss 0.00118\n",
            "INFO:__main__:EPOCH 15163\n",
            "2025-06-26 08:42:59,582 EPOCH 15163\n",
            "INFO:__main__:Epoch 15163: total training loss 0.00112\n",
            "2025-06-26 08:42:59,655 Epoch 15163: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 15164\n",
            "2025-06-26 08:42:59,657 EPOCH 15164\n",
            "INFO:__main__:Epoch 15164: total training loss 0.00106\n",
            "2025-06-26 08:42:59,740 Epoch 15164: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15165\n",
            "2025-06-26 08:42:59,742 EPOCH 15165\n",
            "INFO:__main__:Epoch 15165: total training loss 0.00103\n",
            "2025-06-26 08:42:59,815 Epoch 15165: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15166\n",
            "2025-06-26 08:42:59,817 EPOCH 15166\n",
            "INFO:__main__:Epoch 15166: total training loss 0.00106\n",
            "2025-06-26 08:42:59,888 Epoch 15166: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15167\n",
            "2025-06-26 08:42:59,890 EPOCH 15167\n",
            "INFO:__main__:Epoch 15167: total training loss 0.00099\n",
            "2025-06-26 08:42:59,962 Epoch 15167: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15168\n",
            "2025-06-26 08:42:59,964 EPOCH 15168\n",
            "INFO:__main__:Epoch 15168: total training loss 0.00094\n",
            "2025-06-26 08:43:00,038 Epoch 15168: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15169\n",
            "2025-06-26 08:43:00,040 EPOCH 15169\n",
            "INFO:__main__:Epoch 15169: total training loss 0.00097\n",
            "2025-06-26 08:43:00,117 Epoch 15169: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15170\n",
            "2025-06-26 08:43:00,119 EPOCH 15170\n",
            "INFO:__main__:Epoch 15170: total training loss 0.00094\n",
            "2025-06-26 08:43:00,207 Epoch 15170: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15171\n",
            "2025-06-26 08:43:00,209 EPOCH 15171\n",
            "INFO:__main__:Epoch 15171: total training loss 0.00093\n",
            "2025-06-26 08:43:00,279 Epoch 15171: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15172\n",
            "2025-06-26 08:43:00,281 EPOCH 15172\n",
            "INFO:__main__:Epoch 15172: total training loss 0.00094\n",
            "2025-06-26 08:43:00,368 Epoch 15172: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15173\n",
            "2025-06-26 08:43:00,370 EPOCH 15173\n",
            "INFO:__main__:Epoch 15173: total training loss 0.00090\n",
            "2025-06-26 08:43:00,440 Epoch 15173: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15174\n",
            "2025-06-26 08:43:00,442 EPOCH 15174\n",
            "INFO:__main__:Epoch 15174: total training loss 0.00090\n",
            "2025-06-26 08:43:00,518 Epoch 15174: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15175\n",
            "2025-06-26 08:43:00,520 EPOCH 15175\n",
            "INFO:__main__:Epoch 15175: total training loss 0.00089\n",
            "2025-06-26 08:43:00,599 Epoch 15175: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15176\n",
            "2025-06-26 08:43:00,601 EPOCH 15176\n",
            "INFO:__main__:Epoch 15176: total training loss 0.00089\n",
            "2025-06-26 08:43:00,673 Epoch 15176: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15177\n",
            "2025-06-26 08:43:00,675 EPOCH 15177\n",
            "INFO:__main__:Epoch 15177: total training loss 0.00087\n",
            "2025-06-26 08:43:00,747 Epoch 15177: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15178\n",
            "2025-06-26 08:43:00,749 EPOCH 15178\n",
            "INFO:__main__:Epoch 15178: total training loss 0.00086\n",
            "2025-06-26 08:43:00,824 Epoch 15178: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15179\n",
            "2025-06-26 08:43:00,826 EPOCH 15179\n",
            "INFO:__main__:Epoch 15179: total training loss 0.00089\n",
            "2025-06-26 08:43:00,897 Epoch 15179: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15180\n",
            "2025-06-26 08:43:00,899 EPOCH 15180\n",
            "INFO:__main__:Epoch 15180: total training loss 0.00090\n",
            "2025-06-26 08:43:00,970 Epoch 15180: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15181\n",
            "2025-06-26 08:43:00,972 EPOCH 15181\n",
            "INFO:__main__:Epoch 15181: total training loss 0.00089\n",
            "2025-06-26 08:43:01,044 Epoch 15181: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15182\n",
            "2025-06-26 08:43:01,046 EPOCH 15182\n",
            "INFO:__main__:Epoch 15182: total training loss 0.00094\n",
            "2025-06-26 08:43:01,116 Epoch 15182: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15183\n",
            "2025-06-26 08:43:01,118 EPOCH 15183\n",
            "INFO:__main__:Epoch 15183: total training loss 0.00109\n",
            "2025-06-26 08:43:01,188 Epoch 15183: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15184\n",
            "2025-06-26 08:43:01,190 EPOCH 15184\n",
            "INFO:__main__:Epoch 15184: total training loss 0.00105\n",
            "2025-06-26 08:43:01,261 Epoch 15184: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15185\n",
            "2025-06-26 08:43:01,264 EPOCH 15185\n",
            "INFO:__main__:Epoch 15185: total training loss 0.00116\n",
            "2025-06-26 08:43:01,337 Epoch 15185: total training loss 0.00116\n",
            "INFO:__main__:EPOCH 15186\n",
            "2025-06-26 08:43:01,339 EPOCH 15186\n",
            "INFO:__main__:Epoch 15186: total training loss 0.00108\n",
            "2025-06-26 08:43:01,410 Epoch 15186: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 15187\n",
            "2025-06-26 08:43:01,412 EPOCH 15187\n",
            "INFO:__main__:Epoch 15187: total training loss 0.00118\n",
            "2025-06-26 08:43:01,483 Epoch 15187: total training loss 0.00118\n",
            "INFO:__main__:EPOCH 15188\n",
            "2025-06-26 08:43:01,485 EPOCH 15188\n",
            "INFO:__main__:Epoch 15188: total training loss 0.00104\n",
            "2025-06-26 08:43:01,554 Epoch 15188: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15189\n",
            "2025-06-26 08:43:01,556 EPOCH 15189\n",
            "INFO:__main__:Epoch 15189: total training loss 0.00115\n",
            "2025-06-26 08:43:01,649 Epoch 15189: total training loss 0.00115\n",
            "INFO:__main__:EPOCH 15190\n",
            "2025-06-26 08:43:01,651 EPOCH 15190\n",
            "INFO:__main__:Epoch 15190: total training loss 0.00104\n",
            "2025-06-26 08:43:01,727 Epoch 15190: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15191\n",
            "2025-06-26 08:43:01,729 EPOCH 15191\n",
            "INFO:__main__:Epoch 15191: total training loss 0.00110\n",
            "2025-06-26 08:43:01,798 Epoch 15191: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 15192\n",
            "2025-06-26 08:43:01,800 EPOCH 15192\n",
            "INFO:__main__:Epoch 15192: total training loss 0.00101\n",
            "2025-06-26 08:43:01,872 Epoch 15192: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15193\n",
            "2025-06-26 08:43:01,874 EPOCH 15193\n",
            "INFO:__main__:Epoch 15193: total training loss 0.00100\n",
            "2025-06-26 08:43:01,944 Epoch 15193: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15194\n",
            "2025-06-26 08:43:01,946 EPOCH 15194\n",
            "INFO:__main__:Epoch 15194: total training loss 0.00094\n",
            "2025-06-26 08:43:02,018 Epoch 15194: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15195\n",
            "2025-06-26 08:43:02,021 EPOCH 15195\n",
            "INFO:__main__:Epoch 15195: total training loss 0.00098\n",
            "2025-06-26 08:43:02,094 Epoch 15195: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15196\n",
            "2025-06-26 08:43:02,096 EPOCH 15196\n",
            "INFO:__main__:Epoch 15196: total training loss 0.00095\n",
            "2025-06-26 08:43:02,167 Epoch 15196: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15197\n",
            "2025-06-26 08:43:02,170 EPOCH 15197\n",
            "INFO:__main__:Epoch 15197: total training loss 0.00090\n",
            "2025-06-26 08:43:02,250 Epoch 15197: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15198\n",
            "2025-06-26 08:43:02,252 EPOCH 15198\n",
            "INFO:__main__:Epoch 15198: total training loss 0.00097\n",
            "2025-06-26 08:43:02,324 Epoch 15198: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15199\n",
            "2025-06-26 08:43:02,327 EPOCH 15199\n",
            "INFO:__main__:Epoch 15199: total training loss 0.00095\n",
            "2025-06-26 08:43:02,396 Epoch 15199: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15200\n",
            "2025-06-26 08:43:02,398 EPOCH 15200\n",
            "INFO:__main__:Epoch 15200: total training loss 0.00099\n",
            "2025-06-26 08:43:02,466 Epoch 15200: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15201\n",
            "2025-06-26 08:43:02,469 EPOCH 15201\n",
            "INFO:__main__:Epoch 15201: total training loss 0.00095\n",
            "2025-06-26 08:43:02,540 Epoch 15201: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15202\n",
            "2025-06-26 08:43:02,542 EPOCH 15202\n",
            "INFO:__main__:Epoch 15202: total training loss 0.00095\n",
            "2025-06-26 08:43:02,615 Epoch 15202: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15203\n",
            "2025-06-26 08:43:02,617 EPOCH 15203\n",
            "INFO:__main__:Epoch 15203: total training loss 0.00089\n",
            "2025-06-26 08:43:02,693 Epoch 15203: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15204\n",
            "2025-06-26 08:43:02,695 EPOCH 15204\n",
            "INFO:__main__:Epoch 15204: total training loss 0.00093\n",
            "2025-06-26 08:43:02,782 Epoch 15204: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15205\n",
            "2025-06-26 08:43:02,784 EPOCH 15205\n",
            "INFO:__main__:Epoch 15205: total training loss 0.00094\n",
            "2025-06-26 08:43:02,855 Epoch 15205: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15206\n",
            "2025-06-26 08:43:02,857 EPOCH 15206\n",
            "INFO:__main__:Epoch 15206: total training loss 0.00088\n",
            "2025-06-26 08:43:02,931 Epoch 15206: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15207\n",
            "2025-06-26 08:43:02,932 EPOCH 15207\n",
            "INFO:__main__:Epoch 15207: total training loss 0.00097\n",
            "2025-06-26 08:43:03,002 Epoch 15207: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15208\n",
            "2025-06-26 08:43:03,004 EPOCH 15208\n",
            "INFO:__main__:Epoch 15208: total training loss 0.00100\n",
            "2025-06-26 08:43:03,076 Epoch 15208: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15209\n",
            "2025-06-26 08:43:03,079 EPOCH 15209\n",
            "INFO:__main__:Epoch 15209: total training loss 0.00098\n",
            "2025-06-26 08:43:03,150 Epoch 15209: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15210\n",
            "2025-06-26 08:43:03,152 EPOCH 15210\n",
            "INFO:__main__:Epoch 15210: total training loss 0.00098\n",
            "2025-06-26 08:43:03,225 Epoch 15210: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15211\n",
            "2025-06-26 08:43:03,227 EPOCH 15211\n",
            "INFO:__main__:Epoch 15211: total training loss 0.00100\n",
            "2025-06-26 08:43:03,297 Epoch 15211: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15212\n",
            "2025-06-26 08:43:03,299 EPOCH 15212\n",
            "INFO:__main__:Epoch 15212: total training loss 0.00108\n",
            "2025-06-26 08:43:03,370 Epoch 15212: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 15213\n",
            "2025-06-26 08:43:03,372 EPOCH 15213\n",
            "INFO:__main__:Epoch 15213: total training loss 0.00099\n",
            "2025-06-26 08:43:03,441 Epoch 15213: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15214\n",
            "2025-06-26 08:43:03,443 EPOCH 15214\n",
            "INFO:__main__:Epoch 15214: total training loss 0.00098\n",
            "2025-06-26 08:43:03,513 Epoch 15214: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15215\n",
            "2025-06-26 08:43:03,515 EPOCH 15215\n",
            "INFO:__main__:Epoch 15215: total training loss 0.00098\n",
            "2025-06-26 08:43:03,584 Epoch 15215: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15216\n",
            "2025-06-26 08:43:03,586 EPOCH 15216\n",
            "INFO:__main__:Epoch 15216: total training loss 0.00102\n",
            "2025-06-26 08:43:03,658 Epoch 15216: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15217\n",
            "2025-06-26 08:43:03,660 EPOCH 15217\n",
            "INFO:__main__:Epoch 15217: total training loss 0.00092\n",
            "2025-06-26 08:43:03,729 Epoch 15217: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15218\n",
            "2025-06-26 08:43:03,731 EPOCH 15218\n",
            "INFO:__main__:Epoch 15218: total training loss 0.00092\n",
            "2025-06-26 08:43:03,806 Epoch 15218: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15219\n",
            "2025-06-26 08:43:03,808 EPOCH 15219\n",
            "INFO:__main__:Epoch 15219: total training loss 0.00095\n",
            "2025-06-26 08:43:03,893 Epoch 15219: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15220\n",
            "2025-06-26 08:43:03,895 EPOCH 15220\n",
            "INFO:__main__:Epoch 15220: total training loss 0.00092\n",
            "2025-06-26 08:43:03,965 Epoch 15220: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15221\n",
            "2025-06-26 08:43:03,967 EPOCH 15221\n",
            "INFO:__main__:Epoch 15221: total training loss 0.00093\n",
            "2025-06-26 08:43:04,040 Epoch 15221: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15222\n",
            "2025-06-26 08:43:04,043 EPOCH 15222\n",
            "INFO:__main__:Epoch 15222: total training loss 0.00087\n",
            "2025-06-26 08:43:04,114 Epoch 15222: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15223\n",
            "2025-06-26 08:43:04,116 EPOCH 15223\n",
            "INFO:__main__:Epoch 15223: total training loss 0.00090\n",
            "2025-06-26 08:43:04,185 Epoch 15223: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15224\n",
            "2025-06-26 08:43:04,188 EPOCH 15224\n",
            "INFO:__main__:Epoch 15224: total training loss 0.00100\n",
            "2025-06-26 08:43:04,259 Epoch 15224: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15225\n",
            "2025-06-26 08:43:04,261 EPOCH 15225\n",
            "INFO:__main__:Epoch 15225: total training loss 0.00099\n",
            "2025-06-26 08:43:04,334 Epoch 15225: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15226\n",
            "2025-06-26 08:43:04,336 EPOCH 15226\n",
            "INFO:__main__:Epoch 15226: total training loss 0.00094\n",
            "2025-06-26 08:43:04,407 Epoch 15226: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15227\n",
            "2025-06-26 08:43:04,409 EPOCH 15227\n",
            "INFO:__main__:Epoch 15227: total training loss 0.00092\n",
            "2025-06-26 08:43:04,478 Epoch 15227: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15228\n",
            "2025-06-26 08:43:04,480 EPOCH 15228\n",
            "INFO:__main__:Epoch 15228: total training loss 0.00086\n",
            "2025-06-26 08:43:04,549 Epoch 15228: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15229\n",
            "2025-06-26 08:43:04,551 EPOCH 15229\n",
            "INFO:__main__:Epoch 15229: total training loss 0.00090\n",
            "2025-06-26 08:43:04,626 Epoch 15229: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15230\n",
            "2025-06-26 08:43:04,628 EPOCH 15230\n",
            "INFO:__main__:Epoch 15230: total training loss 0.00092\n",
            "2025-06-26 08:43:04,699 Epoch 15230: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15231\n",
            "2025-06-26 08:43:04,701 EPOCH 15231\n",
            "INFO:__main__:Epoch 15231: total training loss 0.00087\n",
            "2025-06-26 08:43:04,771 Epoch 15231: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15232\n",
            "2025-06-26 08:43:04,773 EPOCH 15232\n",
            "INFO:__main__:Epoch 15232: total training loss 0.00091\n",
            "2025-06-26 08:43:04,842 Epoch 15232: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15233\n",
            "2025-06-26 08:43:04,844 EPOCH 15233\n",
            "INFO:__main__:Epoch 15233: total training loss 0.00089\n",
            "2025-06-26 08:43:04,932 Epoch 15233: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15234\n",
            "2025-06-26 08:43:04,936 EPOCH 15234\n",
            "INFO:__main__:Epoch 15234: total training loss 0.00088\n",
            "2025-06-26 08:43:05,022 Epoch 15234: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15235\n",
            "2025-06-26 08:43:05,024 EPOCH 15235\n",
            "INFO:__main__:Epoch 15235: total training loss 0.00086\n",
            "2025-06-26 08:43:05,102 Epoch 15235: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15236\n",
            "2025-06-26 08:43:05,104 EPOCH 15236\n",
            "INFO:__main__:Epoch 15236: total training loss 0.00098\n",
            "2025-06-26 08:43:05,188 Epoch 15236: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15237\n",
            "2025-06-26 08:43:05,190 EPOCH 15237\n",
            "INFO:__main__:Epoch 15237: total training loss 0.00095\n",
            "2025-06-26 08:43:05,273 Epoch 15237: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15238\n",
            "2025-06-26 08:43:05,275 EPOCH 15238\n",
            "INFO:__main__:Epoch 15238: total training loss 0.00098\n",
            "2025-06-26 08:43:05,349 Epoch 15238: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15239\n",
            "2025-06-26 08:43:05,351 EPOCH 15239\n",
            "INFO:__main__:Epoch 15239: total training loss 0.00095\n",
            "2025-06-26 08:43:05,428 Epoch 15239: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15240\n",
            "2025-06-26 08:43:05,431 EPOCH 15240\n",
            "INFO:__main__:Epoch 15240: total training loss 0.00094\n",
            "2025-06-26 08:43:05,504 Epoch 15240: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15241\n",
            "2025-06-26 08:43:05,506 EPOCH 15241\n",
            "INFO:__main__:Epoch 15241: total training loss 0.00088\n",
            "2025-06-26 08:43:05,579 Epoch 15241: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15242\n",
            "2025-06-26 08:43:05,581 EPOCH 15242\n",
            "INFO:__main__:Epoch 15242: total training loss 0.00096\n",
            "2025-06-26 08:43:05,658 Epoch 15242: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15243\n",
            "2025-06-26 08:43:05,660 EPOCH 15243\n",
            "INFO:__main__:Epoch 15243: total training loss 0.00094\n",
            "2025-06-26 08:43:05,729 Epoch 15243: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15244\n",
            "2025-06-26 08:43:05,731 EPOCH 15244\n",
            "INFO:__main__:Epoch 15244: total training loss 0.00093\n",
            "2025-06-26 08:43:05,803 Epoch 15244: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15245\n",
            "2025-06-26 08:43:05,805 EPOCH 15245\n",
            "INFO:__main__:Epoch 15245: total training loss 0.00086\n",
            "2025-06-26 08:43:05,875 Epoch 15245: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15246\n",
            "2025-06-26 08:43:05,877 EPOCH 15246\n",
            "INFO:__main__:Epoch 15246: total training loss 0.00089\n",
            "2025-06-26 08:43:05,954 Epoch 15246: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15247\n",
            "2025-06-26 08:43:05,956 EPOCH 15247\n",
            "INFO:__main__:Epoch 15247: total training loss 0.00090\n",
            "2025-06-26 08:43:06,042 Epoch 15247: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15248\n",
            "2025-06-26 08:43:06,044 EPOCH 15248\n",
            "INFO:__main__:Epoch 15248: total training loss 0.00091\n",
            "2025-06-26 08:43:06,118 Epoch 15248: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15249\n",
            "2025-06-26 08:43:06,120 EPOCH 15249\n",
            "INFO:__main__:Epoch 15249: total training loss 0.00090\n",
            "2025-06-26 08:43:06,194 Epoch 15249: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15250\n",
            "2025-06-26 08:43:06,196 EPOCH 15250\n",
            "INFO:__main__:Epoch 15250 Step:    15250 Batch Loss:     0.000976 Tokens per Sec:  2068613, Lr: 0.001000\n",
            "2025-06-26 08:43:06,266 Epoch 15250 Step:    15250 Batch Loss:     0.000976 Tokens per Sec:  2068613, Lr: 0.001000\n",
            "INFO:__main__:Epoch 15250: total training loss 0.00098\n",
            "2025-06-26 08:43:06,268 Epoch 15250: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15251\n",
            "2025-06-26 08:43:06,269 EPOCH 15251\n",
            "INFO:__main__:Epoch 15251: total training loss 0.00094\n",
            "2025-06-26 08:43:06,340 Epoch 15251: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15252\n",
            "2025-06-26 08:43:06,342 EPOCH 15252\n",
            "INFO:__main__:Epoch 15252: total training loss 0.00090\n",
            "2025-06-26 08:43:06,440 Epoch 15252: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15253\n",
            "2025-06-26 08:43:06,443 EPOCH 15253\n",
            "INFO:__main__:Epoch 15253: total training loss 0.00094\n",
            "2025-06-26 08:43:06,549 Epoch 15253: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15254\n",
            "2025-06-26 08:43:06,552 EPOCH 15254\n",
            "INFO:__main__:Epoch 15254: total training loss 0.00109\n",
            "2025-06-26 08:43:06,624 Epoch 15254: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15255\n",
            "2025-06-26 08:43:06,627 EPOCH 15255\n",
            "INFO:__main__:Epoch 15255: total training loss 0.00116\n",
            "2025-06-26 08:43:06,695 Epoch 15255: total training loss 0.00116\n",
            "INFO:__main__:EPOCH 15256\n",
            "2025-06-26 08:43:06,698 EPOCH 15256\n",
            "INFO:__main__:Epoch 15256: total training loss 0.00102\n",
            "2025-06-26 08:43:06,769 Epoch 15256: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15257\n",
            "2025-06-26 08:43:06,771 EPOCH 15257\n",
            "INFO:__main__:Epoch 15257: total training loss 0.00106\n",
            "2025-06-26 08:43:06,845 Epoch 15257: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15258\n",
            "2025-06-26 08:43:06,847 EPOCH 15258\n",
            "INFO:__main__:Epoch 15258: total training loss 0.00109\n",
            "2025-06-26 08:43:06,917 Epoch 15258: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15259\n",
            "2025-06-26 08:43:06,919 EPOCH 15259\n",
            "INFO:__main__:Epoch 15259: total training loss 0.00116\n",
            "2025-06-26 08:43:06,992 Epoch 15259: total training loss 0.00116\n",
            "INFO:__main__:EPOCH 15260\n",
            "2025-06-26 08:43:06,994 EPOCH 15260\n",
            "INFO:__main__:Epoch 15260: total training loss 0.00112\n",
            "2025-06-26 08:43:07,081 Epoch 15260: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 15261\n",
            "2025-06-26 08:43:07,084 EPOCH 15261\n",
            "INFO:__main__:Epoch 15261: total training loss 0.00103\n",
            "2025-06-26 08:43:07,172 Epoch 15261: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15262\n",
            "2025-06-26 08:43:07,174 EPOCH 15262\n",
            "INFO:__main__:Epoch 15262: total training loss 0.00101\n",
            "2025-06-26 08:43:07,249 Epoch 15262: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15263\n",
            "2025-06-26 08:43:07,250 EPOCH 15263\n",
            "INFO:__main__:Epoch 15263: total training loss 0.00098\n",
            "2025-06-26 08:43:07,319 Epoch 15263: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15264\n",
            "2025-06-26 08:43:07,321 EPOCH 15264\n",
            "INFO:__main__:Epoch 15264: total training loss 0.00098\n",
            "2025-06-26 08:43:07,390 Epoch 15264: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15265\n",
            "2025-06-26 08:43:07,392 EPOCH 15265\n",
            "INFO:__main__:Epoch 15265: total training loss 0.00097\n",
            "2025-06-26 08:43:07,461 Epoch 15265: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15266\n",
            "2025-06-26 08:43:07,463 EPOCH 15266\n",
            "INFO:__main__:Epoch 15266: total training loss 0.00097\n",
            "2025-06-26 08:43:07,535 Epoch 15266: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15267\n",
            "2025-06-26 08:43:07,537 EPOCH 15267\n",
            "INFO:__main__:Epoch 15267: total training loss 0.00092\n",
            "2025-06-26 08:43:07,609 Epoch 15267: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15268\n",
            "2025-06-26 08:43:07,611 EPOCH 15268\n",
            "INFO:__main__:Epoch 15268: total training loss 0.00097\n",
            "2025-06-26 08:43:07,682 Epoch 15268: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15269\n",
            "2025-06-26 08:43:07,684 EPOCH 15269\n",
            "INFO:__main__:Epoch 15269: total training loss 0.00088\n",
            "2025-06-26 08:43:07,755 Epoch 15269: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15270\n",
            "2025-06-26 08:43:07,757 EPOCH 15270\n",
            "INFO:__main__:Epoch 15270: total training loss 0.00090\n",
            "2025-06-26 08:43:07,827 Epoch 15270: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15271\n",
            "2025-06-26 08:43:07,829 EPOCH 15271\n",
            "INFO:__main__:Epoch 15271: total training loss 0.00095\n",
            "2025-06-26 08:43:07,900 Epoch 15271: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15272\n",
            "2025-06-26 08:43:07,902 EPOCH 15272\n",
            "INFO:__main__:Epoch 15272: total training loss 0.00097\n",
            "2025-06-26 08:43:07,972 Epoch 15272: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15273\n",
            "2025-06-26 08:43:07,974 EPOCH 15273\n",
            "INFO:__main__:Epoch 15273: total training loss 0.00095\n",
            "2025-06-26 08:43:08,048 Epoch 15273: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15274\n",
            "2025-06-26 08:43:08,050 EPOCH 15274\n",
            "INFO:__main__:Epoch 15274: total training loss 0.00097\n",
            "2025-06-26 08:43:08,122 Epoch 15274: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15275\n",
            "2025-06-26 08:43:08,127 EPOCH 15275\n",
            "INFO:__main__:Epoch 15275: total training loss 0.00089\n",
            "2025-06-26 08:43:08,215 Epoch 15275: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15276\n",
            "2025-06-26 08:43:08,219 EPOCH 15276\n",
            "INFO:__main__:Epoch 15276: total training loss 0.00094\n",
            "2025-06-26 08:43:08,288 Epoch 15276: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15277\n",
            "2025-06-26 08:43:08,291 EPOCH 15277\n",
            "INFO:__main__:Epoch 15277: total training loss 0.00101\n",
            "2025-06-26 08:43:08,361 Epoch 15277: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15278\n",
            "2025-06-26 08:43:08,363 EPOCH 15278\n",
            "INFO:__main__:Epoch 15278: total training loss 0.00104\n",
            "2025-06-26 08:43:08,434 Epoch 15278: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15279\n",
            "2025-06-26 08:43:08,436 EPOCH 15279\n",
            "INFO:__main__:Epoch 15279: total training loss 0.00118\n",
            "2025-06-26 08:43:08,509 Epoch 15279: total training loss 0.00118\n",
            "INFO:__main__:EPOCH 15280\n",
            "2025-06-26 08:43:08,512 EPOCH 15280\n",
            "INFO:__main__:Epoch 15280: total training loss 0.00103\n",
            "2025-06-26 08:43:08,586 Epoch 15280: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15281\n",
            "2025-06-26 08:43:08,590 EPOCH 15281\n",
            "INFO:__main__:Epoch 15281: total training loss 0.00100\n",
            "2025-06-26 08:43:08,675 Epoch 15281: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15282\n",
            "2025-06-26 08:43:08,678 EPOCH 15282\n",
            "INFO:__main__:Epoch 15282: total training loss 0.00101\n",
            "2025-06-26 08:43:08,756 Epoch 15282: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15283\n",
            "2025-06-26 08:43:08,759 EPOCH 15283\n",
            "INFO:__main__:Epoch 15283: total training loss 0.00099\n",
            "2025-06-26 08:43:08,843 Epoch 15283: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15284\n",
            "2025-06-26 08:43:08,847 EPOCH 15284\n",
            "INFO:__main__:Epoch 15284: total training loss 0.00103\n",
            "2025-06-26 08:43:08,937 Epoch 15284: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15285\n",
            "2025-06-26 08:43:08,941 EPOCH 15285\n",
            "INFO:__main__:Epoch 15285: total training loss 0.00103\n",
            "2025-06-26 08:43:09,029 Epoch 15285: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15286\n",
            "2025-06-26 08:43:09,032 EPOCH 15286\n",
            "INFO:__main__:Epoch 15286: total training loss 0.00104\n",
            "2025-06-26 08:43:09,113 Epoch 15286: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15287\n",
            "2025-06-26 08:43:09,117 EPOCH 15287\n",
            "INFO:__main__:Epoch 15287: total training loss 0.00099\n",
            "2025-06-26 08:43:09,199 Epoch 15287: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15288\n",
            "2025-06-26 08:43:09,201 EPOCH 15288\n",
            "INFO:__main__:Epoch 15288: total training loss 0.00099\n",
            "2025-06-26 08:43:09,312 Epoch 15288: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15289\n",
            "2025-06-26 08:43:09,314 EPOCH 15289\n",
            "INFO:__main__:Epoch 15289: total training loss 0.00102\n",
            "2025-06-26 08:43:09,421 Epoch 15289: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15290\n",
            "2025-06-26 08:43:09,423 EPOCH 15290\n",
            "INFO:__main__:Epoch 15290: total training loss 0.00104\n",
            "2025-06-26 08:43:09,544 Epoch 15290: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15291\n",
            "2025-06-26 08:43:09,546 EPOCH 15291\n",
            "INFO:__main__:Epoch 15291: total training loss 0.00103\n",
            "2025-06-26 08:43:09,660 Epoch 15291: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15292\n",
            "2025-06-26 08:43:09,662 EPOCH 15292\n",
            "INFO:__main__:Epoch 15292: total training loss 0.00104\n",
            "2025-06-26 08:43:09,782 Epoch 15292: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15293\n",
            "2025-06-26 08:43:09,784 EPOCH 15293\n",
            "INFO:__main__:Epoch 15293: total training loss 0.00103\n",
            "2025-06-26 08:43:09,901 Epoch 15293: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15294\n",
            "2025-06-26 08:43:09,910 EPOCH 15294\n",
            "INFO:__main__:Epoch 15294: total training loss 0.00099\n",
            "2025-06-26 08:43:10,023 Epoch 15294: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15295\n",
            "2025-06-26 08:43:10,025 EPOCH 15295\n",
            "INFO:__main__:Epoch 15295: total training loss 0.00096\n",
            "2025-06-26 08:43:10,142 Epoch 15295: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15296\n",
            "2025-06-26 08:43:10,144 EPOCH 15296\n",
            "INFO:__main__:Epoch 15296: total training loss 0.00098\n",
            "2025-06-26 08:43:10,262 Epoch 15296: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15297\n",
            "2025-06-26 08:43:10,264 EPOCH 15297\n",
            "INFO:__main__:Epoch 15297: total training loss 0.00100\n",
            "2025-06-26 08:43:10,389 Epoch 15297: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15298\n",
            "2025-06-26 08:43:10,391 EPOCH 15298\n",
            "INFO:__main__:Epoch 15298: total training loss 0.00102\n",
            "2025-06-26 08:43:10,513 Epoch 15298: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15299\n",
            "2025-06-26 08:43:10,514 EPOCH 15299\n",
            "INFO:__main__:Epoch 15299: total training loss 0.00100\n",
            "2025-06-26 08:43:10,610 Epoch 15299: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15300\n",
            "2025-06-26 08:43:10,613 EPOCH 15300\n",
            "INFO:__main__:Epoch 15300: total training loss 0.00101\n",
            "2025-06-26 08:43:10,726 Epoch 15300: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15301\n",
            "2025-06-26 08:43:10,730 EPOCH 15301\n",
            "INFO:__main__:Epoch 15301: total training loss 0.00101\n",
            "2025-06-26 08:43:10,819 Epoch 15301: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15302\n",
            "2025-06-26 08:43:10,821 EPOCH 15302\n",
            "INFO:__main__:Epoch 15302: total training loss 0.00099\n",
            "2025-06-26 08:43:10,944 Epoch 15302: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15303\n",
            "2025-06-26 08:43:10,949 EPOCH 15303\n",
            "INFO:__main__:Epoch 15303: total training loss 0.00102\n",
            "2025-06-26 08:43:11,058 Epoch 15303: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15304\n",
            "2025-06-26 08:43:11,060 EPOCH 15304\n",
            "INFO:__main__:Epoch 15304: total training loss 0.00096\n",
            "2025-06-26 08:43:11,167 Epoch 15304: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15305\n",
            "2025-06-26 08:43:11,169 EPOCH 15305\n",
            "INFO:__main__:Epoch 15305: total training loss 0.00093\n",
            "2025-06-26 08:43:11,290 Epoch 15305: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15306\n",
            "2025-06-26 08:43:11,293 EPOCH 15306\n",
            "INFO:__main__:Epoch 15306: total training loss 0.00100\n",
            "2025-06-26 08:43:11,401 Epoch 15306: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15307\n",
            "2025-06-26 08:43:11,403 EPOCH 15307\n",
            "INFO:__main__:Epoch 15307: total training loss 0.00103\n",
            "2025-06-26 08:43:11,504 Epoch 15307: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15308\n",
            "2025-06-26 08:43:11,508 EPOCH 15308\n",
            "INFO:__main__:Epoch 15308: total training loss 0.00100\n",
            "2025-06-26 08:43:11,602 Epoch 15308: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15309\n",
            "2025-06-26 08:43:11,604 EPOCH 15309\n",
            "INFO:__main__:Epoch 15309: total training loss 0.00100\n",
            "2025-06-26 08:43:11,722 Epoch 15309: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15310\n",
            "2025-06-26 08:43:11,724 EPOCH 15310\n",
            "INFO:__main__:Epoch 15310: total training loss 0.00096\n",
            "2025-06-26 08:43:11,843 Epoch 15310: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15311\n",
            "2025-06-26 08:43:11,845 EPOCH 15311\n",
            "INFO:__main__:Epoch 15311: total training loss 0.00091\n",
            "2025-06-26 08:43:11,958 Epoch 15311: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15312\n",
            "2025-06-26 08:43:11,960 EPOCH 15312\n",
            "INFO:__main__:Epoch 15312: total training loss 0.00094\n",
            "2025-06-26 08:43:12,076 Epoch 15312: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15313\n",
            "2025-06-26 08:43:12,079 EPOCH 15313\n",
            "INFO:__main__:Epoch 15313: total training loss 0.00090\n",
            "2025-06-26 08:43:12,201 Epoch 15313: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15314\n",
            "2025-06-26 08:43:12,202 EPOCH 15314\n",
            "INFO:__main__:Epoch 15314: total training loss 0.00088\n",
            "2025-06-26 08:43:12,293 Epoch 15314: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15315\n",
            "2025-06-26 08:43:12,295 EPOCH 15315\n",
            "INFO:__main__:Epoch 15315: total training loss 0.00091\n",
            "2025-06-26 08:43:12,410 Epoch 15315: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15316\n",
            "2025-06-26 08:43:12,412 EPOCH 15316\n",
            "INFO:__main__:Epoch 15316: total training loss 0.00096\n",
            "2025-06-26 08:43:12,525 Epoch 15316: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15317\n",
            "2025-06-26 08:43:12,527 EPOCH 15317\n",
            "INFO:__main__:Epoch 15317: total training loss 0.00095\n",
            "2025-06-26 08:43:12,651 Epoch 15317: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15318\n",
            "2025-06-26 08:43:12,652 EPOCH 15318\n",
            "INFO:__main__:Epoch 15318: total training loss 0.00096\n",
            "2025-06-26 08:43:12,774 Epoch 15318: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15319\n",
            "2025-06-26 08:43:12,779 EPOCH 15319\n",
            "INFO:__main__:Epoch 15319: total training loss 0.00092\n",
            "2025-06-26 08:43:12,905 Epoch 15319: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15320\n",
            "2025-06-26 08:43:12,906 EPOCH 15320\n",
            "INFO:__main__:Epoch 15320: total training loss 0.00090\n",
            "2025-06-26 08:43:12,983 Epoch 15320: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15321\n",
            "2025-06-26 08:43:12,985 EPOCH 15321\n",
            "INFO:__main__:Epoch 15321: total training loss 0.00095\n",
            "2025-06-26 08:43:13,066 Epoch 15321: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15322\n",
            "2025-06-26 08:43:13,072 EPOCH 15322\n",
            "INFO:__main__:Epoch 15322: total training loss 0.00091\n",
            "2025-06-26 08:43:13,164 Epoch 15322: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15323\n",
            "2025-06-26 08:43:13,171 EPOCH 15323\n",
            "INFO:__main__:Epoch 15323: total training loss 0.00084\n",
            "2025-06-26 08:43:13,267 Epoch 15323: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15324\n",
            "2025-06-26 08:43:13,273 EPOCH 15324\n",
            "INFO:__main__:Epoch 15324: total training loss 0.00095\n",
            "2025-06-26 08:43:13,370 Epoch 15324: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15325\n",
            "2025-06-26 08:43:13,375 EPOCH 15325\n",
            "INFO:__main__:Epoch 15325: total training loss 0.00095\n",
            "2025-06-26 08:43:13,486 Epoch 15325: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15326\n",
            "2025-06-26 08:43:13,490 EPOCH 15326\n",
            "INFO:__main__:Epoch 15326: total training loss 0.00094\n",
            "2025-06-26 08:43:13,604 Epoch 15326: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15327\n",
            "2025-06-26 08:43:13,606 EPOCH 15327\n",
            "INFO:__main__:Epoch 15327: total training loss 0.00091\n",
            "2025-06-26 08:43:13,733 Epoch 15327: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15328\n",
            "2025-06-26 08:43:13,739 EPOCH 15328\n",
            "INFO:__main__:Epoch 15328: total training loss 0.00093\n",
            "2025-06-26 08:43:13,867 Epoch 15328: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15329\n",
            "2025-06-26 08:43:13,869 EPOCH 15329\n",
            "INFO:__main__:Epoch 15329: total training loss 0.00093\n",
            "2025-06-26 08:43:13,980 Epoch 15329: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15330\n",
            "2025-06-26 08:43:13,982 EPOCH 15330\n",
            "INFO:__main__:Epoch 15330: total training loss 0.00097\n",
            "2025-06-26 08:43:14,071 Epoch 15330: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15331\n",
            "2025-06-26 08:43:14,073 EPOCH 15331\n",
            "INFO:__main__:Epoch 15331: total training loss 0.00105\n",
            "2025-06-26 08:43:14,152 Epoch 15331: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15332\n",
            "2025-06-26 08:43:14,155 EPOCH 15332\n",
            "INFO:__main__:Epoch 15332: total training loss 0.00103\n",
            "2025-06-26 08:43:14,239 Epoch 15332: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15333\n",
            "2025-06-26 08:43:14,241 EPOCH 15333\n",
            "INFO:__main__:Epoch 15333: total training loss 0.00102\n",
            "2025-06-26 08:43:14,316 Epoch 15333: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15334\n",
            "2025-06-26 08:43:14,320 EPOCH 15334\n",
            "INFO:__main__:Epoch 15334: total training loss 0.00093\n",
            "2025-06-26 08:43:14,412 Epoch 15334: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15335\n",
            "2025-06-26 08:43:14,415 EPOCH 15335\n",
            "INFO:__main__:Epoch 15335: total training loss 0.00093\n",
            "2025-06-26 08:43:14,499 Epoch 15335: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15336\n",
            "2025-06-26 08:43:14,501 EPOCH 15336\n",
            "INFO:__main__:Epoch 15336: total training loss 0.00095\n",
            "2025-06-26 08:43:14,581 Epoch 15336: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15337\n",
            "2025-06-26 08:43:14,586 EPOCH 15337\n",
            "INFO:__main__:Epoch 15337: total training loss 0.00100\n",
            "2025-06-26 08:43:14,682 Epoch 15337: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15338\n",
            "2025-06-26 08:43:14,685 EPOCH 15338\n",
            "INFO:__main__:Epoch 15338: total training loss 0.00095\n",
            "2025-06-26 08:43:14,785 Epoch 15338: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15339\n",
            "2025-06-26 08:43:14,787 EPOCH 15339\n",
            "INFO:__main__:Epoch 15339: total training loss 0.00090\n",
            "2025-06-26 08:43:14,863 Epoch 15339: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15340\n",
            "2025-06-26 08:43:14,865 EPOCH 15340\n",
            "INFO:__main__:Epoch 15340: total training loss 0.00092\n",
            "2025-06-26 08:43:14,948 Epoch 15340: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15341\n",
            "2025-06-26 08:43:14,950 EPOCH 15341\n",
            "INFO:__main__:Epoch 15341: total training loss 0.00094\n",
            "2025-06-26 08:43:15,023 Epoch 15341: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15342\n",
            "2025-06-26 08:43:15,026 EPOCH 15342\n",
            "INFO:__main__:Epoch 15342: total training loss 0.00097\n",
            "2025-06-26 08:43:15,100 Epoch 15342: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15343\n",
            "2025-06-26 08:43:15,102 EPOCH 15343\n",
            "INFO:__main__:Epoch 15343: total training loss 0.00092\n",
            "2025-06-26 08:43:15,175 Epoch 15343: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15344\n",
            "2025-06-26 08:43:15,177 EPOCH 15344\n",
            "INFO:__main__:Epoch 15344: total training loss 0.00095\n",
            "2025-06-26 08:43:15,262 Epoch 15344: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15345\n",
            "2025-06-26 08:43:15,264 EPOCH 15345\n",
            "INFO:__main__:Epoch 15345: total training loss 0.00097\n",
            "2025-06-26 08:43:15,337 Epoch 15345: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15346\n",
            "2025-06-26 08:43:15,339 EPOCH 15346\n",
            "INFO:__main__:Epoch 15346: total training loss 0.00098\n",
            "2025-06-26 08:43:15,411 Epoch 15346: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15347\n",
            "2025-06-26 08:43:15,414 EPOCH 15347\n",
            "INFO:__main__:Epoch 15347: total training loss 0.00091\n",
            "2025-06-26 08:43:15,486 Epoch 15347: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15348\n",
            "2025-06-26 08:43:15,490 EPOCH 15348\n",
            "INFO:__main__:Epoch 15348: total training loss 0.00090\n",
            "2025-06-26 08:43:15,572 Epoch 15348: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15349\n",
            "2025-06-26 08:43:15,575 EPOCH 15349\n",
            "INFO:__main__:Epoch 15349: total training loss 0.00097\n",
            "2025-06-26 08:43:15,650 Epoch 15349: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15350\n",
            "2025-06-26 08:43:15,655 EPOCH 15350\n",
            "INFO:__main__:Epoch 15350: total training loss 0.00090\n",
            "2025-06-26 08:43:15,726 Epoch 15350: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15351\n",
            "2025-06-26 08:43:15,728 EPOCH 15351\n",
            "INFO:__main__:Epoch 15351: total training loss 0.00096\n",
            "2025-06-26 08:43:15,808 Epoch 15351: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15352\n",
            "2025-06-26 08:43:15,810 EPOCH 15352\n",
            "INFO:__main__:Epoch 15352: total training loss 0.00094\n",
            "2025-06-26 08:43:15,892 Epoch 15352: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15353\n",
            "2025-06-26 08:43:15,895 EPOCH 15353\n",
            "INFO:__main__:Epoch 15353: total training loss 0.00095\n",
            "2025-06-26 08:43:15,966 Epoch 15353: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15354\n",
            "2025-06-26 08:43:15,970 EPOCH 15354\n",
            "INFO:__main__:Epoch 15354: total training loss 0.00096\n",
            "2025-06-26 08:43:16,041 Epoch 15354: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15355\n",
            "2025-06-26 08:43:16,043 EPOCH 15355\n",
            "INFO:__main__:Epoch 15355: total training loss 0.00093\n",
            "2025-06-26 08:43:16,118 Epoch 15355: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15356\n",
            "2025-06-26 08:43:16,120 EPOCH 15356\n",
            "INFO:__main__:Epoch 15356: total training loss 0.00098\n",
            "2025-06-26 08:43:16,195 Epoch 15356: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15357\n",
            "2025-06-26 08:43:16,197 EPOCH 15357\n",
            "INFO:__main__:Epoch 15357: total training loss 0.00088\n",
            "2025-06-26 08:43:16,265 Epoch 15357: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15358\n",
            "2025-06-26 08:43:16,267 EPOCH 15358\n",
            "INFO:__main__:Epoch 15358: total training loss 0.00100\n",
            "2025-06-26 08:43:16,340 Epoch 15358: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15359\n",
            "2025-06-26 08:43:16,342 EPOCH 15359\n",
            "INFO:__main__:Epoch 15359: total training loss 0.00094\n",
            "2025-06-26 08:43:16,419 Epoch 15359: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15360\n",
            "2025-06-26 08:43:16,422 EPOCH 15360\n",
            "INFO:__main__:Epoch 15360: total training loss 0.00086\n",
            "2025-06-26 08:43:16,496 Epoch 15360: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15361\n",
            "2025-06-26 08:43:16,498 EPOCH 15361\n",
            "INFO:__main__:Epoch 15361: total training loss 0.00088\n",
            "2025-06-26 08:43:16,570 Epoch 15361: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15362\n",
            "2025-06-26 08:43:16,574 EPOCH 15362\n",
            "INFO:__main__:Epoch 15362: total training loss 0.00087\n",
            "2025-06-26 08:43:16,650 Epoch 15362: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15363\n",
            "2025-06-26 08:43:16,655 EPOCH 15363\n",
            "INFO:__main__:Epoch 15363: total training loss 0.00084\n",
            "2025-06-26 08:43:16,729 Epoch 15363: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15364\n",
            "2025-06-26 08:43:16,731 EPOCH 15364\n",
            "INFO:__main__:Epoch 15364: total training loss 0.00083\n",
            "2025-06-26 08:43:16,821 Epoch 15364: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15365\n",
            "2025-06-26 08:43:16,824 EPOCH 15365\n",
            "INFO:__main__:Epoch 15365: total training loss 0.00088\n",
            "2025-06-26 08:43:16,929 Epoch 15365: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15366\n",
            "2025-06-26 08:43:16,933 EPOCH 15366\n",
            "INFO:__main__:Epoch 15366: total training loss 0.00091\n",
            "2025-06-26 08:43:17,003 Epoch 15366: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15367\n",
            "2025-06-26 08:43:17,005 EPOCH 15367\n",
            "INFO:__main__:Epoch 15367: total training loss 0.00093\n",
            "2025-06-26 08:43:17,076 Epoch 15367: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15368\n",
            "2025-06-26 08:43:17,079 EPOCH 15368\n",
            "INFO:__main__:Epoch 15368: total training loss 0.00091\n",
            "2025-06-26 08:43:17,157 Epoch 15368: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15369\n",
            "2025-06-26 08:43:17,159 EPOCH 15369\n",
            "INFO:__main__:Epoch 15369: total training loss 0.00091\n",
            "2025-06-26 08:43:17,233 Epoch 15369: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15370\n",
            "2025-06-26 08:43:17,235 EPOCH 15370\n",
            "INFO:__main__:Epoch 15370: total training loss 0.00087\n",
            "2025-06-26 08:43:17,306 Epoch 15370: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15371\n",
            "2025-06-26 08:43:17,308 EPOCH 15371\n",
            "INFO:__main__:Epoch 15371: total training loss 0.00090\n",
            "2025-06-26 08:43:17,380 Epoch 15371: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15372\n",
            "2025-06-26 08:43:17,382 EPOCH 15372\n",
            "INFO:__main__:Epoch 15372: total training loss 0.00087\n",
            "2025-06-26 08:43:17,453 Epoch 15372: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15373\n",
            "2025-06-26 08:43:17,455 EPOCH 15373\n",
            "INFO:__main__:Epoch 15373: total training loss 0.00090\n",
            "2025-06-26 08:43:17,528 Epoch 15373: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15374\n",
            "2025-06-26 08:43:17,530 EPOCH 15374\n",
            "INFO:__main__:Epoch 15374: total training loss 0.00084\n",
            "2025-06-26 08:43:17,614 Epoch 15374: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15375\n",
            "2025-06-26 08:43:17,616 EPOCH 15375\n",
            "INFO:__main__:Epoch 15375: total training loss 0.00085\n",
            "2025-06-26 08:43:17,686 Epoch 15375: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15376\n",
            "2025-06-26 08:43:17,688 EPOCH 15376\n",
            "INFO:__main__:Epoch 15376: total training loss 0.00089\n",
            "2025-06-26 08:43:17,765 Epoch 15376: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15377\n",
            "2025-06-26 08:43:17,767 EPOCH 15377\n",
            "INFO:__main__:Epoch 15377: total training loss 0.00089\n",
            "2025-06-26 08:43:17,837 Epoch 15377: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15378\n",
            "2025-06-26 08:43:17,839 EPOCH 15378\n",
            "INFO:__main__:Epoch 15378: total training loss 0.00085\n",
            "2025-06-26 08:43:17,924 Epoch 15378: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15379\n",
            "2025-06-26 08:43:17,926 EPOCH 15379\n",
            "INFO:__main__:Epoch 15379: total training loss 0.00084\n",
            "2025-06-26 08:43:18,007 Epoch 15379: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15380\n",
            "2025-06-26 08:43:18,009 EPOCH 15380\n",
            "INFO:__main__:Epoch 15380: total training loss 0.00088\n",
            "2025-06-26 08:43:18,080 Epoch 15380: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15381\n",
            "2025-06-26 08:43:18,082 EPOCH 15381\n",
            "INFO:__main__:Epoch 15381: total training loss 0.00089\n",
            "2025-06-26 08:43:18,154 Epoch 15381: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15382\n",
            "2025-06-26 08:43:18,156 EPOCH 15382\n",
            "INFO:__main__:Epoch 15382: total training loss 0.00095\n",
            "2025-06-26 08:43:18,229 Epoch 15382: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15383\n",
            "2025-06-26 08:43:18,231 EPOCH 15383\n",
            "INFO:__main__:Epoch 15383: total training loss 0.00106\n",
            "2025-06-26 08:43:18,308 Epoch 15383: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15384\n",
            "2025-06-26 08:43:18,310 EPOCH 15384\n",
            "INFO:__main__:Epoch 15384: total training loss 0.00115\n",
            "2025-06-26 08:43:18,380 Epoch 15384: total training loss 0.00115\n",
            "INFO:__main__:EPOCH 15385\n",
            "2025-06-26 08:43:18,382 EPOCH 15385\n",
            "INFO:__main__:Epoch 15385: total training loss 0.00099\n",
            "2025-06-26 08:43:18,454 Epoch 15385: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15386\n",
            "2025-06-26 08:43:18,456 EPOCH 15386\n",
            "INFO:__main__:Epoch 15386: total training loss 0.00104\n",
            "2025-06-26 08:43:18,527 Epoch 15386: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15387\n",
            "2025-06-26 08:43:18,529 EPOCH 15387\n",
            "INFO:__main__:Epoch 15387: total training loss 0.00096\n",
            "2025-06-26 08:43:18,601 Epoch 15387: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15388\n",
            "2025-06-26 08:43:18,603 EPOCH 15388\n",
            "INFO:__main__:Epoch 15388: total training loss 0.00097\n",
            "2025-06-26 08:43:18,682 Epoch 15388: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15389\n",
            "2025-06-26 08:43:18,684 EPOCH 15389\n",
            "INFO:__main__:Epoch 15389: total training loss 0.00102\n",
            "2025-06-26 08:43:18,755 Epoch 15389: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15390\n",
            "2025-06-26 08:43:18,757 EPOCH 15390\n",
            "INFO:__main__:Epoch 15390: total training loss 0.00096\n",
            "2025-06-26 08:43:18,835 Epoch 15390: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15391\n",
            "2025-06-26 08:43:18,837 EPOCH 15391\n",
            "INFO:__main__:Epoch 15391: total training loss 0.00100\n",
            "2025-06-26 08:43:18,917 Epoch 15391: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15392\n",
            "2025-06-26 08:43:18,919 EPOCH 15392\n",
            "INFO:__main__:Epoch 15392: total training loss 0.00098\n",
            "2025-06-26 08:43:19,001 Epoch 15392: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15393\n",
            "2025-06-26 08:43:19,009 EPOCH 15393\n",
            "INFO:__main__:Epoch 15393: total training loss 0.00094\n",
            "2025-06-26 08:43:19,095 Epoch 15393: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15394\n",
            "2025-06-26 08:43:19,097 EPOCH 15394\n",
            "INFO:__main__:Epoch 15394: total training loss 0.00099\n",
            "2025-06-26 08:43:19,167 Epoch 15394: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15395\n",
            "2025-06-26 08:43:19,169 EPOCH 15395\n",
            "INFO:__main__:Epoch 15395: total training loss 0.00089\n",
            "2025-06-26 08:43:19,260 Epoch 15395: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15396\n",
            "2025-06-26 08:43:19,262 EPOCH 15396\n",
            "INFO:__main__:Epoch 15396: total training loss 0.00094\n",
            "2025-06-26 08:43:19,332 Epoch 15396: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15397\n",
            "2025-06-26 08:43:19,334 EPOCH 15397\n",
            "INFO:__main__:Epoch 15397: total training loss 0.00090\n",
            "2025-06-26 08:43:19,410 Epoch 15397: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15398\n",
            "2025-06-26 08:43:19,412 EPOCH 15398\n",
            "INFO:__main__:Epoch 15398: total training loss 0.00094\n",
            "2025-06-26 08:43:19,483 Epoch 15398: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15399\n",
            "2025-06-26 08:43:19,486 EPOCH 15399\n",
            "INFO:__main__:Epoch 15399: total training loss 0.00088\n",
            "2025-06-26 08:43:19,562 Epoch 15399: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15400\n",
            "2025-06-26 08:43:19,564 EPOCH 15400\n",
            "INFO:__main__:Epoch 15400: total training loss 0.00092\n",
            "2025-06-26 08:43:19,639 Epoch 15400: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15401\n",
            "2025-06-26 08:43:19,641 EPOCH 15401\n",
            "INFO:__main__:Epoch 15401: total training loss 0.00086\n",
            "2025-06-26 08:43:19,713 Epoch 15401: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15402\n",
            "2025-06-26 08:43:19,715 EPOCH 15402\n",
            "INFO:__main__:Epoch 15402: total training loss 0.00090\n",
            "2025-06-26 08:43:19,790 Epoch 15402: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15403\n",
            "2025-06-26 08:43:19,792 EPOCH 15403\n",
            "INFO:__main__:Epoch 15403: total training loss 0.00091\n",
            "2025-06-26 08:43:19,878 Epoch 15403: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15404\n",
            "2025-06-26 08:43:19,882 EPOCH 15404\n",
            "INFO:__main__:Epoch 15404: total training loss 0.00090\n",
            "2025-06-26 08:43:19,952 Epoch 15404: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15405\n",
            "2025-06-26 08:43:19,954 EPOCH 15405\n",
            "INFO:__main__:Epoch 15405: total training loss 0.00088\n",
            "2025-06-26 08:43:20,053 Epoch 15405: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15406\n",
            "2025-06-26 08:43:20,055 EPOCH 15406\n",
            "INFO:__main__:Epoch 15406: total training loss 0.00088\n",
            "2025-06-26 08:43:20,137 Epoch 15406: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15407\n",
            "2025-06-26 08:43:20,139 EPOCH 15407\n",
            "INFO:__main__:Epoch 15407: total training loss 0.00085\n",
            "2025-06-26 08:43:20,215 Epoch 15407: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15408\n",
            "2025-06-26 08:43:20,217 EPOCH 15408\n",
            "INFO:__main__:Epoch 15408: total training loss 0.00086\n",
            "2025-06-26 08:43:20,288 Epoch 15408: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15409\n",
            "2025-06-26 08:43:20,290 EPOCH 15409\n",
            "INFO:__main__:Epoch 15409: total training loss 0.00086\n",
            "2025-06-26 08:43:20,374 Epoch 15409: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15410\n",
            "2025-06-26 08:43:20,376 EPOCH 15410\n",
            "INFO:__main__:Epoch 15410: total training loss 0.00093\n",
            "2025-06-26 08:43:20,449 Epoch 15410: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15411\n",
            "2025-06-26 08:43:20,451 EPOCH 15411\n",
            "INFO:__main__:Epoch 15411: total training loss 0.00095\n",
            "2025-06-26 08:43:20,547 Epoch 15411: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15412\n",
            "2025-06-26 08:43:20,551 EPOCH 15412\n",
            "INFO:__main__:Epoch 15412: total training loss 0.00095\n",
            "2025-06-26 08:43:20,631 Epoch 15412: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15413\n",
            "2025-06-26 08:43:20,635 EPOCH 15413\n",
            "INFO:__main__:Epoch 15413: total training loss 0.00098\n",
            "2025-06-26 08:43:20,713 Epoch 15413: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15414\n",
            "2025-06-26 08:43:20,715 EPOCH 15414\n",
            "INFO:__main__:Epoch 15414: total training loss 0.00102\n",
            "2025-06-26 08:43:20,802 Epoch 15414: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15415\n",
            "2025-06-26 08:43:20,806 EPOCH 15415\n",
            "INFO:__main__:Epoch 15415: total training loss 0.00102\n",
            "2025-06-26 08:43:20,889 Epoch 15415: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15416\n",
            "2025-06-26 08:43:20,891 EPOCH 15416\n",
            "INFO:__main__:Epoch 15416: total training loss 0.00102\n",
            "2025-06-26 08:43:20,978 Epoch 15416: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15417\n",
            "2025-06-26 08:43:20,982 EPOCH 15417\n",
            "INFO:__main__:Epoch 15417: total training loss 0.00101\n",
            "2025-06-26 08:43:21,056 Epoch 15417: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15418\n",
            "2025-06-26 08:43:21,059 EPOCH 15418\n",
            "INFO:__main__:Epoch 15418: total training loss 0.00096\n",
            "2025-06-26 08:43:21,151 Epoch 15418: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15419\n",
            "2025-06-26 08:43:21,153 EPOCH 15419\n",
            "INFO:__main__:Epoch 15419: total training loss 0.00099\n",
            "2025-06-26 08:43:21,242 Epoch 15419: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15420\n",
            "2025-06-26 08:43:21,243 EPOCH 15420\n",
            "INFO:__main__:Epoch 15420: total training loss 0.00103\n",
            "2025-06-26 08:43:21,318 Epoch 15420: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15421\n",
            "2025-06-26 08:43:21,321 EPOCH 15421\n",
            "INFO:__main__:Epoch 15421: total training loss 0.00097\n",
            "2025-06-26 08:43:21,390 Epoch 15421: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15422\n",
            "2025-06-26 08:43:21,392 EPOCH 15422\n",
            "INFO:__main__:Epoch 15422: total training loss 0.00091\n",
            "2025-06-26 08:43:21,465 Epoch 15422: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15423\n",
            "2025-06-26 08:43:21,467 EPOCH 15423\n",
            "INFO:__main__:Epoch 15423: total training loss 0.00090\n",
            "2025-06-26 08:43:21,573 Epoch 15423: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15424\n",
            "2025-06-26 08:43:21,576 EPOCH 15424\n",
            "INFO:__main__:Epoch 15424: total training loss 0.00099\n",
            "2025-06-26 08:43:21,650 Epoch 15424: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15425\n",
            "2025-06-26 08:43:21,652 EPOCH 15425\n",
            "INFO:__main__:Epoch 15425: total training loss 0.00092\n",
            "2025-06-26 08:43:21,723 Epoch 15425: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15426\n",
            "2025-06-26 08:43:21,725 EPOCH 15426\n",
            "INFO:__main__:Epoch 15426: total training loss 0.00092\n",
            "2025-06-26 08:43:21,803 Epoch 15426: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15427\n",
            "2025-06-26 08:43:21,804 EPOCH 15427\n",
            "INFO:__main__:Epoch 15427: total training loss 0.00092\n",
            "2025-06-26 08:43:21,879 Epoch 15427: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15428\n",
            "2025-06-26 08:43:21,881 EPOCH 15428\n",
            "INFO:__main__:Epoch 15428: total training loss 0.00086\n",
            "2025-06-26 08:43:21,954 Epoch 15428: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15429\n",
            "2025-06-26 08:43:21,956 EPOCH 15429\n",
            "INFO:__main__:Epoch 15429: total training loss 0.00088\n",
            "2025-06-26 08:43:22,028 Epoch 15429: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15430\n",
            "2025-06-26 08:43:22,030 EPOCH 15430\n",
            "INFO:__main__:Epoch 15430: total training loss 0.00090\n",
            "2025-06-26 08:43:22,107 Epoch 15430: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15431\n",
            "2025-06-26 08:43:22,109 EPOCH 15431\n",
            "INFO:__main__:Epoch 15431: total training loss 0.00090\n",
            "2025-06-26 08:43:22,192 Epoch 15431: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15432\n",
            "2025-06-26 08:43:22,197 EPOCH 15432\n",
            "INFO:__main__:Epoch 15432: total training loss 0.00092\n",
            "2025-06-26 08:43:22,276 Epoch 15432: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15433\n",
            "2025-06-26 08:43:22,278 EPOCH 15433\n",
            "INFO:__main__:Epoch 15433: total training loss 0.00096\n",
            "2025-06-26 08:43:22,350 Epoch 15433: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15434\n",
            "2025-06-26 08:43:22,356 EPOCH 15434\n",
            "INFO:__main__:Epoch 15434: total training loss 0.00092\n",
            "2025-06-26 08:43:22,429 Epoch 15434: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15435\n",
            "2025-06-26 08:43:22,431 EPOCH 15435\n",
            "INFO:__main__:Epoch 15435: total training loss 0.00093\n",
            "2025-06-26 08:43:22,517 Epoch 15435: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15436\n",
            "2025-06-26 08:43:22,519 EPOCH 15436\n",
            "INFO:__main__:Epoch 15436: total training loss 0.00095\n",
            "2025-06-26 08:43:22,596 Epoch 15436: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15437\n",
            "2025-06-26 08:43:22,599 EPOCH 15437\n",
            "INFO:__main__:Epoch 15437: total training loss 0.00094\n",
            "2025-06-26 08:43:22,706 Epoch 15437: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15438\n",
            "2025-06-26 08:43:22,708 EPOCH 15438\n",
            "INFO:__main__:Epoch 15438: total training loss 0.00103\n",
            "2025-06-26 08:43:22,781 Epoch 15438: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15439\n",
            "2025-06-26 08:43:22,788 EPOCH 15439\n",
            "INFO:__main__:Epoch 15439: total training loss 0.00105\n",
            "2025-06-26 08:43:22,861 Epoch 15439: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15440\n",
            "2025-06-26 08:43:22,863 EPOCH 15440\n",
            "INFO:__main__:Epoch 15440: total training loss 0.00105\n",
            "2025-06-26 08:43:22,942 Epoch 15440: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15441\n",
            "2025-06-26 08:43:22,944 EPOCH 15441\n",
            "INFO:__main__:Epoch 15441: total training loss 0.00105\n",
            "2025-06-26 08:43:23,023 Epoch 15441: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15442\n",
            "2025-06-26 08:43:23,025 EPOCH 15442\n",
            "INFO:__main__:Epoch 15442: total training loss 0.00105\n",
            "2025-06-26 08:43:23,102 Epoch 15442: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15443\n",
            "2025-06-26 08:43:23,104 EPOCH 15443\n",
            "INFO:__main__:Epoch 15443: total training loss 0.00096\n",
            "2025-06-26 08:43:23,177 Epoch 15443: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15444\n",
            "2025-06-26 08:43:23,181 EPOCH 15444\n",
            "INFO:__main__:Epoch 15444: total training loss 0.00099\n",
            "2025-06-26 08:43:23,283 Epoch 15444: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15445\n",
            "2025-06-26 08:43:23,287 EPOCH 15445\n",
            "INFO:__main__:Epoch 15445: total training loss 0.00106\n",
            "2025-06-26 08:43:23,359 Epoch 15445: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15446\n",
            "2025-06-26 08:43:23,361 EPOCH 15446\n",
            "INFO:__main__:Epoch 15446: total training loss 0.00097\n",
            "2025-06-26 08:43:23,435 Epoch 15446: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15447\n",
            "2025-06-26 08:43:23,438 EPOCH 15447\n",
            "INFO:__main__:Epoch 15447: total training loss 0.00098\n",
            "2025-06-26 08:43:23,509 Epoch 15447: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15448\n",
            "2025-06-26 08:43:23,512 EPOCH 15448\n",
            "INFO:__main__:Epoch 15448: total training loss 0.00089\n",
            "2025-06-26 08:43:23,584 Epoch 15448: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15449\n",
            "2025-06-26 08:43:23,587 EPOCH 15449\n",
            "INFO:__main__:Epoch 15449: total training loss 0.00094\n",
            "2025-06-26 08:43:23,660 Epoch 15449: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15450\n",
            "2025-06-26 08:43:23,666 EPOCH 15450\n",
            "INFO:__main__:Epoch 15450: total training loss 0.00090\n",
            "2025-06-26 08:43:23,736 Epoch 15450: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15451\n",
            "2025-06-26 08:43:23,738 EPOCH 15451\n",
            "INFO:__main__:Epoch 15451: total training loss 0.00093\n",
            "2025-06-26 08:43:23,812 Epoch 15451: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15452\n",
            "2025-06-26 08:43:23,814 EPOCH 15452\n",
            "INFO:__main__:Epoch 15452: total training loss 0.00094\n",
            "2025-06-26 08:43:23,883 Epoch 15452: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15453\n",
            "2025-06-26 08:43:23,885 EPOCH 15453\n",
            "INFO:__main__:Epoch 15453: total training loss 0.00089\n",
            "2025-06-26 08:43:23,955 Epoch 15453: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15454\n",
            "2025-06-26 08:43:23,957 EPOCH 15454\n",
            "INFO:__main__:Epoch 15454: total training loss 0.00088\n",
            "2025-06-26 08:43:24,043 Epoch 15454: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15455\n",
            "2025-06-26 08:43:24,049 EPOCH 15455\n",
            "INFO:__main__:Epoch 15455: total training loss 0.00093\n",
            "2025-06-26 08:43:24,131 Epoch 15455: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15456\n",
            "2025-06-26 08:43:24,134 EPOCH 15456\n",
            "INFO:__main__:Epoch 15456: total training loss 0.00088\n",
            "2025-06-26 08:43:24,213 Epoch 15456: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15457\n",
            "2025-06-26 08:43:24,216 EPOCH 15457\n",
            "INFO:__main__:Epoch 15457: total training loss 0.00095\n",
            "2025-06-26 08:43:24,307 Epoch 15457: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15458\n",
            "2025-06-26 08:43:24,310 EPOCH 15458\n",
            "INFO:__main__:Epoch 15458: total training loss 0.00097\n",
            "2025-06-26 08:43:24,417 Epoch 15458: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15459\n",
            "2025-06-26 08:43:24,420 EPOCH 15459\n",
            "INFO:__main__:Epoch 15459: total training loss 0.00097\n",
            "2025-06-26 08:43:24,515 Epoch 15459: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15460\n",
            "2025-06-26 08:43:24,520 EPOCH 15460\n",
            "INFO:__main__:Epoch 15460: total training loss 0.00094\n",
            "2025-06-26 08:43:24,636 Epoch 15460: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15461\n",
            "2025-06-26 08:43:24,643 EPOCH 15461\n",
            "INFO:__main__:Epoch 15461: total training loss 0.00091\n",
            "2025-06-26 08:43:24,757 Epoch 15461: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15462\n",
            "2025-06-26 08:43:24,761 EPOCH 15462\n",
            "INFO:__main__:Epoch 15462: total training loss 0.00096\n",
            "2025-06-26 08:43:24,871 Epoch 15462: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15463\n",
            "2025-06-26 08:43:24,875 EPOCH 15463\n",
            "INFO:__main__:Epoch 15463: total training loss 0.00093\n",
            "2025-06-26 08:43:24,990 Epoch 15463: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15464\n",
            "2025-06-26 08:43:24,992 EPOCH 15464\n",
            "INFO:__main__:Epoch 15464: total training loss 0.00085\n",
            "2025-06-26 08:43:25,109 Epoch 15464: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15465\n",
            "2025-06-26 08:43:25,111 EPOCH 15465\n",
            "INFO:__main__:Epoch 15465: total training loss 0.00092\n",
            "2025-06-26 08:43:25,231 Epoch 15465: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15466\n",
            "2025-06-26 08:43:25,233 EPOCH 15466\n",
            "INFO:__main__:Epoch 15466: total training loss 0.00095\n",
            "2025-06-26 08:43:25,342 Epoch 15466: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15467\n",
            "2025-06-26 08:43:25,345 EPOCH 15467\n",
            "INFO:__main__:Epoch 15467: total training loss 0.00089\n",
            "2025-06-26 08:43:25,471 Epoch 15467: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15468\n",
            "2025-06-26 08:43:25,473 EPOCH 15468\n",
            "INFO:__main__:Epoch 15468: total training loss 0.00094\n",
            "2025-06-26 08:43:25,590 Epoch 15468: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15469\n",
            "2025-06-26 08:43:25,592 EPOCH 15469\n",
            "INFO:__main__:Epoch 15469: total training loss 0.00090\n",
            "2025-06-26 08:43:25,700 Epoch 15469: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15470\n",
            "2025-06-26 08:43:25,704 EPOCH 15470\n",
            "INFO:__main__:Epoch 15470: total training loss 0.00090\n",
            "2025-06-26 08:43:25,811 Epoch 15470: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15471\n",
            "2025-06-26 08:43:25,814 EPOCH 15471\n",
            "INFO:__main__:Epoch 15471: total training loss 0.00099\n",
            "2025-06-26 08:43:25,929 Epoch 15471: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15472\n",
            "2025-06-26 08:43:25,932 EPOCH 15472\n",
            "INFO:__main__:Epoch 15472: total training loss 0.00097\n",
            "2025-06-26 08:43:26,042 Epoch 15472: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15473\n",
            "2025-06-26 08:43:26,044 EPOCH 15473\n",
            "INFO:__main__:Epoch 15473: total training loss 0.00098\n",
            "2025-06-26 08:43:26,133 Epoch 15473: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15474\n",
            "2025-06-26 08:43:26,136 EPOCH 15474\n",
            "INFO:__main__:Epoch 15474: total training loss 0.00093\n",
            "2025-06-26 08:43:26,228 Epoch 15474: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15475\n",
            "2025-06-26 08:43:26,232 EPOCH 15475\n",
            "INFO:__main__:Epoch 15475: total training loss 0.00091\n",
            "2025-06-26 08:43:26,325 Epoch 15475: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15476\n",
            "2025-06-26 08:43:26,329 EPOCH 15476\n",
            "INFO:__main__:Epoch 15476: total training loss 0.00094\n",
            "2025-06-26 08:43:26,431 Epoch 15476: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15477\n",
            "2025-06-26 08:43:26,433 EPOCH 15477\n",
            "INFO:__main__:Epoch 15477: total training loss 0.00090\n",
            "2025-06-26 08:43:26,563 Epoch 15477: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15478\n",
            "2025-06-26 08:43:26,566 EPOCH 15478\n",
            "INFO:__main__:Epoch 15478: total training loss 0.00092\n",
            "2025-06-26 08:43:26,675 Epoch 15478: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15479\n",
            "2025-06-26 08:43:26,678 EPOCH 15479\n",
            "INFO:__main__:Epoch 15479: total training loss 0.00093\n",
            "2025-06-26 08:43:26,796 Epoch 15479: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15480\n",
            "2025-06-26 08:43:26,798 EPOCH 15480\n",
            "INFO:__main__:Epoch 15480: total training loss 0.00091\n",
            "2025-06-26 08:43:26,907 Epoch 15480: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15481\n",
            "2025-06-26 08:43:26,909 EPOCH 15481\n",
            "INFO:__main__:Epoch 15481: total training loss 0.00093\n",
            "2025-06-26 08:43:27,033 Epoch 15481: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15482\n",
            "2025-06-26 08:43:27,038 EPOCH 15482\n",
            "INFO:__main__:Epoch 15482: total training loss 0.00092\n",
            "2025-06-26 08:43:27,154 Epoch 15482: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15483\n",
            "2025-06-26 08:43:27,158 EPOCH 15483\n",
            "INFO:__main__:Epoch 15483: total training loss 0.00089\n",
            "2025-06-26 08:43:27,280 Epoch 15483: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15484\n",
            "2025-06-26 08:43:27,282 EPOCH 15484\n",
            "INFO:__main__:Epoch 15484: total training loss 0.00095\n",
            "2025-06-26 08:43:27,406 Epoch 15484: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15485\n",
            "2025-06-26 08:43:27,410 EPOCH 15485\n",
            "INFO:__main__:Epoch 15485: total training loss 0.00090\n",
            "2025-06-26 08:43:27,520 Epoch 15485: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15486\n",
            "2025-06-26 08:43:27,522 EPOCH 15486\n",
            "INFO:__main__:Epoch 15486: total training loss 0.00089\n",
            "2025-06-26 08:43:27,639 Epoch 15486: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15487\n",
            "2025-06-26 08:43:27,643 EPOCH 15487\n",
            "INFO:__main__:Epoch 15487: total training loss 0.00095\n",
            "2025-06-26 08:43:27,757 Epoch 15487: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15488\n",
            "2025-06-26 08:43:27,762 EPOCH 15488\n",
            "INFO:__main__:Epoch 15488: total training loss 0.00093\n",
            "2025-06-26 08:43:27,875 Epoch 15488: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15489\n",
            "2025-06-26 08:43:27,876 EPOCH 15489\n",
            "INFO:__main__:Epoch 15489: total training loss 0.00098\n",
            "2025-06-26 08:43:27,983 Epoch 15489: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15490\n",
            "2025-06-26 08:43:27,988 EPOCH 15490\n",
            "INFO:__main__:Epoch 15490: total training loss 0.00096\n",
            "2025-06-26 08:43:28,093 Epoch 15490: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15491\n",
            "2025-06-26 08:43:28,095 EPOCH 15491\n",
            "INFO:__main__:Epoch 15491: total training loss 0.00088\n",
            "2025-06-26 08:43:28,206 Epoch 15491: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15492\n",
            "2025-06-26 08:43:28,212 EPOCH 15492\n",
            "INFO:__main__:Epoch 15492: total training loss 0.00094\n",
            "2025-06-26 08:43:28,338 Epoch 15492: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15493\n",
            "2025-06-26 08:43:28,340 EPOCH 15493\n",
            "INFO:__main__:Epoch 15493: total training loss 0.00087\n",
            "2025-06-26 08:43:28,446 Epoch 15493: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15494\n",
            "2025-06-26 08:43:28,450 EPOCH 15494\n",
            "INFO:__main__:Epoch 15494: total training loss 0.00090\n",
            "2025-06-26 08:43:28,566 Epoch 15494: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15495\n",
            "2025-06-26 08:43:28,571 EPOCH 15495\n",
            "INFO:__main__:Epoch 15495: total training loss 0.00091\n",
            "2025-06-26 08:43:28,691 Epoch 15495: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15496\n",
            "2025-06-26 08:43:28,696 EPOCH 15496\n",
            "INFO:__main__:Epoch 15496: total training loss 0.00088\n",
            "2025-06-26 08:43:28,797 Epoch 15496: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15497\n",
            "2025-06-26 08:43:28,801 EPOCH 15497\n",
            "INFO:__main__:Epoch 15497: total training loss 0.00081\n",
            "2025-06-26 08:43:28,918 Epoch 15497: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 15498\n",
            "2025-06-26 08:43:28,921 EPOCH 15498\n",
            "INFO:__main__:Epoch 15498: total training loss 0.00086\n",
            "2025-06-26 08:43:29,043 Epoch 15498: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15499\n",
            "2025-06-26 08:43:29,050 EPOCH 15499\n",
            "INFO:__main__:Epoch 15499: total training loss 0.00092\n",
            "2025-06-26 08:43:29,179 Epoch 15499: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15500\n",
            "2025-06-26 08:43:29,181 EPOCH 15500\n",
            "INFO:__main__:Epoch 15500 Step:    15500 Batch Loss:     0.000870 Tokens per Sec:  1463406, Lr: 0.001000\n",
            "2025-06-26 08:43:29,283 Epoch 15500 Step:    15500 Batch Loss:     0.000870 Tokens per Sec:  1463406, Lr: 0.001000\n",
            "INFO:__main__:Epoch 15500: total training loss 0.00087\n",
            "2025-06-26 08:43:29,285 Epoch 15500: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15501\n",
            "2025-06-26 08:43:29,286 EPOCH 15501\n",
            "INFO:__main__:Epoch 15501: total training loss 0.00085\n",
            "2025-06-26 08:43:29,363 Epoch 15501: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15502\n",
            "2025-06-26 08:43:29,365 EPOCH 15502\n",
            "INFO:__main__:Epoch 15502: total training loss 0.00090\n",
            "2025-06-26 08:43:29,437 Epoch 15502: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15503\n",
            "2025-06-26 08:43:29,439 EPOCH 15503\n",
            "INFO:__main__:Epoch 15503: total training loss 0.00094\n",
            "2025-06-26 08:43:29,510 Epoch 15503: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15504\n",
            "2025-06-26 08:43:29,512 EPOCH 15504\n",
            "INFO:__main__:Epoch 15504: total training loss 0.00099\n",
            "2025-06-26 08:43:29,582 Epoch 15504: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15505\n",
            "2025-06-26 08:43:29,584 EPOCH 15505\n",
            "INFO:__main__:Epoch 15505: total training loss 0.00104\n",
            "2025-06-26 08:43:29,655 Epoch 15505: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15506\n",
            "2025-06-26 08:43:29,658 EPOCH 15506\n",
            "INFO:__main__:Epoch 15506: total training loss 0.00099\n",
            "2025-06-26 08:43:29,743 Epoch 15506: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15507\n",
            "2025-06-26 08:43:29,746 EPOCH 15507\n",
            "INFO:__main__:Epoch 15507: total training loss 0.00091\n",
            "2025-06-26 08:43:29,819 Epoch 15507: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15508\n",
            "2025-06-26 08:43:29,821 EPOCH 15508\n",
            "INFO:__main__:Epoch 15508: total training loss 0.00094\n",
            "2025-06-26 08:43:29,891 Epoch 15508: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15509\n",
            "2025-06-26 08:43:29,896 EPOCH 15509\n",
            "INFO:__main__:Epoch 15509: total training loss 0.00100\n",
            "2025-06-26 08:43:29,972 Epoch 15509: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15510\n",
            "2025-06-26 08:43:29,977 EPOCH 15510\n",
            "INFO:__main__:Epoch 15510: total training loss 0.00099\n",
            "2025-06-26 08:43:30,068 Epoch 15510: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15511\n",
            "2025-06-26 08:43:30,070 EPOCH 15511\n",
            "INFO:__main__:Epoch 15511: total training loss 0.00094\n",
            "2025-06-26 08:43:30,141 Epoch 15511: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15512\n",
            "2025-06-26 08:43:30,144 EPOCH 15512\n",
            "INFO:__main__:Epoch 15512: total training loss 0.00092\n",
            "2025-06-26 08:43:30,227 Epoch 15512: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15513\n",
            "2025-06-26 08:43:30,230 EPOCH 15513\n",
            "INFO:__main__:Epoch 15513: total training loss 0.00089\n",
            "2025-06-26 08:43:30,306 Epoch 15513: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15514\n",
            "2025-06-26 08:43:30,308 EPOCH 15514\n",
            "INFO:__main__:Epoch 15514: total training loss 0.00093\n",
            "2025-06-26 08:43:30,375 Epoch 15514: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15515\n",
            "2025-06-26 08:43:30,377 EPOCH 15515\n",
            "INFO:__main__:Epoch 15515: total training loss 0.00090\n",
            "2025-06-26 08:43:30,447 Epoch 15515: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15516\n",
            "2025-06-26 08:43:30,449 EPOCH 15516\n",
            "INFO:__main__:Epoch 15516: total training loss 0.00093\n",
            "2025-06-26 08:43:30,531 Epoch 15516: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15517\n",
            "2025-06-26 08:43:30,533 EPOCH 15517\n",
            "INFO:__main__:Epoch 15517: total training loss 0.00101\n",
            "2025-06-26 08:43:30,608 Epoch 15517: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15518\n",
            "2025-06-26 08:43:30,610 EPOCH 15518\n",
            "INFO:__main__:Epoch 15518: total training loss 0.00095\n",
            "2025-06-26 08:43:30,681 Epoch 15518: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15519\n",
            "2025-06-26 08:43:30,683 EPOCH 15519\n",
            "INFO:__main__:Epoch 15519: total training loss 0.00091\n",
            "2025-06-26 08:43:30,759 Epoch 15519: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15520\n",
            "2025-06-26 08:43:30,761 EPOCH 15520\n",
            "INFO:__main__:Epoch 15520: total training loss 0.00098\n",
            "2025-06-26 08:43:30,845 Epoch 15520: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15521\n",
            "2025-06-26 08:43:30,847 EPOCH 15521\n",
            "INFO:__main__:Epoch 15521: total training loss 0.00093\n",
            "2025-06-26 08:43:30,923 Epoch 15521: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15522\n",
            "2025-06-26 08:43:30,925 EPOCH 15522\n",
            "INFO:__main__:Epoch 15522: total training loss 0.00099\n",
            "2025-06-26 08:43:31,002 Epoch 15522: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15523\n",
            "2025-06-26 08:43:31,004 EPOCH 15523\n",
            "INFO:__main__:Epoch 15523: total training loss 0.00094\n",
            "2025-06-26 08:43:31,083 Epoch 15523: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15524\n",
            "2025-06-26 08:43:31,085 EPOCH 15524\n",
            "INFO:__main__:Epoch 15524: total training loss 0.00098\n",
            "2025-06-26 08:43:31,160 Epoch 15524: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15525\n",
            "2025-06-26 08:43:31,162 EPOCH 15525\n",
            "INFO:__main__:Epoch 15525: total training loss 0.00094\n",
            "2025-06-26 08:43:31,246 Epoch 15525: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15526\n",
            "2025-06-26 08:43:31,248 EPOCH 15526\n",
            "INFO:__main__:Epoch 15526: total training loss 0.00102\n",
            "2025-06-26 08:43:31,325 Epoch 15526: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15527\n",
            "2025-06-26 08:43:31,328 EPOCH 15527\n",
            "INFO:__main__:Epoch 15527: total training loss 0.00103\n",
            "2025-06-26 08:43:31,401 Epoch 15527: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15528\n",
            "2025-06-26 08:43:31,403 EPOCH 15528\n",
            "INFO:__main__:Epoch 15528: total training loss 0.00104\n",
            "2025-06-26 08:43:31,471 Epoch 15528: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15529\n",
            "2025-06-26 08:43:31,474 EPOCH 15529\n",
            "INFO:__main__:Epoch 15529: total training loss 0.00095\n",
            "2025-06-26 08:43:31,546 Epoch 15529: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15530\n",
            "2025-06-26 08:43:31,548 EPOCH 15530\n",
            "INFO:__main__:Epoch 15530: total training loss 0.00098\n",
            "2025-06-26 08:43:31,633 Epoch 15530: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15531\n",
            "2025-06-26 08:43:31,635 EPOCH 15531\n",
            "INFO:__main__:Epoch 15531: total training loss 0.00101\n",
            "2025-06-26 08:43:31,706 Epoch 15531: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15532\n",
            "2025-06-26 08:43:31,708 EPOCH 15532\n",
            "INFO:__main__:Epoch 15532: total training loss 0.00093\n",
            "2025-06-26 08:43:31,779 Epoch 15532: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15533\n",
            "2025-06-26 08:43:31,782 EPOCH 15533\n",
            "INFO:__main__:Epoch 15533: total training loss 0.00097\n",
            "2025-06-26 08:43:31,875 Epoch 15533: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15534\n",
            "2025-06-26 08:43:31,878 EPOCH 15534\n",
            "INFO:__main__:Epoch 15534: total training loss 0.00099\n",
            "2025-06-26 08:43:31,949 Epoch 15534: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15535\n",
            "2025-06-26 08:43:31,951 EPOCH 15535\n",
            "INFO:__main__:Epoch 15535: total training loss 0.00101\n",
            "2025-06-26 08:43:32,021 Epoch 15535: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15536\n",
            "2025-06-26 08:43:32,023 EPOCH 15536\n",
            "INFO:__main__:Epoch 15536: total training loss 0.00092\n",
            "2025-06-26 08:43:32,099 Epoch 15536: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15537\n",
            "2025-06-26 08:43:32,106 EPOCH 15537\n",
            "INFO:__main__:Epoch 15537: total training loss 0.00089\n",
            "2025-06-26 08:43:32,178 Epoch 15537: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15538\n",
            "2025-06-26 08:43:32,180 EPOCH 15538\n",
            "INFO:__main__:Epoch 15538: total training loss 0.00093\n",
            "2025-06-26 08:43:32,278 Epoch 15538: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15539\n",
            "2025-06-26 08:43:32,280 EPOCH 15539\n",
            "INFO:__main__:Epoch 15539: total training loss 0.00095\n",
            "2025-06-26 08:43:32,352 Epoch 15539: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15540\n",
            "2025-06-26 08:43:32,354 EPOCH 15540\n",
            "INFO:__main__:Epoch 15540: total training loss 0.00097\n",
            "2025-06-26 08:43:32,438 Epoch 15540: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15541\n",
            "2025-06-26 08:43:32,440 EPOCH 15541\n",
            "INFO:__main__:Epoch 15541: total training loss 0.00093\n",
            "2025-06-26 08:43:32,511 Epoch 15541: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15542\n",
            "2025-06-26 08:43:32,513 EPOCH 15542\n",
            "INFO:__main__:Epoch 15542: total training loss 0.00089\n",
            "2025-06-26 08:43:32,586 Epoch 15542: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15543\n",
            "2025-06-26 08:43:32,588 EPOCH 15543\n",
            "INFO:__main__:Epoch 15543: total training loss 0.00091\n",
            "2025-06-26 08:43:32,657 Epoch 15543: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15544\n",
            "2025-06-26 08:43:32,659 EPOCH 15544\n",
            "INFO:__main__:Epoch 15544: total training loss 0.00091\n",
            "2025-06-26 08:43:32,729 Epoch 15544: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15545\n",
            "2025-06-26 08:43:32,731 EPOCH 15545\n",
            "INFO:__main__:Epoch 15545: total training loss 0.00097\n",
            "2025-06-26 08:43:32,805 Epoch 15545: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15546\n",
            "2025-06-26 08:43:32,807 EPOCH 15546\n",
            "INFO:__main__:Epoch 15546: total training loss 0.00088\n",
            "2025-06-26 08:43:32,880 Epoch 15546: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15547\n",
            "2025-06-26 08:43:32,883 EPOCH 15547\n",
            "INFO:__main__:Epoch 15547: total training loss 0.00090\n",
            "2025-06-26 08:43:32,969 Epoch 15547: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15548\n",
            "2025-06-26 08:43:32,971 EPOCH 15548\n",
            "INFO:__main__:Epoch 15548: total training loss 0.00098\n",
            "2025-06-26 08:43:33,048 Epoch 15548: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15549\n",
            "2025-06-26 08:43:33,051 EPOCH 15549\n",
            "INFO:__main__:Epoch 15549: total training loss 0.00095\n",
            "2025-06-26 08:43:33,128 Epoch 15549: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15550\n",
            "2025-06-26 08:43:33,130 EPOCH 15550\n",
            "INFO:__main__:Epoch 15550: total training loss 0.00093\n",
            "2025-06-26 08:43:33,203 Epoch 15550: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15551\n",
            "2025-06-26 08:43:33,206 EPOCH 15551\n",
            "INFO:__main__:Epoch 15551: total training loss 0.00098\n",
            "2025-06-26 08:43:33,280 Epoch 15551: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15552\n",
            "2025-06-26 08:43:33,285 EPOCH 15552\n",
            "INFO:__main__:Epoch 15552: total training loss 0.00092\n",
            "2025-06-26 08:43:33,361 Epoch 15552: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15553\n",
            "2025-06-26 08:43:33,363 EPOCH 15553\n",
            "INFO:__main__:Epoch 15553: total training loss 0.00088\n",
            "2025-06-26 08:43:33,435 Epoch 15553: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15554\n",
            "2025-06-26 08:43:33,438 EPOCH 15554\n",
            "INFO:__main__:Epoch 15554: total training loss 0.00092\n",
            "2025-06-26 08:43:33,509 Epoch 15554: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15555\n",
            "2025-06-26 08:43:33,512 EPOCH 15555\n",
            "INFO:__main__:Epoch 15555: total training loss 0.00093\n",
            "2025-06-26 08:43:33,586 Epoch 15555: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15556\n",
            "2025-06-26 08:43:33,589 EPOCH 15556\n",
            "INFO:__main__:Epoch 15556: total training loss 0.00085\n",
            "2025-06-26 08:43:33,661 Epoch 15556: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15557\n",
            "2025-06-26 08:43:33,664 EPOCH 15557\n",
            "INFO:__main__:Epoch 15557: total training loss 0.00088\n",
            "2025-06-26 08:43:33,737 Epoch 15557: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15558\n",
            "2025-06-26 08:43:33,742 EPOCH 15558\n",
            "INFO:__main__:Epoch 15558: total training loss 0.00088\n",
            "2025-06-26 08:43:33,816 Epoch 15558: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15559\n",
            "2025-06-26 08:43:33,820 EPOCH 15559\n",
            "INFO:__main__:Epoch 15559: total training loss 0.00091\n",
            "2025-06-26 08:43:33,896 Epoch 15559: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15560\n",
            "2025-06-26 08:43:33,898 EPOCH 15560\n",
            "INFO:__main__:Epoch 15560: total training loss 0.00096\n",
            "2025-06-26 08:43:33,972 Epoch 15560: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15561\n",
            "2025-06-26 08:43:33,974 EPOCH 15561\n",
            "INFO:__main__:Epoch 15561: total training loss 0.00092\n",
            "2025-06-26 08:43:34,067 Epoch 15561: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15562\n",
            "2025-06-26 08:43:34,070 EPOCH 15562\n",
            "INFO:__main__:Epoch 15562: total training loss 0.00092\n",
            "2025-06-26 08:43:34,142 Epoch 15562: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15563\n",
            "2025-06-26 08:43:34,144 EPOCH 15563\n",
            "INFO:__main__:Epoch 15563: total training loss 0.00088\n",
            "2025-06-26 08:43:34,227 Epoch 15563: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15564\n",
            "2025-06-26 08:43:34,235 EPOCH 15564\n",
            "INFO:__main__:Epoch 15564: total training loss 0.00093\n",
            "2025-06-26 08:43:34,310 Epoch 15564: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15565\n",
            "2025-06-26 08:43:34,312 EPOCH 15565\n",
            "INFO:__main__:Epoch 15565: total training loss 0.00092\n",
            "2025-06-26 08:43:34,387 Epoch 15565: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15566\n",
            "2025-06-26 08:43:34,389 EPOCH 15566\n",
            "INFO:__main__:Epoch 15566: total training loss 0.00090\n",
            "2025-06-26 08:43:34,464 Epoch 15566: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15567\n",
            "2025-06-26 08:43:34,466 EPOCH 15567\n",
            "INFO:__main__:Epoch 15567: total training loss 0.00096\n",
            "2025-06-26 08:43:34,537 Epoch 15567: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15568\n",
            "2025-06-26 08:43:34,540 EPOCH 15568\n",
            "INFO:__main__:Epoch 15568: total training loss 0.00092\n",
            "2025-06-26 08:43:34,612 Epoch 15568: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15569\n",
            "2025-06-26 08:43:34,614 EPOCH 15569\n",
            "INFO:__main__:Epoch 15569: total training loss 0.00090\n",
            "2025-06-26 08:43:34,686 Epoch 15569: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15570\n",
            "2025-06-26 08:43:34,688 EPOCH 15570\n",
            "INFO:__main__:Epoch 15570: total training loss 0.00092\n",
            "2025-06-26 08:43:34,764 Epoch 15570: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15571\n",
            "2025-06-26 08:43:34,766 EPOCH 15571\n",
            "INFO:__main__:Epoch 15571: total training loss 0.00097\n",
            "2025-06-26 08:43:34,840 Epoch 15571: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15572\n",
            "2025-06-26 08:43:34,842 EPOCH 15572\n",
            "INFO:__main__:Epoch 15572: total training loss 0.00092\n",
            "2025-06-26 08:43:34,914 Epoch 15572: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15573\n",
            "2025-06-26 08:43:34,916 EPOCH 15573\n",
            "INFO:__main__:Epoch 15573: total training loss 0.00094\n",
            "2025-06-26 08:43:34,987 Epoch 15573: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15574\n",
            "2025-06-26 08:43:34,988 EPOCH 15574\n",
            "INFO:__main__:Epoch 15574: total training loss 0.00099\n",
            "2025-06-26 08:43:35,066 Epoch 15574: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15575\n",
            "2025-06-26 08:43:35,068 EPOCH 15575\n",
            "INFO:__main__:Epoch 15575: total training loss 0.00098\n",
            "2025-06-26 08:43:35,154 Epoch 15575: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15576\n",
            "2025-06-26 08:43:35,156 EPOCH 15576\n",
            "INFO:__main__:Epoch 15576: total training loss 0.00093\n",
            "2025-06-26 08:43:35,227 Epoch 15576: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15577\n",
            "2025-06-26 08:43:35,229 EPOCH 15577\n",
            "INFO:__main__:Epoch 15577: total training loss 0.00097\n",
            "2025-06-26 08:43:35,299 Epoch 15577: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15578\n",
            "2025-06-26 08:43:35,301 EPOCH 15578\n",
            "INFO:__main__:Epoch 15578: total training loss 0.00092\n",
            "2025-06-26 08:43:35,371 Epoch 15578: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15579\n",
            "2025-06-26 08:43:35,376 EPOCH 15579\n",
            "INFO:__main__:Epoch 15579: total training loss 0.00088\n",
            "2025-06-26 08:43:35,460 Epoch 15579: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15580\n",
            "2025-06-26 08:43:35,462 EPOCH 15580\n",
            "INFO:__main__:Epoch 15580: total training loss 0.00098\n",
            "2025-06-26 08:43:35,536 Epoch 15580: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15581\n",
            "2025-06-26 08:43:35,538 EPOCH 15581\n",
            "INFO:__main__:Epoch 15581: total training loss 0.00101\n",
            "2025-06-26 08:43:35,611 Epoch 15581: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15582\n",
            "2025-06-26 08:43:35,613 EPOCH 15582\n",
            "INFO:__main__:Epoch 15582: total training loss 0.00098\n",
            "2025-06-26 08:43:35,697 Epoch 15582: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15583\n",
            "2025-06-26 08:43:35,699 EPOCH 15583\n",
            "INFO:__main__:Epoch 15583: total training loss 0.00105\n",
            "2025-06-26 08:43:35,781 Epoch 15583: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15584\n",
            "2025-06-26 08:43:35,783 EPOCH 15584\n",
            "INFO:__main__:Epoch 15584: total training loss 0.00099\n",
            "2025-06-26 08:43:35,855 Epoch 15584: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15585\n",
            "2025-06-26 08:43:35,857 EPOCH 15585\n",
            "INFO:__main__:Epoch 15585: total training loss 0.00095\n",
            "2025-06-26 08:43:35,931 Epoch 15585: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15586\n",
            "2025-06-26 08:43:35,933 EPOCH 15586\n",
            "INFO:__main__:Epoch 15586: total training loss 0.00093\n",
            "2025-06-26 08:43:36,011 Epoch 15586: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15587\n",
            "2025-06-26 08:43:36,013 EPOCH 15587\n",
            "INFO:__main__:Epoch 15587: total training loss 0.00098\n",
            "2025-06-26 08:43:36,093 Epoch 15587: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15588\n",
            "2025-06-26 08:43:36,095 EPOCH 15588\n",
            "INFO:__main__:Epoch 15588: total training loss 0.00093\n",
            "2025-06-26 08:43:36,198 Epoch 15588: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15589\n",
            "2025-06-26 08:43:36,200 EPOCH 15589\n",
            "INFO:__main__:Epoch 15589: total training loss 0.00095\n",
            "2025-06-26 08:43:36,279 Epoch 15589: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15590\n",
            "2025-06-26 08:43:36,281 EPOCH 15590\n",
            "INFO:__main__:Epoch 15590: total training loss 0.00097\n",
            "2025-06-26 08:43:36,358 Epoch 15590: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15591\n",
            "2025-06-26 08:43:36,360 EPOCH 15591\n",
            "INFO:__main__:Epoch 15591: total training loss 0.00089\n",
            "2025-06-26 08:43:36,434 Epoch 15591: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15592\n",
            "2025-06-26 08:43:36,437 EPOCH 15592\n",
            "INFO:__main__:Epoch 15592: total training loss 0.00096\n",
            "2025-06-26 08:43:36,529 Epoch 15592: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15593\n",
            "2025-06-26 08:43:36,531 EPOCH 15593\n",
            "INFO:__main__:Epoch 15593: total training loss 0.00094\n",
            "2025-06-26 08:43:36,604 Epoch 15593: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15594\n",
            "2025-06-26 08:43:36,606 EPOCH 15594\n",
            "INFO:__main__:Epoch 15594: total training loss 0.00096\n",
            "2025-06-26 08:43:36,679 Epoch 15594: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15595\n",
            "2025-06-26 08:43:36,681 EPOCH 15595\n",
            "INFO:__main__:Epoch 15595: total training loss 0.00095\n",
            "2025-06-26 08:43:36,765 Epoch 15595: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15596\n",
            "2025-06-26 08:43:36,767 EPOCH 15596\n",
            "INFO:__main__:Epoch 15596: total training loss 0.00086\n",
            "2025-06-26 08:43:36,862 Epoch 15596: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15597\n",
            "2025-06-26 08:43:36,864 EPOCH 15597\n",
            "INFO:__main__:Epoch 15597: total training loss 0.00090\n",
            "2025-06-26 08:43:36,942 Epoch 15597: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15598\n",
            "2025-06-26 08:43:36,944 EPOCH 15598\n",
            "INFO:__main__:Epoch 15598: total training loss 0.00091\n",
            "2025-06-26 08:43:37,018 Epoch 15598: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15599\n",
            "2025-06-26 08:43:37,020 EPOCH 15599\n",
            "INFO:__main__:Epoch 15599: total training loss 0.00086\n",
            "2025-06-26 08:43:37,090 Epoch 15599: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15600\n",
            "2025-06-26 08:43:37,092 EPOCH 15600\n",
            "INFO:__main__:Epoch 15600: total training loss 0.00089\n",
            "2025-06-26 08:43:37,167 Epoch 15600: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15601\n",
            "2025-06-26 08:43:37,169 EPOCH 15601\n",
            "INFO:__main__:Epoch 15601: total training loss 0.00087\n",
            "2025-06-26 08:43:37,261 Epoch 15601: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15602\n",
            "2025-06-26 08:43:37,263 EPOCH 15602\n",
            "INFO:__main__:Epoch 15602: total training loss 0.00085\n",
            "2025-06-26 08:43:37,332 Epoch 15602: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15603\n",
            "2025-06-26 08:43:37,334 EPOCH 15603\n",
            "INFO:__main__:Epoch 15603: total training loss 0.00091\n",
            "2025-06-26 08:43:37,403 Epoch 15603: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15604\n",
            "2025-06-26 08:43:37,405 EPOCH 15604\n",
            "INFO:__main__:Epoch 15604: total training loss 0.00090\n",
            "2025-06-26 08:43:37,477 Epoch 15604: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15605\n",
            "2025-06-26 08:43:37,479 EPOCH 15605\n",
            "INFO:__main__:Epoch 15605: total training loss 0.00092\n",
            "2025-06-26 08:43:37,551 Epoch 15605: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15606\n",
            "2025-06-26 08:43:37,553 EPOCH 15606\n",
            "INFO:__main__:Epoch 15606: total training loss 0.00086\n",
            "2025-06-26 08:43:37,623 Epoch 15606: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15607\n",
            "2025-06-26 08:43:37,625 EPOCH 15607\n",
            "INFO:__main__:Epoch 15607: total training loss 0.00091\n",
            "2025-06-26 08:43:37,694 Epoch 15607: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15608\n",
            "2025-06-26 08:43:37,696 EPOCH 15608\n",
            "INFO:__main__:Epoch 15608: total training loss 0.00095\n",
            "2025-06-26 08:43:37,769 Epoch 15608: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15609\n",
            "2025-06-26 08:43:37,771 EPOCH 15609\n",
            "INFO:__main__:Epoch 15609: total training loss 0.00095\n",
            "2025-06-26 08:43:37,845 Epoch 15609: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15610\n",
            "2025-06-26 08:43:37,847 EPOCH 15610\n",
            "INFO:__main__:Epoch 15610: total training loss 0.00096\n",
            "2025-06-26 08:43:37,915 Epoch 15610: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15611\n",
            "2025-06-26 08:43:37,917 EPOCH 15611\n",
            "INFO:__main__:Epoch 15611: total training loss 0.00092\n",
            "2025-06-26 08:43:37,988 Epoch 15611: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15612\n",
            "2025-06-26 08:43:37,990 EPOCH 15612\n",
            "INFO:__main__:Epoch 15612: total training loss 0.00088\n",
            "2025-06-26 08:43:38,060 Epoch 15612: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15613\n",
            "2025-06-26 08:43:38,062 EPOCH 15613\n",
            "INFO:__main__:Epoch 15613: total training loss 0.00097\n",
            "2025-06-26 08:43:38,137 Epoch 15613: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15614\n",
            "2025-06-26 08:43:38,161 EPOCH 15614\n",
            "INFO:__main__:Epoch 15614: total training loss 0.00091\n",
            "2025-06-26 08:43:38,233 Epoch 15614: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15615\n",
            "2025-06-26 08:43:38,239 EPOCH 15615\n",
            "INFO:__main__:Epoch 15615: total training loss 0.00091\n",
            "2025-06-26 08:43:38,319 Epoch 15615: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15616\n",
            "2025-06-26 08:43:38,321 EPOCH 15616\n",
            "INFO:__main__:Epoch 15616: total training loss 0.00092\n",
            "2025-06-26 08:43:38,397 Epoch 15616: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15617\n",
            "2025-06-26 08:43:38,399 EPOCH 15617\n",
            "INFO:__main__:Epoch 15617: total training loss 0.00093\n",
            "2025-06-26 08:43:38,476 Epoch 15617: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15618\n",
            "2025-06-26 08:43:38,478 EPOCH 15618\n",
            "INFO:__main__:Epoch 15618: total training loss 0.00091\n",
            "2025-06-26 08:43:38,548 Epoch 15618: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15619\n",
            "2025-06-26 08:43:38,550 EPOCH 15619\n",
            "INFO:__main__:Epoch 15619: total training loss 0.00089\n",
            "2025-06-26 08:43:38,640 Epoch 15619: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15620\n",
            "2025-06-26 08:43:38,642 EPOCH 15620\n",
            "INFO:__main__:Epoch 15620: total training loss 0.00093\n",
            "2025-06-26 08:43:38,734 Epoch 15620: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15621\n",
            "2025-06-26 08:43:38,736 EPOCH 15621\n",
            "INFO:__main__:Epoch 15621: total training loss 0.00093\n",
            "2025-06-26 08:43:38,822 Epoch 15621: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15622\n",
            "2025-06-26 08:43:38,825 EPOCH 15622\n",
            "INFO:__main__:Epoch 15622: total training loss 0.00094\n",
            "2025-06-26 08:43:38,901 Epoch 15622: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15623\n",
            "2025-06-26 08:43:38,903 EPOCH 15623\n",
            "INFO:__main__:Epoch 15623: total training loss 0.00091\n",
            "2025-06-26 08:43:38,987 Epoch 15623: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15624\n",
            "2025-06-26 08:43:38,991 EPOCH 15624\n",
            "INFO:__main__:Epoch 15624: total training loss 0.00090\n",
            "2025-06-26 08:43:39,068 Epoch 15624: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15625\n",
            "2025-06-26 08:43:39,070 EPOCH 15625\n",
            "INFO:__main__:Epoch 15625: total training loss 0.00089\n",
            "2025-06-26 08:43:39,144 Epoch 15625: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15626\n",
            "2025-06-26 08:43:39,147 EPOCH 15626\n",
            "INFO:__main__:Epoch 15626: total training loss 0.00093\n",
            "2025-06-26 08:43:39,222 Epoch 15626: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15627\n",
            "2025-06-26 08:43:39,225 EPOCH 15627\n",
            "INFO:__main__:Epoch 15627: total training loss 0.00097\n",
            "2025-06-26 08:43:39,304 Epoch 15627: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15628\n",
            "2025-06-26 08:43:39,306 EPOCH 15628\n",
            "INFO:__main__:Epoch 15628: total training loss 0.00095\n",
            "2025-06-26 08:43:39,390 Epoch 15628: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15629\n",
            "2025-06-26 08:43:39,392 EPOCH 15629\n",
            "INFO:__main__:Epoch 15629: total training loss 0.00094\n",
            "2025-06-26 08:43:39,484 Epoch 15629: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15630\n",
            "2025-06-26 08:43:39,486 EPOCH 15630\n",
            "INFO:__main__:Epoch 15630: total training loss 0.00093\n",
            "2025-06-26 08:43:39,564 Epoch 15630: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15631\n",
            "2025-06-26 08:43:39,565 EPOCH 15631\n",
            "INFO:__main__:Epoch 15631: total training loss 0.00093\n",
            "2025-06-26 08:43:39,650 Epoch 15631: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15632\n",
            "2025-06-26 08:43:39,652 EPOCH 15632\n",
            "INFO:__main__:Epoch 15632: total training loss 0.00096\n",
            "2025-06-26 08:43:39,724 Epoch 15632: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15633\n",
            "2025-06-26 08:43:39,726 EPOCH 15633\n",
            "INFO:__main__:Epoch 15633: total training loss 0.00101\n",
            "2025-06-26 08:43:39,813 Epoch 15633: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15634\n",
            "2025-06-26 08:43:39,815 EPOCH 15634\n",
            "INFO:__main__:Epoch 15634: total training loss 0.00101\n",
            "2025-06-26 08:43:39,889 Epoch 15634: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15635\n",
            "2025-06-26 08:43:39,892 EPOCH 15635\n",
            "INFO:__main__:Epoch 15635: total training loss 0.00103\n",
            "2025-06-26 08:43:39,981 Epoch 15635: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15636\n",
            "2025-06-26 08:43:39,983 EPOCH 15636\n",
            "INFO:__main__:Epoch 15636: total training loss 0.00101\n",
            "2025-06-26 08:43:40,072 Epoch 15636: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15637\n",
            "2025-06-26 08:43:40,075 EPOCH 15637\n",
            "INFO:__main__:Epoch 15637: total training loss 0.00094\n",
            "2025-06-26 08:43:40,158 Epoch 15637: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15638\n",
            "2025-06-26 08:43:40,160 EPOCH 15638\n",
            "INFO:__main__:Epoch 15638: total training loss 0.00094\n",
            "2025-06-26 08:43:40,231 Epoch 15638: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15639\n",
            "2025-06-26 08:43:40,233 EPOCH 15639\n",
            "INFO:__main__:Epoch 15639: total training loss 0.00098\n",
            "2025-06-26 08:43:40,319 Epoch 15639: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15640\n",
            "2025-06-26 08:43:40,321 EPOCH 15640\n",
            "INFO:__main__:Epoch 15640: total training loss 0.00090\n",
            "2025-06-26 08:43:40,391 Epoch 15640: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15641\n",
            "2025-06-26 08:43:40,393 EPOCH 15641\n",
            "INFO:__main__:Epoch 15641: total training loss 0.00089\n",
            "2025-06-26 08:43:40,464 Epoch 15641: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15642\n",
            "2025-06-26 08:43:40,466 EPOCH 15642\n",
            "INFO:__main__:Epoch 15642: total training loss 0.00088\n",
            "2025-06-26 08:43:40,548 Epoch 15642: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15643\n",
            "2025-06-26 08:43:40,551 EPOCH 15643\n",
            "INFO:__main__:Epoch 15643: total training loss 0.00091\n",
            "2025-06-26 08:43:40,624 Epoch 15643: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15644\n",
            "2025-06-26 08:43:40,626 EPOCH 15644\n",
            "INFO:__main__:Epoch 15644: total training loss 0.00094\n",
            "2025-06-26 08:43:40,695 Epoch 15644: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15645\n",
            "2025-06-26 08:43:40,697 EPOCH 15645\n",
            "INFO:__main__:Epoch 15645: total training loss 0.00094\n",
            "2025-06-26 08:43:40,782 Epoch 15645: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15646\n",
            "2025-06-26 08:43:40,784 EPOCH 15646\n",
            "INFO:__main__:Epoch 15646: total training loss 0.00090\n",
            "2025-06-26 08:43:40,858 Epoch 15646: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15647\n",
            "2025-06-26 08:43:40,860 EPOCH 15647\n",
            "INFO:__main__:Epoch 15647: total training loss 0.00089\n",
            "2025-06-26 08:43:40,929 Epoch 15647: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15648\n",
            "2025-06-26 08:43:40,931 EPOCH 15648\n",
            "INFO:__main__:Epoch 15648: total training loss 0.00099\n",
            "2025-06-26 08:43:41,000 Epoch 15648: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15649\n",
            "2025-06-26 08:43:41,002 EPOCH 15649\n",
            "INFO:__main__:Epoch 15649: total training loss 0.00105\n",
            "2025-06-26 08:43:41,077 Epoch 15649: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15650\n",
            "2025-06-26 08:43:41,079 EPOCH 15650\n",
            "INFO:__main__:Epoch 15650: total training loss 0.00103\n",
            "2025-06-26 08:43:41,147 Epoch 15650: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15651\n",
            "2025-06-26 08:43:41,149 EPOCH 15651\n",
            "INFO:__main__:Epoch 15651: total training loss 0.00107\n",
            "2025-06-26 08:43:41,218 Epoch 15651: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15652\n",
            "2025-06-26 08:43:41,220 EPOCH 15652\n",
            "INFO:__main__:Epoch 15652: total training loss 0.00100\n",
            "2025-06-26 08:43:41,299 Epoch 15652: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15653\n",
            "2025-06-26 08:43:41,300 EPOCH 15653\n",
            "INFO:__main__:Epoch 15653: total training loss 0.00102\n",
            "2025-06-26 08:43:41,367 Epoch 15653: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15654\n",
            "2025-06-26 08:43:41,370 EPOCH 15654\n",
            "INFO:__main__:Epoch 15654: total training loss 0.00096\n",
            "2025-06-26 08:43:41,449 Epoch 15654: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15655\n",
            "2025-06-26 08:43:41,451 EPOCH 15655\n",
            "INFO:__main__:Epoch 15655: total training loss 0.00095\n",
            "2025-06-26 08:43:41,538 Epoch 15655: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15656\n",
            "2025-06-26 08:43:41,541 EPOCH 15656\n",
            "INFO:__main__:Epoch 15656: total training loss 0.00096\n",
            "2025-06-26 08:43:41,639 Epoch 15656: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15657\n",
            "2025-06-26 08:43:41,642 EPOCH 15657\n",
            "INFO:__main__:Epoch 15657: total training loss 0.00089\n",
            "2025-06-26 08:43:41,731 Epoch 15657: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15658\n",
            "2025-06-26 08:43:41,735 EPOCH 15658\n",
            "INFO:__main__:Epoch 15658: total training loss 0.00093\n",
            "2025-06-26 08:43:41,823 Epoch 15658: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15659\n",
            "2025-06-26 08:43:41,826 EPOCH 15659\n",
            "INFO:__main__:Epoch 15659: total training loss 0.00086\n",
            "2025-06-26 08:43:41,916 Epoch 15659: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15660\n",
            "2025-06-26 08:43:41,918 EPOCH 15660\n",
            "INFO:__main__:Epoch 15660: total training loss 0.00092\n",
            "2025-06-26 08:43:42,015 Epoch 15660: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15661\n",
            "2025-06-26 08:43:42,018 EPOCH 15661\n",
            "INFO:__main__:Epoch 15661: total training loss 0.00088\n",
            "2025-06-26 08:43:42,106 Epoch 15661: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15662\n",
            "2025-06-26 08:43:42,112 EPOCH 15662\n",
            "INFO:__main__:Epoch 15662: total training loss 0.00092\n",
            "2025-06-26 08:43:42,180 Epoch 15662: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15663\n",
            "2025-06-26 08:43:42,187 EPOCH 15663\n",
            "INFO:__main__:Epoch 15663: total training loss 0.00090\n",
            "2025-06-26 08:43:42,270 Epoch 15663: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15664\n",
            "2025-06-26 08:43:42,276 EPOCH 15664\n",
            "INFO:__main__:Epoch 15664: total training loss 0.00087\n",
            "2025-06-26 08:43:42,350 Epoch 15664: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15665\n",
            "2025-06-26 08:43:42,356 EPOCH 15665\n",
            "INFO:__main__:Epoch 15665: total training loss 0.00087\n",
            "2025-06-26 08:43:42,445 Epoch 15665: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15666\n",
            "2025-06-26 08:43:42,453 EPOCH 15666\n",
            "INFO:__main__:Epoch 15666: total training loss 0.00089\n",
            "2025-06-26 08:43:42,523 Epoch 15666: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15667\n",
            "2025-06-26 08:43:42,528 EPOCH 15667\n",
            "INFO:__main__:Epoch 15667: total training loss 0.00093\n",
            "2025-06-26 08:43:42,604 Epoch 15667: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15668\n",
            "2025-06-26 08:43:42,609 EPOCH 15668\n",
            "INFO:__main__:Epoch 15668: total training loss 0.00088\n",
            "2025-06-26 08:43:42,688 Epoch 15668: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15669\n",
            "2025-06-26 08:43:42,690 EPOCH 15669\n",
            "INFO:__main__:Epoch 15669: total training loss 0.00089\n",
            "2025-06-26 08:43:42,776 Epoch 15669: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15670\n",
            "2025-06-26 08:43:42,781 EPOCH 15670\n",
            "INFO:__main__:Epoch 15670: total training loss 0.00094\n",
            "2025-06-26 08:43:42,867 Epoch 15670: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15671\n",
            "2025-06-26 08:43:42,871 EPOCH 15671\n",
            "INFO:__main__:Epoch 15671: total training loss 0.00092\n",
            "2025-06-26 08:43:42,960 Epoch 15671: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15672\n",
            "2025-06-26 08:43:42,969 EPOCH 15672\n",
            "INFO:__main__:Epoch 15672: total training loss 0.00098\n",
            "2025-06-26 08:43:43,082 Epoch 15672: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15673\n",
            "2025-06-26 08:43:43,086 EPOCH 15673\n",
            "INFO:__main__:Epoch 15673: total training loss 0.00100\n",
            "2025-06-26 08:43:43,189 Epoch 15673: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15674\n",
            "2025-06-26 08:43:43,195 EPOCH 15674\n",
            "INFO:__main__:Epoch 15674: total training loss 0.00100\n",
            "2025-06-26 08:43:43,290 Epoch 15674: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15675\n",
            "2025-06-26 08:43:43,294 EPOCH 15675\n",
            "INFO:__main__:Epoch 15675: total training loss 0.00099\n",
            "2025-06-26 08:43:43,405 Epoch 15675: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15676\n",
            "2025-06-26 08:43:43,409 EPOCH 15676\n",
            "INFO:__main__:Epoch 15676: total training loss 0.00093\n",
            "2025-06-26 08:43:43,522 Epoch 15676: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15677\n",
            "2025-06-26 08:43:43,524 EPOCH 15677\n",
            "INFO:__main__:Epoch 15677: total training loss 0.00090\n",
            "2025-06-26 08:43:43,637 Epoch 15677: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15678\n",
            "2025-06-26 08:43:43,642 EPOCH 15678\n",
            "INFO:__main__:Epoch 15678: total training loss 0.00092\n",
            "2025-06-26 08:43:43,752 Epoch 15678: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15679\n",
            "2025-06-26 08:43:43,755 EPOCH 15679\n",
            "INFO:__main__:Epoch 15679: total training loss 0.00090\n",
            "2025-06-26 08:43:43,874 Epoch 15679: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15680\n",
            "2025-06-26 08:43:43,878 EPOCH 15680\n",
            "INFO:__main__:Epoch 15680: total training loss 0.00096\n",
            "2025-06-26 08:43:43,991 Epoch 15680: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15681\n",
            "2025-06-26 08:43:43,994 EPOCH 15681\n",
            "INFO:__main__:Epoch 15681: total training loss 0.00090\n",
            "2025-06-26 08:43:44,117 Epoch 15681: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15682\n",
            "2025-06-26 08:43:44,121 EPOCH 15682\n",
            "INFO:__main__:Epoch 15682: total training loss 0.00089\n",
            "2025-06-26 08:43:44,237 Epoch 15682: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15683\n",
            "2025-06-26 08:43:44,239 EPOCH 15683\n",
            "INFO:__main__:Epoch 15683: total training loss 0.00093\n",
            "2025-06-26 08:43:44,360 Epoch 15683: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15684\n",
            "2025-06-26 08:43:44,365 EPOCH 15684\n",
            "INFO:__main__:Epoch 15684: total training loss 0.00097\n",
            "2025-06-26 08:43:44,459 Epoch 15684: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15685\n",
            "2025-06-26 08:43:44,465 EPOCH 15685\n",
            "INFO:__main__:Epoch 15685: total training loss 0.00093\n",
            "2025-06-26 08:43:44,548 Epoch 15685: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15686\n",
            "2025-06-26 08:43:44,553 EPOCH 15686\n",
            "INFO:__main__:Epoch 15686: total training loss 0.00088\n",
            "2025-06-26 08:43:44,643 Epoch 15686: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15687\n",
            "2025-06-26 08:43:44,651 EPOCH 15687\n",
            "INFO:__main__:Epoch 15687: total training loss 0.00093\n",
            "2025-06-26 08:43:44,745 Epoch 15687: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15688\n",
            "2025-06-26 08:43:44,751 EPOCH 15688\n",
            "INFO:__main__:Epoch 15688: total training loss 0.00085\n",
            "2025-06-26 08:43:44,836 Epoch 15688: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15689\n",
            "2025-06-26 08:43:44,843 EPOCH 15689\n",
            "INFO:__main__:Epoch 15689: total training loss 0.00090\n",
            "2025-06-26 08:43:44,936 Epoch 15689: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15690\n",
            "2025-06-26 08:43:44,942 EPOCH 15690\n",
            "INFO:__main__:Epoch 15690: total training loss 0.00090\n",
            "2025-06-26 08:43:45,064 Epoch 15690: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15691\n",
            "2025-06-26 08:43:45,066 EPOCH 15691\n",
            "INFO:__main__:Epoch 15691: total training loss 0.00090\n",
            "2025-06-26 08:43:45,143 Epoch 15691: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15692\n",
            "2025-06-26 08:43:45,147 EPOCH 15692\n",
            "INFO:__main__:Epoch 15692: total training loss 0.00087\n",
            "2025-06-26 08:43:45,221 Epoch 15692: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15693\n",
            "2025-06-26 08:43:45,223 EPOCH 15693\n",
            "INFO:__main__:Epoch 15693: total training loss 0.00092\n",
            "2025-06-26 08:43:45,294 Epoch 15693: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15694\n",
            "2025-06-26 08:43:45,296 EPOCH 15694\n",
            "INFO:__main__:Epoch 15694: total training loss 0.00094\n",
            "2025-06-26 08:43:45,369 Epoch 15694: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15695\n",
            "2025-06-26 08:43:45,371 EPOCH 15695\n",
            "INFO:__main__:Epoch 15695: total training loss 0.00095\n",
            "2025-06-26 08:43:45,444 Epoch 15695: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15696\n",
            "2025-06-26 08:43:45,447 EPOCH 15696\n",
            "INFO:__main__:Epoch 15696: total training loss 0.00096\n",
            "2025-06-26 08:43:45,521 Epoch 15696: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15697\n",
            "2025-06-26 08:43:45,523 EPOCH 15697\n",
            "INFO:__main__:Epoch 15697: total training loss 0.00088\n",
            "2025-06-26 08:43:45,602 Epoch 15697: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15698\n",
            "2025-06-26 08:43:45,605 EPOCH 15698\n",
            "INFO:__main__:Epoch 15698: total training loss 0.00093\n",
            "2025-06-26 08:43:45,686 Epoch 15698: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15699\n",
            "2025-06-26 08:43:45,690 EPOCH 15699\n",
            "INFO:__main__:Epoch 15699: total training loss 0.00097\n",
            "2025-06-26 08:43:45,768 Epoch 15699: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15700\n",
            "2025-06-26 08:43:45,770 EPOCH 15700\n",
            "INFO:__main__:Epoch 15700: total training loss 0.00096\n",
            "2025-06-26 08:43:45,844 Epoch 15700: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15701\n",
            "2025-06-26 08:43:45,846 EPOCH 15701\n",
            "INFO:__main__:Epoch 15701: total training loss 0.00094\n",
            "2025-06-26 08:43:45,925 Epoch 15701: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15702\n",
            "2025-06-26 08:43:45,928 EPOCH 15702\n",
            "INFO:__main__:Epoch 15702: total training loss 0.00100\n",
            "2025-06-26 08:43:46,004 Epoch 15702: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15703\n",
            "2025-06-26 08:43:46,010 EPOCH 15703\n",
            "INFO:__main__:Epoch 15703: total training loss 0.00089\n",
            "2025-06-26 08:43:46,107 Epoch 15703: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15704\n",
            "2025-06-26 08:43:46,109 EPOCH 15704\n",
            "INFO:__main__:Epoch 15704: total training loss 0.00096\n",
            "2025-06-26 08:43:46,185 Epoch 15704: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15705\n",
            "2025-06-26 08:43:46,187 EPOCH 15705\n",
            "INFO:__main__:Epoch 15705: total training loss 0.00097\n",
            "2025-06-26 08:43:46,256 Epoch 15705: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15706\n",
            "2025-06-26 08:43:46,258 EPOCH 15706\n",
            "INFO:__main__:Epoch 15706: total training loss 0.00092\n",
            "2025-06-26 08:43:46,325 Epoch 15706: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15707\n",
            "2025-06-26 08:43:46,327 EPOCH 15707\n",
            "INFO:__main__:Epoch 15707: total training loss 0.00094\n",
            "2025-06-26 08:43:46,395 Epoch 15707: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15708\n",
            "2025-06-26 08:43:46,397 EPOCH 15708\n",
            "INFO:__main__:Epoch 15708: total training loss 0.00090\n",
            "2025-06-26 08:43:46,467 Epoch 15708: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15709\n",
            "2025-06-26 08:43:46,469 EPOCH 15709\n",
            "INFO:__main__:Epoch 15709: total training loss 0.00092\n",
            "2025-06-26 08:43:46,541 Epoch 15709: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15710\n",
            "2025-06-26 08:43:46,543 EPOCH 15710\n",
            "INFO:__main__:Epoch 15710: total training loss 0.00086\n",
            "2025-06-26 08:43:46,615 Epoch 15710: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15711\n",
            "2025-06-26 08:43:46,617 EPOCH 15711\n",
            "INFO:__main__:Epoch 15711: total training loss 0.00086\n",
            "2025-06-26 08:43:46,688 Epoch 15711: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15712\n",
            "2025-06-26 08:43:46,690 EPOCH 15712\n",
            "INFO:__main__:Epoch 15712: total training loss 0.00087\n",
            "2025-06-26 08:43:46,759 Epoch 15712: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15713\n",
            "2025-06-26 08:43:46,761 EPOCH 15713\n",
            "INFO:__main__:Epoch 15713: total training loss 0.00084\n",
            "2025-06-26 08:43:46,832 Epoch 15713: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15714\n",
            "2025-06-26 08:43:46,834 EPOCH 15714\n",
            "INFO:__main__:Epoch 15714: total training loss 0.00083\n",
            "2025-06-26 08:43:46,905 Epoch 15714: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15715\n",
            "2025-06-26 08:43:46,907 EPOCH 15715\n",
            "INFO:__main__:Epoch 15715: total training loss 0.00087\n",
            "2025-06-26 08:43:46,979 Epoch 15715: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15716\n",
            "2025-06-26 08:43:46,981 EPOCH 15716\n",
            "INFO:__main__:Epoch 15716: total training loss 0.00088\n",
            "2025-06-26 08:43:47,049 Epoch 15716: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15717\n",
            "2025-06-26 08:43:47,051 EPOCH 15717\n",
            "INFO:__main__:Epoch 15717: total training loss 0.00085\n",
            "2025-06-26 08:43:47,124 Epoch 15717: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15718\n",
            "2025-06-26 08:43:47,127 EPOCH 15718\n",
            "INFO:__main__:Epoch 15718: total training loss 0.00098\n",
            "2025-06-26 08:43:47,221 Epoch 15718: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15719\n",
            "2025-06-26 08:43:47,223 EPOCH 15719\n",
            "INFO:__main__:Epoch 15719: total training loss 0.00094\n",
            "2025-06-26 08:43:47,298 Epoch 15719: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15720\n",
            "2025-06-26 08:43:47,300 EPOCH 15720\n",
            "INFO:__main__:Epoch 15720: total training loss 0.00090\n",
            "2025-06-26 08:43:47,384 Epoch 15720: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15721\n",
            "2025-06-26 08:43:47,386 EPOCH 15721\n",
            "INFO:__main__:Epoch 15721: total training loss 0.00091\n",
            "2025-06-26 08:43:47,460 Epoch 15721: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15722\n",
            "2025-06-26 08:43:47,462 EPOCH 15722\n",
            "INFO:__main__:Epoch 15722: total training loss 0.00103\n",
            "2025-06-26 08:43:47,551 Epoch 15722: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15723\n",
            "2025-06-26 08:43:47,553 EPOCH 15723\n",
            "INFO:__main__:Epoch 15723: total training loss 0.00110\n",
            "2025-06-26 08:43:47,637 Epoch 15723: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 15724\n",
            "2025-06-26 08:43:47,639 EPOCH 15724\n",
            "INFO:__main__:Epoch 15724: total training loss 0.00101\n",
            "2025-06-26 08:43:47,713 Epoch 15724: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15725\n",
            "2025-06-26 08:43:47,716 EPOCH 15725\n",
            "INFO:__main__:Epoch 15725: total training loss 0.00103\n",
            "2025-06-26 08:43:47,806 Epoch 15725: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15726\n",
            "2025-06-26 08:43:47,808 EPOCH 15726\n",
            "INFO:__main__:Epoch 15726: total training loss 0.00102\n",
            "2025-06-26 08:43:47,892 Epoch 15726: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15727\n",
            "2025-06-26 08:43:47,898 EPOCH 15727\n",
            "INFO:__main__:Epoch 15727: total training loss 0.00095\n",
            "2025-06-26 08:43:47,986 Epoch 15727: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15728\n",
            "2025-06-26 08:43:47,988 EPOCH 15728\n",
            "INFO:__main__:Epoch 15728: total training loss 0.00094\n",
            "2025-06-26 08:43:48,069 Epoch 15728: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15729\n",
            "2025-06-26 08:43:48,072 EPOCH 15729\n",
            "INFO:__main__:Epoch 15729: total training loss 0.00099\n",
            "2025-06-26 08:43:48,154 Epoch 15729: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15730\n",
            "2025-06-26 08:43:48,156 EPOCH 15730\n",
            "INFO:__main__:Epoch 15730: total training loss 0.00096\n",
            "2025-06-26 08:43:48,252 Epoch 15730: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15731\n",
            "2025-06-26 08:43:48,254 EPOCH 15731\n",
            "INFO:__main__:Epoch 15731: total training loss 0.00093\n",
            "2025-06-26 08:43:48,332 Epoch 15731: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15732\n",
            "2025-06-26 08:43:48,336 EPOCH 15732\n",
            "INFO:__main__:Epoch 15732: total training loss 0.00089\n",
            "2025-06-26 08:43:48,410 Epoch 15732: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15733\n",
            "2025-06-26 08:43:48,412 EPOCH 15733\n",
            "INFO:__main__:Epoch 15733: total training loss 0.00096\n",
            "2025-06-26 08:43:48,489 Epoch 15733: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15734\n",
            "2025-06-26 08:43:48,492 EPOCH 15734\n",
            "INFO:__main__:Epoch 15734: total training loss 0.00089\n",
            "2025-06-26 08:43:48,565 Epoch 15734: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15735\n",
            "2025-06-26 08:43:48,567 EPOCH 15735\n",
            "INFO:__main__:Epoch 15735: total training loss 0.00087\n",
            "2025-06-26 08:43:48,640 Epoch 15735: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15736\n",
            "2025-06-26 08:43:48,643 EPOCH 15736\n",
            "INFO:__main__:Epoch 15736: total training loss 0.00088\n",
            "2025-06-26 08:43:48,714 Epoch 15736: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15737\n",
            "2025-06-26 08:43:48,716 EPOCH 15737\n",
            "INFO:__main__:Epoch 15737: total training loss 0.00091\n",
            "2025-06-26 08:43:48,796 Epoch 15737: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15738\n",
            "2025-06-26 08:43:48,798 EPOCH 15738\n",
            "INFO:__main__:Epoch 15738: total training loss 0.00091\n",
            "2025-06-26 08:43:48,882 Epoch 15738: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15739\n",
            "2025-06-26 08:43:48,884 EPOCH 15739\n",
            "INFO:__main__:Epoch 15739: total training loss 0.00091\n",
            "2025-06-26 08:43:48,960 Epoch 15739: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15740\n",
            "2025-06-26 08:43:48,963 EPOCH 15740\n",
            "INFO:__main__:Epoch 15740: total training loss 0.00095\n",
            "2025-06-26 08:43:49,036 Epoch 15740: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15741\n",
            "2025-06-26 08:43:49,039 EPOCH 15741\n",
            "INFO:__main__:Epoch 15741: total training loss 0.00098\n",
            "2025-06-26 08:43:49,110 Epoch 15741: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15742\n",
            "2025-06-26 08:43:49,112 EPOCH 15742\n",
            "INFO:__main__:Epoch 15742: total training loss 0.00090\n",
            "2025-06-26 08:43:49,200 Epoch 15742: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15743\n",
            "2025-06-26 08:43:49,201 EPOCH 15743\n",
            "INFO:__main__:Epoch 15743: total training loss 0.00085\n",
            "2025-06-26 08:43:49,279 Epoch 15743: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15744\n",
            "2025-06-26 08:43:49,281 EPOCH 15744\n",
            "INFO:__main__:Epoch 15744: total training loss 0.00084\n",
            "2025-06-26 08:43:49,374 Epoch 15744: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15745\n",
            "2025-06-26 08:43:49,384 EPOCH 15745\n",
            "INFO:__main__:Epoch 15745: total training loss 0.00088\n",
            "2025-06-26 08:43:49,462 Epoch 15745: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15746\n",
            "2025-06-26 08:43:49,465 EPOCH 15746\n",
            "INFO:__main__:Epoch 15746: total training loss 0.00091\n",
            "2025-06-26 08:43:49,547 Epoch 15746: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15747\n",
            "2025-06-26 08:43:49,549 EPOCH 15747\n",
            "INFO:__main__:Epoch 15747: total training loss 0.00091\n",
            "2025-06-26 08:43:49,625 Epoch 15747: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15748\n",
            "2025-06-26 08:43:49,627 EPOCH 15748\n",
            "INFO:__main__:Epoch 15748: total training loss 0.00091\n",
            "2025-06-26 08:43:49,698 Epoch 15748: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15749\n",
            "2025-06-26 08:43:49,700 EPOCH 15749\n",
            "INFO:__main__:Epoch 15749: total training loss 0.00087\n",
            "2025-06-26 08:43:49,771 Epoch 15749: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15750\n",
            "2025-06-26 08:43:49,773 EPOCH 15750\n",
            "INFO:__main__:Epoch 15750 Step:    15750 Batch Loss:     0.000863 Tokens per Sec:  1934325, Lr: 0.001000\n",
            "2025-06-26 08:43:49,848 Epoch 15750 Step:    15750 Batch Loss:     0.000863 Tokens per Sec:  1934325, Lr: 0.001000\n",
            "INFO:__main__:Epoch 15750: total training loss 0.00086\n",
            "2025-06-26 08:43:49,850 Epoch 15750: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15751\n",
            "2025-06-26 08:43:49,851 EPOCH 15751\n",
            "INFO:__main__:Epoch 15751: total training loss 0.00083\n",
            "2025-06-26 08:43:49,923 Epoch 15751: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15752\n",
            "2025-06-26 08:43:49,925 EPOCH 15752\n",
            "INFO:__main__:Epoch 15752: total training loss 0.00081\n",
            "2025-06-26 08:43:49,997 Epoch 15752: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 15753\n",
            "2025-06-26 08:43:49,999 EPOCH 15753\n",
            "INFO:__main__:Epoch 15753: total training loss 0.00088\n",
            "2025-06-26 08:43:50,070 Epoch 15753: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15754\n",
            "2025-06-26 08:43:50,072 EPOCH 15754\n",
            "INFO:__main__:Epoch 15754: total training loss 0.00084\n",
            "2025-06-26 08:43:50,142 Epoch 15754: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15755\n",
            "2025-06-26 08:43:50,144 EPOCH 15755\n",
            "INFO:__main__:Epoch 15755: total training loss 0.00081\n",
            "2025-06-26 08:43:50,223 Epoch 15755: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 15756\n",
            "2025-06-26 08:43:50,225 EPOCH 15756\n",
            "INFO:__main__:Epoch 15756: total training loss 0.00084\n",
            "2025-06-26 08:43:50,299 Epoch 15756: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15757\n",
            "2025-06-26 08:43:50,301 EPOCH 15757\n",
            "INFO:__main__:Epoch 15757: total training loss 0.00094\n",
            "2025-06-26 08:43:50,385 Epoch 15757: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15758\n",
            "2025-06-26 08:43:50,392 EPOCH 15758\n",
            "INFO:__main__:Epoch 15758: total training loss 0.00108\n",
            "2025-06-26 08:43:50,471 Epoch 15758: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 15759\n",
            "2025-06-26 08:43:50,476 EPOCH 15759\n",
            "INFO:__main__:Epoch 15759: total training loss 0.00099\n",
            "2025-06-26 08:43:50,557 Epoch 15759: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15760\n",
            "2025-06-26 08:43:50,559 EPOCH 15760\n",
            "INFO:__main__:Epoch 15760: total training loss 0.00107\n",
            "2025-06-26 08:43:50,649 Epoch 15760: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15761\n",
            "2025-06-26 08:43:50,651 EPOCH 15761\n",
            "INFO:__main__:Epoch 15761: total training loss 0.00103\n",
            "2025-06-26 08:43:50,724 Epoch 15761: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15762\n",
            "2025-06-26 08:43:50,726 EPOCH 15762\n",
            "INFO:__main__:Epoch 15762: total training loss 0.00107\n",
            "2025-06-26 08:43:50,816 Epoch 15762: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 15763\n",
            "2025-06-26 08:43:50,819 EPOCH 15763\n",
            "INFO:__main__:Epoch 15763: total training loss 0.00109\n",
            "2025-06-26 08:43:50,893 Epoch 15763: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15764\n",
            "2025-06-26 08:43:50,896 EPOCH 15764\n",
            "INFO:__main__:Epoch 15764: total training loss 0.00109\n",
            "2025-06-26 08:43:50,967 Epoch 15764: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15765\n",
            "2025-06-26 08:43:50,972 EPOCH 15765\n",
            "INFO:__main__:Epoch 15765: total training loss 0.00110\n",
            "2025-06-26 08:43:51,046 Epoch 15765: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 15766\n",
            "2025-06-26 08:43:51,048 EPOCH 15766\n",
            "INFO:__main__:Epoch 15766: total training loss 0.00104\n",
            "2025-06-26 08:43:51,121 Epoch 15766: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15767\n",
            "2025-06-26 08:43:51,124 EPOCH 15767\n",
            "INFO:__main__:Epoch 15767: total training loss 0.00097\n",
            "2025-06-26 08:43:51,198 Epoch 15767: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15768\n",
            "2025-06-26 08:43:51,200 EPOCH 15768\n",
            "INFO:__main__:Epoch 15768: total training loss 0.00097\n",
            "2025-06-26 08:43:51,278 Epoch 15768: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15769\n",
            "2025-06-26 08:43:51,280 EPOCH 15769\n",
            "INFO:__main__:Epoch 15769: total training loss 0.00097\n",
            "2025-06-26 08:43:51,353 Epoch 15769: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15770\n",
            "2025-06-26 08:43:51,356 EPOCH 15770\n",
            "INFO:__main__:Epoch 15770: total training loss 0.00093\n",
            "2025-06-26 08:43:51,431 Epoch 15770: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15771\n",
            "2025-06-26 08:43:51,433 EPOCH 15771\n",
            "INFO:__main__:Epoch 15771: total training loss 0.00088\n",
            "2025-06-26 08:43:51,522 Epoch 15771: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15772\n",
            "2025-06-26 08:43:51,526 EPOCH 15772\n",
            "INFO:__main__:Epoch 15772: total training loss 0.00090\n",
            "2025-06-26 08:43:51,602 Epoch 15772: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15773\n",
            "2025-06-26 08:43:51,604 EPOCH 15773\n",
            "INFO:__main__:Epoch 15773: total training loss 0.00085\n",
            "2025-06-26 08:43:51,677 Epoch 15773: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15774\n",
            "2025-06-26 08:43:51,680 EPOCH 15774\n",
            "INFO:__main__:Epoch 15774: total training loss 0.00088\n",
            "2025-06-26 08:43:51,751 Epoch 15774: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15775\n",
            "2025-06-26 08:43:51,753 EPOCH 15775\n",
            "INFO:__main__:Epoch 15775: total training loss 0.00085\n",
            "2025-06-26 08:43:51,833 Epoch 15775: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15776\n",
            "2025-06-26 08:43:51,835 EPOCH 15776\n",
            "INFO:__main__:Epoch 15776: total training loss 0.00081\n",
            "2025-06-26 08:43:51,909 Epoch 15776: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 15777\n",
            "2025-06-26 08:43:51,911 EPOCH 15777\n",
            "INFO:__main__:Epoch 15777: total training loss 0.00085\n",
            "2025-06-26 08:43:51,990 Epoch 15777: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15778\n",
            "2025-06-26 08:43:51,992 EPOCH 15778\n",
            "INFO:__main__:Epoch 15778: total training loss 0.00082\n",
            "2025-06-26 08:43:52,068 Epoch 15778: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 15779\n",
            "2025-06-26 08:43:52,070 EPOCH 15779\n",
            "INFO:__main__:Epoch 15779: total training loss 0.00087\n",
            "2025-06-26 08:43:52,160 Epoch 15779: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15780\n",
            "2025-06-26 08:43:52,162 EPOCH 15780\n",
            "INFO:__main__:Epoch 15780: total training loss 0.00085\n",
            "2025-06-26 08:43:52,243 Epoch 15780: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15781\n",
            "2025-06-26 08:43:52,245 EPOCH 15781\n",
            "INFO:__main__:Epoch 15781: total training loss 0.00088\n",
            "2025-06-26 08:43:52,328 Epoch 15781: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15782\n",
            "2025-06-26 08:43:52,330 EPOCH 15782\n",
            "INFO:__main__:Epoch 15782: total training loss 0.00087\n",
            "2025-06-26 08:43:52,402 Epoch 15782: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15783\n",
            "2025-06-26 08:43:52,403 EPOCH 15783\n",
            "INFO:__main__:Epoch 15783: total training loss 0.00088\n",
            "2025-06-26 08:43:52,473 Epoch 15783: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15784\n",
            "2025-06-26 08:43:52,475 EPOCH 15784\n",
            "INFO:__main__:Epoch 15784: total training loss 0.00090\n",
            "2025-06-26 08:43:52,553 Epoch 15784: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15785\n",
            "2025-06-26 08:43:52,555 EPOCH 15785\n",
            "INFO:__main__:Epoch 15785: total training loss 0.00089\n",
            "2025-06-26 08:43:52,629 Epoch 15785: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15786\n",
            "2025-06-26 08:43:52,631 EPOCH 15786\n",
            "INFO:__main__:Epoch 15786: total training loss 0.00086\n",
            "2025-06-26 08:43:52,709 Epoch 15786: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15787\n",
            "2025-06-26 08:43:52,711 EPOCH 15787\n",
            "INFO:__main__:Epoch 15787: total training loss 0.00088\n",
            "2025-06-26 08:43:52,788 Epoch 15787: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15788\n",
            "2025-06-26 08:43:52,790 EPOCH 15788\n",
            "INFO:__main__:Epoch 15788: total training loss 0.00086\n",
            "2025-06-26 08:43:52,864 Epoch 15788: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15789\n",
            "2025-06-26 08:43:52,870 EPOCH 15789\n",
            "INFO:__main__:Epoch 15789: total training loss 0.00085\n",
            "2025-06-26 08:43:52,960 Epoch 15789: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15790\n",
            "2025-06-26 08:43:52,962 EPOCH 15790\n",
            "INFO:__main__:Epoch 15790: total training loss 0.00084\n",
            "2025-06-26 08:43:53,034 Epoch 15790: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15791\n",
            "2025-06-26 08:43:53,036 EPOCH 15791\n",
            "INFO:__main__:Epoch 15791: total training loss 0.00086\n",
            "2025-06-26 08:43:53,116 Epoch 15791: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15792\n",
            "2025-06-26 08:43:53,118 EPOCH 15792\n",
            "INFO:__main__:Epoch 15792: total training loss 0.00085\n",
            "2025-06-26 08:43:53,186 Epoch 15792: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15793\n",
            "2025-06-26 08:43:53,188 EPOCH 15793\n",
            "INFO:__main__:Epoch 15793: total training loss 0.00087\n",
            "2025-06-26 08:43:53,285 Epoch 15793: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15794\n",
            "2025-06-26 08:43:53,287 EPOCH 15794\n",
            "INFO:__main__:Epoch 15794: total training loss 0.00089\n",
            "2025-06-26 08:43:53,359 Epoch 15794: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15795\n",
            "2025-06-26 08:43:53,361 EPOCH 15795\n",
            "INFO:__main__:Epoch 15795: total training loss 0.00093\n",
            "2025-06-26 08:43:53,449 Epoch 15795: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15796\n",
            "2025-06-26 08:43:53,453 EPOCH 15796\n",
            "INFO:__main__:Epoch 15796: total training loss 0.00095\n",
            "2025-06-26 08:43:53,523 Epoch 15796: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15797\n",
            "2025-06-26 08:43:53,527 EPOCH 15797\n",
            "INFO:__main__:Epoch 15797: total training loss 0.00094\n",
            "2025-06-26 08:43:53,611 Epoch 15797: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15798\n",
            "2025-06-26 08:43:53,613 EPOCH 15798\n",
            "INFO:__main__:Epoch 15798: total training loss 0.00095\n",
            "2025-06-26 08:43:53,700 Epoch 15798: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15799\n",
            "2025-06-26 08:43:53,702 EPOCH 15799\n",
            "INFO:__main__:Epoch 15799: total training loss 0.00097\n",
            "2025-06-26 08:43:53,796 Epoch 15799: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15800\n",
            "2025-06-26 08:43:53,798 EPOCH 15800\n",
            "INFO:__main__:Epoch 15800: total training loss 0.00094\n",
            "2025-06-26 08:43:53,872 Epoch 15800: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15801\n",
            "2025-06-26 08:43:53,874 EPOCH 15801\n",
            "INFO:__main__:Epoch 15801: total training loss 0.00088\n",
            "2025-06-26 08:43:53,960 Epoch 15801: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15802\n",
            "2025-06-26 08:43:53,962 EPOCH 15802\n",
            "INFO:__main__:Epoch 15802: total training loss 0.00089\n",
            "2025-06-26 08:43:54,036 Epoch 15802: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15803\n",
            "2025-06-26 08:43:54,038 EPOCH 15803\n",
            "INFO:__main__:Epoch 15803: total training loss 0.00092\n",
            "2025-06-26 08:43:54,112 Epoch 15803: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15804\n",
            "2025-06-26 08:43:54,114 EPOCH 15804\n",
            "INFO:__main__:Epoch 15804: total training loss 0.00091\n",
            "2025-06-26 08:43:54,186 Epoch 15804: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15805\n",
            "2025-06-26 08:43:54,188 EPOCH 15805\n",
            "INFO:__main__:Epoch 15805: total training loss 0.00089\n",
            "2025-06-26 08:43:54,264 Epoch 15805: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15806\n",
            "2025-06-26 08:43:54,266 EPOCH 15806\n",
            "INFO:__main__:Epoch 15806: total training loss 0.00087\n",
            "2025-06-26 08:43:54,355 Epoch 15806: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15807\n",
            "2025-06-26 08:43:54,356 EPOCH 15807\n",
            "INFO:__main__:Epoch 15807: total training loss 0.00090\n",
            "2025-06-26 08:43:54,429 Epoch 15807: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15808\n",
            "2025-06-26 08:43:54,431 EPOCH 15808\n",
            "INFO:__main__:Epoch 15808: total training loss 0.00087\n",
            "2025-06-26 08:43:54,524 Epoch 15808: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15809\n",
            "2025-06-26 08:43:54,527 EPOCH 15809\n",
            "INFO:__main__:Epoch 15809: total training loss 0.00086\n",
            "2025-06-26 08:43:54,604 Epoch 15809: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15810\n",
            "2025-06-26 08:43:54,606 EPOCH 15810\n",
            "INFO:__main__:Epoch 15810: total training loss 0.00083\n",
            "2025-06-26 08:43:54,697 Epoch 15810: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15811\n",
            "2025-06-26 08:43:54,699 EPOCH 15811\n",
            "INFO:__main__:Epoch 15811: total training loss 0.00087\n",
            "2025-06-26 08:43:54,777 Epoch 15811: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15812\n",
            "2025-06-26 08:43:54,779 EPOCH 15812\n",
            "INFO:__main__:Epoch 15812: total training loss 0.00087\n",
            "2025-06-26 08:43:54,856 Epoch 15812: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15813\n",
            "2025-06-26 08:43:54,859 EPOCH 15813\n",
            "INFO:__main__:Epoch 15813: total training loss 0.00088\n",
            "2025-06-26 08:43:54,937 Epoch 15813: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15814\n",
            "2025-06-26 08:43:54,939 EPOCH 15814\n",
            "INFO:__main__:Epoch 15814: total training loss 0.00084\n",
            "2025-06-26 08:43:55,015 Epoch 15814: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15815\n",
            "2025-06-26 08:43:55,017 EPOCH 15815\n",
            "INFO:__main__:Epoch 15815: total training loss 0.00092\n",
            "2025-06-26 08:43:55,133 Epoch 15815: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15816\n",
            "2025-06-26 08:43:55,136 EPOCH 15816\n",
            "INFO:__main__:Epoch 15816: total training loss 0.00091\n",
            "2025-06-26 08:43:55,264 Epoch 15816: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15817\n",
            "2025-06-26 08:43:55,267 EPOCH 15817\n",
            "INFO:__main__:Epoch 15817: total training loss 0.00090\n",
            "2025-06-26 08:43:55,364 Epoch 15817: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15818\n",
            "2025-06-26 08:43:55,366 EPOCH 15818\n",
            "INFO:__main__:Epoch 15818: total training loss 0.00086\n",
            "2025-06-26 08:43:55,447 Epoch 15818: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15819\n",
            "2025-06-26 08:43:55,451 EPOCH 15819\n",
            "INFO:__main__:Epoch 15819: total training loss 0.00087\n",
            "2025-06-26 08:43:55,532 Epoch 15819: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15820\n",
            "2025-06-26 08:43:55,538 EPOCH 15820\n",
            "INFO:__main__:Epoch 15820: total training loss 0.00092\n",
            "2025-06-26 08:43:55,641 Epoch 15820: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15821\n",
            "2025-06-26 08:43:55,646 EPOCH 15821\n",
            "INFO:__main__:Epoch 15821: total training loss 0.00099\n",
            "2025-06-26 08:43:55,746 Epoch 15821: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15822\n",
            "2025-06-26 08:43:55,750 EPOCH 15822\n",
            "INFO:__main__:Epoch 15822: total training loss 0.00098\n",
            "2025-06-26 08:43:55,845 Epoch 15822: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15823\n",
            "2025-06-26 08:43:55,851 EPOCH 15823\n",
            "INFO:__main__:Epoch 15823: total training loss 0.00092\n",
            "2025-06-26 08:43:55,970 Epoch 15823: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15824\n",
            "2025-06-26 08:43:55,972 EPOCH 15824\n",
            "INFO:__main__:Epoch 15824: total training loss 0.00091\n",
            "2025-06-26 08:43:56,088 Epoch 15824: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15825\n",
            "2025-06-26 08:43:56,090 EPOCH 15825\n",
            "INFO:__main__:Epoch 15825: total training loss 0.00096\n",
            "2025-06-26 08:43:56,194 Epoch 15825: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15826\n",
            "2025-06-26 08:43:56,196 EPOCH 15826\n",
            "INFO:__main__:Epoch 15826: total training loss 0.00100\n",
            "2025-06-26 08:43:56,275 Epoch 15826: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15827\n",
            "2025-06-26 08:43:56,277 EPOCH 15827\n",
            "INFO:__main__:Epoch 15827: total training loss 0.00095\n",
            "2025-06-26 08:43:56,348 Epoch 15827: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15828\n",
            "2025-06-26 08:43:56,350 EPOCH 15828\n",
            "INFO:__main__:Epoch 15828: total training loss 0.00092\n",
            "2025-06-26 08:43:56,424 Epoch 15828: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15829\n",
            "2025-06-26 08:43:56,426 EPOCH 15829\n",
            "INFO:__main__:Epoch 15829: total training loss 0.00092\n",
            "2025-06-26 08:43:56,496 Epoch 15829: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15830\n",
            "2025-06-26 08:43:56,498 EPOCH 15830\n",
            "INFO:__main__:Epoch 15830: total training loss 0.00104\n",
            "2025-06-26 08:43:56,568 Epoch 15830: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15831\n",
            "2025-06-26 08:43:56,570 EPOCH 15831\n",
            "INFO:__main__:Epoch 15831: total training loss 0.00102\n",
            "2025-06-26 08:43:56,639 Epoch 15831: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15832\n",
            "2025-06-26 08:43:56,641 EPOCH 15832\n",
            "INFO:__main__:Epoch 15832: total training loss 0.00106\n",
            "2025-06-26 08:43:56,711 Epoch 15832: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15833\n",
            "2025-06-26 08:43:56,712 EPOCH 15833\n",
            "INFO:__main__:Epoch 15833: total training loss 0.00101\n",
            "2025-06-26 08:43:56,808 Epoch 15833: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15834\n",
            "2025-06-26 08:43:56,810 EPOCH 15834\n",
            "INFO:__main__:Epoch 15834: total training loss 0.00093\n",
            "2025-06-26 08:43:56,910 Epoch 15834: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15835\n",
            "2025-06-26 08:43:56,912 EPOCH 15835\n",
            "INFO:__main__:Epoch 15835: total training loss 0.00096\n",
            "2025-06-26 08:43:57,000 Epoch 15835: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15836\n",
            "2025-06-26 08:43:57,002 EPOCH 15836\n",
            "INFO:__main__:Epoch 15836: total training loss 0.00103\n",
            "2025-06-26 08:43:57,089 Epoch 15836: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15837\n",
            "2025-06-26 08:43:57,092 EPOCH 15837\n",
            "INFO:__main__:Epoch 15837: total training loss 0.00100\n",
            "2025-06-26 08:43:57,182 Epoch 15837: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15838\n",
            "2025-06-26 08:43:57,185 EPOCH 15838\n",
            "INFO:__main__:Epoch 15838: total training loss 0.00096\n",
            "2025-06-26 08:43:57,274 Epoch 15838: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15839\n",
            "2025-06-26 08:43:57,276 EPOCH 15839\n",
            "INFO:__main__:Epoch 15839: total training loss 0.00095\n",
            "2025-06-26 08:43:57,389 Epoch 15839: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15840\n",
            "2025-06-26 08:43:57,395 EPOCH 15840\n",
            "INFO:__main__:Epoch 15840: total training loss 0.00094\n",
            "2025-06-26 08:43:57,512 Epoch 15840: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15841\n",
            "2025-06-26 08:43:57,514 EPOCH 15841\n",
            "INFO:__main__:Epoch 15841: total training loss 0.00101\n",
            "2025-06-26 08:43:57,617 Epoch 15841: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15842\n",
            "2025-06-26 08:43:57,618 EPOCH 15842\n",
            "INFO:__main__:Epoch 15842: total training loss 0.00093\n",
            "2025-06-26 08:43:57,732 Epoch 15842: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15843\n",
            "2025-06-26 08:43:57,735 EPOCH 15843\n",
            "INFO:__main__:Epoch 15843: total training loss 0.00099\n",
            "2025-06-26 08:43:57,829 Epoch 15843: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15844\n",
            "2025-06-26 08:43:57,831 EPOCH 15844\n",
            "INFO:__main__:Epoch 15844: total training loss 0.00101\n",
            "2025-06-26 08:43:57,959 Epoch 15844: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15845\n",
            "2025-06-26 08:43:57,962 EPOCH 15845\n",
            "INFO:__main__:Epoch 15845: total training loss 0.00104\n",
            "2025-06-26 08:43:58,084 Epoch 15845: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15846\n",
            "2025-06-26 08:43:58,087 EPOCH 15846\n",
            "INFO:__main__:Epoch 15846: total training loss 0.00094\n",
            "2025-06-26 08:43:58,166 Epoch 15846: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15847\n",
            "2025-06-26 08:43:58,169 EPOCH 15847\n",
            "INFO:__main__:Epoch 15847: total training loss 0.00106\n",
            "2025-06-26 08:43:58,276 Epoch 15847: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15848\n",
            "2025-06-26 08:43:58,278 EPOCH 15848\n",
            "INFO:__main__:Epoch 15848: total training loss 0.00104\n",
            "2025-06-26 08:43:58,371 Epoch 15848: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15849\n",
            "2025-06-26 08:43:58,372 EPOCH 15849\n",
            "INFO:__main__:Epoch 15849: total training loss 0.00099\n",
            "2025-06-26 08:43:58,486 Epoch 15849: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15850\n",
            "2025-06-26 08:43:58,488 EPOCH 15850\n",
            "INFO:__main__:Epoch 15850: total training loss 0.00095\n",
            "2025-06-26 08:43:58,608 Epoch 15850: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15851\n",
            "2025-06-26 08:43:58,610 EPOCH 15851\n",
            "INFO:__main__:Epoch 15851: total training loss 0.00101\n",
            "2025-06-26 08:43:58,730 Epoch 15851: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15852\n",
            "2025-06-26 08:43:58,732 EPOCH 15852\n",
            "INFO:__main__:Epoch 15852: total training loss 0.00092\n",
            "2025-06-26 08:43:58,843 Epoch 15852: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15853\n",
            "2025-06-26 08:43:58,845 EPOCH 15853\n",
            "INFO:__main__:Epoch 15853: total training loss 0.00093\n",
            "2025-06-26 08:43:58,965 Epoch 15853: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15854\n",
            "2025-06-26 08:43:58,967 EPOCH 15854\n",
            "INFO:__main__:Epoch 15854: total training loss 0.00091\n",
            "2025-06-26 08:43:59,082 Epoch 15854: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15855\n",
            "2025-06-26 08:43:59,088 EPOCH 15855\n",
            "INFO:__main__:Epoch 15855: total training loss 0.00092\n",
            "2025-06-26 08:43:59,209 Epoch 15855: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15856\n",
            "2025-06-26 08:43:59,211 EPOCH 15856\n",
            "INFO:__main__:Epoch 15856: total training loss 0.00087\n",
            "2025-06-26 08:43:59,334 Epoch 15856: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15857\n",
            "2025-06-26 08:43:59,335 EPOCH 15857\n",
            "INFO:__main__:Epoch 15857: total training loss 0.00086\n",
            "2025-06-26 08:43:59,449 Epoch 15857: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15858\n",
            "2025-06-26 08:43:59,451 EPOCH 15858\n",
            "INFO:__main__:Epoch 15858: total training loss 0.00086\n",
            "2025-06-26 08:43:59,567 Epoch 15858: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15859\n",
            "2025-06-26 08:43:59,570 EPOCH 15859\n",
            "INFO:__main__:Epoch 15859: total training loss 0.00090\n",
            "2025-06-26 08:43:59,671 Epoch 15859: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15860\n",
            "2025-06-26 08:43:59,679 EPOCH 15860\n",
            "INFO:__main__:Epoch 15860: total training loss 0.00084\n",
            "2025-06-26 08:43:59,788 Epoch 15860: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15861\n",
            "2025-06-26 08:43:59,792 EPOCH 15861\n",
            "INFO:__main__:Epoch 15861: total training loss 0.00085\n",
            "2025-06-26 08:43:59,904 Epoch 15861: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15862\n",
            "2025-06-26 08:43:59,907 EPOCH 15862\n",
            "INFO:__main__:Epoch 15862: total training loss 0.00087\n",
            "2025-06-26 08:44:00,031 Epoch 15862: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15863\n",
            "2025-06-26 08:44:00,033 EPOCH 15863\n",
            "INFO:__main__:Epoch 15863: total training loss 0.00087\n",
            "2025-06-26 08:44:00,158 Epoch 15863: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15864\n",
            "2025-06-26 08:44:00,160 EPOCH 15864\n",
            "INFO:__main__:Epoch 15864: total training loss 0.00086\n",
            "2025-06-26 08:44:00,280 Epoch 15864: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 15865\n",
            "2025-06-26 08:44:00,288 EPOCH 15865\n",
            "INFO:__main__:Epoch 15865: total training loss 0.00085\n",
            "2025-06-26 08:44:00,387 Epoch 15865: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15866\n",
            "2025-06-26 08:44:00,391 EPOCH 15866\n",
            "INFO:__main__:Epoch 15866: total training loss 0.00087\n",
            "2025-06-26 08:44:00,467 Epoch 15866: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15867\n",
            "2025-06-26 08:44:00,470 EPOCH 15867\n",
            "INFO:__main__:Epoch 15867: total training loss 0.00089\n",
            "2025-06-26 08:44:00,561 Epoch 15867: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15868\n",
            "2025-06-26 08:44:00,564 EPOCH 15868\n",
            "INFO:__main__:Epoch 15868: total training loss 0.00089\n",
            "2025-06-26 08:44:00,641 Epoch 15868: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15869\n",
            "2025-06-26 08:44:00,647 EPOCH 15869\n",
            "INFO:__main__:Epoch 15869: total training loss 0.00088\n",
            "2025-06-26 08:44:00,734 Epoch 15869: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15870\n",
            "2025-06-26 08:44:00,736 EPOCH 15870\n",
            "INFO:__main__:Epoch 15870: total training loss 0.00092\n",
            "2025-06-26 08:44:00,810 Epoch 15870: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15871\n",
            "2025-06-26 08:44:00,813 EPOCH 15871\n",
            "INFO:__main__:Epoch 15871: total training loss 0.00095\n",
            "2025-06-26 08:44:00,903 Epoch 15871: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15872\n",
            "2025-06-26 08:44:00,905 EPOCH 15872\n",
            "INFO:__main__:Epoch 15872: total training loss 0.00092\n",
            "2025-06-26 08:44:00,978 Epoch 15872: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15873\n",
            "2025-06-26 08:44:00,981 EPOCH 15873\n",
            "INFO:__main__:Epoch 15873: total training loss 0.00091\n",
            "2025-06-26 08:44:01,052 Epoch 15873: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15874\n",
            "2025-06-26 08:44:01,054 EPOCH 15874\n",
            "INFO:__main__:Epoch 15874: total training loss 0.00091\n",
            "2025-06-26 08:44:01,126 Epoch 15874: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15875\n",
            "2025-06-26 08:44:01,128 EPOCH 15875\n",
            "INFO:__main__:Epoch 15875: total training loss 0.00094\n",
            "2025-06-26 08:44:01,203 Epoch 15875: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15876\n",
            "2025-06-26 08:44:01,205 EPOCH 15876\n",
            "INFO:__main__:Epoch 15876: total training loss 0.00093\n",
            "2025-06-26 08:44:01,299 Epoch 15876: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15877\n",
            "2025-06-26 08:44:01,301 EPOCH 15877\n",
            "INFO:__main__:Epoch 15877: total training loss 0.00094\n",
            "2025-06-26 08:44:01,371 Epoch 15877: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15878\n",
            "2025-06-26 08:44:01,374 EPOCH 15878\n",
            "INFO:__main__:Epoch 15878: total training loss 0.00089\n",
            "2025-06-26 08:44:01,447 Epoch 15878: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15879\n",
            "2025-06-26 08:44:01,449 EPOCH 15879\n",
            "INFO:__main__:Epoch 15879: total training loss 0.00088\n",
            "2025-06-26 08:44:01,524 Epoch 15879: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15880\n",
            "2025-06-26 08:44:01,526 EPOCH 15880\n",
            "INFO:__main__:Epoch 15880: total training loss 0.00094\n",
            "2025-06-26 08:44:01,619 Epoch 15880: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15881\n",
            "2025-06-26 08:44:01,621 EPOCH 15881\n",
            "INFO:__main__:Epoch 15881: total training loss 0.00094\n",
            "2025-06-26 08:44:01,690 Epoch 15881: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15882\n",
            "2025-06-26 08:44:01,692 EPOCH 15882\n",
            "INFO:__main__:Epoch 15882: total training loss 0.00099\n",
            "2025-06-26 08:44:01,761 Epoch 15882: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15883\n",
            "2025-06-26 08:44:01,763 EPOCH 15883\n",
            "INFO:__main__:Epoch 15883: total training loss 0.00101\n",
            "2025-06-26 08:44:01,834 Epoch 15883: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15884\n",
            "2025-06-26 08:44:01,836 EPOCH 15884\n",
            "INFO:__main__:Epoch 15884: total training loss 0.00099\n",
            "2025-06-26 08:44:01,907 Epoch 15884: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15885\n",
            "2025-06-26 08:44:01,909 EPOCH 15885\n",
            "INFO:__main__:Epoch 15885: total training loss 0.00102\n",
            "2025-06-26 08:44:01,995 Epoch 15885: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15886\n",
            "2025-06-26 08:44:01,997 EPOCH 15886\n",
            "INFO:__main__:Epoch 15886: total training loss 0.00102\n",
            "2025-06-26 08:44:02,076 Epoch 15886: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15887\n",
            "2025-06-26 08:44:02,080 EPOCH 15887\n",
            "INFO:__main__:Epoch 15887: total training loss 0.00104\n",
            "2025-06-26 08:44:02,167 Epoch 15887: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15888\n",
            "2025-06-26 08:44:02,170 EPOCH 15888\n",
            "INFO:__main__:Epoch 15888: total training loss 0.00097\n",
            "2025-06-26 08:44:02,257 Epoch 15888: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15889\n",
            "2025-06-26 08:44:02,259 EPOCH 15889\n",
            "INFO:__main__:Epoch 15889: total training loss 0.00096\n",
            "2025-06-26 08:44:02,371 Epoch 15889: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15890\n",
            "2025-06-26 08:44:02,373 EPOCH 15890\n",
            "INFO:__main__:Epoch 15890: total training loss 0.00096\n",
            "2025-06-26 08:44:02,464 Epoch 15890: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15891\n",
            "2025-06-26 08:44:02,466 EPOCH 15891\n",
            "INFO:__main__:Epoch 15891: total training loss 0.00092\n",
            "2025-06-26 08:44:02,541 Epoch 15891: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15892\n",
            "2025-06-26 08:44:02,543 EPOCH 15892\n",
            "INFO:__main__:Epoch 15892: total training loss 0.00096\n",
            "2025-06-26 08:44:02,625 Epoch 15892: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15893\n",
            "2025-06-26 08:44:02,626 EPOCH 15893\n",
            "INFO:__main__:Epoch 15893: total training loss 0.00096\n",
            "2025-06-26 08:44:02,699 Epoch 15893: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15894\n",
            "2025-06-26 08:44:02,701 EPOCH 15894\n",
            "INFO:__main__:Epoch 15894: total training loss 0.00097\n",
            "2025-06-26 08:44:02,778 Epoch 15894: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15895\n",
            "2025-06-26 08:44:02,780 EPOCH 15895\n",
            "INFO:__main__:Epoch 15895: total training loss 0.00105\n",
            "2025-06-26 08:44:02,856 Epoch 15895: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15896\n",
            "2025-06-26 08:44:02,859 EPOCH 15896\n",
            "INFO:__main__:Epoch 15896: total training loss 0.00100\n",
            "2025-06-26 08:44:02,931 Epoch 15896: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15897\n",
            "2025-06-26 08:44:02,933 EPOCH 15897\n",
            "INFO:__main__:Epoch 15897: total training loss 0.00095\n",
            "2025-06-26 08:44:03,015 Epoch 15897: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15898\n",
            "2025-06-26 08:44:03,017 EPOCH 15898\n",
            "INFO:__main__:Epoch 15898: total training loss 0.00094\n",
            "2025-06-26 08:44:03,090 Epoch 15898: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15899\n",
            "2025-06-26 08:44:03,092 EPOCH 15899\n",
            "INFO:__main__:Epoch 15899: total training loss 0.00095\n",
            "2025-06-26 08:44:03,165 Epoch 15899: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15900\n",
            "2025-06-26 08:44:03,167 EPOCH 15900\n",
            "INFO:__main__:Epoch 15900: total training loss 0.00096\n",
            "2025-06-26 08:44:03,247 Epoch 15900: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15901\n",
            "2025-06-26 08:44:03,249 EPOCH 15901\n",
            "INFO:__main__:Epoch 15901: total training loss 0.00092\n",
            "2025-06-26 08:44:03,335 Epoch 15901: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15902\n",
            "2025-06-26 08:44:03,338 EPOCH 15902\n",
            "INFO:__main__:Epoch 15902: total training loss 0.00091\n",
            "2025-06-26 08:44:03,427 Epoch 15902: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15903\n",
            "2025-06-26 08:44:03,429 EPOCH 15903\n",
            "INFO:__main__:Epoch 15903: total training loss 0.00087\n",
            "2025-06-26 08:44:03,500 Epoch 15903: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15904\n",
            "2025-06-26 08:44:03,502 EPOCH 15904\n",
            "INFO:__main__:Epoch 15904: total training loss 0.00088\n",
            "2025-06-26 08:44:03,581 Epoch 15904: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15905\n",
            "2025-06-26 08:44:03,583 EPOCH 15905\n",
            "INFO:__main__:Epoch 15905: total training loss 0.00091\n",
            "2025-06-26 08:44:03,651 Epoch 15905: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15906\n",
            "2025-06-26 08:44:03,653 EPOCH 15906\n",
            "INFO:__main__:Epoch 15906: total training loss 0.00095\n",
            "2025-06-26 08:44:03,725 Epoch 15906: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15907\n",
            "2025-06-26 08:44:03,727 EPOCH 15907\n",
            "INFO:__main__:Epoch 15907: total training loss 0.00089\n",
            "2025-06-26 08:44:03,804 Epoch 15907: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15908\n",
            "2025-06-26 08:44:03,806 EPOCH 15908\n",
            "INFO:__main__:Epoch 15908: total training loss 0.00087\n",
            "2025-06-26 08:44:03,879 Epoch 15908: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15909\n",
            "2025-06-26 08:44:03,881 EPOCH 15909\n",
            "INFO:__main__:Epoch 15909: total training loss 0.00090\n",
            "2025-06-26 08:44:03,950 Epoch 15909: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15910\n",
            "2025-06-26 08:44:03,952 EPOCH 15910\n",
            "INFO:__main__:Epoch 15910: total training loss 0.00093\n",
            "2025-06-26 08:44:04,034 Epoch 15910: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15911\n",
            "2025-06-26 08:44:04,036 EPOCH 15911\n",
            "INFO:__main__:Epoch 15911: total training loss 0.00099\n",
            "2025-06-26 08:44:04,109 Epoch 15911: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15912\n",
            "2025-06-26 08:44:04,111 EPOCH 15912\n",
            "INFO:__main__:Epoch 15912: total training loss 0.00093\n",
            "2025-06-26 08:44:04,180 Epoch 15912: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15913\n",
            "2025-06-26 08:44:04,182 EPOCH 15913\n",
            "INFO:__main__:Epoch 15913: total training loss 0.00089\n",
            "2025-06-26 08:44:04,257 Epoch 15913: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15914\n",
            "2025-06-26 08:44:04,260 EPOCH 15914\n",
            "INFO:__main__:Epoch 15914: total training loss 0.00087\n",
            "2025-06-26 08:44:04,351 Epoch 15914: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15915\n",
            "2025-06-26 08:44:04,356 EPOCH 15915\n",
            "INFO:__main__:Epoch 15915: total training loss 0.00087\n",
            "2025-06-26 08:44:04,431 Epoch 15915: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15916\n",
            "2025-06-26 08:44:04,438 EPOCH 15916\n",
            "INFO:__main__:Epoch 15916: total training loss 0.00085\n",
            "2025-06-26 08:44:04,529 Epoch 15916: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15917\n",
            "2025-06-26 08:44:04,534 EPOCH 15917\n",
            "INFO:__main__:Epoch 15917: total training loss 0.00089\n",
            "2025-06-26 08:44:04,610 Epoch 15917: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15918\n",
            "2025-06-26 08:44:04,612 EPOCH 15918\n",
            "INFO:__main__:Epoch 15918: total training loss 0.00091\n",
            "2025-06-26 08:44:04,688 Epoch 15918: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 15919\n",
            "2025-06-26 08:44:04,690 EPOCH 15919\n",
            "INFO:__main__:Epoch 15919: total training loss 0.00084\n",
            "2025-06-26 08:44:04,774 Epoch 15919: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15920\n",
            "2025-06-26 08:44:04,776 EPOCH 15920\n",
            "INFO:__main__:Epoch 15920: total training loss 0.00089\n",
            "2025-06-26 08:44:04,853 Epoch 15920: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15921\n",
            "2025-06-26 08:44:04,855 EPOCH 15921\n",
            "INFO:__main__:Epoch 15921: total training loss 0.00088\n",
            "2025-06-26 08:44:04,940 Epoch 15921: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15922\n",
            "2025-06-26 08:44:04,942 EPOCH 15922\n",
            "INFO:__main__:Epoch 15922: total training loss 0.00094\n",
            "2025-06-26 08:44:05,013 Epoch 15922: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15923\n",
            "2025-06-26 08:44:05,015 EPOCH 15923\n",
            "INFO:__main__:Epoch 15923: total training loss 0.00097\n",
            "2025-06-26 08:44:05,101 Epoch 15923: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15924\n",
            "2025-06-26 08:44:05,103 EPOCH 15924\n",
            "INFO:__main__:Epoch 15924: total training loss 0.00109\n",
            "2025-06-26 08:44:05,174 Epoch 15924: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 15925\n",
            "2025-06-26 08:44:05,176 EPOCH 15925\n",
            "INFO:__main__:Epoch 15925: total training loss 0.00128\n",
            "2025-06-26 08:44:05,247 Epoch 15925: total training loss 0.00128\n",
            "INFO:__main__:EPOCH 15926\n",
            "2025-06-26 08:44:05,249 EPOCH 15926\n",
            "INFO:__main__:Epoch 15926: total training loss 0.00137\n",
            "2025-06-26 08:44:05,328 Epoch 15926: total training loss 0.00137\n",
            "INFO:__main__:EPOCH 15927\n",
            "2025-06-26 08:44:05,330 EPOCH 15927\n",
            "INFO:__main__:Epoch 15927: total training loss 0.00143\n",
            "2025-06-26 08:44:05,408 Epoch 15927: total training loss 0.00143\n",
            "INFO:__main__:EPOCH 15928\n",
            "2025-06-26 08:44:05,410 EPOCH 15928\n",
            "INFO:__main__:Epoch 15928: total training loss 0.00143\n",
            "2025-06-26 08:44:05,485 Epoch 15928: total training loss 0.00143\n",
            "INFO:__main__:EPOCH 15929\n",
            "2025-06-26 08:44:05,489 EPOCH 15929\n",
            "INFO:__main__:Epoch 15929: total training loss 0.00135\n",
            "2025-06-26 08:44:05,584 Epoch 15929: total training loss 0.00135\n",
            "INFO:__main__:EPOCH 15930\n",
            "2025-06-26 08:44:05,586 EPOCH 15930\n",
            "INFO:__main__:Epoch 15930: total training loss 0.00126\n",
            "2025-06-26 08:44:05,657 Epoch 15930: total training loss 0.00126\n",
            "INFO:__main__:EPOCH 15931\n",
            "2025-06-26 08:44:05,659 EPOCH 15931\n",
            "INFO:__main__:Epoch 15931: total training loss 0.00130\n",
            "2025-06-26 08:44:05,729 Epoch 15931: total training loss 0.00130\n",
            "INFO:__main__:EPOCH 15932\n",
            "2025-06-26 08:44:05,732 EPOCH 15932\n",
            "INFO:__main__:Epoch 15932: total training loss 0.00129\n",
            "2025-06-26 08:44:05,808 Epoch 15932: total training loss 0.00129\n",
            "INFO:__main__:EPOCH 15933\n",
            "2025-06-26 08:44:05,812 EPOCH 15933\n",
            "INFO:__main__:Epoch 15933: total training loss 0.00119\n",
            "2025-06-26 08:44:05,885 Epoch 15933: total training loss 0.00119\n",
            "INFO:__main__:EPOCH 15934\n",
            "2025-06-26 08:44:05,889 EPOCH 15934\n",
            "INFO:__main__:Epoch 15934: total training loss 0.00106\n",
            "2025-06-26 08:44:05,961 Epoch 15934: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15935\n",
            "2025-06-26 08:44:05,965 EPOCH 15935\n",
            "INFO:__main__:Epoch 15935: total training loss 0.00120\n",
            "2025-06-26 08:44:06,037 Epoch 15935: total training loss 0.00120\n",
            "INFO:__main__:EPOCH 15936\n",
            "2025-06-26 08:44:06,040 EPOCH 15936\n",
            "INFO:__main__:Epoch 15936: total training loss 0.00117\n",
            "2025-06-26 08:44:06,112 Epoch 15936: total training loss 0.00117\n",
            "INFO:__main__:EPOCH 15937\n",
            "2025-06-26 08:44:06,125 EPOCH 15937\n",
            "INFO:__main__:Epoch 15937: total training loss 0.00110\n",
            "2025-06-26 08:44:06,199 Epoch 15937: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 15938\n",
            "2025-06-26 08:44:06,201 EPOCH 15938\n",
            "INFO:__main__:Epoch 15938: total training loss 0.00103\n",
            "2025-06-26 08:44:06,277 Epoch 15938: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15939\n",
            "2025-06-26 08:44:06,281 EPOCH 15939\n",
            "INFO:__main__:Epoch 15939: total training loss 0.00101\n",
            "2025-06-26 08:44:06,352 Epoch 15939: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15940\n",
            "2025-06-26 08:44:06,353 EPOCH 15940\n",
            "INFO:__main__:Epoch 15940: total training loss 0.00100\n",
            "2025-06-26 08:44:06,428 Epoch 15940: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15941\n",
            "2025-06-26 08:44:06,431 EPOCH 15941\n",
            "INFO:__main__:Epoch 15941: total training loss 0.00100\n",
            "2025-06-26 08:44:06,505 Epoch 15941: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15942\n",
            "2025-06-26 08:44:06,507 EPOCH 15942\n",
            "INFO:__main__:Epoch 15942: total training loss 0.00104\n",
            "2025-06-26 08:44:06,588 Epoch 15942: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 15943\n",
            "2025-06-26 08:44:06,592 EPOCH 15943\n",
            "INFO:__main__:Epoch 15943: total training loss 0.00096\n",
            "2025-06-26 08:44:06,673 Epoch 15943: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15944\n",
            "2025-06-26 08:44:06,676 EPOCH 15944\n",
            "INFO:__main__:Epoch 15944: total training loss 0.00094\n",
            "2025-06-26 08:44:06,747 Epoch 15944: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15945\n",
            "2025-06-26 08:44:06,749 EPOCH 15945\n",
            "INFO:__main__:Epoch 15945: total training loss 0.00099\n",
            "2025-06-26 08:44:06,824 Epoch 15945: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15946\n",
            "2025-06-26 08:44:06,828 EPOCH 15946\n",
            "INFO:__main__:Epoch 15946: total training loss 0.00103\n",
            "2025-06-26 08:44:06,904 Epoch 15946: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15947\n",
            "2025-06-26 08:44:06,906 EPOCH 15947\n",
            "INFO:__main__:Epoch 15947: total training loss 0.00100\n",
            "2025-06-26 08:44:06,980 Epoch 15947: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15948\n",
            "2025-06-26 08:44:06,982 EPOCH 15948\n",
            "INFO:__main__:Epoch 15948: total training loss 0.00099\n",
            "2025-06-26 08:44:07,072 Epoch 15948: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15949\n",
            "2025-06-26 08:44:07,074 EPOCH 15949\n",
            "INFO:__main__:Epoch 15949: total training loss 0.00096\n",
            "2025-06-26 08:44:07,160 Epoch 15949: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15950\n",
            "2025-06-26 08:44:07,163 EPOCH 15950\n",
            "INFO:__main__:Epoch 15950: total training loss 0.00101\n",
            "2025-06-26 08:44:07,270 Epoch 15950: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15951\n",
            "2025-06-26 08:44:07,273 EPOCH 15951\n",
            "INFO:__main__:Epoch 15951: total training loss 0.00099\n",
            "2025-06-26 08:44:07,345 Epoch 15951: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15952\n",
            "2025-06-26 08:44:07,347 EPOCH 15952\n",
            "INFO:__main__:Epoch 15952: total training loss 0.00100\n",
            "2025-06-26 08:44:07,419 Epoch 15952: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15953\n",
            "2025-06-26 08:44:07,421 EPOCH 15953\n",
            "INFO:__main__:Epoch 15953: total training loss 0.00100\n",
            "2025-06-26 08:44:07,491 Epoch 15953: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15954\n",
            "2025-06-26 08:44:07,493 EPOCH 15954\n",
            "INFO:__main__:Epoch 15954: total training loss 0.00097\n",
            "2025-06-26 08:44:07,566 Epoch 15954: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15955\n",
            "2025-06-26 08:44:07,568 EPOCH 15955\n",
            "INFO:__main__:Epoch 15955: total training loss 0.00105\n",
            "2025-06-26 08:44:07,656 Epoch 15955: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15956\n",
            "2025-06-26 08:44:07,659 EPOCH 15956\n",
            "INFO:__main__:Epoch 15956: total training loss 0.00116\n",
            "2025-06-26 08:44:07,746 Epoch 15956: total training loss 0.00116\n",
            "INFO:__main__:EPOCH 15957\n",
            "2025-06-26 08:44:07,748 EPOCH 15957\n",
            "INFO:__main__:Epoch 15957: total training loss 0.00116\n",
            "2025-06-26 08:44:07,817 Epoch 15957: total training loss 0.00116\n",
            "INFO:__main__:EPOCH 15958\n",
            "2025-06-26 08:44:07,819 EPOCH 15958\n",
            "INFO:__main__:Epoch 15958: total training loss 0.00105\n",
            "2025-06-26 08:44:07,894 Epoch 15958: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 15959\n",
            "2025-06-26 08:44:07,897 EPOCH 15959\n",
            "INFO:__main__:Epoch 15959: total training loss 0.00106\n",
            "2025-06-26 08:44:07,971 Epoch 15959: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15960\n",
            "2025-06-26 08:44:07,973 EPOCH 15960\n",
            "INFO:__main__:Epoch 15960: total training loss 0.00100\n",
            "2025-06-26 08:44:08,058 Epoch 15960: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15961\n",
            "2025-06-26 08:44:08,060 EPOCH 15961\n",
            "INFO:__main__:Epoch 15961: total training loss 0.00099\n",
            "2025-06-26 08:44:08,133 Epoch 15961: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 15962\n",
            "2025-06-26 08:44:08,135 EPOCH 15962\n",
            "INFO:__main__:Epoch 15962: total training loss 0.00103\n",
            "2025-06-26 08:44:08,213 Epoch 15962: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 15963\n",
            "2025-06-26 08:44:08,215 EPOCH 15963\n",
            "INFO:__main__:Epoch 15963: total training loss 0.00102\n",
            "2025-06-26 08:44:08,287 Epoch 15963: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15964\n",
            "2025-06-26 08:44:08,289 EPOCH 15964\n",
            "INFO:__main__:Epoch 15964: total training loss 0.00106\n",
            "2025-06-26 08:44:08,366 Epoch 15964: total training loss 0.00106\n",
            "INFO:__main__:EPOCH 15965\n",
            "2025-06-26 08:44:08,372 EPOCH 15965\n",
            "INFO:__main__:Epoch 15965: total training loss 0.00100\n",
            "2025-06-26 08:44:08,462 Epoch 15965: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 15966\n",
            "2025-06-26 08:44:08,467 EPOCH 15966\n",
            "INFO:__main__:Epoch 15966: total training loss 0.00092\n",
            "2025-06-26 08:44:08,539 Epoch 15966: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15967\n",
            "2025-06-26 08:44:08,541 EPOCH 15967\n",
            "INFO:__main__:Epoch 15967: total training loss 0.00098\n",
            "2025-06-26 08:44:08,632 Epoch 15967: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 15968\n",
            "2025-06-26 08:44:08,637 EPOCH 15968\n",
            "INFO:__main__:Epoch 15968: total training loss 0.00094\n",
            "2025-06-26 08:44:08,711 Epoch 15968: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15969\n",
            "2025-06-26 08:44:08,717 EPOCH 15969\n",
            "INFO:__main__:Epoch 15969: total training loss 0.00094\n",
            "2025-06-26 08:44:08,820 Epoch 15969: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 15970\n",
            "2025-06-26 08:44:08,825 EPOCH 15970\n",
            "INFO:__main__:Epoch 15970: total training loss 0.00092\n",
            "2025-06-26 08:44:08,900 Epoch 15970: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 15971\n",
            "2025-06-26 08:44:08,904 EPOCH 15971\n",
            "INFO:__main__:Epoch 15971: total training loss 0.00097\n",
            "2025-06-26 08:44:08,992 Epoch 15971: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15972\n",
            "2025-06-26 08:44:08,996 EPOCH 15972\n",
            "INFO:__main__:Epoch 15972: total training loss 0.00089\n",
            "2025-06-26 08:44:09,072 Epoch 15972: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15973\n",
            "2025-06-26 08:44:09,074 EPOCH 15973\n",
            "INFO:__main__:Epoch 15973: total training loss 0.00090\n",
            "2025-06-26 08:44:09,165 Epoch 15973: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15974\n",
            "2025-06-26 08:44:09,167 EPOCH 15974\n",
            "INFO:__main__:Epoch 15974: total training loss 0.00090\n",
            "2025-06-26 08:44:09,243 Epoch 15974: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15975\n",
            "2025-06-26 08:44:09,245 EPOCH 15975\n",
            "INFO:__main__:Epoch 15975: total training loss 0.00088\n",
            "2025-06-26 08:44:09,314 Epoch 15975: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15976\n",
            "2025-06-26 08:44:09,316 EPOCH 15976\n",
            "INFO:__main__:Epoch 15976: total training loss 0.00089\n",
            "2025-06-26 08:44:09,386 Epoch 15976: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15977\n",
            "2025-06-26 08:44:09,388 EPOCH 15977\n",
            "INFO:__main__:Epoch 15977: total training loss 0.00085\n",
            "2025-06-26 08:44:09,458 Epoch 15977: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15978\n",
            "2025-06-26 08:44:09,460 EPOCH 15978\n",
            "INFO:__main__:Epoch 15978: total training loss 0.00087\n",
            "2025-06-26 08:44:09,529 Epoch 15978: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 15979\n",
            "2025-06-26 08:44:09,531 EPOCH 15979\n",
            "INFO:__main__:Epoch 15979: total training loss 0.00081\n",
            "2025-06-26 08:44:09,602 Epoch 15979: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 15980\n",
            "2025-06-26 08:44:09,604 EPOCH 15980\n",
            "INFO:__main__:Epoch 15980: total training loss 0.00085\n",
            "2025-06-26 08:44:09,676 Epoch 15980: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 15981\n",
            "2025-06-26 08:44:09,678 EPOCH 15981\n",
            "INFO:__main__:Epoch 15981: total training loss 0.00084\n",
            "2025-06-26 08:44:09,756 Epoch 15981: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15982\n",
            "2025-06-26 08:44:09,757 EPOCH 15982\n",
            "INFO:__main__:Epoch 15982: total training loss 0.00083\n",
            "2025-06-26 08:44:09,842 Epoch 15982: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15983\n",
            "2025-06-26 08:44:09,846 EPOCH 15983\n",
            "INFO:__main__:Epoch 15983: total training loss 0.00089\n",
            "2025-06-26 08:44:09,918 Epoch 15983: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15984\n",
            "2025-06-26 08:44:09,920 EPOCH 15984\n",
            "INFO:__main__:Epoch 15984: total training loss 0.00084\n",
            "2025-06-26 08:44:09,991 Epoch 15984: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15985\n",
            "2025-06-26 08:44:09,993 EPOCH 15985\n",
            "INFO:__main__:Epoch 15985: total training loss 0.00083\n",
            "2025-06-26 08:44:10,067 Epoch 15985: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 15986\n",
            "2025-06-26 08:44:10,069 EPOCH 15986\n",
            "INFO:__main__:Epoch 15986: total training loss 0.00088\n",
            "2025-06-26 08:44:10,148 Epoch 15986: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 15987\n",
            "2025-06-26 08:44:10,150 EPOCH 15987\n",
            "INFO:__main__:Epoch 15987: total training loss 0.00089\n",
            "2025-06-26 08:44:10,225 Epoch 15987: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 15988\n",
            "2025-06-26 08:44:10,227 EPOCH 15988\n",
            "INFO:__main__:Epoch 15988: total training loss 0.00082\n",
            "2025-06-26 08:44:10,298 Epoch 15988: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 15989\n",
            "2025-06-26 08:44:10,300 EPOCH 15989\n",
            "INFO:__main__:Epoch 15989: total training loss 0.00079\n",
            "2025-06-26 08:44:10,375 Epoch 15989: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 15990\n",
            "2025-06-26 08:44:10,377 EPOCH 15990\n",
            "INFO:__main__:Epoch 15990: total training loss 0.00084\n",
            "2025-06-26 08:44:10,461 Epoch 15990: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 15991\n",
            "2025-06-26 08:44:10,467 EPOCH 15991\n",
            "INFO:__main__:Epoch 15991: total training loss 0.00090\n",
            "2025-06-26 08:44:10,554 Epoch 15991: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 15992\n",
            "2025-06-26 08:44:10,560 EPOCH 15992\n",
            "INFO:__main__:Epoch 15992: total training loss 0.00096\n",
            "2025-06-26 08:44:10,637 Epoch 15992: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15993\n",
            "2025-06-26 08:44:10,641 EPOCH 15993\n",
            "INFO:__main__:Epoch 15993: total training loss 0.00093\n",
            "2025-06-26 08:44:10,763 Epoch 15993: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 15994\n",
            "2025-06-26 08:44:10,765 EPOCH 15994\n",
            "INFO:__main__:Epoch 15994: total training loss 0.00102\n",
            "2025-06-26 08:44:10,867 Epoch 15994: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 15995\n",
            "2025-06-26 08:44:10,869 EPOCH 15995\n",
            "INFO:__main__:Epoch 15995: total training loss 0.00097\n",
            "2025-06-26 08:44:10,982 Epoch 15995: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 15996\n",
            "2025-06-26 08:44:10,986 EPOCH 15996\n",
            "INFO:__main__:Epoch 15996: total training loss 0.00101\n",
            "2025-06-26 08:44:11,088 Epoch 15996: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 15997\n",
            "2025-06-26 08:44:11,089 EPOCH 15997\n",
            "INFO:__main__:Epoch 15997: total training loss 0.00096\n",
            "2025-06-26 08:44:11,166 Epoch 15997: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 15998\n",
            "2025-06-26 08:44:11,167 EPOCH 15998\n",
            "INFO:__main__:Epoch 15998: total training loss 0.00095\n",
            "2025-06-26 08:44:11,272 Epoch 15998: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 15999\n",
            "2025-06-26 08:44:11,274 EPOCH 15999\n",
            "INFO:__main__:Epoch 15999: total training loss 0.00098\n",
            "2025-06-26 08:44:11,359 Epoch 15999: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 16000\n",
            "2025-06-26 08:44:11,364 EPOCH 16000\n",
            "INFO:__main__:Epoch 16000 Step:    16000 Batch Loss:     0.000973 Tokens per Sec:  1721199, Lr: 0.001000\n",
            "2025-06-26 08:44:11,448 Epoch 16000 Step:    16000 Batch Loss:     0.000973 Tokens per Sec:  1721199, Lr: 0.001000\n",
            "INFO:__main__:Hooray! New best validation result [dtw]!\n",
            "2025-06-26 08:44:12,630 Hooray! New best validation result [dtw]!\n",
            "INFO:__main__:Saving new checkpoint.\n",
            "2025-06-26 08:44:12,632 Saving new checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev/11August_2010_Wednesday_tagesschau-2    dtw: 14.85\n",
            "dev/11August_2010_Wednesday_tagesschau-3    dtw: 10.74\n",
            "dev/11August_2010_Wednesday_tagesschau-8    dtw: 13.34\n",
            "dev/25October_2010_Monday_tagesschau-22    dtw: 15.74\n",
            "dev/05May_2011_Thursday_tagesschau-25    dtw: 10.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 16754\n",
            "2025-06-26 08:45:46,275 EPOCH 16754\n",
            "INFO:__main__:Epoch 16754: total training loss 0.00095\n",
            "2025-06-26 08:45:46,350 Epoch 16754: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 16755\n",
            "2025-06-26 08:45:46,353 EPOCH 16755\n",
            "INFO:__main__:Epoch 16755: total training loss 0.00087\n",
            "2025-06-26 08:45:46,426 Epoch 16755: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16756\n",
            "2025-06-26 08:45:46,430 EPOCH 16756\n",
            "INFO:__main__:Epoch 16756: total training loss 0.00087\n",
            "2025-06-26 08:45:46,502 Epoch 16756: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16757\n",
            "2025-06-26 08:45:46,506 EPOCH 16757\n",
            "INFO:__main__:Epoch 16757: total training loss 0.00095\n",
            "2025-06-26 08:45:46,582 Epoch 16757: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 16758\n",
            "2025-06-26 08:45:46,585 EPOCH 16758\n",
            "INFO:__main__:Epoch 16758: total training loss 0.00091\n",
            "2025-06-26 08:45:46,662 Epoch 16758: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16759\n",
            "2025-06-26 08:45:46,664 EPOCH 16759\n",
            "INFO:__main__:Epoch 16759: total training loss 0.00084\n",
            "2025-06-26 08:45:46,735 Epoch 16759: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16760\n",
            "2025-06-26 08:45:46,737 EPOCH 16760\n",
            "INFO:__main__:Epoch 16760: total training loss 0.00090\n",
            "2025-06-26 08:45:46,811 Epoch 16760: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16761\n",
            "2025-06-26 08:45:46,813 EPOCH 16761\n",
            "INFO:__main__:Epoch 16761: total training loss 0.00086\n",
            "2025-06-26 08:45:46,896 Epoch 16761: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16762\n",
            "2025-06-26 08:45:46,898 EPOCH 16762\n",
            "INFO:__main__:Epoch 16762: total training loss 0.00089\n",
            "2025-06-26 08:45:46,973 Epoch 16762: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16763\n",
            "2025-06-26 08:45:46,975 EPOCH 16763\n",
            "INFO:__main__:Epoch 16763: total training loss 0.00092\n",
            "2025-06-26 08:45:47,052 Epoch 16763: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16764\n",
            "2025-06-26 08:45:47,055 EPOCH 16764\n",
            "INFO:__main__:Epoch 16764: total training loss 0.00091\n",
            "2025-06-26 08:45:47,125 Epoch 16764: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16765\n",
            "2025-06-26 08:45:47,127 EPOCH 16765\n",
            "INFO:__main__:Epoch 16765: total training loss 0.00087\n",
            "2025-06-26 08:45:47,200 Epoch 16765: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16766\n",
            "2025-06-26 08:45:47,202 EPOCH 16766\n",
            "INFO:__main__:Epoch 16766: total training loss 0.00085\n",
            "2025-06-26 08:45:47,288 Epoch 16766: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16767\n",
            "2025-06-26 08:45:47,290 EPOCH 16767\n",
            "INFO:__main__:Epoch 16767: total training loss 0.00083\n",
            "2025-06-26 08:45:47,365 Epoch 16767: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16768\n",
            "2025-06-26 08:45:47,367 EPOCH 16768\n",
            "INFO:__main__:Epoch 16768: total training loss 0.00090\n",
            "2025-06-26 08:45:47,438 Epoch 16768: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16769\n",
            "2025-06-26 08:45:47,440 EPOCH 16769\n",
            "INFO:__main__:Epoch 16769: total training loss 0.00090\n",
            "2025-06-26 08:45:47,508 Epoch 16769: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16770\n",
            "2025-06-26 08:45:47,510 EPOCH 16770\n",
            "INFO:__main__:Epoch 16770: total training loss 0.00088\n",
            "2025-06-26 08:45:47,581 Epoch 16770: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16771\n",
            "2025-06-26 08:45:47,583 EPOCH 16771\n",
            "INFO:__main__:Epoch 16771: total training loss 0.00086\n",
            "2025-06-26 08:45:47,654 Epoch 16771: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16772\n",
            "2025-06-26 08:45:47,656 EPOCH 16772\n",
            "INFO:__main__:Epoch 16772: total training loss 0.00086\n",
            "2025-06-26 08:45:47,728 Epoch 16772: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16773\n",
            "2025-06-26 08:45:47,730 EPOCH 16773\n",
            "INFO:__main__:Epoch 16773: total training loss 0.00085\n",
            "2025-06-26 08:45:47,802 Epoch 16773: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16774\n",
            "2025-06-26 08:45:47,804 EPOCH 16774\n",
            "INFO:__main__:Epoch 16774: total training loss 0.00087\n",
            "2025-06-26 08:45:47,877 Epoch 16774: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16775\n",
            "2025-06-26 08:45:47,879 EPOCH 16775\n",
            "INFO:__main__:Epoch 16775: total training loss 0.00087\n",
            "2025-06-26 08:45:47,950 Epoch 16775: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16776\n",
            "2025-06-26 08:45:47,952 EPOCH 16776\n",
            "INFO:__main__:Epoch 16776: total training loss 0.00086\n",
            "2025-06-26 08:45:48,023 Epoch 16776: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16777\n",
            "2025-06-26 08:45:48,025 EPOCH 16777\n",
            "INFO:__main__:Epoch 16777: total training loss 0.00085\n",
            "2025-06-26 08:45:48,103 Epoch 16777: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16778\n",
            "2025-06-26 08:45:48,105 EPOCH 16778\n",
            "INFO:__main__:Epoch 16778: total training loss 0.00085\n",
            "2025-06-26 08:45:48,176 Epoch 16778: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16779\n",
            "2025-06-26 08:45:48,178 EPOCH 16779\n",
            "INFO:__main__:Epoch 16779: total training loss 0.00081\n",
            "2025-06-26 08:45:48,254 Epoch 16779: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16780\n",
            "2025-06-26 08:45:48,256 EPOCH 16780\n",
            "INFO:__main__:Epoch 16780: total training loss 0.00083\n",
            "2025-06-26 08:45:48,327 Epoch 16780: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16781\n",
            "2025-06-26 08:45:48,332 EPOCH 16781\n",
            "INFO:__main__:Epoch 16781: total training loss 0.00082\n",
            "2025-06-26 08:45:48,410 Epoch 16781: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16782\n",
            "2025-06-26 08:45:48,412 EPOCH 16782\n",
            "INFO:__main__:Epoch 16782: total training loss 0.00083\n",
            "2025-06-26 08:45:48,485 Epoch 16782: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16783\n",
            "2025-06-26 08:45:48,487 EPOCH 16783\n",
            "INFO:__main__:Epoch 16783: total training loss 0.00081\n",
            "2025-06-26 08:45:48,558 Epoch 16783: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16784\n",
            "2025-06-26 08:45:48,561 EPOCH 16784\n",
            "INFO:__main__:Epoch 16784: total training loss 0.00089\n",
            "2025-06-26 08:45:48,633 Epoch 16784: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16785\n",
            "2025-06-26 08:45:48,635 EPOCH 16785\n",
            "INFO:__main__:Epoch 16785: total training loss 0.00090\n",
            "2025-06-26 08:45:48,707 Epoch 16785: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16786\n",
            "2025-06-26 08:45:48,709 EPOCH 16786\n",
            "INFO:__main__:Epoch 16786: total training loss 0.00085\n",
            "2025-06-26 08:45:48,785 Epoch 16786: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16787\n",
            "2025-06-26 08:45:48,787 EPOCH 16787\n",
            "INFO:__main__:Epoch 16787: total training loss 0.00089\n",
            "2025-06-26 08:45:48,856 Epoch 16787: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16788\n",
            "2025-06-26 08:45:48,858 EPOCH 16788\n",
            "INFO:__main__:Epoch 16788: total training loss 0.00093\n",
            "2025-06-26 08:45:48,931 Epoch 16788: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16789\n",
            "2025-06-26 08:45:48,933 EPOCH 16789\n",
            "INFO:__main__:Epoch 16789: total training loss 0.00088\n",
            "2025-06-26 08:45:49,005 Epoch 16789: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16790\n",
            "2025-06-26 08:45:49,007 EPOCH 16790\n",
            "INFO:__main__:Epoch 16790: total training loss 0.00088\n",
            "2025-06-26 08:45:49,091 Epoch 16790: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16791\n",
            "2025-06-26 08:45:49,092 EPOCH 16791\n",
            "INFO:__main__:Epoch 16791: total training loss 0.00089\n",
            "2025-06-26 08:45:49,165 Epoch 16791: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16792\n",
            "2025-06-26 08:45:49,167 EPOCH 16792\n",
            "INFO:__main__:Epoch 16792: total training loss 0.00090\n",
            "2025-06-26 08:45:49,245 Epoch 16792: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16793\n",
            "2025-06-26 08:45:49,247 EPOCH 16793\n",
            "INFO:__main__:Epoch 16793: total training loss 0.00087\n",
            "2025-06-26 08:45:49,319 Epoch 16793: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16794\n",
            "2025-06-26 08:45:49,322 EPOCH 16794\n",
            "INFO:__main__:Epoch 16794: total training loss 0.00089\n",
            "2025-06-26 08:45:49,393 Epoch 16794: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16795\n",
            "2025-06-26 08:45:49,395 EPOCH 16795\n",
            "INFO:__main__:Epoch 16795: total training loss 0.00090\n",
            "2025-06-26 08:45:49,490 Epoch 16795: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16796\n",
            "2025-06-26 08:45:49,491 EPOCH 16796\n",
            "INFO:__main__:Epoch 16796: total training loss 0.00090\n",
            "2025-06-26 08:45:49,566 Epoch 16796: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16797\n",
            "2025-06-26 08:45:49,568 EPOCH 16797\n",
            "INFO:__main__:Epoch 16797: total training loss 0.00086\n",
            "2025-06-26 08:45:49,640 Epoch 16797: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16798\n",
            "2025-06-26 08:45:49,642 EPOCH 16798\n",
            "INFO:__main__:Epoch 16798: total training loss 0.00090\n",
            "2025-06-26 08:45:49,712 Epoch 16798: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16799\n",
            "2025-06-26 08:45:49,714 EPOCH 16799\n",
            "INFO:__main__:Epoch 16799: total training loss 0.00091\n",
            "2025-06-26 08:45:49,786 Epoch 16799: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16800\n",
            "2025-06-26 08:45:49,788 EPOCH 16800\n",
            "INFO:__main__:Epoch 16800: total training loss 0.00092\n",
            "2025-06-26 08:45:49,863 Epoch 16800: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16801\n",
            "2025-06-26 08:45:49,865 EPOCH 16801\n",
            "INFO:__main__:Epoch 16801: total training loss 0.00093\n",
            "2025-06-26 08:45:49,938 Epoch 16801: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16802\n",
            "2025-06-26 08:45:49,940 EPOCH 16802\n",
            "INFO:__main__:Epoch 16802: total training loss 0.00088\n",
            "2025-06-26 08:45:50,012 Epoch 16802: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16803\n",
            "2025-06-26 08:45:50,014 EPOCH 16803\n",
            "INFO:__main__:Epoch 16803: total training loss 0.00089\n",
            "2025-06-26 08:45:50,085 Epoch 16803: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16804\n",
            "2025-06-26 08:45:50,087 EPOCH 16804\n",
            "INFO:__main__:Epoch 16804: total training loss 0.00089\n",
            "2025-06-26 08:45:50,158 Epoch 16804: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16805\n",
            "2025-06-26 08:45:50,160 EPOCH 16805\n",
            "INFO:__main__:Epoch 16805: total training loss 0.00088\n",
            "2025-06-26 08:45:50,241 Epoch 16805: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16806\n",
            "2025-06-26 08:45:50,243 EPOCH 16806\n",
            "INFO:__main__:Epoch 16806: total training loss 0.00085\n",
            "2025-06-26 08:45:50,312 Epoch 16806: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16807\n",
            "2025-06-26 08:45:50,314 EPOCH 16807\n",
            "INFO:__main__:Epoch 16807: total training loss 0.00088\n",
            "2025-06-26 08:45:50,382 Epoch 16807: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16808\n",
            "2025-06-26 08:45:50,384 EPOCH 16808\n",
            "INFO:__main__:Epoch 16808: total training loss 0.00093\n",
            "2025-06-26 08:45:50,454 Epoch 16808: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16809\n",
            "2025-06-26 08:45:50,456 EPOCH 16809\n",
            "INFO:__main__:Epoch 16809: total training loss 0.00086\n",
            "2025-06-26 08:45:50,556 Epoch 16809: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16810\n",
            "2025-06-26 08:45:50,559 EPOCH 16810\n",
            "INFO:__main__:Epoch 16810: total training loss 0.00084\n",
            "2025-06-26 08:45:50,633 Epoch 16810: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16811\n",
            "2025-06-26 08:45:50,635 EPOCH 16811\n",
            "INFO:__main__:Epoch 16811: total training loss 0.00088\n",
            "2025-06-26 08:45:50,706 Epoch 16811: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16812\n",
            "2025-06-26 08:45:50,710 EPOCH 16812\n",
            "INFO:__main__:Epoch 16812: total training loss 0.00089\n",
            "2025-06-26 08:45:50,788 Epoch 16812: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16813\n",
            "2025-06-26 08:45:50,791 EPOCH 16813\n",
            "INFO:__main__:Epoch 16813: total training loss 0.00088\n",
            "2025-06-26 08:45:50,866 Epoch 16813: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16814\n",
            "2025-06-26 08:45:50,868 EPOCH 16814\n",
            "INFO:__main__:Epoch 16814: total training loss 0.00086\n",
            "2025-06-26 08:45:50,941 Epoch 16814: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16815\n",
            "2025-06-26 08:45:50,943 EPOCH 16815\n",
            "INFO:__main__:Epoch 16815: total training loss 0.00081\n",
            "2025-06-26 08:45:51,013 Epoch 16815: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16816\n",
            "2025-06-26 08:45:51,015 EPOCH 16816\n",
            "INFO:__main__:Epoch 16816: total training loss 0.00085\n",
            "2025-06-26 08:45:51,094 Epoch 16816: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16817\n",
            "2025-06-26 08:45:51,096 EPOCH 16817\n",
            "INFO:__main__:Epoch 16817: total training loss 0.00088\n",
            "2025-06-26 08:45:51,167 Epoch 16817: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16818\n",
            "2025-06-26 08:45:51,169 EPOCH 16818\n",
            "INFO:__main__:Epoch 16818: total training loss 0.00089\n",
            "2025-06-26 08:45:51,243 Epoch 16818: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16819\n",
            "2025-06-26 08:45:51,245 EPOCH 16819\n",
            "INFO:__main__:Epoch 16819: total training loss 0.00082\n",
            "2025-06-26 08:45:51,316 Epoch 16819: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16820\n",
            "2025-06-26 08:45:51,319 EPOCH 16820\n",
            "INFO:__main__:Epoch 16820: total training loss 0.00083\n",
            "2025-06-26 08:45:51,391 Epoch 16820: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16821\n",
            "2025-06-26 08:45:51,393 EPOCH 16821\n",
            "INFO:__main__:Epoch 16821: total training loss 0.00080\n",
            "2025-06-26 08:45:51,462 Epoch 16821: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 16822\n",
            "2025-06-26 08:45:51,465 EPOCH 16822\n",
            "INFO:__main__:Epoch 16822: total training loss 0.00082\n",
            "2025-06-26 08:45:51,536 Epoch 16822: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16823\n",
            "2025-06-26 08:45:51,540 EPOCH 16823\n",
            "INFO:__main__:Epoch 16823: total training loss 0.00084\n",
            "2025-06-26 08:45:51,630 Epoch 16823: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16824\n",
            "2025-06-26 08:45:51,632 EPOCH 16824\n",
            "INFO:__main__:Epoch 16824: total training loss 0.00089\n",
            "2025-06-26 08:45:51,704 Epoch 16824: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16825\n",
            "2025-06-26 08:45:51,706 EPOCH 16825\n",
            "INFO:__main__:Epoch 16825: total training loss 0.00098\n",
            "2025-06-26 08:45:51,779 Epoch 16825: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 16826\n",
            "2025-06-26 08:45:51,781 EPOCH 16826\n",
            "INFO:__main__:Epoch 16826: total training loss 0.00102\n",
            "2025-06-26 08:45:51,852 Epoch 16826: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 16827\n",
            "2025-06-26 08:45:51,854 EPOCH 16827\n",
            "INFO:__main__:Epoch 16827: total training loss 0.00103\n",
            "2025-06-26 08:45:51,927 Epoch 16827: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 16828\n",
            "2025-06-26 08:45:51,929 EPOCH 16828\n",
            "INFO:__main__:Epoch 16828: total training loss 0.00115\n",
            "2025-06-26 08:45:52,006 Epoch 16828: total training loss 0.00115\n",
            "INFO:__main__:EPOCH 16829\n",
            "2025-06-26 08:45:52,008 EPOCH 16829\n",
            "INFO:__main__:Epoch 16829: total training loss 0.00094\n",
            "2025-06-26 08:45:52,080 Epoch 16829: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 16830\n",
            "2025-06-26 08:45:52,083 EPOCH 16830\n",
            "INFO:__main__:Epoch 16830: total training loss 0.00099\n",
            "2025-06-26 08:45:52,153 Epoch 16830: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 16831\n",
            "2025-06-26 08:45:52,155 EPOCH 16831\n",
            "INFO:__main__:Epoch 16831: total training loss 0.00114\n",
            "2025-06-26 08:45:52,230 Epoch 16831: total training loss 0.00114\n",
            "INFO:__main__:EPOCH 16832\n",
            "2025-06-26 08:45:52,233 EPOCH 16832\n",
            "INFO:__main__:Epoch 16832: total training loss 0.00103\n",
            "2025-06-26 08:45:52,309 Epoch 16832: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 16833\n",
            "2025-06-26 08:45:52,311 EPOCH 16833\n",
            "INFO:__main__:Epoch 16833: total training loss 0.00100\n",
            "2025-06-26 08:45:52,381 Epoch 16833: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 16834\n",
            "2025-06-26 08:45:52,383 EPOCH 16834\n",
            "INFO:__main__:Epoch 16834: total training loss 0.00101\n",
            "2025-06-26 08:45:52,455 Epoch 16834: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 16835\n",
            "2025-06-26 08:45:52,457 EPOCH 16835\n",
            "INFO:__main__:Epoch 16835: total training loss 0.00101\n",
            "2025-06-26 08:45:52,529 Epoch 16835: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 16836\n",
            "2025-06-26 08:45:52,531 EPOCH 16836\n",
            "INFO:__main__:Epoch 16836: total training loss 0.00097\n",
            "2025-06-26 08:45:52,605 Epoch 16836: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 16837\n",
            "2025-06-26 08:45:52,607 EPOCH 16837\n",
            "INFO:__main__:Epoch 16837: total training loss 0.00096\n",
            "2025-06-26 08:45:52,698 Epoch 16837: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16838\n",
            "2025-06-26 08:45:52,701 EPOCH 16838\n",
            "INFO:__main__:Epoch 16838: total training loss 0.00093\n",
            "2025-06-26 08:45:52,782 Epoch 16838: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16839\n",
            "2025-06-26 08:45:52,784 EPOCH 16839\n",
            "INFO:__main__:Epoch 16839: total training loss 0.00093\n",
            "2025-06-26 08:45:52,861 Epoch 16839: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16840\n",
            "2025-06-26 08:45:52,863 EPOCH 16840\n",
            "INFO:__main__:Epoch 16840: total training loss 0.00090\n",
            "2025-06-26 08:45:52,934 Epoch 16840: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16841\n",
            "2025-06-26 08:45:52,937 EPOCH 16841\n",
            "INFO:__main__:Epoch 16841: total training loss 0.00096\n",
            "2025-06-26 08:45:53,007 Epoch 16841: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16842\n",
            "2025-06-26 08:45:53,010 EPOCH 16842\n",
            "INFO:__main__:Epoch 16842: total training loss 0.00096\n",
            "2025-06-26 08:45:53,088 Epoch 16842: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16843\n",
            "2025-06-26 08:45:53,090 EPOCH 16843\n",
            "INFO:__main__:Epoch 16843: total training loss 0.00092\n",
            "2025-06-26 08:45:53,164 Epoch 16843: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16844\n",
            "2025-06-26 08:45:53,167 EPOCH 16844\n",
            "INFO:__main__:Epoch 16844: total training loss 0.00085\n",
            "2025-06-26 08:45:53,247 Epoch 16844: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16845\n",
            "2025-06-26 08:45:53,251 EPOCH 16845\n",
            "INFO:__main__:Epoch 16845: total training loss 0.00089\n",
            "2025-06-26 08:45:53,328 Epoch 16845: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16846\n",
            "2025-06-26 08:45:53,330 EPOCH 16846\n",
            "INFO:__main__:Epoch 16846: total training loss 0.00088\n",
            "2025-06-26 08:45:53,403 Epoch 16846: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16847\n",
            "2025-06-26 08:45:53,405 EPOCH 16847\n",
            "INFO:__main__:Epoch 16847: total training loss 0.00089\n",
            "2025-06-26 08:45:53,479 Epoch 16847: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16848\n",
            "2025-06-26 08:45:53,480 EPOCH 16848\n",
            "INFO:__main__:Epoch 16848: total training loss 0.00086\n",
            "2025-06-26 08:45:53,553 Epoch 16848: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16849\n",
            "2025-06-26 08:45:53,555 EPOCH 16849\n",
            "INFO:__main__:Epoch 16849: total training loss 0.00084\n",
            "2025-06-26 08:45:53,627 Epoch 16849: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16850\n",
            "2025-06-26 08:45:53,631 EPOCH 16850\n",
            "INFO:__main__:Epoch 16850: total training loss 0.00084\n",
            "2025-06-26 08:45:53,712 Epoch 16850: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16851\n",
            "2025-06-26 08:45:53,718 EPOCH 16851\n",
            "INFO:__main__:Epoch 16851: total training loss 0.00083\n",
            "2025-06-26 08:45:53,802 Epoch 16851: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16852\n",
            "2025-06-26 08:45:53,805 EPOCH 16852\n",
            "INFO:__main__:Epoch 16852: total training loss 0.00079\n",
            "2025-06-26 08:45:53,875 Epoch 16852: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 16853\n",
            "2025-06-26 08:45:53,878 EPOCH 16853\n",
            "INFO:__main__:Epoch 16853: total training loss 0.00079\n",
            "2025-06-26 08:45:53,956 Epoch 16853: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 16854\n",
            "2025-06-26 08:45:53,958 EPOCH 16854\n",
            "INFO:__main__:Epoch 16854: total training loss 0.00081\n",
            "2025-06-26 08:45:54,026 Epoch 16854: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16855\n",
            "2025-06-26 08:45:54,027 EPOCH 16855\n",
            "INFO:__main__:Epoch 16855: total training loss 0.00078\n",
            "2025-06-26 08:45:54,100 Epoch 16855: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 16856\n",
            "2025-06-26 08:45:54,103 EPOCH 16856\n",
            "INFO:__main__:Epoch 16856: total training loss 0.00078\n",
            "2025-06-26 08:45:54,182 Epoch 16856: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 16857\n",
            "2025-06-26 08:45:54,188 EPOCH 16857\n",
            "INFO:__main__:Epoch 16857: total training loss 0.00076\n",
            "2025-06-26 08:45:54,268 Epoch 16857: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 16858\n",
            "2025-06-26 08:45:54,271 EPOCH 16858\n",
            "INFO:__main__:Epoch 16858: total training loss 0.00077\n",
            "2025-06-26 08:45:54,344 Epoch 16858: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 16859\n",
            "2025-06-26 08:45:54,347 EPOCH 16859\n",
            "INFO:__main__:Epoch 16859: total training loss 0.00083\n",
            "2025-06-26 08:45:54,421 Epoch 16859: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16860\n",
            "2025-06-26 08:45:54,425 EPOCH 16860\n",
            "INFO:__main__:Epoch 16860: total training loss 0.00087\n",
            "2025-06-26 08:45:54,501 Epoch 16860: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16861\n",
            "2025-06-26 08:45:54,505 EPOCH 16861\n",
            "INFO:__main__:Epoch 16861: total training loss 0.00091\n",
            "2025-06-26 08:45:54,579 Epoch 16861: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16862\n",
            "2025-06-26 08:45:54,582 EPOCH 16862\n",
            "INFO:__main__:Epoch 16862: total training loss 0.00089\n",
            "2025-06-26 08:45:54,653 Epoch 16862: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16863\n",
            "2025-06-26 08:45:54,655 EPOCH 16863\n",
            "INFO:__main__:Epoch 16863: total training loss 0.00087\n",
            "2025-06-26 08:45:54,726 Epoch 16863: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16864\n",
            "2025-06-26 08:45:54,728 EPOCH 16864\n",
            "INFO:__main__:Epoch 16864: total training loss 0.00087\n",
            "2025-06-26 08:45:54,810 Epoch 16864: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16865\n",
            "2025-06-26 08:45:54,812 EPOCH 16865\n",
            "INFO:__main__:Epoch 16865: total training loss 0.00083\n",
            "2025-06-26 08:45:54,888 Epoch 16865: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16866\n",
            "2025-06-26 08:45:54,890 EPOCH 16866\n",
            "INFO:__main__:Epoch 16866: total training loss 0.00092\n",
            "2025-06-26 08:45:54,961 Epoch 16866: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16867\n",
            "2025-06-26 08:45:54,963 EPOCH 16867\n",
            "INFO:__main__:Epoch 16867: total training loss 0.00093\n",
            "2025-06-26 08:45:55,037 Epoch 16867: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16868\n",
            "2025-06-26 08:45:55,039 EPOCH 16868\n",
            "INFO:__main__:Epoch 16868: total training loss 0.00088\n",
            "2025-06-26 08:45:55,114 Epoch 16868: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16869\n",
            "2025-06-26 08:45:55,116 EPOCH 16869\n",
            "INFO:__main__:Epoch 16869: total training loss 0.00089\n",
            "2025-06-26 08:45:55,185 Epoch 16869: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16870\n",
            "2025-06-26 08:45:55,188 EPOCH 16870\n",
            "INFO:__main__:Epoch 16870: total training loss 0.00089\n",
            "2025-06-26 08:45:55,260 Epoch 16870: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16871\n",
            "2025-06-26 08:45:55,262 EPOCH 16871\n",
            "INFO:__main__:Epoch 16871: total training loss 0.00091\n",
            "2025-06-26 08:45:55,334 Epoch 16871: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16872\n",
            "2025-06-26 08:45:55,337 EPOCH 16872\n",
            "INFO:__main__:Epoch 16872: total training loss 0.00092\n",
            "2025-06-26 08:45:55,406 Epoch 16872: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16873\n",
            "2025-06-26 08:45:55,408 EPOCH 16873\n",
            "INFO:__main__:Epoch 16873: total training loss 0.00087\n",
            "2025-06-26 08:45:55,478 Epoch 16873: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16874\n",
            "2025-06-26 08:45:55,480 EPOCH 16874\n",
            "INFO:__main__:Epoch 16874: total training loss 0.00087\n",
            "2025-06-26 08:45:55,551 Epoch 16874: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16875\n",
            "2025-06-26 08:45:55,553 EPOCH 16875\n",
            "INFO:__main__:Epoch 16875: total training loss 0.00086\n",
            "2025-06-26 08:45:55,623 Epoch 16875: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16876\n",
            "2025-06-26 08:45:55,625 EPOCH 16876\n",
            "INFO:__main__:Epoch 16876: total training loss 0.00089\n",
            "2025-06-26 08:45:55,697 Epoch 16876: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16877\n",
            "2025-06-26 08:45:55,699 EPOCH 16877\n",
            "INFO:__main__:Epoch 16877: total training loss 0.00090\n",
            "2025-06-26 08:45:55,767 Epoch 16877: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16878\n",
            "2025-06-26 08:45:55,770 EPOCH 16878\n",
            "INFO:__main__:Epoch 16878: total training loss 0.00088\n",
            "2025-06-26 08:45:55,839 Epoch 16878: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16879\n",
            "2025-06-26 08:45:55,842 EPOCH 16879\n",
            "INFO:__main__:Epoch 16879: total training loss 0.00090\n",
            "2025-06-26 08:45:55,929 Epoch 16879: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16880\n",
            "2025-06-26 08:45:55,931 EPOCH 16880\n",
            "INFO:__main__:Epoch 16880: total training loss 0.00088\n",
            "2025-06-26 08:45:56,017 Epoch 16880: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16881\n",
            "2025-06-26 08:45:56,019 EPOCH 16881\n",
            "INFO:__main__:Epoch 16881: total training loss 0.00086\n",
            "2025-06-26 08:45:56,102 Epoch 16881: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16882\n",
            "2025-06-26 08:45:56,104 EPOCH 16882\n",
            "INFO:__main__:Epoch 16882: total training loss 0.00088\n",
            "2025-06-26 08:45:56,180 Epoch 16882: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16883\n",
            "2025-06-26 08:45:56,188 EPOCH 16883\n",
            "INFO:__main__:Epoch 16883: total training loss 0.00084\n",
            "2025-06-26 08:45:56,289 Epoch 16883: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16884\n",
            "2025-06-26 08:45:56,294 EPOCH 16884\n",
            "INFO:__main__:Epoch 16884: total training loss 0.00090\n",
            "2025-06-26 08:45:56,373 Epoch 16884: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16885\n",
            "2025-06-26 08:45:56,379 EPOCH 16885\n",
            "INFO:__main__:Epoch 16885: total training loss 0.00084\n",
            "2025-06-26 08:45:56,474 Epoch 16885: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16886\n",
            "2025-06-26 08:45:56,478 EPOCH 16886\n",
            "INFO:__main__:Epoch 16886: total training loss 0.00080\n",
            "2025-06-26 08:45:56,562 Epoch 16886: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 16887\n",
            "2025-06-26 08:45:56,567 EPOCH 16887\n",
            "INFO:__main__:Epoch 16887: total training loss 0.00085\n",
            "2025-06-26 08:45:56,641 Epoch 16887: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16888\n",
            "2025-06-26 08:45:56,646 EPOCH 16888\n",
            "INFO:__main__:Epoch 16888: total training loss 0.00083\n",
            "2025-06-26 08:45:56,728 Epoch 16888: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16889\n",
            "2025-06-26 08:45:56,731 EPOCH 16889\n",
            "INFO:__main__:Epoch 16889: total training loss 0.00082\n",
            "2025-06-26 08:45:56,815 Epoch 16889: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16890\n",
            "2025-06-26 08:45:56,823 EPOCH 16890\n",
            "INFO:__main__:Epoch 16890: total training loss 0.00082\n",
            "2025-06-26 08:45:56,904 Epoch 16890: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16891\n",
            "2025-06-26 08:45:56,907 EPOCH 16891\n",
            "INFO:__main__:Epoch 16891: total training loss 0.00078\n",
            "2025-06-26 08:45:57,001 Epoch 16891: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 16892\n",
            "2025-06-26 08:45:57,004 EPOCH 16892\n",
            "INFO:__main__:Epoch 16892: total training loss 0.00081\n",
            "2025-06-26 08:45:57,083 Epoch 16892: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16893\n",
            "2025-06-26 08:45:57,089 EPOCH 16893\n",
            "INFO:__main__:Epoch 16893: total training loss 0.00080\n",
            "2025-06-26 08:45:57,183 Epoch 16893: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 16894\n",
            "2025-06-26 08:45:57,185 EPOCH 16894\n",
            "INFO:__main__:Epoch 16894: total training loss 0.00082\n",
            "2025-06-26 08:45:57,281 Epoch 16894: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16895\n",
            "2025-06-26 08:45:57,283 EPOCH 16895\n",
            "INFO:__main__:Epoch 16895: total training loss 0.00088\n",
            "2025-06-26 08:45:57,368 Epoch 16895: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16896\n",
            "2025-06-26 08:45:57,370 EPOCH 16896\n",
            "INFO:__main__:Epoch 16896: total training loss 0.00088\n",
            "2025-06-26 08:45:57,487 Epoch 16896: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16897\n",
            "2025-06-26 08:45:57,489 EPOCH 16897\n",
            "INFO:__main__:Epoch 16897: total training loss 0.00090\n",
            "2025-06-26 08:45:57,589 Epoch 16897: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16898\n",
            "2025-06-26 08:45:57,591 EPOCH 16898\n",
            "INFO:__main__:Epoch 16898: total training loss 0.00086\n",
            "2025-06-26 08:45:57,687 Epoch 16898: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16899\n",
            "2025-06-26 08:45:57,689 EPOCH 16899\n",
            "INFO:__main__:Epoch 16899: total training loss 0.00090\n",
            "2025-06-26 08:45:57,793 Epoch 16899: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16900\n",
            "2025-06-26 08:45:57,799 EPOCH 16900\n",
            "INFO:__main__:Epoch 16900: total training loss 0.00087\n",
            "2025-06-26 08:45:57,893 Epoch 16900: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16901\n",
            "2025-06-26 08:45:57,898 EPOCH 16901\n",
            "INFO:__main__:Epoch 16901: total training loss 0.00083\n",
            "2025-06-26 08:45:58,006 Epoch 16901: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16902\n",
            "2025-06-26 08:45:58,010 EPOCH 16902\n",
            "INFO:__main__:Epoch 16902: total training loss 0.00086\n",
            "2025-06-26 08:45:58,121 Epoch 16902: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16903\n",
            "2025-06-26 08:45:58,127 EPOCH 16903\n",
            "INFO:__main__:Epoch 16903: total training loss 0.00083\n",
            "2025-06-26 08:45:58,222 Epoch 16903: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16904\n",
            "2025-06-26 08:45:58,226 EPOCH 16904\n",
            "INFO:__main__:Epoch 16904: total training loss 0.00080\n",
            "2025-06-26 08:45:58,335 Epoch 16904: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 16905\n",
            "2025-06-26 08:45:58,340 EPOCH 16905\n",
            "INFO:__main__:Epoch 16905: total training loss 0.00081\n",
            "2025-06-26 08:45:58,412 Epoch 16905: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16906\n",
            "2025-06-26 08:45:58,418 EPOCH 16906\n",
            "INFO:__main__:Epoch 16906: total training loss 0.00086\n",
            "2025-06-26 08:45:58,492 Epoch 16906: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16907\n",
            "2025-06-26 08:45:58,496 EPOCH 16907\n",
            "INFO:__main__:Epoch 16907: total training loss 0.00084\n",
            "2025-06-26 08:45:58,580 Epoch 16907: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16908\n",
            "2025-06-26 08:45:58,586 EPOCH 16908\n",
            "INFO:__main__:Epoch 16908: total training loss 0.00085\n",
            "2025-06-26 08:45:58,671 Epoch 16908: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16909\n",
            "2025-06-26 08:45:58,678 EPOCH 16909\n",
            "INFO:__main__:Epoch 16909: total training loss 0.00082\n",
            "2025-06-26 08:45:58,772 Epoch 16909: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16910\n",
            "2025-06-26 08:45:58,782 EPOCH 16910\n",
            "INFO:__main__:Epoch 16910: total training loss 0.00087\n",
            "2025-06-26 08:45:58,860 Epoch 16910: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16911\n",
            "2025-06-26 08:45:58,867 EPOCH 16911\n",
            "INFO:__main__:Epoch 16911: total training loss 0.00090\n",
            "2025-06-26 08:45:58,986 Epoch 16911: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16912\n",
            "2025-06-26 08:45:58,988 EPOCH 16912\n",
            "INFO:__main__:Epoch 16912: total training loss 0.00086\n",
            "2025-06-26 08:45:59,093 Epoch 16912: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16913\n",
            "2025-06-26 08:45:59,100 EPOCH 16913\n",
            "INFO:__main__:Epoch 16913: total training loss 0.00083\n",
            "2025-06-26 08:45:59,212 Epoch 16913: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16914\n",
            "2025-06-26 08:45:59,216 EPOCH 16914\n",
            "INFO:__main__:Epoch 16914: total training loss 0.00094\n",
            "2025-06-26 08:45:59,304 Epoch 16914: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 16915\n",
            "2025-06-26 08:45:59,307 EPOCH 16915\n",
            "INFO:__main__:Epoch 16915: total training loss 0.00091\n",
            "2025-06-26 08:45:59,380 Epoch 16915: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16916\n",
            "2025-06-26 08:45:59,386 EPOCH 16916\n",
            "INFO:__main__:Epoch 16916: total training loss 0.00084\n",
            "2025-06-26 08:45:59,470 Epoch 16916: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16917\n",
            "2025-06-26 08:45:59,472 EPOCH 16917\n",
            "INFO:__main__:Epoch 16917: total training loss 0.00091\n",
            "2025-06-26 08:45:59,551 Epoch 16917: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16918\n",
            "2025-06-26 08:45:59,553 EPOCH 16918\n",
            "INFO:__main__:Epoch 16918: total training loss 0.00085\n",
            "2025-06-26 08:45:59,627 Epoch 16918: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16919\n",
            "2025-06-26 08:45:59,629 EPOCH 16919\n",
            "INFO:__main__:Epoch 16919: total training loss 0.00085\n",
            "2025-06-26 08:45:59,698 Epoch 16919: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16920\n",
            "2025-06-26 08:45:59,700 EPOCH 16920\n",
            "INFO:__main__:Epoch 16920: total training loss 0.00088\n",
            "2025-06-26 08:45:59,795 Epoch 16920: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16921\n",
            "2025-06-26 08:45:59,797 EPOCH 16921\n",
            "INFO:__main__:Epoch 16921: total training loss 0.00085\n",
            "2025-06-26 08:45:59,914 Epoch 16921: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16922\n",
            "2025-06-26 08:45:59,916 EPOCH 16922\n",
            "INFO:__main__:Epoch 16922: total training loss 0.00090\n",
            "2025-06-26 08:46:00,032 Epoch 16922: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16923\n",
            "2025-06-26 08:46:00,034 EPOCH 16923\n",
            "INFO:__main__:Epoch 16923: total training loss 0.00083\n",
            "2025-06-26 08:46:00,143 Epoch 16923: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16924\n",
            "2025-06-26 08:46:00,147 EPOCH 16924\n",
            "INFO:__main__:Epoch 16924: total training loss 0.00089\n",
            "2025-06-26 08:46:00,270 Epoch 16924: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16925\n",
            "2025-06-26 08:46:00,272 EPOCH 16925\n",
            "INFO:__main__:Epoch 16925: total training loss 0.00096\n",
            "2025-06-26 08:46:00,392 Epoch 16925: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16926\n",
            "2025-06-26 08:46:00,395 EPOCH 16926\n",
            "INFO:__main__:Epoch 16926: total training loss 0.00103\n",
            "2025-06-26 08:46:00,506 Epoch 16926: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 16927\n",
            "2025-06-26 08:46:00,511 EPOCH 16927\n",
            "INFO:__main__:Epoch 16927: total training loss 0.00112\n",
            "2025-06-26 08:46:00,620 Epoch 16927: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 16928\n",
            "2025-06-26 08:46:00,624 EPOCH 16928\n",
            "INFO:__main__:Epoch 16928: total training loss 0.00119\n",
            "2025-06-26 08:46:00,711 Epoch 16928: total training loss 0.00119\n",
            "INFO:__main__:EPOCH 16929\n",
            "2025-06-26 08:46:00,714 EPOCH 16929\n",
            "INFO:__main__:Epoch 16929: total training loss 0.00110\n",
            "2025-06-26 08:46:00,799 Epoch 16929: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 16930\n",
            "2025-06-26 08:46:00,801 EPOCH 16930\n",
            "INFO:__main__:Epoch 16930: total training loss 0.00107\n",
            "2025-06-26 08:46:00,889 Epoch 16930: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 16931\n",
            "2025-06-26 08:46:00,891 EPOCH 16931\n",
            "INFO:__main__:Epoch 16931: total training loss 0.00100\n",
            "2025-06-26 08:46:00,986 Epoch 16931: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 16932\n",
            "2025-06-26 08:46:00,992 EPOCH 16932\n",
            "INFO:__main__:Epoch 16932: total training loss 0.00105\n",
            "2025-06-26 08:46:01,113 Epoch 16932: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 16933\n",
            "2025-06-26 08:46:01,114 EPOCH 16933\n",
            "INFO:__main__:Epoch 16933: total training loss 0.00104\n",
            "2025-06-26 08:46:01,204 Epoch 16933: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 16934\n",
            "2025-06-26 08:46:01,206 EPOCH 16934\n",
            "INFO:__main__:Epoch 16934: total training loss 0.00102\n",
            "2025-06-26 08:46:01,301 Epoch 16934: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 16935\n",
            "2025-06-26 08:46:01,303 EPOCH 16935\n",
            "INFO:__main__:Epoch 16935: total training loss 0.00102\n",
            "2025-06-26 08:46:01,377 Epoch 16935: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 16936\n",
            "2025-06-26 08:46:01,381 EPOCH 16936\n",
            "INFO:__main__:Epoch 16936: total training loss 0.00096\n",
            "2025-06-26 08:46:01,460 Epoch 16936: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16937\n",
            "2025-06-26 08:46:01,461 EPOCH 16937\n",
            "INFO:__main__:Epoch 16937: total training loss 0.00096\n",
            "2025-06-26 08:46:01,536 Epoch 16937: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16938\n",
            "2025-06-26 08:46:01,538 EPOCH 16938\n",
            "INFO:__main__:Epoch 16938: total training loss 0.00093\n",
            "2025-06-26 08:46:01,621 Epoch 16938: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16939\n",
            "2025-06-26 08:46:01,622 EPOCH 16939\n",
            "INFO:__main__:Epoch 16939: total training loss 0.00092\n",
            "2025-06-26 08:46:01,700 Epoch 16939: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16940\n",
            "2025-06-26 08:46:01,703 EPOCH 16940\n",
            "INFO:__main__:Epoch 16940: total training loss 0.00089\n",
            "2025-06-26 08:46:01,776 Epoch 16940: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16941\n",
            "2025-06-26 08:46:01,779 EPOCH 16941\n",
            "INFO:__main__:Epoch 16941: total training loss 0.00089\n",
            "2025-06-26 08:46:01,855 Epoch 16941: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16942\n",
            "2025-06-26 08:46:01,859 EPOCH 16942\n",
            "INFO:__main__:Epoch 16942: total training loss 0.00090\n",
            "2025-06-26 08:46:01,932 Epoch 16942: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16943\n",
            "2025-06-26 08:46:01,934 EPOCH 16943\n",
            "INFO:__main__:Epoch 16943: total training loss 0.00087\n",
            "2025-06-26 08:46:02,007 Epoch 16943: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16944\n",
            "2025-06-26 08:46:02,014 EPOCH 16944\n",
            "INFO:__main__:Epoch 16944: total training loss 0.00084\n",
            "2025-06-26 08:46:02,095 Epoch 16944: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16945\n",
            "2025-06-26 08:46:02,097 EPOCH 16945\n",
            "INFO:__main__:Epoch 16945: total training loss 0.00085\n",
            "2025-06-26 08:46:02,175 Epoch 16945: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16946\n",
            "2025-06-26 08:46:02,177 EPOCH 16946\n",
            "INFO:__main__:Epoch 16946: total training loss 0.00079\n",
            "2025-06-26 08:46:02,255 Epoch 16946: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 16947\n",
            "2025-06-26 08:46:02,257 EPOCH 16947\n",
            "INFO:__main__:Epoch 16947: total training loss 0.00082\n",
            "2025-06-26 08:46:02,337 Epoch 16947: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16948\n",
            "2025-06-26 08:46:02,340 EPOCH 16948\n",
            "INFO:__main__:Epoch 16948: total training loss 0.00082\n",
            "2025-06-26 08:46:02,425 Epoch 16948: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16949\n",
            "2025-06-26 08:46:02,427 EPOCH 16949\n",
            "INFO:__main__:Epoch 16949: total training loss 0.00085\n",
            "2025-06-26 08:46:02,499 Epoch 16949: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16950\n",
            "2025-06-26 08:46:02,501 EPOCH 16950\n",
            "INFO:__main__:Epoch 16950: total training loss 0.00085\n",
            "2025-06-26 08:46:02,574 Epoch 16950: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16951\n",
            "2025-06-26 08:46:02,576 EPOCH 16951\n",
            "INFO:__main__:Epoch 16951: total training loss 0.00080\n",
            "2025-06-26 08:46:02,647 Epoch 16951: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 16952\n",
            "2025-06-26 08:46:02,649 EPOCH 16952\n",
            "INFO:__main__:Epoch 16952: total training loss 0.00084\n",
            "2025-06-26 08:46:02,720 Epoch 16952: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16953\n",
            "2025-06-26 08:46:02,722 EPOCH 16953\n",
            "INFO:__main__:Epoch 16953: total training loss 0.00083\n",
            "2025-06-26 08:46:02,796 Epoch 16953: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16954\n",
            "2025-06-26 08:46:02,798 EPOCH 16954\n",
            "INFO:__main__:Epoch 16954: total training loss 0.00078\n",
            "2025-06-26 08:46:02,868 Epoch 16954: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 16955\n",
            "2025-06-26 08:46:02,870 EPOCH 16955\n",
            "INFO:__main__:Epoch 16955: total training loss 0.00078\n",
            "2025-06-26 08:46:02,942 Epoch 16955: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 16956\n",
            "2025-06-26 08:46:02,944 EPOCH 16956\n",
            "INFO:__main__:Epoch 16956: total training loss 0.00083\n",
            "2025-06-26 08:46:03,014 Epoch 16956: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16957\n",
            "2025-06-26 08:46:03,016 EPOCH 16957\n",
            "INFO:__main__:Epoch 16957: total training loss 0.00082\n",
            "2025-06-26 08:46:03,088 Epoch 16957: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16958\n",
            "2025-06-26 08:46:03,090 EPOCH 16958\n",
            "INFO:__main__:Epoch 16958: total training loss 0.00079\n",
            "2025-06-26 08:46:03,160 Epoch 16958: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 16959\n",
            "2025-06-26 08:46:03,162 EPOCH 16959\n",
            "INFO:__main__:Epoch 16959: total training loss 0.00083\n",
            "2025-06-26 08:46:03,236 Epoch 16959: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16960\n",
            "2025-06-26 08:46:03,238 EPOCH 16960\n",
            "INFO:__main__:Epoch 16960: total training loss 0.00089\n",
            "2025-06-26 08:46:03,307 Epoch 16960: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16961\n",
            "2025-06-26 08:46:03,309 EPOCH 16961\n",
            "INFO:__main__:Epoch 16961: total training loss 0.00092\n",
            "2025-06-26 08:46:03,378 Epoch 16961: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16962\n",
            "2025-06-26 08:46:03,380 EPOCH 16962\n",
            "INFO:__main__:Epoch 16962: total training loss 0.00099\n",
            "2025-06-26 08:46:03,468 Epoch 16962: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 16963\n",
            "2025-06-26 08:46:03,470 EPOCH 16963\n",
            "INFO:__main__:Epoch 16963: total training loss 0.00100\n",
            "2025-06-26 08:46:03,544 Epoch 16963: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 16964\n",
            "2025-06-26 08:46:03,547 EPOCH 16964\n",
            "INFO:__main__:Epoch 16964: total training loss 0.00094\n",
            "2025-06-26 08:46:03,618 Epoch 16964: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 16965\n",
            "2025-06-26 08:46:03,628 EPOCH 16965\n",
            "INFO:__main__:Epoch 16965: total training loss 0.00087\n",
            "2025-06-26 08:46:03,700 Epoch 16965: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16966\n",
            "2025-06-26 08:46:03,703 EPOCH 16966\n",
            "INFO:__main__:Epoch 16966: total training loss 0.00088\n",
            "2025-06-26 08:46:03,776 Epoch 16966: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16967\n",
            "2025-06-26 08:46:03,780 EPOCH 16967\n",
            "INFO:__main__:Epoch 16967: total training loss 0.00085\n",
            "2025-06-26 08:46:03,850 Epoch 16967: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16968\n",
            "2025-06-26 08:46:03,852 EPOCH 16968\n",
            "INFO:__main__:Epoch 16968: total training loss 0.00093\n",
            "2025-06-26 08:46:03,932 Epoch 16968: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16969\n",
            "2025-06-26 08:46:03,934 EPOCH 16969\n",
            "INFO:__main__:Epoch 16969: total training loss 0.00093\n",
            "2025-06-26 08:46:04,007 Epoch 16969: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 16970\n",
            "2025-06-26 08:46:04,011 EPOCH 16970\n",
            "INFO:__main__:Epoch 16970: total training loss 0.00089\n",
            "2025-06-26 08:46:04,099 Epoch 16970: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16971\n",
            "2025-06-26 08:46:04,101 EPOCH 16971\n",
            "INFO:__main__:Epoch 16971: total training loss 0.00086\n",
            "2025-06-26 08:46:04,175 Epoch 16971: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16972\n",
            "2025-06-26 08:46:04,177 EPOCH 16972\n",
            "INFO:__main__:Epoch 16972: total training loss 0.00091\n",
            "2025-06-26 08:46:04,251 Epoch 16972: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16973\n",
            "2025-06-26 08:46:04,253 EPOCH 16973\n",
            "INFO:__main__:Epoch 16973: total training loss 0.00092\n",
            "2025-06-26 08:46:04,324 Epoch 16973: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16974\n",
            "2025-06-26 08:46:04,333 EPOCH 16974\n",
            "INFO:__main__:Epoch 16974: total training loss 0.00096\n",
            "2025-06-26 08:46:04,404 Epoch 16974: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16975\n",
            "2025-06-26 08:46:04,406 EPOCH 16975\n",
            "INFO:__main__:Epoch 16975: total training loss 0.00092\n",
            "2025-06-26 08:46:04,483 Epoch 16975: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 16976\n",
            "2025-06-26 08:46:04,490 EPOCH 16976\n",
            "INFO:__main__:Epoch 16976: total training loss 0.00096\n",
            "2025-06-26 08:46:04,573 Epoch 16976: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 16977\n",
            "2025-06-26 08:46:04,575 EPOCH 16977\n",
            "INFO:__main__:Epoch 16977: total training loss 0.00094\n",
            "2025-06-26 08:46:04,645 Epoch 16977: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 16978\n",
            "2025-06-26 08:46:04,648 EPOCH 16978\n",
            "INFO:__main__:Epoch 16978: total training loss 0.00091\n",
            "2025-06-26 08:46:04,719 Epoch 16978: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16979\n",
            "2025-06-26 08:46:04,721 EPOCH 16979\n",
            "INFO:__main__:Epoch 16979: total training loss 0.00095\n",
            "2025-06-26 08:46:04,794 Epoch 16979: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 16980\n",
            "2025-06-26 08:46:04,796 EPOCH 16980\n",
            "INFO:__main__:Epoch 16980: total training loss 0.00095\n",
            "2025-06-26 08:46:04,867 Epoch 16980: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 16981\n",
            "2025-06-26 08:46:04,869 EPOCH 16981\n",
            "INFO:__main__:Epoch 16981: total training loss 0.00087\n",
            "2025-06-26 08:46:04,942 Epoch 16981: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 16982\n",
            "2025-06-26 08:46:04,944 EPOCH 16982\n",
            "INFO:__main__:Epoch 16982: total training loss 0.00090\n",
            "2025-06-26 08:46:05,014 Epoch 16982: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 16983\n",
            "2025-06-26 08:46:05,022 EPOCH 16983\n",
            "INFO:__main__:Epoch 16983: total training loss 0.00089\n",
            "2025-06-26 08:46:05,100 Epoch 16983: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16984\n",
            "2025-06-26 08:46:05,104 EPOCH 16984\n",
            "INFO:__main__:Epoch 16984: total training loss 0.00089\n",
            "2025-06-26 08:46:05,181 Epoch 16984: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16985\n",
            "2025-06-26 08:46:05,183 EPOCH 16985\n",
            "INFO:__main__:Epoch 16985: total training loss 0.00086\n",
            "2025-06-26 08:46:05,261 Epoch 16985: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16986\n",
            "2025-06-26 08:46:05,264 EPOCH 16986\n",
            "INFO:__main__:Epoch 16986: total training loss 0.00088\n",
            "2025-06-26 08:46:05,336 Epoch 16986: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16987\n",
            "2025-06-26 08:46:05,339 EPOCH 16987\n",
            "INFO:__main__:Epoch 16987: total training loss 0.00085\n",
            "2025-06-26 08:46:05,410 Epoch 16987: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 16988\n",
            "2025-06-26 08:46:05,412 EPOCH 16988\n",
            "INFO:__main__:Epoch 16988: total training loss 0.00083\n",
            "2025-06-26 08:46:05,493 Epoch 16988: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16989\n",
            "2025-06-26 08:46:05,495 EPOCH 16989\n",
            "INFO:__main__:Epoch 16989: total training loss 0.00086\n",
            "2025-06-26 08:46:05,595 Epoch 16989: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16990\n",
            "2025-06-26 08:46:05,597 EPOCH 16990\n",
            "INFO:__main__:Epoch 16990: total training loss 0.00081\n",
            "2025-06-26 08:46:05,678 Epoch 16990: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 16991\n",
            "2025-06-26 08:46:05,681 EPOCH 16991\n",
            "INFO:__main__:Epoch 16991: total training loss 0.00082\n",
            "2025-06-26 08:46:05,754 Epoch 16991: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 16992\n",
            "2025-06-26 08:46:05,757 EPOCH 16992\n",
            "INFO:__main__:Epoch 16992: total training loss 0.00084\n",
            "2025-06-26 08:46:05,831 Epoch 16992: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 16993\n",
            "2025-06-26 08:46:05,834 EPOCH 16993\n",
            "INFO:__main__:Epoch 16993: total training loss 0.00086\n",
            "2025-06-26 08:46:05,912 Epoch 16993: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16994\n",
            "2025-06-26 08:46:05,914 EPOCH 16994\n",
            "INFO:__main__:Epoch 16994: total training loss 0.00086\n",
            "2025-06-26 08:46:05,993 Epoch 16994: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 16995\n",
            "2025-06-26 08:46:05,995 EPOCH 16995\n",
            "INFO:__main__:Epoch 16995: total training loss 0.00083\n",
            "2025-06-26 08:46:06,066 Epoch 16995: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 16996\n",
            "2025-06-26 08:46:06,069 EPOCH 16996\n",
            "INFO:__main__:Epoch 16996: total training loss 0.00091\n",
            "2025-06-26 08:46:06,145 Epoch 16996: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 16997\n",
            "2025-06-26 08:46:06,148 EPOCH 16997\n",
            "INFO:__main__:Epoch 16997: total training loss 0.00089\n",
            "2025-06-26 08:46:06,225 Epoch 16997: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 16998\n",
            "2025-06-26 08:46:06,227 EPOCH 16998\n",
            "INFO:__main__:Epoch 16998: total training loss 0.00088\n",
            "2025-06-26 08:46:06,309 Epoch 16998: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 16999\n",
            "2025-06-26 08:46:06,311 EPOCH 16999\n",
            "INFO:__main__:Epoch 16999: total training loss 0.00081\n",
            "2025-06-26 08:46:06,383 Epoch 16999: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17000\n",
            "2025-06-26 08:46:06,386 EPOCH 17000\n",
            "INFO:__main__:Epoch 17000 Step:    17000 Batch Loss:     0.000840 Tokens per Sec:  2058047, Lr: 0.001000\n",
            "2025-06-26 08:46:06,456 Epoch 17000 Step:    17000 Batch Loss:     0.000840 Tokens per Sec:  2058047, Lr: 0.001000\n",
            "INFO:__main__:Epoch 17000: total training loss 0.00084\n",
            "2025-06-26 08:46:06,458 Epoch 17000: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17001\n",
            "2025-06-26 08:46:06,459 EPOCH 17001\n",
            "INFO:__main__:Epoch 17001: total training loss 0.00091\n",
            "2025-06-26 08:46:06,531 Epoch 17001: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17002\n",
            "2025-06-26 08:46:06,534 EPOCH 17002\n",
            "INFO:__main__:Epoch 17002: total training loss 0.00097\n",
            "2025-06-26 08:46:06,613 Epoch 17002: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17003\n",
            "2025-06-26 08:46:06,615 EPOCH 17003\n",
            "INFO:__main__:Epoch 17003: total training loss 0.00093\n",
            "2025-06-26 08:46:06,702 Epoch 17003: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17004\n",
            "2025-06-26 08:46:06,704 EPOCH 17004\n",
            "INFO:__main__:Epoch 17004: total training loss 0.00090\n",
            "2025-06-26 08:46:06,775 Epoch 17004: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17005\n",
            "2025-06-26 08:46:06,777 EPOCH 17005\n",
            "INFO:__main__:Epoch 17005: total training loss 0.00090\n",
            "2025-06-26 08:46:06,857 Epoch 17005: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17006\n",
            "2025-06-26 08:46:06,859 EPOCH 17006\n",
            "INFO:__main__:Epoch 17006: total training loss 0.00091\n",
            "2025-06-26 08:46:06,931 Epoch 17006: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17007\n",
            "2025-06-26 08:46:06,933 EPOCH 17007\n",
            "INFO:__main__:Epoch 17007: total training loss 0.00095\n",
            "2025-06-26 08:46:07,011 Epoch 17007: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17008\n",
            "2025-06-26 08:46:07,013 EPOCH 17008\n",
            "INFO:__main__:Epoch 17008: total training loss 0.00086\n",
            "2025-06-26 08:46:07,086 Epoch 17008: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17009\n",
            "2025-06-26 08:46:07,088 EPOCH 17009\n",
            "INFO:__main__:Epoch 17009: total training loss 0.00088\n",
            "2025-06-26 08:46:07,174 Epoch 17009: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17010\n",
            "2025-06-26 08:46:07,176 EPOCH 17010\n",
            "INFO:__main__:Epoch 17010: total training loss 0.00084\n",
            "2025-06-26 08:46:07,255 Epoch 17010: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17011\n",
            "2025-06-26 08:46:07,257 EPOCH 17011\n",
            "INFO:__main__:Epoch 17011: total training loss 0.00084\n",
            "2025-06-26 08:46:07,331 Epoch 17011: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17012\n",
            "2025-06-26 08:46:07,333 EPOCH 17012\n",
            "INFO:__main__:Epoch 17012: total training loss 0.00087\n",
            "2025-06-26 08:46:07,406 Epoch 17012: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17013\n",
            "2025-06-26 08:46:07,408 EPOCH 17013\n",
            "INFO:__main__:Epoch 17013: total training loss 0.00088\n",
            "2025-06-26 08:46:07,480 Epoch 17013: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17014\n",
            "2025-06-26 08:46:07,482 EPOCH 17014\n",
            "INFO:__main__:Epoch 17014: total training loss 0.00086\n",
            "2025-06-26 08:46:07,554 Epoch 17014: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17015\n",
            "2025-06-26 08:46:07,557 EPOCH 17015\n",
            "INFO:__main__:Epoch 17015: total training loss 0.00087\n",
            "2025-06-26 08:46:07,634 Epoch 17015: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17016\n",
            "2025-06-26 08:46:07,637 EPOCH 17016\n",
            "INFO:__main__:Epoch 17016: total training loss 0.00087\n",
            "2025-06-26 08:46:07,733 Epoch 17016: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17017\n",
            "2025-06-26 08:46:07,735 EPOCH 17017\n",
            "INFO:__main__:Epoch 17017: total training loss 0.00092\n",
            "2025-06-26 08:46:07,816 Epoch 17017: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17018\n",
            "2025-06-26 08:46:07,819 EPOCH 17018\n",
            "INFO:__main__:Epoch 17018: total training loss 0.00088\n",
            "2025-06-26 08:46:07,895 Epoch 17018: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17019\n",
            "2025-06-26 08:46:07,897 EPOCH 17019\n",
            "INFO:__main__:Epoch 17019: total training loss 0.00088\n",
            "2025-06-26 08:46:07,977 Epoch 17019: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17020\n",
            "2025-06-26 08:46:07,979 EPOCH 17020\n",
            "INFO:__main__:Epoch 17020: total training loss 0.00092\n",
            "2025-06-26 08:46:08,051 Epoch 17020: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17021\n",
            "2025-06-26 08:46:08,053 EPOCH 17021\n",
            "INFO:__main__:Epoch 17021: total training loss 0.00088\n",
            "2025-06-26 08:46:08,126 Epoch 17021: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17022\n",
            "2025-06-26 08:46:08,128 EPOCH 17022\n",
            "INFO:__main__:Epoch 17022: total training loss 0.00081\n",
            "2025-06-26 08:46:08,206 Epoch 17022: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17023\n",
            "2025-06-26 08:46:08,208 EPOCH 17023\n",
            "INFO:__main__:Epoch 17023: total training loss 0.00082\n",
            "2025-06-26 08:46:08,279 Epoch 17023: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17024\n",
            "2025-06-26 08:46:08,281 EPOCH 17024\n",
            "INFO:__main__:Epoch 17024: total training loss 0.00083\n",
            "2025-06-26 08:46:08,360 Epoch 17024: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17025\n",
            "2025-06-26 08:46:08,363 EPOCH 17025\n",
            "INFO:__main__:Epoch 17025: total training loss 0.00083\n",
            "2025-06-26 08:46:08,438 Epoch 17025: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17026\n",
            "2025-06-26 08:46:08,440 EPOCH 17026\n",
            "INFO:__main__:Epoch 17026: total training loss 0.00082\n",
            "2025-06-26 08:46:08,511 Epoch 17026: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17027\n",
            "2025-06-26 08:46:08,513 EPOCH 17027\n",
            "INFO:__main__:Epoch 17027: total training loss 0.00079\n",
            "2025-06-26 08:46:08,590 Epoch 17027: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17028\n",
            "2025-06-26 08:46:08,592 EPOCH 17028\n",
            "INFO:__main__:Epoch 17028: total training loss 0.00080\n",
            "2025-06-26 08:46:08,667 Epoch 17028: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17029\n",
            "2025-06-26 08:46:08,669 EPOCH 17029\n",
            "INFO:__main__:Epoch 17029: total training loss 0.00081\n",
            "2025-06-26 08:46:08,745 Epoch 17029: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17030\n",
            "2025-06-26 08:46:08,747 EPOCH 17030\n",
            "INFO:__main__:Epoch 17030: total training loss 0.00081\n",
            "2025-06-26 08:46:08,824 Epoch 17030: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17031\n",
            "2025-06-26 08:46:08,826 EPOCH 17031\n",
            "INFO:__main__:Epoch 17031: total training loss 0.00081\n",
            "2025-06-26 08:46:08,894 Epoch 17031: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17032\n",
            "2025-06-26 08:46:08,896 EPOCH 17032\n",
            "INFO:__main__:Epoch 17032: total training loss 0.00084\n",
            "2025-06-26 08:46:08,963 Epoch 17032: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17033\n",
            "2025-06-26 08:46:08,965 EPOCH 17033\n",
            "INFO:__main__:Epoch 17033: total training loss 0.00084\n",
            "2025-06-26 08:46:09,033 Epoch 17033: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17034\n",
            "2025-06-26 08:46:09,035 EPOCH 17034\n",
            "INFO:__main__:Epoch 17034: total training loss 0.00084\n",
            "2025-06-26 08:46:09,104 Epoch 17034: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17035\n",
            "2025-06-26 08:46:09,106 EPOCH 17035\n",
            "INFO:__main__:Epoch 17035: total training loss 0.00086\n",
            "2025-06-26 08:46:09,177 Epoch 17035: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17036\n",
            "2025-06-26 08:46:09,180 EPOCH 17036\n",
            "INFO:__main__:Epoch 17036: total training loss 0.00089\n",
            "2025-06-26 08:46:09,263 Epoch 17036: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17037\n",
            "2025-06-26 08:46:09,265 EPOCH 17037\n",
            "INFO:__main__:Epoch 17037: total training loss 0.00085\n",
            "2025-06-26 08:46:09,343 Epoch 17037: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17038\n",
            "2025-06-26 08:46:09,348 EPOCH 17038\n",
            "INFO:__main__:Epoch 17038: total training loss 0.00084\n",
            "2025-06-26 08:46:09,452 Epoch 17038: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17039\n",
            "2025-06-26 08:46:09,456 EPOCH 17039\n",
            "INFO:__main__:Epoch 17039: total training loss 0.00091\n",
            "2025-06-26 08:46:09,531 Epoch 17039: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17040\n",
            "2025-06-26 08:46:09,534 EPOCH 17040\n",
            "INFO:__main__:Epoch 17040: total training loss 0.00088\n",
            "2025-06-26 08:46:09,605 Epoch 17040: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17041\n",
            "2025-06-26 08:46:09,607 EPOCH 17041\n",
            "INFO:__main__:Epoch 17041: total training loss 0.00085\n",
            "2025-06-26 08:46:09,676 Epoch 17041: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17042\n",
            "2025-06-26 08:46:09,677 EPOCH 17042\n",
            "INFO:__main__:Epoch 17042: total training loss 0.00085\n",
            "2025-06-26 08:46:09,747 Epoch 17042: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17043\n",
            "2025-06-26 08:46:09,750 EPOCH 17043\n",
            "INFO:__main__:Epoch 17043: total training loss 0.00086\n",
            "2025-06-26 08:46:09,832 Epoch 17043: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17044\n",
            "2025-06-26 08:46:09,834 EPOCH 17044\n",
            "INFO:__main__:Epoch 17044: total training loss 0.00089\n",
            "2025-06-26 08:46:09,909 Epoch 17044: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17045\n",
            "2025-06-26 08:46:09,912 EPOCH 17045\n",
            "INFO:__main__:Epoch 17045: total training loss 0.00082\n",
            "2025-06-26 08:46:09,984 Epoch 17045: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17046\n",
            "2025-06-26 08:46:09,987 EPOCH 17046\n",
            "INFO:__main__:Epoch 17046: total training loss 0.00081\n",
            "2025-06-26 08:46:10,059 Epoch 17046: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17047\n",
            "2025-06-26 08:46:10,063 EPOCH 17047\n",
            "INFO:__main__:Epoch 17047: total training loss 0.00084\n",
            "2025-06-26 08:46:10,140 Epoch 17047: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17048\n",
            "2025-06-26 08:46:10,144 EPOCH 17048\n",
            "INFO:__main__:Epoch 17048: total training loss 0.00084\n",
            "2025-06-26 08:46:10,227 Epoch 17048: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17049\n",
            "2025-06-26 08:46:10,229 EPOCH 17049\n",
            "INFO:__main__:Epoch 17049: total training loss 0.00088\n",
            "2025-06-26 08:46:10,305 Epoch 17049: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17050\n",
            "2025-06-26 08:46:10,308 EPOCH 17050\n",
            "INFO:__main__:Epoch 17050: total training loss 0.00093\n",
            "2025-06-26 08:46:10,380 Epoch 17050: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17051\n",
            "2025-06-26 08:46:10,383 EPOCH 17051\n",
            "INFO:__main__:Epoch 17051: total training loss 0.00089\n",
            "2025-06-26 08:46:10,456 Epoch 17051: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17052\n",
            "2025-06-26 08:46:10,458 EPOCH 17052\n",
            "INFO:__main__:Epoch 17052: total training loss 0.00096\n",
            "2025-06-26 08:46:10,531 Epoch 17052: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17053\n",
            "2025-06-26 08:46:10,535 EPOCH 17053\n",
            "INFO:__main__:Epoch 17053: total training loss 0.00103\n",
            "2025-06-26 08:46:10,608 Epoch 17053: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17054\n",
            "2025-06-26 08:46:10,615 EPOCH 17054\n",
            "INFO:__main__:Epoch 17054: total training loss 0.00111\n",
            "2025-06-26 08:46:10,689 Epoch 17054: total training loss 0.00111\n",
            "INFO:__main__:EPOCH 17055\n",
            "2025-06-26 08:46:10,695 EPOCH 17055\n",
            "INFO:__main__:Epoch 17055: total training loss 0.00100\n",
            "2025-06-26 08:46:10,769 Epoch 17055: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17056\n",
            "2025-06-26 08:46:10,771 EPOCH 17056\n",
            "INFO:__main__:Epoch 17056: total training loss 0.00100\n",
            "2025-06-26 08:46:10,852 Epoch 17056: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17057\n",
            "2025-06-26 08:46:10,855 EPOCH 17057\n",
            "INFO:__main__:Epoch 17057: total training loss 0.00095\n",
            "2025-06-26 08:46:10,950 Epoch 17057: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17058\n",
            "2025-06-26 08:46:10,954 EPOCH 17058\n",
            "INFO:__main__:Epoch 17058: total training loss 0.00099\n",
            "2025-06-26 08:46:11,030 Epoch 17058: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17059\n",
            "2025-06-26 08:46:11,033 EPOCH 17059\n",
            "INFO:__main__:Epoch 17059: total training loss 0.00089\n",
            "2025-06-26 08:46:11,109 Epoch 17059: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17060\n",
            "2025-06-26 08:46:11,111 EPOCH 17060\n",
            "INFO:__main__:Epoch 17060: total training loss 0.00098\n",
            "2025-06-26 08:46:11,180 Epoch 17060: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17061\n",
            "2025-06-26 08:46:11,183 EPOCH 17061\n",
            "INFO:__main__:Epoch 17061: total training loss 0.00097\n",
            "2025-06-26 08:46:11,274 Epoch 17061: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17062\n",
            "2025-06-26 08:46:11,276 EPOCH 17062\n",
            "INFO:__main__:Epoch 17062: total training loss 0.00090\n",
            "2025-06-26 08:46:11,362 Epoch 17062: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17063\n",
            "2025-06-26 08:46:11,365 EPOCH 17063\n",
            "INFO:__main__:Epoch 17063: total training loss 0.00087\n",
            "2025-06-26 08:46:11,472 Epoch 17063: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17064\n",
            "2025-06-26 08:46:11,474 EPOCH 17064\n",
            "INFO:__main__:Epoch 17064: total training loss 0.00093\n",
            "2025-06-26 08:46:11,562 Epoch 17064: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17065\n",
            "2025-06-26 08:46:11,566 EPOCH 17065\n",
            "INFO:__main__:Epoch 17065: total training loss 0.00087\n",
            "2025-06-26 08:46:11,654 Epoch 17065: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17066\n",
            "2025-06-26 08:46:11,656 EPOCH 17066\n",
            "INFO:__main__:Epoch 17066: total training loss 0.00089\n",
            "2025-06-26 08:46:11,748 Epoch 17066: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17067\n",
            "2025-06-26 08:46:11,750 EPOCH 17067\n",
            "INFO:__main__:Epoch 17067: total training loss 0.00090\n",
            "2025-06-26 08:46:11,833 Epoch 17067: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17068\n",
            "2025-06-26 08:46:11,835 EPOCH 17068\n",
            "INFO:__main__:Epoch 17068: total training loss 0.00092\n",
            "2025-06-26 08:46:11,933 Epoch 17068: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17069\n",
            "2025-06-26 08:46:11,935 EPOCH 17069\n",
            "INFO:__main__:Epoch 17069: total training loss 0.00087\n",
            "2025-06-26 08:46:12,032 Epoch 17069: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17070\n",
            "2025-06-26 08:46:12,036 EPOCH 17070\n",
            "INFO:__main__:Epoch 17070: total training loss 0.00092\n",
            "2025-06-26 08:46:12,108 Epoch 17070: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17071\n",
            "2025-06-26 08:46:12,110 EPOCH 17071\n",
            "INFO:__main__:Epoch 17071: total training loss 0.00085\n",
            "2025-06-26 08:46:12,183 Epoch 17071: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17072\n",
            "2025-06-26 08:46:12,185 EPOCH 17072\n",
            "INFO:__main__:Epoch 17072: total training loss 0.00086\n",
            "2025-06-26 08:46:12,262 Epoch 17072: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17073\n",
            "2025-06-26 08:46:12,264 EPOCH 17073\n",
            "INFO:__main__:Epoch 17073: total training loss 0.00092\n",
            "2025-06-26 08:46:12,335 Epoch 17073: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17074\n",
            "2025-06-26 08:46:12,337 EPOCH 17074\n",
            "INFO:__main__:Epoch 17074: total training loss 0.00087\n",
            "2025-06-26 08:46:12,418 Epoch 17074: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17075\n",
            "2025-06-26 08:46:12,420 EPOCH 17075\n",
            "INFO:__main__:Epoch 17075: total training loss 0.00085\n",
            "2025-06-26 08:46:12,499 Epoch 17075: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17076\n",
            "2025-06-26 08:46:12,501 EPOCH 17076\n",
            "INFO:__main__:Epoch 17076: total training loss 0.00084\n",
            "2025-06-26 08:46:12,573 Epoch 17076: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17077\n",
            "2025-06-26 08:46:12,576 EPOCH 17077\n",
            "INFO:__main__:Epoch 17077: total training loss 0.00084\n",
            "2025-06-26 08:46:12,667 Epoch 17077: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17078\n",
            "2025-06-26 08:46:12,671 EPOCH 17078\n",
            "INFO:__main__:Epoch 17078: total training loss 0.00085\n",
            "2025-06-26 08:46:12,772 Epoch 17078: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17079\n",
            "2025-06-26 08:46:12,774 EPOCH 17079\n",
            "INFO:__main__:Epoch 17079: total training loss 0.00086\n",
            "2025-06-26 08:46:12,888 Epoch 17079: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17080\n",
            "2025-06-26 08:46:12,892 EPOCH 17080\n",
            "INFO:__main__:Epoch 17080: total training loss 0.00085\n",
            "2025-06-26 08:46:13,002 Epoch 17080: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17081\n",
            "2025-06-26 08:46:13,007 EPOCH 17081\n",
            "INFO:__main__:Epoch 17081: total training loss 0.00088\n",
            "2025-06-26 08:46:13,100 Epoch 17081: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17082\n",
            "2025-06-26 08:46:13,102 EPOCH 17082\n",
            "INFO:__main__:Epoch 17082: total training loss 0.00093\n",
            "2025-06-26 08:46:13,190 Epoch 17082: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17083\n",
            "2025-06-26 08:46:13,195 EPOCH 17083\n",
            "INFO:__main__:Epoch 17083: total training loss 0.00089\n",
            "2025-06-26 08:46:13,270 Epoch 17083: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17084\n",
            "2025-06-26 08:46:13,274 EPOCH 17084\n",
            "INFO:__main__:Epoch 17084: total training loss 0.00089\n",
            "2025-06-26 08:46:13,364 Epoch 17084: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17085\n",
            "2025-06-26 08:46:13,371 EPOCH 17085\n",
            "INFO:__main__:Epoch 17085: total training loss 0.00094\n",
            "2025-06-26 08:46:13,465 Epoch 17085: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17086\n",
            "2025-06-26 08:46:13,471 EPOCH 17086\n",
            "INFO:__main__:Epoch 17086: total training loss 0.00096\n",
            "2025-06-26 08:46:13,550 Epoch 17086: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17087\n",
            "2025-06-26 08:46:13,555 EPOCH 17087\n",
            "INFO:__main__:Epoch 17087: total training loss 0.00092\n",
            "2025-06-26 08:46:13,646 Epoch 17087: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17088\n",
            "2025-06-26 08:46:13,654 EPOCH 17088\n",
            "INFO:__main__:Epoch 17088: total training loss 0.00088\n",
            "2025-06-26 08:46:13,745 Epoch 17088: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17089\n",
            "2025-06-26 08:46:13,751 EPOCH 17089\n",
            "INFO:__main__:Epoch 17089: total training loss 0.00087\n",
            "2025-06-26 08:46:13,822 Epoch 17089: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17090\n",
            "2025-06-26 08:46:13,828 EPOCH 17090\n",
            "INFO:__main__:Epoch 17090: total training loss 0.00088\n",
            "2025-06-26 08:46:13,934 Epoch 17090: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17091\n",
            "2025-06-26 08:46:13,936 EPOCH 17091\n",
            "INFO:__main__:Epoch 17091: total training loss 0.00092\n",
            "2025-06-26 08:46:14,043 Epoch 17091: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17092\n",
            "2025-06-26 08:46:14,044 EPOCH 17092\n",
            "INFO:__main__:Epoch 17092: total training loss 0.00087\n",
            "2025-06-26 08:46:14,145 Epoch 17092: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17093\n",
            "2025-06-26 08:46:14,150 EPOCH 17093\n",
            "INFO:__main__:Epoch 17093: total training loss 0.00090\n",
            "2025-06-26 08:46:14,245 Epoch 17093: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17094\n",
            "2025-06-26 08:46:14,249 EPOCH 17094\n",
            "INFO:__main__:Epoch 17094: total training loss 0.00080\n",
            "2025-06-26 08:46:14,366 Epoch 17094: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17095\n",
            "2025-06-26 08:46:14,368 EPOCH 17095\n",
            "INFO:__main__:Epoch 17095: total training loss 0.00089\n",
            "2025-06-26 08:46:14,469 Epoch 17095: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17096\n",
            "2025-06-26 08:46:14,471 EPOCH 17096\n",
            "INFO:__main__:Epoch 17096: total training loss 0.00085\n",
            "2025-06-26 08:46:14,547 Epoch 17096: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17097\n",
            "2025-06-26 08:46:14,553 EPOCH 17097\n",
            "INFO:__main__:Epoch 17097: total training loss 0.00087\n",
            "2025-06-26 08:46:14,630 Epoch 17097: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17098\n",
            "2025-06-26 08:46:14,638 EPOCH 17098\n",
            "INFO:__main__:Epoch 17098: total training loss 0.00090\n",
            "2025-06-26 08:46:14,738 Epoch 17098: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17099\n",
            "2025-06-26 08:46:14,739 EPOCH 17099\n",
            "INFO:__main__:Epoch 17099: total training loss 0.00089\n",
            "2025-06-26 08:46:14,850 Epoch 17099: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17100\n",
            "2025-06-26 08:46:14,853 EPOCH 17100\n",
            "INFO:__main__:Epoch 17100: total training loss 0.00080\n",
            "2025-06-26 08:46:14,957 Epoch 17100: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17101\n",
            "2025-06-26 08:46:14,962 EPOCH 17101\n",
            "INFO:__main__:Epoch 17101: total training loss 0.00086\n",
            "2025-06-26 08:46:15,064 Epoch 17101: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17102\n",
            "2025-06-26 08:46:15,065 EPOCH 17102\n",
            "INFO:__main__:Epoch 17102: total training loss 0.00085\n",
            "2025-06-26 08:46:15,172 Epoch 17102: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17103\n",
            "2025-06-26 08:46:15,174 EPOCH 17103\n",
            "INFO:__main__:Epoch 17103: total training loss 0.00085\n",
            "2025-06-26 08:46:15,247 Epoch 17103: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17104\n",
            "2025-06-26 08:46:15,249 EPOCH 17104\n",
            "INFO:__main__:Epoch 17104: total training loss 0.00088\n",
            "2025-06-26 08:46:15,341 Epoch 17104: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17105\n",
            "2025-06-26 08:46:15,345 EPOCH 17105\n",
            "INFO:__main__:Epoch 17105: total training loss 0.00086\n",
            "2025-06-26 08:46:15,433 Epoch 17105: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17106\n",
            "2025-06-26 08:46:15,439 EPOCH 17106\n",
            "INFO:__main__:Epoch 17106: total training loss 0.00084\n",
            "2025-06-26 08:46:15,529 Epoch 17106: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17107\n",
            "2025-06-26 08:46:15,536 EPOCH 17107\n",
            "INFO:__main__:Epoch 17107: total training loss 0.00084\n",
            "2025-06-26 08:46:15,635 Epoch 17107: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17108\n",
            "2025-06-26 08:46:15,640 EPOCH 17108\n",
            "INFO:__main__:Epoch 17108: total training loss 0.00086\n",
            "2025-06-26 08:46:15,735 Epoch 17108: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17109\n",
            "2025-06-26 08:46:15,742 EPOCH 17109\n",
            "INFO:__main__:Epoch 17109: total training loss 0.00085\n",
            "2025-06-26 08:46:15,825 Epoch 17109: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17110\n",
            "2025-06-26 08:46:15,830 EPOCH 17110\n",
            "INFO:__main__:Epoch 17110: total training loss 0.00085\n",
            "2025-06-26 08:46:15,936 Epoch 17110: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17111\n",
            "2025-06-26 08:46:15,941 EPOCH 17111\n",
            "INFO:__main__:Epoch 17111: total training loss 0.00092\n",
            "2025-06-26 08:46:16,051 Epoch 17111: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17112\n",
            "2025-06-26 08:46:16,057 EPOCH 17112\n",
            "INFO:__main__:Epoch 17112: total training loss 0.00092\n",
            "2025-06-26 08:46:16,147 Epoch 17112: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17113\n",
            "2025-06-26 08:46:16,153 EPOCH 17113\n",
            "INFO:__main__:Epoch 17113: total training loss 0.00094\n",
            "2025-06-26 08:46:16,250 Epoch 17113: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17114\n",
            "2025-06-26 08:46:16,256 EPOCH 17114\n",
            "INFO:__main__:Epoch 17114: total training loss 0.00097\n",
            "2025-06-26 08:46:16,350 Epoch 17114: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17115\n",
            "2025-06-26 08:46:16,353 EPOCH 17115\n",
            "INFO:__main__:Epoch 17115: total training loss 0.00092\n",
            "2025-06-26 08:46:16,446 Epoch 17115: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17116\n",
            "2025-06-26 08:46:16,450 EPOCH 17116\n",
            "INFO:__main__:Epoch 17116: total training loss 0.00097\n",
            "2025-06-26 08:46:16,555 Epoch 17116: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17117\n",
            "2025-06-26 08:46:16,559 EPOCH 17117\n",
            "INFO:__main__:Epoch 17117: total training loss 0.00093\n",
            "2025-06-26 08:46:16,649 Epoch 17117: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17118\n",
            "2025-06-26 08:46:16,654 EPOCH 17118\n",
            "INFO:__main__:Epoch 17118: total training loss 0.00091\n",
            "2025-06-26 08:46:16,743 Epoch 17118: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17119\n",
            "2025-06-26 08:46:16,749 EPOCH 17119\n",
            "INFO:__main__:Epoch 17119: total training loss 0.00086\n",
            "2025-06-26 08:46:16,829 Epoch 17119: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17120\n",
            "2025-06-26 08:46:16,832 EPOCH 17120\n",
            "INFO:__main__:Epoch 17120: total training loss 0.00085\n",
            "2025-06-26 08:46:16,903 Epoch 17120: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17121\n",
            "2025-06-26 08:46:16,911 EPOCH 17121\n",
            "INFO:__main__:Epoch 17121: total training loss 0.00089\n",
            "2025-06-26 08:46:16,986 Epoch 17121: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17122\n",
            "2025-06-26 08:46:16,988 EPOCH 17122\n",
            "INFO:__main__:Epoch 17122: total training loss 0.00087\n",
            "2025-06-26 08:46:17,064 Epoch 17122: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17123\n",
            "2025-06-26 08:46:17,066 EPOCH 17123\n",
            "INFO:__main__:Epoch 17123: total training loss 0.00083\n",
            "2025-06-26 08:46:17,139 Epoch 17123: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17124\n",
            "2025-06-26 08:46:17,141 EPOCH 17124\n",
            "INFO:__main__:Epoch 17124: total training loss 0.00086\n",
            "2025-06-26 08:46:17,223 Epoch 17124: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17125\n",
            "2025-06-26 08:46:17,225 EPOCH 17125\n",
            "INFO:__main__:Epoch 17125: total training loss 0.00085\n",
            "2025-06-26 08:46:17,300 Epoch 17125: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17126\n",
            "2025-06-26 08:46:17,302 EPOCH 17126\n",
            "INFO:__main__:Epoch 17126: total training loss 0.00079\n",
            "2025-06-26 08:46:17,377 Epoch 17126: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17127\n",
            "2025-06-26 08:46:17,380 EPOCH 17127\n",
            "INFO:__main__:Epoch 17127: total training loss 0.00081\n",
            "2025-06-26 08:46:17,451 Epoch 17127: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17128\n",
            "2025-06-26 08:46:17,454 EPOCH 17128\n",
            "INFO:__main__:Epoch 17128: total training loss 0.00082\n",
            "2025-06-26 08:46:17,537 Epoch 17128: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17129\n",
            "2025-06-26 08:46:17,541 EPOCH 17129\n",
            "INFO:__main__:Epoch 17129: total training loss 0.00082\n",
            "2025-06-26 08:46:17,614 Epoch 17129: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17130\n",
            "2025-06-26 08:46:17,617 EPOCH 17130\n",
            "INFO:__main__:Epoch 17130: total training loss 0.00081\n",
            "2025-06-26 08:46:17,691 Epoch 17130: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17131\n",
            "2025-06-26 08:46:17,695 EPOCH 17131\n",
            "INFO:__main__:Epoch 17131: total training loss 0.00086\n",
            "2025-06-26 08:46:17,770 Epoch 17131: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17132\n",
            "2025-06-26 08:46:17,772 EPOCH 17132\n",
            "INFO:__main__:Epoch 17132: total training loss 0.00087\n",
            "2025-06-26 08:46:17,856 Epoch 17132: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17133\n",
            "2025-06-26 08:46:17,858 EPOCH 17133\n",
            "INFO:__main__:Epoch 17133: total training loss 0.00085\n",
            "2025-06-26 08:46:17,930 Epoch 17133: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17134\n",
            "2025-06-26 08:46:17,932 EPOCH 17134\n",
            "INFO:__main__:Epoch 17134: total training loss 0.00084\n",
            "2025-06-26 08:46:18,011 Epoch 17134: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17135\n",
            "2025-06-26 08:46:18,014 EPOCH 17135\n",
            "INFO:__main__:Epoch 17135: total training loss 0.00087\n",
            "2025-06-26 08:46:18,092 Epoch 17135: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17136\n",
            "2025-06-26 08:46:18,094 EPOCH 17136\n",
            "INFO:__main__:Epoch 17136: total training loss 0.00090\n",
            "2025-06-26 08:46:18,170 Epoch 17136: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17137\n",
            "2025-06-26 08:46:18,173 EPOCH 17137\n",
            "INFO:__main__:Epoch 17137: total training loss 0.00082\n",
            "2025-06-26 08:46:18,253 Epoch 17137: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17138\n",
            "2025-06-26 08:46:18,257 EPOCH 17138\n",
            "INFO:__main__:Epoch 17138: total training loss 0.00081\n",
            "2025-06-26 08:46:18,333 Epoch 17138: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17139\n",
            "2025-06-26 08:46:18,335 EPOCH 17139\n",
            "INFO:__main__:Epoch 17139: total training loss 0.00085\n",
            "2025-06-26 08:46:18,414 Epoch 17139: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17140\n",
            "2025-06-26 08:46:18,418 EPOCH 17140\n",
            "INFO:__main__:Epoch 17140: total training loss 0.00090\n",
            "2025-06-26 08:46:18,489 Epoch 17140: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17141\n",
            "2025-06-26 08:46:18,491 EPOCH 17141\n",
            "INFO:__main__:Epoch 17141: total training loss 0.00085\n",
            "2025-06-26 08:46:18,594 Epoch 17141: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17142\n",
            "2025-06-26 08:46:18,597 EPOCH 17142\n",
            "INFO:__main__:Epoch 17142: total training loss 0.00088\n",
            "2025-06-26 08:46:18,674 Epoch 17142: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17143\n",
            "2025-06-26 08:46:18,676 EPOCH 17143\n",
            "INFO:__main__:Epoch 17143: total training loss 0.00085\n",
            "2025-06-26 08:46:18,751 Epoch 17143: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17144\n",
            "2025-06-26 08:46:18,756 EPOCH 17144\n",
            "INFO:__main__:Epoch 17144: total training loss 0.00086\n",
            "2025-06-26 08:46:18,829 Epoch 17144: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17145\n",
            "2025-06-26 08:46:18,831 EPOCH 17145\n",
            "INFO:__main__:Epoch 17145: total training loss 0.00087\n",
            "2025-06-26 08:46:18,910 Epoch 17145: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17146\n",
            "2025-06-26 08:46:18,912 EPOCH 17146\n",
            "INFO:__main__:Epoch 17146: total training loss 0.00083\n",
            "2025-06-26 08:46:18,989 Epoch 17146: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17147\n",
            "2025-06-26 08:46:18,991 EPOCH 17147\n",
            "INFO:__main__:Epoch 17147: total training loss 0.00086\n",
            "2025-06-26 08:46:19,070 Epoch 17147: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17148\n",
            "2025-06-26 08:46:19,074 EPOCH 17148\n",
            "INFO:__main__:Epoch 17148: total training loss 0.00082\n",
            "2025-06-26 08:46:19,148 Epoch 17148: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17149\n",
            "2025-06-26 08:46:19,151 EPOCH 17149\n",
            "INFO:__main__:Epoch 17149: total training loss 0.00083\n",
            "2025-06-26 08:46:19,227 Epoch 17149: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17150\n",
            "2025-06-26 08:46:19,229 EPOCH 17150\n",
            "INFO:__main__:Epoch 17150: total training loss 0.00084\n",
            "2025-06-26 08:46:19,312 Epoch 17150: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17151\n",
            "2025-06-26 08:46:19,314 EPOCH 17151\n",
            "INFO:__main__:Epoch 17151: total training loss 0.00086\n",
            "2025-06-26 08:46:19,402 Epoch 17151: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17152\n",
            "2025-06-26 08:46:19,403 EPOCH 17152\n",
            "INFO:__main__:Epoch 17152: total training loss 0.00086\n",
            "2025-06-26 08:46:19,473 Epoch 17152: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17153\n",
            "2025-06-26 08:46:19,475 EPOCH 17153\n",
            "INFO:__main__:Epoch 17153: total training loss 0.00087\n",
            "2025-06-26 08:46:19,555 Epoch 17153: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17154\n",
            "2025-06-26 08:46:19,558 EPOCH 17154\n",
            "INFO:__main__:Epoch 17154: total training loss 0.00091\n",
            "2025-06-26 08:46:19,653 Epoch 17154: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17155\n",
            "2025-06-26 08:46:19,656 EPOCH 17155\n",
            "INFO:__main__:Epoch 17155: total training loss 0.00088\n",
            "2025-06-26 08:46:19,728 Epoch 17155: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17156\n",
            "2025-06-26 08:46:19,731 EPOCH 17156\n",
            "INFO:__main__:Epoch 17156: total training loss 0.00093\n",
            "2025-06-26 08:46:19,811 Epoch 17156: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17157\n",
            "2025-06-26 08:46:19,813 EPOCH 17157\n",
            "INFO:__main__:Epoch 17157: total training loss 0.00104\n",
            "2025-06-26 08:46:19,886 Epoch 17157: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 17158\n",
            "2025-06-26 08:46:19,888 EPOCH 17158\n",
            "INFO:__main__:Epoch 17158: total training loss 0.00095\n",
            "2025-06-26 08:46:19,967 Epoch 17158: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17159\n",
            "2025-06-26 08:46:19,969 EPOCH 17159\n",
            "INFO:__main__:Epoch 17159: total training loss 0.00098\n",
            "2025-06-26 08:46:20,047 Epoch 17159: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17160\n",
            "2025-06-26 08:46:20,049 EPOCH 17160\n",
            "INFO:__main__:Epoch 17160: total training loss 0.00094\n",
            "2025-06-26 08:46:20,124 Epoch 17160: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17161\n",
            "2025-06-26 08:46:20,126 EPOCH 17161\n",
            "INFO:__main__:Epoch 17161: total training loss 0.00089\n",
            "2025-06-26 08:46:20,198 Epoch 17161: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17162\n",
            "2025-06-26 08:46:20,200 EPOCH 17162\n",
            "INFO:__main__:Epoch 17162: total training loss 0.00095\n",
            "2025-06-26 08:46:20,284 Epoch 17162: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17163\n",
            "2025-06-26 08:46:20,288 EPOCH 17163\n",
            "INFO:__main__:Epoch 17163: total training loss 0.00099\n",
            "2025-06-26 08:46:20,367 Epoch 17163: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17164\n",
            "2025-06-26 08:46:20,369 EPOCH 17164\n",
            "INFO:__main__:Epoch 17164: total training loss 0.00100\n",
            "2025-06-26 08:46:20,441 Epoch 17164: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17165\n",
            "2025-06-26 08:46:20,443 EPOCH 17165\n",
            "INFO:__main__:Epoch 17165: total training loss 0.00107\n",
            "2025-06-26 08:46:20,517 Epoch 17165: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 17166\n",
            "2025-06-26 08:46:20,519 EPOCH 17166\n",
            "INFO:__main__:Epoch 17166: total training loss 0.00099\n",
            "2025-06-26 08:46:20,589 Epoch 17166: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17167\n",
            "2025-06-26 08:46:20,591 EPOCH 17167\n",
            "INFO:__main__:Epoch 17167: total training loss 0.00093\n",
            "2025-06-26 08:46:20,668 Epoch 17167: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17168\n",
            "2025-06-26 08:46:20,671 EPOCH 17168\n",
            "INFO:__main__:Epoch 17168: total training loss 0.00097\n",
            "2025-06-26 08:46:20,745 Epoch 17168: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17169\n",
            "2025-06-26 08:46:20,747 EPOCH 17169\n",
            "INFO:__main__:Epoch 17169: total training loss 0.00095\n",
            "2025-06-26 08:46:20,821 Epoch 17169: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17170\n",
            "2025-06-26 08:46:20,823 EPOCH 17170\n",
            "INFO:__main__:Epoch 17170: total training loss 0.00100\n",
            "2025-06-26 08:46:20,893 Epoch 17170: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17171\n",
            "2025-06-26 08:46:20,895 EPOCH 17171\n",
            "INFO:__main__:Epoch 17171: total training loss 0.00098\n",
            "2025-06-26 08:46:20,965 Epoch 17171: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17172\n",
            "2025-06-26 08:46:20,967 EPOCH 17172\n",
            "INFO:__main__:Epoch 17172: total training loss 0.00105\n",
            "2025-06-26 08:46:21,039 Epoch 17172: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 17173\n",
            "2025-06-26 08:46:21,041 EPOCH 17173\n",
            "INFO:__main__:Epoch 17173: total training loss 0.00095\n",
            "2025-06-26 08:46:21,116 Epoch 17173: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17174\n",
            "2025-06-26 08:46:21,118 EPOCH 17174\n",
            "INFO:__main__:Epoch 17174: total training loss 0.00089\n",
            "2025-06-26 08:46:21,193 Epoch 17174: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17175\n",
            "2025-06-26 08:46:21,201 EPOCH 17175\n",
            "INFO:__main__:Epoch 17175: total training loss 0.00093\n",
            "2025-06-26 08:46:21,273 Epoch 17175: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17176\n",
            "2025-06-26 08:46:21,275 EPOCH 17176\n",
            "INFO:__main__:Epoch 17176: total training loss 0.00094\n",
            "2025-06-26 08:46:21,350 Epoch 17176: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17177\n",
            "2025-06-26 08:46:21,352 EPOCH 17177\n",
            "INFO:__main__:Epoch 17177: total training loss 0.00086\n",
            "2025-06-26 08:46:21,423 Epoch 17177: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17178\n",
            "2025-06-26 08:46:21,425 EPOCH 17178\n",
            "INFO:__main__:Epoch 17178: total training loss 0.00087\n",
            "2025-06-26 08:46:21,496 Epoch 17178: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17179\n",
            "2025-06-26 08:46:21,498 EPOCH 17179\n",
            "INFO:__main__:Epoch 17179: total training loss 0.00087\n",
            "2025-06-26 08:46:21,568 Epoch 17179: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17180\n",
            "2025-06-26 08:46:21,569 EPOCH 17180\n",
            "INFO:__main__:Epoch 17180: total training loss 0.00087\n",
            "2025-06-26 08:46:21,641 Epoch 17180: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17181\n",
            "2025-06-26 08:46:21,643 EPOCH 17181\n",
            "INFO:__main__:Epoch 17181: total training loss 0.00081\n",
            "2025-06-26 08:46:21,723 Epoch 17181: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17182\n",
            "2025-06-26 08:46:21,725 EPOCH 17182\n",
            "INFO:__main__:Epoch 17182: total training loss 0.00085\n",
            "2025-06-26 08:46:21,820 Epoch 17182: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17183\n",
            "2025-06-26 08:46:21,824 EPOCH 17183\n",
            "INFO:__main__:Epoch 17183: total training loss 0.00086\n",
            "2025-06-26 08:46:21,901 Epoch 17183: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17184\n",
            "2025-06-26 08:46:21,904 EPOCH 17184\n",
            "INFO:__main__:Epoch 17184: total training loss 0.00077\n",
            "2025-06-26 08:46:21,982 Epoch 17184: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17185\n",
            "2025-06-26 08:46:21,985 EPOCH 17185\n",
            "INFO:__main__:Epoch 17185: total training loss 0.00083\n",
            "2025-06-26 08:46:22,063 Epoch 17185: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17186\n",
            "2025-06-26 08:46:22,066 EPOCH 17186\n",
            "INFO:__main__:Epoch 17186: total training loss 0.00085\n",
            "2025-06-26 08:46:22,156 Epoch 17186: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17187\n",
            "2025-06-26 08:46:22,161 EPOCH 17187\n",
            "INFO:__main__:Epoch 17187: total training loss 0.00084\n",
            "2025-06-26 08:46:22,236 Epoch 17187: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17188\n",
            "2025-06-26 08:46:22,238 EPOCH 17188\n",
            "INFO:__main__:Epoch 17188: total training loss 0.00085\n",
            "2025-06-26 08:46:22,308 Epoch 17188: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17189\n",
            "2025-06-26 08:46:22,311 EPOCH 17189\n",
            "INFO:__main__:Epoch 17189: total training loss 0.00085\n",
            "2025-06-26 08:46:22,386 Epoch 17189: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17190\n",
            "2025-06-26 08:46:22,391 EPOCH 17190\n",
            "INFO:__main__:Epoch 17190: total training loss 0.00092\n",
            "2025-06-26 08:46:22,459 Epoch 17190: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17191\n",
            "2025-06-26 08:46:22,462 EPOCH 17191\n",
            "INFO:__main__:Epoch 17191: total training loss 0.00096\n",
            "2025-06-26 08:46:22,535 Epoch 17191: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17192\n",
            "2025-06-26 08:46:22,538 EPOCH 17192\n",
            "INFO:__main__:Epoch 17192: total training loss 0.00097\n",
            "2025-06-26 08:46:22,610 Epoch 17192: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17193\n",
            "2025-06-26 08:46:22,612 EPOCH 17193\n",
            "INFO:__main__:Epoch 17193: total training loss 0.00103\n",
            "2025-06-26 08:46:22,684 Epoch 17193: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17194\n",
            "2025-06-26 08:46:22,686 EPOCH 17194\n",
            "INFO:__main__:Epoch 17194: total training loss 0.00099\n",
            "2025-06-26 08:46:22,760 Epoch 17194: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17195\n",
            "2025-06-26 08:46:22,762 EPOCH 17195\n",
            "INFO:__main__:Epoch 17195: total training loss 0.00091\n",
            "2025-06-26 08:46:22,840 Epoch 17195: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17196\n",
            "2025-06-26 08:46:22,842 EPOCH 17196\n",
            "INFO:__main__:Epoch 17196: total training loss 0.00086\n",
            "2025-06-26 08:46:22,919 Epoch 17196: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17197\n",
            "2025-06-26 08:46:22,921 EPOCH 17197\n",
            "INFO:__main__:Epoch 17197: total training loss 0.00095\n",
            "2025-06-26 08:46:22,993 Epoch 17197: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17198\n",
            "2025-06-26 08:46:22,997 EPOCH 17198\n",
            "INFO:__main__:Epoch 17198: total training loss 0.00095\n",
            "2025-06-26 08:46:23,070 Epoch 17198: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17199\n",
            "2025-06-26 08:46:23,072 EPOCH 17199\n",
            "INFO:__main__:Epoch 17199: total training loss 0.00089\n",
            "2025-06-26 08:46:23,142 Epoch 17199: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17200\n",
            "2025-06-26 08:46:23,144 EPOCH 17200\n",
            "INFO:__main__:Epoch 17200: total training loss 0.00090\n",
            "2025-06-26 08:46:23,217 Epoch 17200: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17201\n",
            "2025-06-26 08:46:23,219 EPOCH 17201\n",
            "INFO:__main__:Epoch 17201: total training loss 0.00089\n",
            "2025-06-26 08:46:23,296 Epoch 17201: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17202\n",
            "2025-06-26 08:46:23,298 EPOCH 17202\n",
            "INFO:__main__:Epoch 17202: total training loss 0.00091\n",
            "2025-06-26 08:46:23,369 Epoch 17202: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17203\n",
            "2025-06-26 08:46:23,371 EPOCH 17203\n",
            "INFO:__main__:Epoch 17203: total training loss 0.00089\n",
            "2025-06-26 08:46:23,439 Epoch 17203: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17204\n",
            "2025-06-26 08:46:23,441 EPOCH 17204\n",
            "INFO:__main__:Epoch 17204: total training loss 0.00090\n",
            "2025-06-26 08:46:23,517 Epoch 17204: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17205\n",
            "2025-06-26 08:46:23,520 EPOCH 17205\n",
            "INFO:__main__:Epoch 17205: total training loss 0.00085\n",
            "2025-06-26 08:46:23,594 Epoch 17205: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17206\n",
            "2025-06-26 08:46:23,596 EPOCH 17206\n",
            "INFO:__main__:Epoch 17206: total training loss 0.00085\n",
            "2025-06-26 08:46:23,665 Epoch 17206: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17207\n",
            "2025-06-26 08:46:23,667 EPOCH 17207\n",
            "INFO:__main__:Epoch 17207: total training loss 0.00090\n",
            "2025-06-26 08:46:23,737 Epoch 17207: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17208\n",
            "2025-06-26 08:46:23,739 EPOCH 17208\n",
            "INFO:__main__:Epoch 17208: total training loss 0.00086\n",
            "2025-06-26 08:46:23,810 Epoch 17208: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17209\n",
            "2025-06-26 08:46:23,812 EPOCH 17209\n",
            "INFO:__main__:Epoch 17209: total training loss 0.00091\n",
            "2025-06-26 08:46:23,886 Epoch 17209: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17210\n",
            "2025-06-26 08:46:23,888 EPOCH 17210\n",
            "INFO:__main__:Epoch 17210: total training loss 0.00093\n",
            "2025-06-26 08:46:23,974 Epoch 17210: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17211\n",
            "2025-06-26 08:46:23,977 EPOCH 17211\n",
            "INFO:__main__:Epoch 17211: total training loss 0.00087\n",
            "2025-06-26 08:46:24,048 Epoch 17211: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17212\n",
            "2025-06-26 08:46:24,050 EPOCH 17212\n",
            "INFO:__main__:Epoch 17212: total training loss 0.00081\n",
            "2025-06-26 08:46:24,119 Epoch 17212: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17213\n",
            "2025-06-26 08:46:24,121 EPOCH 17213\n",
            "INFO:__main__:Epoch 17213: total training loss 0.00082\n",
            "2025-06-26 08:46:24,208 Epoch 17213: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17214\n",
            "2025-06-26 08:46:24,211 EPOCH 17214\n",
            "INFO:__main__:Epoch 17214: total training loss 0.00085\n",
            "2025-06-26 08:46:24,284 Epoch 17214: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17215\n",
            "2025-06-26 08:46:24,286 EPOCH 17215\n",
            "INFO:__main__:Epoch 17215: total training loss 0.00092\n",
            "2025-06-26 08:46:24,357 Epoch 17215: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17216\n",
            "2025-06-26 08:46:24,359 EPOCH 17216\n",
            "INFO:__main__:Epoch 17216: total training loss 0.00087\n",
            "2025-06-26 08:46:24,428 Epoch 17216: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17217\n",
            "2025-06-26 08:46:24,431 EPOCH 17217\n",
            "INFO:__main__:Epoch 17217: total training loss 0.00091\n",
            "2025-06-26 08:46:24,505 Epoch 17217: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17218\n",
            "2025-06-26 08:46:24,507 EPOCH 17218\n",
            "INFO:__main__:Epoch 17218: total training loss 0.00088\n",
            "2025-06-26 08:46:24,582 Epoch 17218: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17219\n",
            "2025-06-26 08:46:24,584 EPOCH 17219\n",
            "INFO:__main__:Epoch 17219: total training loss 0.00084\n",
            "2025-06-26 08:46:24,652 Epoch 17219: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17220\n",
            "2025-06-26 08:46:24,654 EPOCH 17220\n",
            "INFO:__main__:Epoch 17220: total training loss 0.00083\n",
            "2025-06-26 08:46:24,724 Epoch 17220: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17221\n",
            "2025-06-26 08:46:24,726 EPOCH 17221\n",
            "INFO:__main__:Epoch 17221: total training loss 0.00095\n",
            "2025-06-26 08:46:24,802 Epoch 17221: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17222\n",
            "2025-06-26 08:46:24,804 EPOCH 17222\n",
            "INFO:__main__:Epoch 17222: total training loss 0.00097\n",
            "2025-06-26 08:46:24,871 Epoch 17222: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17223\n",
            "2025-06-26 08:46:24,873 EPOCH 17223\n",
            "INFO:__main__:Epoch 17223: total training loss 0.00092\n",
            "2025-06-26 08:46:24,947 Epoch 17223: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17224\n",
            "2025-06-26 08:46:24,949 EPOCH 17224\n",
            "INFO:__main__:Epoch 17224: total training loss 0.00093\n",
            "2025-06-26 08:46:25,054 Epoch 17224: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17225\n",
            "2025-06-26 08:46:25,056 EPOCH 17225\n",
            "INFO:__main__:Epoch 17225: total training loss 0.00092\n",
            "2025-06-26 08:46:25,130 Epoch 17225: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17226\n",
            "2025-06-26 08:46:25,132 EPOCH 17226\n",
            "INFO:__main__:Epoch 17226: total training loss 0.00088\n",
            "2025-06-26 08:46:25,203 Epoch 17226: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17227\n",
            "2025-06-26 08:46:25,207 EPOCH 17227\n",
            "INFO:__main__:Epoch 17227: total training loss 0.00090\n",
            "2025-06-26 08:46:25,279 Epoch 17227: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17228\n",
            "2025-06-26 08:46:25,281 EPOCH 17228\n",
            "INFO:__main__:Epoch 17228: total training loss 0.00087\n",
            "2025-06-26 08:46:25,361 Epoch 17228: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17229\n",
            "2025-06-26 08:46:25,363 EPOCH 17229\n",
            "INFO:__main__:Epoch 17229: total training loss 0.00089\n",
            "2025-06-26 08:46:25,437 Epoch 17229: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17230\n",
            "2025-06-26 08:46:25,439 EPOCH 17230\n",
            "INFO:__main__:Epoch 17230: total training loss 0.00083\n",
            "2025-06-26 08:46:25,516 Epoch 17230: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17231\n",
            "2025-06-26 08:46:25,518 EPOCH 17231\n",
            "INFO:__main__:Epoch 17231: total training loss 0.00081\n",
            "2025-06-26 08:46:25,592 Epoch 17231: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17232\n",
            "2025-06-26 08:46:25,594 EPOCH 17232\n",
            "INFO:__main__:Epoch 17232: total training loss 0.00084\n",
            "2025-06-26 08:46:25,663 Epoch 17232: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17233\n",
            "2025-06-26 08:46:25,665 EPOCH 17233\n",
            "INFO:__main__:Epoch 17233: total training loss 0.00082\n",
            "2025-06-26 08:46:25,737 Epoch 17233: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17234\n",
            "2025-06-26 08:46:25,739 EPOCH 17234\n",
            "INFO:__main__:Epoch 17234: total training loss 0.00087\n",
            "2025-06-26 08:46:25,815 Epoch 17234: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17235\n",
            "2025-06-26 08:46:25,817 EPOCH 17235\n",
            "INFO:__main__:Epoch 17235: total training loss 0.00089\n",
            "2025-06-26 08:46:25,887 Epoch 17235: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17236\n",
            "2025-06-26 08:46:25,890 EPOCH 17236\n",
            "INFO:__main__:Epoch 17236: total training loss 0.00089\n",
            "2025-06-26 08:46:25,970 Epoch 17236: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17237\n",
            "2025-06-26 08:46:25,972 EPOCH 17237\n",
            "INFO:__main__:Epoch 17237: total training loss 0.00084\n",
            "2025-06-26 08:46:26,046 Epoch 17237: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17238\n",
            "2025-06-26 08:46:26,049 EPOCH 17238\n",
            "INFO:__main__:Epoch 17238: total training loss 0.00090\n",
            "2025-06-26 08:46:26,128 Epoch 17238: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17239\n",
            "2025-06-26 08:46:26,130 EPOCH 17239\n",
            "INFO:__main__:Epoch 17239: total training loss 0.00088\n",
            "2025-06-26 08:46:26,204 Epoch 17239: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17240\n",
            "2025-06-26 08:46:26,207 EPOCH 17240\n",
            "INFO:__main__:Epoch 17240: total training loss 0.00088\n",
            "2025-06-26 08:46:26,278 Epoch 17240: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17241\n",
            "2025-06-26 08:46:26,280 EPOCH 17241\n",
            "INFO:__main__:Epoch 17241: total training loss 0.00084\n",
            "2025-06-26 08:46:26,365 Epoch 17241: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17242\n",
            "2025-06-26 08:46:26,367 EPOCH 17242\n",
            "INFO:__main__:Epoch 17242: total training loss 0.00091\n",
            "2025-06-26 08:46:26,438 Epoch 17242: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17243\n",
            "2025-06-26 08:46:26,440 EPOCH 17243\n",
            "INFO:__main__:Epoch 17243: total training loss 0.00086\n",
            "2025-06-26 08:46:26,511 Epoch 17243: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17244\n",
            "2025-06-26 08:46:26,513 EPOCH 17244\n",
            "INFO:__main__:Epoch 17244: total training loss 0.00086\n",
            "2025-06-26 08:46:26,594 Epoch 17244: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17245\n",
            "2025-06-26 08:46:26,596 EPOCH 17245\n",
            "INFO:__main__:Epoch 17245: total training loss 0.00087\n",
            "2025-06-26 08:46:26,671 Epoch 17245: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17246\n",
            "2025-06-26 08:46:26,673 EPOCH 17246\n",
            "INFO:__main__:Epoch 17246: total training loss 0.00096\n",
            "2025-06-26 08:46:26,747 Epoch 17246: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17247\n",
            "2025-06-26 08:46:26,750 EPOCH 17247\n",
            "INFO:__main__:Epoch 17247: total training loss 0.00086\n",
            "2025-06-26 08:46:26,835 Epoch 17247: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17248\n",
            "2025-06-26 08:46:26,837 EPOCH 17248\n",
            "INFO:__main__:Epoch 17248: total training loss 0.00086\n",
            "2025-06-26 08:46:26,923 Epoch 17248: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17249\n",
            "2025-06-26 08:46:26,927 EPOCH 17249\n",
            "INFO:__main__:Epoch 17249: total training loss 0.00090\n",
            "2025-06-26 08:46:27,006 Epoch 17249: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17250\n",
            "2025-06-26 08:46:27,012 EPOCH 17250\n",
            "INFO:__main__:Epoch 17250 Step:    17250 Batch Loss:     0.000840 Tokens per Sec:  1751216, Lr: 0.001000\n",
            "2025-06-26 08:46:27,094 Epoch 17250 Step:    17250 Batch Loss:     0.000840 Tokens per Sec:  1751216, Lr: 0.001000\n",
            "INFO:__main__:Epoch 17250: total training loss 0.00084\n",
            "2025-06-26 08:46:27,101 Epoch 17250: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17251\n",
            "2025-06-26 08:46:27,103 EPOCH 17251\n",
            "INFO:__main__:Epoch 17251: total training loss 0.00079\n",
            "2025-06-26 08:46:27,209 Epoch 17251: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17252\n",
            "2025-06-26 08:46:27,213 EPOCH 17252\n",
            "INFO:__main__:Epoch 17252: total training loss 0.00081\n",
            "2025-06-26 08:46:27,295 Epoch 17252: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17253\n",
            "2025-06-26 08:46:27,301 EPOCH 17253\n",
            "INFO:__main__:Epoch 17253: total training loss 0.00079\n",
            "2025-06-26 08:46:27,391 Epoch 17253: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17254\n",
            "2025-06-26 08:46:27,398 EPOCH 17254\n",
            "INFO:__main__:Epoch 17254: total training loss 0.00084\n",
            "2025-06-26 08:46:27,502 Epoch 17254: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17255\n",
            "2025-06-26 08:46:27,506 EPOCH 17255\n",
            "INFO:__main__:Epoch 17255: total training loss 0.00088\n",
            "2025-06-26 08:46:27,628 Epoch 17255: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17256\n",
            "2025-06-26 08:46:27,630 EPOCH 17256\n",
            "INFO:__main__:Epoch 17256: total training loss 0.00085\n",
            "2025-06-26 08:46:27,739 Epoch 17256: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17257\n",
            "2025-06-26 08:46:27,746 EPOCH 17257\n",
            "INFO:__main__:Epoch 17257: total training loss 0.00089\n",
            "2025-06-26 08:46:27,830 Epoch 17257: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17258\n",
            "2025-06-26 08:46:27,837 EPOCH 17258\n",
            "INFO:__main__:Epoch 17258: total training loss 0.00083\n",
            "2025-06-26 08:46:27,951 Epoch 17258: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17259\n",
            "2025-06-26 08:46:27,953 EPOCH 17259\n",
            "INFO:__main__:Epoch 17259: total training loss 0.00082\n",
            "2025-06-26 08:46:28,063 Epoch 17259: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17260\n",
            "2025-06-26 08:46:28,065 EPOCH 17260\n",
            "INFO:__main__:Epoch 17260: total training loss 0.00094\n",
            "2025-06-26 08:46:28,185 Epoch 17260: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17261\n",
            "2025-06-26 08:46:28,190 EPOCH 17261\n",
            "INFO:__main__:Epoch 17261: total training loss 0.00084\n",
            "2025-06-26 08:46:28,298 Epoch 17261: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17262\n",
            "2025-06-26 08:46:28,299 EPOCH 17262\n",
            "INFO:__main__:Epoch 17262: total training loss 0.00086\n",
            "2025-06-26 08:46:28,406 Epoch 17262: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17263\n",
            "2025-06-26 08:46:28,409 EPOCH 17263\n",
            "INFO:__main__:Epoch 17263: total training loss 0.00084\n",
            "2025-06-26 08:46:28,518 Epoch 17263: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17264\n",
            "2025-06-26 08:46:28,520 EPOCH 17264\n",
            "INFO:__main__:Epoch 17264: total training loss 0.00080\n",
            "2025-06-26 08:46:28,622 Epoch 17264: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17265\n",
            "2025-06-26 08:46:28,625 EPOCH 17265\n",
            "INFO:__main__:Epoch 17265: total training loss 0.00097\n",
            "2025-06-26 08:46:28,724 Epoch 17265: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17266\n",
            "2025-06-26 08:46:28,729 EPOCH 17266\n",
            "INFO:__main__:Epoch 17266: total training loss 0.00089\n",
            "2025-06-26 08:46:28,822 Epoch 17266: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17267\n",
            "2025-06-26 08:46:28,827 EPOCH 17267\n",
            "INFO:__main__:Epoch 17267: total training loss 0.00086\n",
            "2025-06-26 08:46:28,923 Epoch 17267: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17268\n",
            "2025-06-26 08:46:28,927 EPOCH 17268\n",
            "INFO:__main__:Epoch 17268: total training loss 0.00089\n",
            "2025-06-26 08:46:29,003 Epoch 17268: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17269\n",
            "2025-06-26 08:46:29,009 EPOCH 17269\n",
            "INFO:__main__:Epoch 17269: total training loss 0.00090\n",
            "2025-06-26 08:46:29,128 Epoch 17269: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17270\n",
            "2025-06-26 08:46:29,131 EPOCH 17270\n",
            "INFO:__main__:Epoch 17270: total training loss 0.00094\n",
            "2025-06-26 08:46:29,237 Epoch 17270: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17271\n",
            "2025-06-26 08:46:29,240 EPOCH 17271\n",
            "INFO:__main__:Epoch 17271: total training loss 0.00096\n",
            "2025-06-26 08:46:29,324 Epoch 17271: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17272\n",
            "2025-06-26 08:46:29,326 EPOCH 17272\n",
            "INFO:__main__:Epoch 17272: total training loss 0.00094\n",
            "2025-06-26 08:46:29,435 Epoch 17272: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17273\n",
            "2025-06-26 08:46:29,437 EPOCH 17273\n",
            "INFO:__main__:Epoch 17273: total training loss 0.00082\n",
            "2025-06-26 08:46:29,545 Epoch 17273: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17274\n",
            "2025-06-26 08:46:29,547 EPOCH 17274\n",
            "INFO:__main__:Epoch 17274: total training loss 0.00085\n",
            "2025-06-26 08:46:29,664 Epoch 17274: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17275\n",
            "2025-06-26 08:46:29,666 EPOCH 17275\n",
            "INFO:__main__:Epoch 17275: total training loss 0.00085\n",
            "2025-06-26 08:46:29,761 Epoch 17275: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17276\n",
            "2025-06-26 08:46:29,763 EPOCH 17276\n",
            "INFO:__main__:Epoch 17276: total training loss 0.00086\n",
            "2025-06-26 08:46:29,870 Epoch 17276: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17277\n",
            "2025-06-26 08:46:29,872 EPOCH 17277\n",
            "INFO:__main__:Epoch 17277: total training loss 0.00081\n",
            "2025-06-26 08:46:29,959 Epoch 17277: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17278\n",
            "2025-06-26 08:46:29,965 EPOCH 17278\n",
            "INFO:__main__:Epoch 17278: total training loss 0.00081\n",
            "2025-06-26 08:46:30,036 Epoch 17278: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17279\n",
            "2025-06-26 08:46:30,041 EPOCH 17279\n",
            "INFO:__main__:Epoch 17279: total training loss 0.00087\n",
            "2025-06-26 08:46:30,134 Epoch 17279: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17280\n",
            "2025-06-26 08:46:30,139 EPOCH 17280\n",
            "INFO:__main__:Epoch 17280: total training loss 0.00082\n",
            "2025-06-26 08:46:30,223 Epoch 17280: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17281\n",
            "2025-06-26 08:46:30,228 EPOCH 17281\n",
            "INFO:__main__:Epoch 17281: total training loss 0.00089\n",
            "2025-06-26 08:46:30,314 Epoch 17281: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17282\n",
            "2025-06-26 08:46:30,316 EPOCH 17282\n",
            "INFO:__main__:Epoch 17282: total training loss 0.00088\n",
            "2025-06-26 08:46:30,399 Epoch 17282: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17283\n",
            "2025-06-26 08:46:30,405 EPOCH 17283\n",
            "INFO:__main__:Epoch 17283: total training loss 0.00085\n",
            "2025-06-26 08:46:30,495 Epoch 17283: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17284\n",
            "2025-06-26 08:46:30,497 EPOCH 17284\n",
            "INFO:__main__:Epoch 17284: total training loss 0.00083\n",
            "2025-06-26 08:46:30,586 Epoch 17284: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17285\n",
            "2025-06-26 08:46:30,591 EPOCH 17285\n",
            "INFO:__main__:Epoch 17285: total training loss 0.00084\n",
            "2025-06-26 08:46:30,687 Epoch 17285: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17286\n",
            "2025-06-26 08:46:30,694 EPOCH 17286\n",
            "INFO:__main__:Epoch 17286: total training loss 0.00082\n",
            "2025-06-26 08:46:30,797 Epoch 17286: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17287\n",
            "2025-06-26 08:46:30,804 EPOCH 17287\n",
            "INFO:__main__:Epoch 17287: total training loss 0.00084\n",
            "2025-06-26 08:46:30,884 Epoch 17287: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17288\n",
            "2025-06-26 08:46:30,891 EPOCH 17288\n",
            "INFO:__main__:Epoch 17288: total training loss 0.00089\n",
            "2025-06-26 08:46:30,980 Epoch 17288: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17289\n",
            "2025-06-26 08:46:30,985 EPOCH 17289\n",
            "INFO:__main__:Epoch 17289: total training loss 0.00087\n",
            "2025-06-26 08:46:31,065 Epoch 17289: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17290\n",
            "2025-06-26 08:46:31,072 EPOCH 17290\n",
            "INFO:__main__:Epoch 17290: total training loss 0.00086\n",
            "2025-06-26 08:46:31,161 Epoch 17290: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17291\n",
            "2025-06-26 08:46:31,164 EPOCH 17291\n",
            "INFO:__main__:Epoch 17291: total training loss 0.00084\n",
            "2025-06-26 08:46:31,259 Epoch 17291: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17292\n",
            "2025-06-26 08:46:31,266 EPOCH 17292\n",
            "INFO:__main__:Epoch 17292: total training loss 0.00085\n",
            "2025-06-26 08:46:31,348 Epoch 17292: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17293\n",
            "2025-06-26 08:46:31,354 EPOCH 17293\n",
            "INFO:__main__:Epoch 17293: total training loss 0.00087\n",
            "2025-06-26 08:46:31,451 Epoch 17293: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17294\n",
            "2025-06-26 08:46:31,454 EPOCH 17294\n",
            "INFO:__main__:Epoch 17294: total training loss 0.00094\n",
            "2025-06-26 08:46:31,557 Epoch 17294: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17295\n",
            "2025-06-26 08:46:31,562 EPOCH 17295\n",
            "INFO:__main__:Epoch 17295: total training loss 0.00089\n",
            "2025-06-26 08:46:31,671 Epoch 17295: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17296\n",
            "2025-06-26 08:46:31,673 EPOCH 17296\n",
            "INFO:__main__:Epoch 17296: total training loss 0.00089\n",
            "2025-06-26 08:46:31,789 Epoch 17296: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17297\n",
            "2025-06-26 08:46:31,792 EPOCH 17297\n",
            "INFO:__main__:Epoch 17297: total training loss 0.00081\n",
            "2025-06-26 08:46:31,878 Epoch 17297: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17298\n",
            "2025-06-26 08:46:31,884 EPOCH 17298\n",
            "INFO:__main__:Epoch 17298: total training loss 0.00085\n",
            "2025-06-26 08:46:31,997 Epoch 17298: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17299\n",
            "2025-06-26 08:46:32,000 EPOCH 17299\n",
            "INFO:__main__:Epoch 17299: total training loss 0.00085\n",
            "2025-06-26 08:46:32,103 Epoch 17299: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17300\n",
            "2025-06-26 08:46:32,109 EPOCH 17300\n",
            "INFO:__main__:Epoch 17300: total training loss 0.00082\n",
            "2025-06-26 08:46:32,203 Epoch 17300: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17301\n",
            "2025-06-26 08:46:32,205 EPOCH 17301\n",
            "INFO:__main__:Epoch 17301: total training loss 0.00081\n",
            "2025-06-26 08:46:32,278 Epoch 17301: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17302\n",
            "2025-06-26 08:46:32,282 EPOCH 17302\n",
            "INFO:__main__:Epoch 17302: total training loss 0.00089\n",
            "2025-06-26 08:46:32,354 Epoch 17302: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17303\n",
            "2025-06-26 08:46:32,359 EPOCH 17303\n",
            "INFO:__main__:Epoch 17303: total training loss 0.00090\n",
            "2025-06-26 08:46:32,431 Epoch 17303: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17304\n",
            "2025-06-26 08:46:32,433 EPOCH 17304\n",
            "INFO:__main__:Epoch 17304: total training loss 0.00087\n",
            "2025-06-26 08:46:32,511 Epoch 17304: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17305\n",
            "2025-06-26 08:46:32,513 EPOCH 17305\n",
            "INFO:__main__:Epoch 17305: total training loss 0.00091\n",
            "2025-06-26 08:46:32,588 Epoch 17305: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17306\n",
            "2025-06-26 08:46:32,590 EPOCH 17306\n",
            "INFO:__main__:Epoch 17306: total training loss 0.00094\n",
            "2025-06-26 08:46:32,684 Epoch 17306: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17307\n",
            "2025-06-26 08:46:32,688 EPOCH 17307\n",
            "INFO:__main__:Epoch 17307: total training loss 0.00094\n",
            "2025-06-26 08:46:32,765 Epoch 17307: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17308\n",
            "2025-06-26 08:46:32,769 EPOCH 17308\n",
            "INFO:__main__:Epoch 17308: total training loss 0.00091\n",
            "2025-06-26 08:46:32,842 Epoch 17308: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17309\n",
            "2025-06-26 08:46:32,844 EPOCH 17309\n",
            "INFO:__main__:Epoch 17309: total training loss 0.00087\n",
            "2025-06-26 08:46:32,921 Epoch 17309: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17310\n",
            "2025-06-26 08:46:32,923 EPOCH 17310\n",
            "INFO:__main__:Epoch 17310: total training loss 0.00094\n",
            "2025-06-26 08:46:33,017 Epoch 17310: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17311\n",
            "2025-06-26 08:46:33,019 EPOCH 17311\n",
            "INFO:__main__:Epoch 17311: total training loss 0.00087\n",
            "2025-06-26 08:46:33,100 Epoch 17311: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17312\n",
            "2025-06-26 08:46:33,102 EPOCH 17312\n",
            "INFO:__main__:Epoch 17312: total training loss 0.00082\n",
            "2025-06-26 08:46:33,173 Epoch 17312: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17313\n",
            "2025-06-26 08:46:33,175 EPOCH 17313\n",
            "INFO:__main__:Epoch 17313: total training loss 0.00086\n",
            "2025-06-26 08:46:33,248 Epoch 17313: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17314\n",
            "2025-06-26 08:46:33,250 EPOCH 17314\n",
            "INFO:__main__:Epoch 17314: total training loss 0.00086\n",
            "2025-06-26 08:46:33,324 Epoch 17314: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17315\n",
            "2025-06-26 08:46:33,326 EPOCH 17315\n",
            "INFO:__main__:Epoch 17315: total training loss 0.00083\n",
            "2025-06-26 08:46:33,401 Epoch 17315: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17316\n",
            "2025-06-26 08:46:33,403 EPOCH 17316\n",
            "INFO:__main__:Epoch 17316: total training loss 0.00081\n",
            "2025-06-26 08:46:33,474 Epoch 17316: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17317\n",
            "2025-06-26 08:46:33,476 EPOCH 17317\n",
            "INFO:__main__:Epoch 17317: total training loss 0.00088\n",
            "2025-06-26 08:46:33,546 Epoch 17317: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17318\n",
            "2025-06-26 08:46:33,548 EPOCH 17318\n",
            "INFO:__main__:Epoch 17318: total training loss 0.00080\n",
            "2025-06-26 08:46:33,620 Epoch 17318: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17319\n",
            "2025-06-26 08:46:33,623 EPOCH 17319\n",
            "INFO:__main__:Epoch 17319: total training loss 0.00082\n",
            "2025-06-26 08:46:33,700 Epoch 17319: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17320\n",
            "2025-06-26 08:46:33,705 EPOCH 17320\n",
            "INFO:__main__:Epoch 17320: total training loss 0.00076\n",
            "2025-06-26 08:46:33,795 Epoch 17320: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17321\n",
            "2025-06-26 08:46:33,797 EPOCH 17321\n",
            "INFO:__main__:Epoch 17321: total training loss 0.00083\n",
            "2025-06-26 08:46:33,868 Epoch 17321: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17322\n",
            "2025-06-26 08:46:33,870 EPOCH 17322\n",
            "INFO:__main__:Epoch 17322: total training loss 0.00082\n",
            "2025-06-26 08:46:33,940 Epoch 17322: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17323\n",
            "2025-06-26 08:46:33,942 EPOCH 17323\n",
            "INFO:__main__:Epoch 17323: total training loss 0.00083\n",
            "2025-06-26 08:46:34,011 Epoch 17323: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17324\n",
            "2025-06-26 08:46:34,014 EPOCH 17324\n",
            "INFO:__main__:Epoch 17324: total training loss 0.00082\n",
            "2025-06-26 08:46:34,084 Epoch 17324: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17325\n",
            "2025-06-26 08:46:34,086 EPOCH 17325\n",
            "INFO:__main__:Epoch 17325: total training loss 0.00084\n",
            "2025-06-26 08:46:34,156 Epoch 17325: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17326\n",
            "2025-06-26 08:46:34,158 EPOCH 17326\n",
            "INFO:__main__:Epoch 17326: total training loss 0.00086\n",
            "2025-06-26 08:46:34,236 Epoch 17326: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17327\n",
            "2025-06-26 08:46:34,238 EPOCH 17327\n",
            "INFO:__main__:Epoch 17327: total training loss 0.00085\n",
            "2025-06-26 08:46:34,305 Epoch 17327: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17328\n",
            "2025-06-26 08:46:34,307 EPOCH 17328\n",
            "INFO:__main__:Epoch 17328: total training loss 0.00080\n",
            "2025-06-26 08:46:34,380 Epoch 17328: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17329\n",
            "2025-06-26 08:46:34,382 EPOCH 17329\n",
            "INFO:__main__:Epoch 17329: total training loss 0.00079\n",
            "2025-06-26 08:46:34,452 Epoch 17329: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17330\n",
            "2025-06-26 08:46:34,454 EPOCH 17330\n",
            "INFO:__main__:Epoch 17330: total training loss 0.00081\n",
            "2025-06-26 08:46:34,526 Epoch 17330: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17331\n",
            "2025-06-26 08:46:34,527 EPOCH 17331\n",
            "INFO:__main__:Epoch 17331: total training loss 0.00081\n",
            "2025-06-26 08:46:34,599 Epoch 17331: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17332\n",
            "2025-06-26 08:46:34,601 EPOCH 17332\n",
            "INFO:__main__:Epoch 17332: total training loss 0.00084\n",
            "2025-06-26 08:46:34,672 Epoch 17332: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17333\n",
            "2025-06-26 08:46:34,674 EPOCH 17333\n",
            "INFO:__main__:Epoch 17333: total training loss 0.00082\n",
            "2025-06-26 08:46:34,744 Epoch 17333: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17334\n",
            "2025-06-26 08:46:34,746 EPOCH 17334\n",
            "INFO:__main__:Epoch 17334: total training loss 0.00084\n",
            "2025-06-26 08:46:34,834 Epoch 17334: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17335\n",
            "2025-06-26 08:46:34,837 EPOCH 17335\n",
            "INFO:__main__:Epoch 17335: total training loss 0.00086\n",
            "2025-06-26 08:46:34,909 Epoch 17335: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17336\n",
            "2025-06-26 08:46:34,911 EPOCH 17336\n",
            "INFO:__main__:Epoch 17336: total training loss 0.00085\n",
            "2025-06-26 08:46:34,987 Epoch 17336: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17337\n",
            "2025-06-26 08:46:34,990 EPOCH 17337\n",
            "INFO:__main__:Epoch 17337: total training loss 0.00082\n",
            "2025-06-26 08:46:35,064 Epoch 17337: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17338\n",
            "2025-06-26 08:46:35,067 EPOCH 17338\n",
            "INFO:__main__:Epoch 17338: total training loss 0.00082\n",
            "2025-06-26 08:46:35,138 Epoch 17338: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17339\n",
            "2025-06-26 08:46:35,140 EPOCH 17339\n",
            "INFO:__main__:Epoch 17339: total training loss 0.00082\n",
            "2025-06-26 08:46:35,217 Epoch 17339: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17340\n",
            "2025-06-26 08:46:35,220 EPOCH 17340\n",
            "INFO:__main__:Epoch 17340: total training loss 0.00091\n",
            "2025-06-26 08:46:35,289 Epoch 17340: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17341\n",
            "2025-06-26 08:46:35,292 EPOCH 17341\n",
            "INFO:__main__:Epoch 17341: total training loss 0.00091\n",
            "2025-06-26 08:46:35,365 Epoch 17341: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17342\n",
            "2025-06-26 08:46:35,367 EPOCH 17342\n",
            "INFO:__main__:Epoch 17342: total training loss 0.00094\n",
            "2025-06-26 08:46:35,438 Epoch 17342: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17343\n",
            "2025-06-26 08:46:35,440 EPOCH 17343\n",
            "INFO:__main__:Epoch 17343: total training loss 0.00090\n",
            "2025-06-26 08:46:35,510 Epoch 17343: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17344\n",
            "2025-06-26 08:46:35,512 EPOCH 17344\n",
            "INFO:__main__:Epoch 17344: total training loss 0.00085\n",
            "2025-06-26 08:46:35,585 Epoch 17344: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17345\n",
            "2025-06-26 08:46:35,587 EPOCH 17345\n",
            "INFO:__main__:Epoch 17345: total training loss 0.00082\n",
            "2025-06-26 08:46:35,660 Epoch 17345: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17346\n",
            "2025-06-26 08:46:35,662 EPOCH 17346\n",
            "INFO:__main__:Epoch 17346: total training loss 0.00083\n",
            "2025-06-26 08:46:35,732 Epoch 17346: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17347\n",
            "2025-06-26 08:46:35,734 EPOCH 17347\n",
            "INFO:__main__:Epoch 17347: total training loss 0.00088\n",
            "2025-06-26 08:46:35,808 Epoch 17347: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17348\n",
            "2025-06-26 08:46:35,810 EPOCH 17348\n",
            "INFO:__main__:Epoch 17348: total training loss 0.00079\n",
            "2025-06-26 08:46:35,897 Epoch 17348: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17349\n",
            "2025-06-26 08:46:35,899 EPOCH 17349\n",
            "INFO:__main__:Epoch 17349: total training loss 0.00077\n",
            "2025-06-26 08:46:35,980 Epoch 17349: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17350\n",
            "2025-06-26 08:46:35,982 EPOCH 17350\n",
            "INFO:__main__:Epoch 17350: total training loss 0.00079\n",
            "2025-06-26 08:46:36,051 Epoch 17350: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17351\n",
            "2025-06-26 08:46:36,053 EPOCH 17351\n",
            "INFO:__main__:Epoch 17351: total training loss 0.00082\n",
            "2025-06-26 08:46:36,124 Epoch 17351: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17352\n",
            "2025-06-26 08:46:36,126 EPOCH 17352\n",
            "INFO:__main__:Epoch 17352: total training loss 0.00082\n",
            "2025-06-26 08:46:36,199 Epoch 17352: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17353\n",
            "2025-06-26 08:46:36,201 EPOCH 17353\n",
            "INFO:__main__:Epoch 17353: total training loss 0.00079\n",
            "2025-06-26 08:46:36,276 Epoch 17353: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17354\n",
            "2025-06-26 08:46:36,278 EPOCH 17354\n",
            "INFO:__main__:Epoch 17354: total training loss 0.00086\n",
            "2025-06-26 08:46:36,352 Epoch 17354: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17355\n",
            "2025-06-26 08:46:36,354 EPOCH 17355\n",
            "INFO:__main__:Epoch 17355: total training loss 0.00084\n",
            "2025-06-26 08:46:36,428 Epoch 17355: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17356\n",
            "2025-06-26 08:46:36,430 EPOCH 17356\n",
            "INFO:__main__:Epoch 17356: total training loss 0.00084\n",
            "2025-06-26 08:46:36,504 Epoch 17356: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17357\n",
            "2025-06-26 08:46:36,506 EPOCH 17357\n",
            "INFO:__main__:Epoch 17357: total training loss 0.00084\n",
            "2025-06-26 08:46:36,580 Epoch 17357: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17358\n",
            "2025-06-26 08:46:36,584 EPOCH 17358\n",
            "INFO:__main__:Epoch 17358: total training loss 0.00087\n",
            "2025-06-26 08:46:36,656 Epoch 17358: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17359\n",
            "2025-06-26 08:46:36,658 EPOCH 17359\n",
            "INFO:__main__:Epoch 17359: total training loss 0.00092\n",
            "2025-06-26 08:46:36,731 Epoch 17359: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17360\n",
            "2025-06-26 08:46:36,733 EPOCH 17360\n",
            "INFO:__main__:Epoch 17360: total training loss 0.00092\n",
            "2025-06-26 08:46:36,811 Epoch 17360: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17361\n",
            "2025-06-26 08:46:36,813 EPOCH 17361\n",
            "INFO:__main__:Epoch 17361: total training loss 0.00093\n",
            "2025-06-26 08:46:36,891 Epoch 17361: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17362\n",
            "2025-06-26 08:46:36,894 EPOCH 17362\n",
            "INFO:__main__:Epoch 17362: total training loss 0.00090\n",
            "2025-06-26 08:46:36,976 Epoch 17362: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17363\n",
            "2025-06-26 08:46:36,980 EPOCH 17363\n",
            "INFO:__main__:Epoch 17363: total training loss 0.00092\n",
            "2025-06-26 08:46:37,054 Epoch 17363: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17364\n",
            "2025-06-26 08:46:37,055 EPOCH 17364\n",
            "INFO:__main__:Epoch 17364: total training loss 0.00092\n",
            "2025-06-26 08:46:37,134 Epoch 17364: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17365\n",
            "2025-06-26 08:46:37,136 EPOCH 17365\n",
            "INFO:__main__:Epoch 17365: total training loss 0.00090\n",
            "2025-06-26 08:46:37,212 Epoch 17365: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17366\n",
            "2025-06-26 08:46:37,215 EPOCH 17366\n",
            "INFO:__main__:Epoch 17366: total training loss 0.00085\n",
            "2025-06-26 08:46:37,285 Epoch 17366: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17367\n",
            "2025-06-26 08:46:37,288 EPOCH 17367\n",
            "INFO:__main__:Epoch 17367: total training loss 0.00083\n",
            "2025-06-26 08:46:37,359 Epoch 17367: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17368\n",
            "2025-06-26 08:46:37,361 EPOCH 17368\n",
            "INFO:__main__:Epoch 17368: total training loss 0.00086\n",
            "2025-06-26 08:46:37,433 Epoch 17368: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17369\n",
            "2025-06-26 08:46:37,435 EPOCH 17369\n",
            "INFO:__main__:Epoch 17369: total training loss 0.00083\n",
            "2025-06-26 08:46:37,508 Epoch 17369: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17370\n",
            "2025-06-26 08:46:37,510 EPOCH 17370\n",
            "INFO:__main__:Epoch 17370: total training loss 0.00085\n",
            "2025-06-26 08:46:37,584 Epoch 17370: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17371\n",
            "2025-06-26 08:46:37,588 EPOCH 17371\n",
            "INFO:__main__:Epoch 17371: total training loss 0.00090\n",
            "2025-06-26 08:46:37,659 Epoch 17371: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17372\n",
            "2025-06-26 08:46:37,661 EPOCH 17372\n",
            "INFO:__main__:Epoch 17372: total training loss 0.00098\n",
            "2025-06-26 08:46:37,733 Epoch 17372: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17373\n",
            "2025-06-26 08:46:37,737 EPOCH 17373\n",
            "INFO:__main__:Epoch 17373: total training loss 0.00110\n",
            "2025-06-26 08:46:37,810 Epoch 17373: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 17374\n",
            "2025-06-26 08:46:37,812 EPOCH 17374\n",
            "INFO:__main__:Epoch 17374: total training loss 0.00096\n",
            "2025-06-26 08:46:37,886 Epoch 17374: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17375\n",
            "2025-06-26 08:46:37,890 EPOCH 17375\n",
            "INFO:__main__:Epoch 17375: total training loss 0.00112\n",
            "2025-06-26 08:46:37,965 Epoch 17375: total training loss 0.00112\n",
            "INFO:__main__:EPOCH 17376\n",
            "2025-06-26 08:46:37,967 EPOCH 17376\n",
            "INFO:__main__:Epoch 17376: total training loss 0.00102\n",
            "2025-06-26 08:46:38,067 Epoch 17376: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 17377\n",
            "2025-06-26 08:46:38,071 EPOCH 17377\n",
            "INFO:__main__:Epoch 17377: total training loss 0.00103\n",
            "2025-06-26 08:46:38,148 Epoch 17377: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17378\n",
            "2025-06-26 08:46:38,150 EPOCH 17378\n",
            "INFO:__main__:Epoch 17378: total training loss 0.00099\n",
            "2025-06-26 08:46:38,223 Epoch 17378: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17379\n",
            "2025-06-26 08:46:38,225 EPOCH 17379\n",
            "INFO:__main__:Epoch 17379: total training loss 0.00096\n",
            "2025-06-26 08:46:38,297 Epoch 17379: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17380\n",
            "2025-06-26 08:46:38,299 EPOCH 17380\n",
            "INFO:__main__:Epoch 17380: total training loss 0.00092\n",
            "2025-06-26 08:46:38,372 Epoch 17380: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17381\n",
            "2025-06-26 08:46:38,374 EPOCH 17381\n",
            "INFO:__main__:Epoch 17381: total training loss 0.00090\n",
            "2025-06-26 08:46:38,447 Epoch 17381: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17382\n",
            "2025-06-26 08:46:38,449 EPOCH 17382\n",
            "INFO:__main__:Epoch 17382: total training loss 0.00092\n",
            "2025-06-26 08:46:38,520 Epoch 17382: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17383\n",
            "2025-06-26 08:46:38,522 EPOCH 17383\n",
            "INFO:__main__:Epoch 17383: total training loss 0.00089\n",
            "2025-06-26 08:46:38,595 Epoch 17383: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17384\n",
            "2025-06-26 08:46:38,597 EPOCH 17384\n",
            "INFO:__main__:Epoch 17384: total training loss 0.00089\n",
            "2025-06-26 08:46:38,666 Epoch 17384: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17385\n",
            "2025-06-26 08:46:38,668 EPOCH 17385\n",
            "INFO:__main__:Epoch 17385: total training loss 0.00091\n",
            "2025-06-26 08:46:38,739 Epoch 17385: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17386\n",
            "2025-06-26 08:46:38,741 EPOCH 17386\n",
            "INFO:__main__:Epoch 17386: total training loss 0.00091\n",
            "2025-06-26 08:46:38,811 Epoch 17386: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17387\n",
            "2025-06-26 08:46:38,813 EPOCH 17387\n",
            "INFO:__main__:Epoch 17387: total training loss 0.00087\n",
            "2025-06-26 08:46:38,885 Epoch 17387: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17388\n",
            "2025-06-26 08:46:38,887 EPOCH 17388\n",
            "INFO:__main__:Epoch 17388: total training loss 0.00089\n",
            "2025-06-26 08:46:38,956 Epoch 17388: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17389\n",
            "2025-06-26 08:46:38,957 EPOCH 17389\n",
            "INFO:__main__:Epoch 17389: total training loss 0.00090\n",
            "2025-06-26 08:46:39,030 Epoch 17389: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17390\n",
            "2025-06-26 08:46:39,032 EPOCH 17390\n",
            "INFO:__main__:Epoch 17390: total training loss 0.00090\n",
            "2025-06-26 08:46:39,116 Epoch 17390: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17391\n",
            "2025-06-26 08:46:39,119 EPOCH 17391\n",
            "INFO:__main__:Epoch 17391: total training loss 0.00087\n",
            "2025-06-26 08:46:39,194 Epoch 17391: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17392\n",
            "2025-06-26 08:46:39,196 EPOCH 17392\n",
            "INFO:__main__:Epoch 17392: total training loss 0.00085\n",
            "2025-06-26 08:46:39,268 Epoch 17392: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17393\n",
            "2025-06-26 08:46:39,270 EPOCH 17393\n",
            "INFO:__main__:Epoch 17393: total training loss 0.00083\n",
            "2025-06-26 08:46:39,345 Epoch 17393: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17394\n",
            "2025-06-26 08:46:39,347 EPOCH 17394\n",
            "INFO:__main__:Epoch 17394: total training loss 0.00081\n",
            "2025-06-26 08:46:39,425 Epoch 17394: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17395\n",
            "2025-06-26 08:46:39,427 EPOCH 17395\n",
            "INFO:__main__:Epoch 17395: total training loss 0.00084\n",
            "2025-06-26 08:46:39,498 Epoch 17395: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17396\n",
            "2025-06-26 08:46:39,502 EPOCH 17396\n",
            "INFO:__main__:Epoch 17396: total training loss 0.00081\n",
            "2025-06-26 08:46:39,577 Epoch 17396: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17397\n",
            "2025-06-26 08:46:39,579 EPOCH 17397\n",
            "INFO:__main__:Epoch 17397: total training loss 0.00080\n",
            "2025-06-26 08:46:39,667 Epoch 17397: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17398\n",
            "2025-06-26 08:46:39,669 EPOCH 17398\n",
            "INFO:__main__:Epoch 17398: total training loss 0.00076\n",
            "2025-06-26 08:46:39,766 Epoch 17398: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17399\n",
            "2025-06-26 08:46:39,775 EPOCH 17399\n",
            "INFO:__main__:Epoch 17399: total training loss 0.00081\n",
            "2025-06-26 08:46:39,851 Epoch 17399: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17400\n",
            "2025-06-26 08:46:39,853 EPOCH 17400\n",
            "INFO:__main__:Epoch 17400: total training loss 0.00088\n",
            "2025-06-26 08:46:39,932 Epoch 17400: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17401\n",
            "2025-06-26 08:46:39,937 EPOCH 17401\n",
            "INFO:__main__:Epoch 17401: total training loss 0.00090\n",
            "2025-06-26 08:46:40,009 Epoch 17401: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17402\n",
            "2025-06-26 08:46:40,011 EPOCH 17402\n",
            "INFO:__main__:Epoch 17402: total training loss 0.00086\n",
            "2025-06-26 08:46:40,091 Epoch 17402: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17403\n",
            "2025-06-26 08:46:40,093 EPOCH 17403\n",
            "INFO:__main__:Epoch 17403: total training loss 0.00083\n",
            "2025-06-26 08:46:40,187 Epoch 17403: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17404\n",
            "2025-06-26 08:46:40,191 EPOCH 17404\n",
            "INFO:__main__:Epoch 17404: total training loss 0.00084\n",
            "2025-06-26 08:46:40,272 Epoch 17404: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17405\n",
            "2025-06-26 08:46:40,275 EPOCH 17405\n",
            "INFO:__main__:Epoch 17405: total training loss 0.00086\n",
            "2025-06-26 08:46:40,348 Epoch 17405: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17406\n",
            "2025-06-26 08:46:40,352 EPOCH 17406\n",
            "INFO:__main__:Epoch 17406: total training loss 0.00085\n",
            "2025-06-26 08:46:40,429 Epoch 17406: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17407\n",
            "2025-06-26 08:46:40,433 EPOCH 17407\n",
            "INFO:__main__:Epoch 17407: total training loss 0.00082\n",
            "2025-06-26 08:46:40,508 Epoch 17407: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17408\n",
            "2025-06-26 08:46:40,510 EPOCH 17408\n",
            "INFO:__main__:Epoch 17408: total training loss 0.00087\n",
            "2025-06-26 08:46:40,584 Epoch 17408: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17409\n",
            "2025-06-26 08:46:40,587 EPOCH 17409\n",
            "INFO:__main__:Epoch 17409: total training loss 0.00090\n",
            "2025-06-26 08:46:40,659 Epoch 17409: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17410\n",
            "2025-06-26 08:46:40,662 EPOCH 17410\n",
            "INFO:__main__:Epoch 17410: total training loss 0.00086\n",
            "2025-06-26 08:46:40,734 Epoch 17410: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17411\n",
            "2025-06-26 08:46:40,738 EPOCH 17411\n",
            "INFO:__main__:Epoch 17411: total training loss 0.00090\n",
            "2025-06-26 08:46:40,812 Epoch 17411: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17412\n",
            "2025-06-26 08:46:40,814 EPOCH 17412\n",
            "INFO:__main__:Epoch 17412: total training loss 0.00090\n",
            "2025-06-26 08:46:40,888 Epoch 17412: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17413\n",
            "2025-06-26 08:46:40,890 EPOCH 17413\n",
            "INFO:__main__:Epoch 17413: total training loss 0.00086\n",
            "2025-06-26 08:46:40,968 Epoch 17413: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17414\n",
            "2025-06-26 08:46:40,970 EPOCH 17414\n",
            "INFO:__main__:Epoch 17414: total training loss 0.00094\n",
            "2025-06-26 08:46:41,044 Epoch 17414: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17415\n",
            "2025-06-26 08:46:41,046 EPOCH 17415\n",
            "INFO:__main__:Epoch 17415: total training loss 0.00092\n",
            "2025-06-26 08:46:41,122 Epoch 17415: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17416\n",
            "2025-06-26 08:46:41,125 EPOCH 17416\n",
            "INFO:__main__:Epoch 17416: total training loss 0.00087\n",
            "2025-06-26 08:46:41,200 Epoch 17416: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17417\n",
            "2025-06-26 08:46:41,204 EPOCH 17417\n",
            "INFO:__main__:Epoch 17417: total training loss 0.00089\n",
            "2025-06-26 08:46:41,286 Epoch 17417: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17418\n",
            "2025-06-26 08:46:41,288 EPOCH 17418\n",
            "INFO:__main__:Epoch 17418: total training loss 0.00085\n",
            "2025-06-26 08:46:41,359 Epoch 17418: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17419\n",
            "2025-06-26 08:46:41,362 EPOCH 17419\n",
            "INFO:__main__:Epoch 17419: total training loss 0.00086\n",
            "2025-06-26 08:46:41,434 Epoch 17419: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17420\n",
            "2025-06-26 08:46:41,436 EPOCH 17420\n",
            "INFO:__main__:Epoch 17420: total training loss 0.00086\n",
            "2025-06-26 08:46:41,506 Epoch 17420: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17421\n",
            "2025-06-26 08:46:41,508 EPOCH 17421\n",
            "INFO:__main__:Epoch 17421: total training loss 0.00083\n",
            "2025-06-26 08:46:41,583 Epoch 17421: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17422\n",
            "2025-06-26 08:46:41,585 EPOCH 17422\n",
            "INFO:__main__:Epoch 17422: total training loss 0.00084\n",
            "2025-06-26 08:46:41,657 Epoch 17422: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17423\n",
            "2025-06-26 08:46:41,659 EPOCH 17423\n",
            "INFO:__main__:Epoch 17423: total training loss 0.00083\n",
            "2025-06-26 08:46:41,730 Epoch 17423: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17424\n",
            "2025-06-26 08:46:41,732 EPOCH 17424\n",
            "INFO:__main__:Epoch 17424: total training loss 0.00082\n",
            "2025-06-26 08:46:41,803 Epoch 17424: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17425\n",
            "2025-06-26 08:46:41,805 EPOCH 17425\n",
            "INFO:__main__:Epoch 17425: total training loss 0.00081\n",
            "2025-06-26 08:46:41,878 Epoch 17425: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17426\n",
            "2025-06-26 08:46:41,880 EPOCH 17426\n",
            "INFO:__main__:Epoch 17426: total training loss 0.00081\n",
            "2025-06-26 08:46:41,955 Epoch 17426: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17427\n",
            "2025-06-26 08:46:41,957 EPOCH 17427\n",
            "INFO:__main__:Epoch 17427: total training loss 0.00082\n",
            "2025-06-26 08:46:42,031 Epoch 17427: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17428\n",
            "2025-06-26 08:46:42,033 EPOCH 17428\n",
            "INFO:__main__:Epoch 17428: total training loss 0.00077\n",
            "2025-06-26 08:46:42,106 Epoch 17428: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17429\n",
            "2025-06-26 08:46:42,108 EPOCH 17429\n",
            "INFO:__main__:Epoch 17429: total training loss 0.00079\n",
            "2025-06-26 08:46:42,196 Epoch 17429: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17430\n",
            "2025-06-26 08:46:42,205 EPOCH 17430\n",
            "INFO:__main__:Epoch 17430: total training loss 0.00086\n",
            "2025-06-26 08:46:42,287 Epoch 17430: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17431\n",
            "2025-06-26 08:46:42,290 EPOCH 17431\n",
            "INFO:__main__:Epoch 17431: total training loss 0.00080\n",
            "2025-06-26 08:46:42,408 Epoch 17431: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17432\n",
            "2025-06-26 08:46:42,413 EPOCH 17432\n",
            "INFO:__main__:Epoch 17432: total training loss 0.00083\n",
            "2025-06-26 08:46:42,506 Epoch 17432: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17433\n",
            "2025-06-26 08:46:42,507 EPOCH 17433\n",
            "INFO:__main__:Epoch 17433: total training loss 0.00093\n",
            "2025-06-26 08:46:42,591 Epoch 17433: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17434\n",
            "2025-06-26 08:46:42,598 EPOCH 17434\n",
            "INFO:__main__:Epoch 17434: total training loss 0.00089\n",
            "2025-06-26 08:46:42,710 Epoch 17434: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17435\n",
            "2025-06-26 08:46:42,712 EPOCH 17435\n",
            "INFO:__main__:Epoch 17435: total training loss 0.00096\n",
            "2025-06-26 08:46:42,829 Epoch 17435: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17436\n",
            "2025-06-26 08:46:42,835 EPOCH 17436\n",
            "INFO:__main__:Epoch 17436: total training loss 0.00108\n",
            "2025-06-26 08:46:42,951 Epoch 17436: total training loss 0.00108\n",
            "INFO:__main__:EPOCH 17437\n",
            "2025-06-26 08:46:42,955 EPOCH 17437\n",
            "INFO:__main__:Epoch 17437: total training loss 0.00109\n",
            "2025-06-26 08:46:43,058 Epoch 17437: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 17438\n",
            "2025-06-26 08:46:43,062 EPOCH 17438\n",
            "INFO:__main__:Epoch 17438: total training loss 0.00110\n",
            "2025-06-26 08:46:43,170 Epoch 17438: total training loss 0.00110\n",
            "INFO:__main__:EPOCH 17439\n",
            "2025-06-26 08:46:43,174 EPOCH 17439\n",
            "INFO:__main__:Epoch 17439: total training loss 0.00094\n",
            "2025-06-26 08:46:43,291 Epoch 17439: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17440\n",
            "2025-06-26 08:46:43,293 EPOCH 17440\n",
            "INFO:__main__:Epoch 17440: total training loss 0.00097\n",
            "2025-06-26 08:46:43,400 Epoch 17440: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17441\n",
            "2025-06-26 08:46:43,405 EPOCH 17441\n",
            "INFO:__main__:Epoch 17441: total training loss 0.00098\n",
            "2025-06-26 08:46:43,526 Epoch 17441: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17442\n",
            "2025-06-26 08:46:43,528 EPOCH 17442\n",
            "INFO:__main__:Epoch 17442: total training loss 0.00097\n",
            "2025-06-26 08:46:43,646 Epoch 17442: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17443\n",
            "2025-06-26 08:46:43,648 EPOCH 17443\n",
            "INFO:__main__:Epoch 17443: total training loss 0.00093\n",
            "2025-06-26 08:46:43,769 Epoch 17443: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17444\n",
            "2025-06-26 08:46:43,772 EPOCH 17444\n",
            "INFO:__main__:Epoch 17444: total training loss 0.00100\n",
            "2025-06-26 08:46:43,870 Epoch 17444: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17445\n",
            "2025-06-26 08:46:43,872 EPOCH 17445\n",
            "INFO:__main__:Epoch 17445: total training loss 0.00093\n",
            "2025-06-26 08:46:43,961 Epoch 17445: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17446\n",
            "2025-06-26 08:46:43,963 EPOCH 17446\n",
            "INFO:__main__:Epoch 17446: total training loss 0.00089\n",
            "2025-06-26 08:46:44,050 Epoch 17446: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17447\n",
            "2025-06-26 08:46:44,052 EPOCH 17447\n",
            "INFO:__main__:Epoch 17447: total training loss 0.00090\n",
            "2025-06-26 08:46:44,155 Epoch 17447: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17448\n",
            "2025-06-26 08:46:44,157 EPOCH 17448\n",
            "INFO:__main__:Epoch 17448: total training loss 0.00089\n",
            "2025-06-26 08:46:44,260 Epoch 17448: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17449\n",
            "2025-06-26 08:46:44,264 EPOCH 17449\n",
            "INFO:__main__:Epoch 17449: total training loss 0.00088\n",
            "2025-06-26 08:46:44,354 Epoch 17449: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17450\n",
            "2025-06-26 08:46:44,361 EPOCH 17450\n",
            "INFO:__main__:Epoch 17450: total training loss 0.00085\n",
            "2025-06-26 08:46:44,461 Epoch 17450: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17451\n",
            "2025-06-26 08:46:44,466 EPOCH 17451\n",
            "INFO:__main__:Epoch 17451: total training loss 0.00084\n",
            "2025-06-26 08:46:44,559 Epoch 17451: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17452\n",
            "2025-06-26 08:46:44,567 EPOCH 17452\n",
            "INFO:__main__:Epoch 17452: total training loss 0.00081\n",
            "2025-06-26 08:46:44,646 Epoch 17452: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17453\n",
            "2025-06-26 08:46:44,653 EPOCH 17453\n",
            "INFO:__main__:Epoch 17453: total training loss 0.00083\n",
            "2025-06-26 08:46:44,744 Epoch 17453: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17454\n",
            "2025-06-26 08:46:44,749 EPOCH 17454\n",
            "INFO:__main__:Epoch 17454: total training loss 0.00083\n",
            "2025-06-26 08:46:44,842 Epoch 17454: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17455\n",
            "2025-06-26 08:46:44,849 EPOCH 17455\n",
            "INFO:__main__:Epoch 17455: total training loss 0.00084\n",
            "2025-06-26 08:46:44,929 Epoch 17455: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17456\n",
            "2025-06-26 08:46:44,936 EPOCH 17456\n",
            "INFO:__main__:Epoch 17456: total training loss 0.00081\n",
            "2025-06-26 08:46:45,026 Epoch 17456: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17457\n",
            "2025-06-26 08:46:45,031 EPOCH 17457\n",
            "INFO:__main__:Epoch 17457: total training loss 0.00085\n",
            "2025-06-26 08:46:45,121 Epoch 17457: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17458\n",
            "2025-06-26 08:46:45,128 EPOCH 17458\n",
            "INFO:__main__:Epoch 17458: total training loss 0.00084\n",
            "2025-06-26 08:46:45,213 Epoch 17458: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17459\n",
            "2025-06-26 08:46:45,218 EPOCH 17459\n",
            "INFO:__main__:Epoch 17459: total training loss 0.00083\n",
            "2025-06-26 08:46:45,298 Epoch 17459: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17460\n",
            "2025-06-26 08:46:45,300 EPOCH 17460\n",
            "INFO:__main__:Epoch 17460: total training loss 0.00086\n",
            "2025-06-26 08:46:45,418 Epoch 17460: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17461\n",
            "2025-06-26 08:46:45,420 EPOCH 17461\n",
            "INFO:__main__:Epoch 17461: total training loss 0.00088\n",
            "2025-06-26 08:46:45,530 Epoch 17461: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17462\n",
            "2025-06-26 08:46:45,532 EPOCH 17462\n",
            "INFO:__main__:Epoch 17462: total training loss 0.00089\n",
            "2025-06-26 08:46:45,652 Epoch 17462: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17463\n",
            "2025-06-26 08:46:45,655 EPOCH 17463\n",
            "INFO:__main__:Epoch 17463: total training loss 0.00086\n",
            "2025-06-26 08:46:45,759 Epoch 17463: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17464\n",
            "2025-06-26 08:46:45,763 EPOCH 17464\n",
            "INFO:__main__:Epoch 17464: total training loss 0.00080\n",
            "2025-06-26 08:46:45,877 Epoch 17464: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17465\n",
            "2025-06-26 08:46:45,878 EPOCH 17465\n",
            "INFO:__main__:Epoch 17465: total training loss 0.00085\n",
            "2025-06-26 08:46:45,991 Epoch 17465: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17466\n",
            "2025-06-26 08:46:45,995 EPOCH 17466\n",
            "INFO:__main__:Epoch 17466: total training loss 0.00084\n",
            "2025-06-26 08:46:46,107 Epoch 17466: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17467\n",
            "2025-06-26 08:46:46,112 EPOCH 17467\n",
            "INFO:__main__:Epoch 17467: total training loss 0.00082\n",
            "2025-06-26 08:46:46,223 Epoch 17467: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17468\n",
            "2025-06-26 08:46:46,227 EPOCH 17468\n",
            "INFO:__main__:Epoch 17468: total training loss 0.00083\n",
            "2025-06-26 08:46:46,344 Epoch 17468: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17469\n",
            "2025-06-26 08:46:46,350 EPOCH 17469\n",
            "INFO:__main__:Epoch 17469: total training loss 0.00084\n",
            "2025-06-26 08:46:46,431 Epoch 17469: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17470\n",
            "2025-06-26 08:46:46,438 EPOCH 17470\n",
            "INFO:__main__:Epoch 17470: total training loss 0.00089\n",
            "2025-06-26 08:46:46,543 Epoch 17470: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17471\n",
            "2025-06-26 08:46:46,545 EPOCH 17471\n",
            "INFO:__main__:Epoch 17471: total training loss 0.00085\n",
            "2025-06-26 08:46:46,651 Epoch 17471: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17472\n",
            "2025-06-26 08:46:46,655 EPOCH 17472\n",
            "INFO:__main__:Epoch 17472: total training loss 0.00086\n",
            "2025-06-26 08:46:46,757 Epoch 17472: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17473\n",
            "2025-06-26 08:46:46,759 EPOCH 17473\n",
            "INFO:__main__:Epoch 17473: total training loss 0.00091\n",
            "2025-06-26 08:46:46,836 Epoch 17473: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17474\n",
            "2025-06-26 08:46:46,838 EPOCH 17474\n",
            "INFO:__main__:Epoch 17474: total training loss 0.00090\n",
            "2025-06-26 08:46:46,945 Epoch 17474: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17475\n",
            "2025-06-26 08:46:46,949 EPOCH 17475\n",
            "INFO:__main__:Epoch 17475: total training loss 0.00091\n",
            "2025-06-26 08:46:47,060 Epoch 17475: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17476\n",
            "2025-06-26 08:46:47,062 EPOCH 17476\n",
            "INFO:__main__:Epoch 17476: total training loss 0.00083\n",
            "2025-06-26 08:46:47,180 Epoch 17476: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17477\n",
            "2025-06-26 08:46:47,189 EPOCH 17477\n",
            "INFO:__main__:Epoch 17477: total training loss 0.00086\n",
            "2025-06-26 08:46:47,290 Epoch 17477: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17478\n",
            "2025-06-26 08:46:47,293 EPOCH 17478\n",
            "INFO:__main__:Epoch 17478: total training loss 0.00086\n",
            "2025-06-26 08:46:47,376 Epoch 17478: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17479\n",
            "2025-06-26 08:46:47,378 EPOCH 17479\n",
            "INFO:__main__:Epoch 17479: total training loss 0.00088\n",
            "2025-06-26 08:46:47,456 Epoch 17479: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17480\n",
            "2025-06-26 08:46:47,460 EPOCH 17480\n",
            "INFO:__main__:Epoch 17480: total training loss 0.00090\n",
            "2025-06-26 08:46:47,532 Epoch 17480: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17481\n",
            "2025-06-26 08:46:47,534 EPOCH 17481\n",
            "INFO:__main__:Epoch 17481: total training loss 0.00086\n",
            "2025-06-26 08:46:47,617 Epoch 17481: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17482\n",
            "2025-06-26 08:46:47,619 EPOCH 17482\n",
            "INFO:__main__:Epoch 17482: total training loss 0.00087\n",
            "2025-06-26 08:46:47,688 Epoch 17482: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17483\n",
            "2025-06-26 08:46:47,690 EPOCH 17483\n",
            "INFO:__main__:Epoch 17483: total training loss 0.00088\n",
            "2025-06-26 08:46:47,771 Epoch 17483: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17484\n",
            "2025-06-26 08:46:47,773 EPOCH 17484\n",
            "INFO:__main__:Epoch 17484: total training loss 0.00086\n",
            "2025-06-26 08:46:47,859 Epoch 17484: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17485\n",
            "2025-06-26 08:46:47,861 EPOCH 17485\n",
            "INFO:__main__:Epoch 17485: total training loss 0.00087\n",
            "2025-06-26 08:46:47,933 Epoch 17485: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17486\n",
            "2025-06-26 08:46:47,935 EPOCH 17486\n",
            "INFO:__main__:Epoch 17486: total training loss 0.00090\n",
            "2025-06-26 08:46:48,004 Epoch 17486: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17487\n",
            "2025-06-26 08:46:48,006 EPOCH 17487\n",
            "INFO:__main__:Epoch 17487: total training loss 0.00099\n",
            "2025-06-26 08:46:48,082 Epoch 17487: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17488\n",
            "2025-06-26 08:46:48,084 EPOCH 17488\n",
            "INFO:__main__:Epoch 17488: total training loss 0.00090\n",
            "2025-06-26 08:46:48,158 Epoch 17488: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17489\n",
            "2025-06-26 08:46:48,160 EPOCH 17489\n",
            "INFO:__main__:Epoch 17489: total training loss 0.00094\n",
            "2025-06-26 08:46:48,234 Epoch 17489: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17490\n",
            "2025-06-26 08:46:48,236 EPOCH 17490\n",
            "INFO:__main__:Epoch 17490: total training loss 0.00095\n",
            "2025-06-26 08:46:48,305 Epoch 17490: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17491\n",
            "2025-06-26 08:46:48,307 EPOCH 17491\n",
            "INFO:__main__:Epoch 17491: total training loss 0.00092\n",
            "2025-06-26 08:46:48,379 Epoch 17491: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17492\n",
            "2025-06-26 08:46:48,381 EPOCH 17492\n",
            "INFO:__main__:Epoch 17492: total training loss 0.00085\n",
            "2025-06-26 08:46:48,453 Epoch 17492: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17493\n",
            "2025-06-26 08:46:48,455 EPOCH 17493\n",
            "INFO:__main__:Epoch 17493: total training loss 0.00095\n",
            "2025-06-26 08:46:48,527 Epoch 17493: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17494\n",
            "2025-06-26 08:46:48,529 EPOCH 17494\n",
            "INFO:__main__:Epoch 17494: total training loss 0.00095\n",
            "2025-06-26 08:46:48,602 Epoch 17494: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17495\n",
            "2025-06-26 08:46:48,604 EPOCH 17495\n",
            "INFO:__main__:Epoch 17495: total training loss 0.00094\n",
            "2025-06-26 08:46:48,675 Epoch 17495: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17496\n",
            "2025-06-26 08:46:48,676 EPOCH 17496\n",
            "INFO:__main__:Epoch 17496: total training loss 0.00094\n",
            "2025-06-26 08:46:48,752 Epoch 17496: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17497\n",
            "2025-06-26 08:46:48,754 EPOCH 17497\n",
            "INFO:__main__:Epoch 17497: total training loss 0.00095\n",
            "2025-06-26 08:46:48,848 Epoch 17497: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17498\n",
            "2025-06-26 08:46:48,850 EPOCH 17498\n",
            "INFO:__main__:Epoch 17498: total training loss 0.00088\n",
            "2025-06-26 08:46:48,929 Epoch 17498: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17499\n",
            "2025-06-26 08:46:48,931 EPOCH 17499\n",
            "INFO:__main__:Epoch 17499: total training loss 0.00099\n",
            "2025-06-26 08:46:49,002 Epoch 17499: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17500\n",
            "2025-06-26 08:46:49,004 EPOCH 17500\n",
            "INFO:__main__:Epoch 17500 Step:    17500 Batch Loss:     0.000922 Tokens per Sec:  2052459, Lr: 0.001000\n",
            "2025-06-26 08:46:49,074 Epoch 17500 Step:    17500 Batch Loss:     0.000922 Tokens per Sec:  2052459, Lr: 0.001000\n",
            "INFO:__main__:Epoch 17500: total training loss 0.00092\n",
            "2025-06-26 08:46:49,078 Epoch 17500: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17501\n",
            "2025-06-26 08:46:49,081 EPOCH 17501\n",
            "INFO:__main__:Epoch 17501: total training loss 0.00093\n",
            "2025-06-26 08:46:49,173 Epoch 17501: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17502\n",
            "2025-06-26 08:46:49,175 EPOCH 17502\n",
            "INFO:__main__:Epoch 17502: total training loss 0.00100\n",
            "2025-06-26 08:46:49,247 Epoch 17502: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17503\n",
            "2025-06-26 08:46:49,249 EPOCH 17503\n",
            "INFO:__main__:Epoch 17503: total training loss 0.00089\n",
            "2025-06-26 08:46:49,321 Epoch 17503: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17504\n",
            "2025-06-26 08:46:49,323 EPOCH 17504\n",
            "INFO:__main__:Epoch 17504: total training loss 0.00090\n",
            "2025-06-26 08:46:49,395 Epoch 17504: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17505\n",
            "2025-06-26 08:46:49,399 EPOCH 17505\n",
            "INFO:__main__:Epoch 17505: total training loss 0.00093\n",
            "2025-06-26 08:46:49,473 Epoch 17505: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17506\n",
            "2025-06-26 08:46:49,475 EPOCH 17506\n",
            "INFO:__main__:Epoch 17506: total training loss 0.00090\n",
            "2025-06-26 08:46:49,548 Epoch 17506: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17507\n",
            "2025-06-26 08:46:49,550 EPOCH 17507\n",
            "INFO:__main__:Epoch 17507: total training loss 0.00088\n",
            "2025-06-26 08:46:49,621 Epoch 17507: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17508\n",
            "2025-06-26 08:46:49,624 EPOCH 17508\n",
            "INFO:__main__:Epoch 17508: total training loss 0.00087\n",
            "2025-06-26 08:46:49,696 Epoch 17508: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17509\n",
            "2025-06-26 08:46:49,698 EPOCH 17509\n",
            "INFO:__main__:Epoch 17509: total training loss 0.00081\n",
            "2025-06-26 08:46:49,773 Epoch 17509: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17510\n",
            "2025-06-26 08:46:49,775 EPOCH 17510\n",
            "INFO:__main__:Epoch 17510: total training loss 0.00088\n",
            "2025-06-26 08:46:49,845 Epoch 17510: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17511\n",
            "2025-06-26 08:46:49,847 EPOCH 17511\n",
            "INFO:__main__:Epoch 17511: total training loss 0.00084\n",
            "2025-06-26 08:46:49,937 Epoch 17511: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17512\n",
            "2025-06-26 08:46:49,939 EPOCH 17512\n",
            "INFO:__main__:Epoch 17512: total training loss 0.00083\n",
            "2025-06-26 08:46:50,022 Epoch 17512: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17513\n",
            "2025-06-26 08:46:50,025 EPOCH 17513\n",
            "INFO:__main__:Epoch 17513: total training loss 0.00088\n",
            "2025-06-26 08:46:50,101 Epoch 17513: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17514\n",
            "2025-06-26 08:46:50,103 EPOCH 17514\n",
            "INFO:__main__:Epoch 17514: total training loss 0.00083\n",
            "2025-06-26 08:46:50,174 Epoch 17514: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17515\n",
            "2025-06-26 08:46:50,176 EPOCH 17515\n",
            "INFO:__main__:Epoch 17515: total training loss 0.00081\n",
            "2025-06-26 08:46:50,248 Epoch 17515: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17516\n",
            "2025-06-26 08:46:50,250 EPOCH 17516\n",
            "INFO:__main__:Epoch 17516: total training loss 0.00084\n",
            "2025-06-26 08:46:50,320 Epoch 17516: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17517\n",
            "2025-06-26 08:46:50,322 EPOCH 17517\n",
            "INFO:__main__:Epoch 17517: total training loss 0.00083\n",
            "2025-06-26 08:46:50,399 Epoch 17517: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17518\n",
            "2025-06-26 08:46:50,401 EPOCH 17518\n",
            "INFO:__main__:Epoch 17518: total training loss 0.00077\n",
            "2025-06-26 08:46:50,470 Epoch 17518: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17519\n",
            "2025-06-26 08:46:50,472 EPOCH 17519\n",
            "INFO:__main__:Epoch 17519: total training loss 0.00081\n",
            "2025-06-26 08:46:50,548 Epoch 17519: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17520\n",
            "2025-06-26 08:46:50,550 EPOCH 17520\n",
            "INFO:__main__:Epoch 17520: total training loss 0.00087\n",
            "2025-06-26 08:46:50,622 Epoch 17520: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17521\n",
            "2025-06-26 08:46:50,624 EPOCH 17521\n",
            "INFO:__main__:Epoch 17521: total training loss 0.00081\n",
            "2025-06-26 08:46:50,694 Epoch 17521: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17522\n",
            "2025-06-26 08:46:50,696 EPOCH 17522\n",
            "INFO:__main__:Epoch 17522: total training loss 0.00090\n",
            "2025-06-26 08:46:50,772 Epoch 17522: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17523\n",
            "2025-06-26 08:46:50,774 EPOCH 17523\n",
            "INFO:__main__:Epoch 17523: total training loss 0.00088\n",
            "2025-06-26 08:46:50,846 Epoch 17523: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17524\n",
            "2025-06-26 08:46:50,848 EPOCH 17524\n",
            "INFO:__main__:Epoch 17524: total training loss 0.00087\n",
            "2025-06-26 08:46:50,917 Epoch 17524: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17525\n",
            "2025-06-26 08:46:50,919 EPOCH 17525\n",
            "INFO:__main__:Epoch 17525: total training loss 0.00086\n",
            "2025-06-26 08:46:50,998 Epoch 17525: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17526\n",
            "2025-06-26 08:46:51,001 EPOCH 17526\n",
            "INFO:__main__:Epoch 17526: total training loss 0.00087\n",
            "2025-06-26 08:46:51,078 Epoch 17526: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17527\n",
            "2025-06-26 08:46:51,081 EPOCH 17527\n",
            "INFO:__main__:Epoch 17527: total training loss 0.00088\n",
            "2025-06-26 08:46:51,154 Epoch 17527: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17528\n",
            "2025-06-26 08:46:51,157 EPOCH 17528\n",
            "INFO:__main__:Epoch 17528: total training loss 0.00086\n",
            "2025-06-26 08:46:51,237 Epoch 17528: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17529\n",
            "2025-06-26 08:46:51,239 EPOCH 17529\n",
            "INFO:__main__:Epoch 17529: total training loss 0.00084\n",
            "2025-06-26 08:46:51,318 Epoch 17529: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17530\n",
            "2025-06-26 08:46:51,319 EPOCH 17530\n",
            "INFO:__main__:Epoch 17530: total training loss 0.00088\n",
            "2025-06-26 08:46:51,399 Epoch 17530: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17531\n",
            "2025-06-26 08:46:51,401 EPOCH 17531\n",
            "INFO:__main__:Epoch 17531: total training loss 0.00091\n",
            "2025-06-26 08:46:51,482 Epoch 17531: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17532\n",
            "2025-06-26 08:46:51,484 EPOCH 17532\n",
            "INFO:__main__:Epoch 17532: total training loss 0.00088\n",
            "2025-06-26 08:46:51,560 Epoch 17532: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17533\n",
            "2025-06-26 08:46:51,565 EPOCH 17533\n",
            "INFO:__main__:Epoch 17533: total training loss 0.00082\n",
            "2025-06-26 08:46:51,644 Epoch 17533: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17534\n",
            "2025-06-26 08:46:51,648 EPOCH 17534\n",
            "INFO:__main__:Epoch 17534: total training loss 0.00086\n",
            "2025-06-26 08:46:51,720 Epoch 17534: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17535\n",
            "2025-06-26 08:46:51,722 EPOCH 17535\n",
            "INFO:__main__:Epoch 17535: total training loss 0.00087\n",
            "2025-06-26 08:46:51,805 Epoch 17535: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17536\n",
            "2025-06-26 08:46:51,807 EPOCH 17536\n",
            "INFO:__main__:Epoch 17536: total training loss 0.00086\n",
            "2025-06-26 08:46:51,883 Epoch 17536: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17537\n",
            "2025-06-26 08:46:51,887 EPOCH 17537\n",
            "INFO:__main__:Epoch 17537: total training loss 0.00087\n",
            "2025-06-26 08:46:51,964 Epoch 17537: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17538\n",
            "2025-06-26 08:46:51,966 EPOCH 17538\n",
            "INFO:__main__:Epoch 17538: total training loss 0.00082\n",
            "2025-06-26 08:46:52,039 Epoch 17538: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17539\n",
            "2025-06-26 08:46:52,041 EPOCH 17539\n",
            "INFO:__main__:Epoch 17539: total training loss 0.00076\n",
            "2025-06-26 08:46:52,133 Epoch 17539: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17540\n",
            "2025-06-26 08:46:52,136 EPOCH 17540\n",
            "INFO:__main__:Epoch 17540: total training loss 0.00080\n",
            "2025-06-26 08:46:52,216 Epoch 17540: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17541\n",
            "2025-06-26 08:46:52,218 EPOCH 17541\n",
            "INFO:__main__:Epoch 17541: total training loss 0.00086\n",
            "2025-06-26 08:46:52,288 Epoch 17541: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17542\n",
            "2025-06-26 08:46:52,290 EPOCH 17542\n",
            "INFO:__main__:Epoch 17542: total training loss 0.00085\n",
            "2025-06-26 08:46:52,361 Epoch 17542: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17543\n",
            "2025-06-26 08:46:52,364 EPOCH 17543\n",
            "INFO:__main__:Epoch 17543: total training loss 0.00089\n",
            "2025-06-26 08:46:52,439 Epoch 17543: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17544\n",
            "2025-06-26 08:46:52,440 EPOCH 17544\n",
            "INFO:__main__:Epoch 17544: total training loss 0.00090\n",
            "2025-06-26 08:46:52,511 Epoch 17544: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17545\n",
            "2025-06-26 08:46:52,513 EPOCH 17545\n",
            "INFO:__main__:Epoch 17545: total training loss 0.00079\n",
            "2025-06-26 08:46:52,590 Epoch 17545: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17546\n",
            "2025-06-26 08:46:52,592 EPOCH 17546\n",
            "INFO:__main__:Epoch 17546: total training loss 0.00088\n",
            "2025-06-26 08:46:52,670 Epoch 17546: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17547\n",
            "2025-06-26 08:46:52,672 EPOCH 17547\n",
            "INFO:__main__:Epoch 17547: total training loss 0.00088\n",
            "2025-06-26 08:46:52,742 Epoch 17547: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17548\n",
            "2025-06-26 08:46:52,744 EPOCH 17548\n",
            "INFO:__main__:Epoch 17548: total training loss 0.00089\n",
            "2025-06-26 08:46:52,817 Epoch 17548: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17549\n",
            "2025-06-26 08:46:52,819 EPOCH 17549\n",
            "INFO:__main__:Epoch 17549: total training loss 0.00089\n",
            "2025-06-26 08:46:52,892 Epoch 17549: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17550\n",
            "2025-06-26 08:46:52,894 EPOCH 17550\n",
            "INFO:__main__:Epoch 17550: total training loss 0.00085\n",
            "2025-06-26 08:46:52,963 Epoch 17550: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17551\n",
            "2025-06-26 08:46:52,965 EPOCH 17551\n",
            "INFO:__main__:Epoch 17551: total training loss 0.00085\n",
            "2025-06-26 08:46:53,039 Epoch 17551: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17552\n",
            "2025-06-26 08:46:53,041 EPOCH 17552\n",
            "INFO:__main__:Epoch 17552: total training loss 0.00082\n",
            "2025-06-26 08:46:53,115 Epoch 17552: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17553\n",
            "2025-06-26 08:46:53,117 EPOCH 17553\n",
            "INFO:__main__:Epoch 17553: total training loss 0.00084\n",
            "2025-06-26 08:46:53,209 Epoch 17553: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17554\n",
            "2025-06-26 08:46:53,212 EPOCH 17554\n",
            "INFO:__main__:Epoch 17554: total training loss 0.00086\n",
            "2025-06-26 08:46:53,291 Epoch 17554: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17555\n",
            "2025-06-26 08:46:53,293 EPOCH 17555\n",
            "INFO:__main__:Epoch 17555: total training loss 0.00088\n",
            "2025-06-26 08:46:53,366 Epoch 17555: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17556\n",
            "2025-06-26 08:46:53,368 EPOCH 17556\n",
            "INFO:__main__:Epoch 17556: total training loss 0.00086\n",
            "2025-06-26 08:46:53,442 Epoch 17556: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17557\n",
            "2025-06-26 08:46:53,444 EPOCH 17557\n",
            "INFO:__main__:Epoch 17557: total training loss 0.00080\n",
            "2025-06-26 08:46:53,515 Epoch 17557: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17558\n",
            "2025-06-26 08:46:53,517 EPOCH 17558\n",
            "INFO:__main__:Epoch 17558: total training loss 0.00088\n",
            "2025-06-26 08:46:53,588 Epoch 17558: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17559\n",
            "2025-06-26 08:46:53,590 EPOCH 17559\n",
            "INFO:__main__:Epoch 17559: total training loss 0.00091\n",
            "2025-06-26 08:46:53,661 Epoch 17559: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17560\n",
            "2025-06-26 08:46:53,663 EPOCH 17560\n",
            "INFO:__main__:Epoch 17560: total training loss 0.00089\n",
            "2025-06-26 08:46:53,733 Epoch 17560: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17561\n",
            "2025-06-26 08:46:53,735 EPOCH 17561\n",
            "INFO:__main__:Epoch 17561: total training loss 0.00091\n",
            "2025-06-26 08:46:53,806 Epoch 17561: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17562\n",
            "2025-06-26 08:46:53,808 EPOCH 17562\n",
            "INFO:__main__:Epoch 17562: total training loss 0.00096\n",
            "2025-06-26 08:46:53,878 Epoch 17562: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17563\n",
            "2025-06-26 08:46:53,879 EPOCH 17563\n",
            "INFO:__main__:Epoch 17563: total training loss 0.00087\n",
            "2025-06-26 08:46:53,955 Epoch 17563: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17564\n",
            "2025-06-26 08:46:53,958 EPOCH 17564\n",
            "INFO:__main__:Epoch 17564: total training loss 0.00089\n",
            "2025-06-26 08:46:54,027 Epoch 17564: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17565\n",
            "2025-06-26 08:46:54,029 EPOCH 17565\n",
            "INFO:__main__:Epoch 17565: total training loss 0.00092\n",
            "2025-06-26 08:46:54,100 Epoch 17565: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17566\n",
            "2025-06-26 08:46:54,102 EPOCH 17566\n",
            "INFO:__main__:Epoch 17566: total training loss 0.00089\n",
            "2025-06-26 08:46:54,174 Epoch 17566: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17567\n",
            "2025-06-26 08:46:54,176 EPOCH 17567\n",
            "INFO:__main__:Epoch 17567: total training loss 0.00103\n",
            "2025-06-26 08:46:54,283 Epoch 17567: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17568\n",
            "2025-06-26 08:46:54,285 EPOCH 17568\n",
            "INFO:__main__:Epoch 17568: total training loss 0.00095\n",
            "2025-06-26 08:46:54,366 Epoch 17568: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17569\n",
            "2025-06-26 08:46:54,369 EPOCH 17569\n",
            "INFO:__main__:Epoch 17569: total training loss 0.00092\n",
            "2025-06-26 08:46:54,442 Epoch 17569: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17570\n",
            "2025-06-26 08:46:54,444 EPOCH 17570\n",
            "INFO:__main__:Epoch 17570: total training loss 0.00094\n",
            "2025-06-26 08:46:54,517 Epoch 17570: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17571\n",
            "2025-06-26 08:46:54,520 EPOCH 17571\n",
            "INFO:__main__:Epoch 17571: total training loss 0.00096\n",
            "2025-06-26 08:46:54,593 Epoch 17571: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17572\n",
            "2025-06-26 08:46:54,595 EPOCH 17572\n",
            "INFO:__main__:Epoch 17572: total training loss 0.00092\n",
            "2025-06-26 08:46:54,664 Epoch 17572: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17573\n",
            "2025-06-26 08:46:54,666 EPOCH 17573\n",
            "INFO:__main__:Epoch 17573: total training loss 0.00090\n",
            "2025-06-26 08:46:54,736 Epoch 17573: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17574\n",
            "2025-06-26 08:46:54,738 EPOCH 17574\n",
            "INFO:__main__:Epoch 17574: total training loss 0.00090\n",
            "2025-06-26 08:46:54,812 Epoch 17574: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17575\n",
            "2025-06-26 08:46:54,814 EPOCH 17575\n",
            "INFO:__main__:Epoch 17575: total training loss 0.00094\n",
            "2025-06-26 08:46:54,886 Epoch 17575: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17576\n",
            "2025-06-26 08:46:54,888 EPOCH 17576\n",
            "INFO:__main__:Epoch 17576: total training loss 0.00084\n",
            "2025-06-26 08:46:54,963 Epoch 17576: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17577\n",
            "2025-06-26 08:46:54,965 EPOCH 17577\n",
            "INFO:__main__:Epoch 17577: total training loss 0.00092\n",
            "2025-06-26 08:46:55,034 Epoch 17577: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17578\n",
            "2025-06-26 08:46:55,036 EPOCH 17578\n",
            "INFO:__main__:Epoch 17578: total training loss 0.00081\n",
            "2025-06-26 08:46:55,113 Epoch 17578: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17579\n",
            "2025-06-26 08:46:55,115 EPOCH 17579\n",
            "INFO:__main__:Epoch 17579: total training loss 0.00085\n",
            "2025-06-26 08:46:55,187 Epoch 17579: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17580\n",
            "2025-06-26 08:46:55,189 EPOCH 17580\n",
            "INFO:__main__:Epoch 17580: total training loss 0.00084\n",
            "2025-06-26 08:46:55,258 Epoch 17580: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17581\n",
            "2025-06-26 08:46:55,260 EPOCH 17581\n",
            "INFO:__main__:Epoch 17581: total training loss 0.00083\n",
            "2025-06-26 08:46:55,340 Epoch 17581: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17582\n",
            "2025-06-26 08:46:55,343 EPOCH 17582\n",
            "INFO:__main__:Epoch 17582: total training loss 0.00085\n",
            "2025-06-26 08:46:55,416 Epoch 17582: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17583\n",
            "2025-06-26 08:46:55,418 EPOCH 17583\n",
            "INFO:__main__:Epoch 17583: total training loss 0.00085\n",
            "2025-06-26 08:46:55,487 Epoch 17583: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17584\n",
            "2025-06-26 08:46:55,489 EPOCH 17584\n",
            "INFO:__main__:Epoch 17584: total training loss 0.00085\n",
            "2025-06-26 08:46:55,557 Epoch 17584: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17585\n",
            "2025-06-26 08:46:55,560 EPOCH 17585\n",
            "INFO:__main__:Epoch 17585: total training loss 0.00084\n",
            "2025-06-26 08:46:55,629 Epoch 17585: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17586\n",
            "2025-06-26 08:46:55,632 EPOCH 17586\n",
            "INFO:__main__:Epoch 17586: total training loss 0.00080\n",
            "2025-06-26 08:46:55,704 Epoch 17586: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17587\n",
            "2025-06-26 08:46:55,706 EPOCH 17587\n",
            "INFO:__main__:Epoch 17587: total training loss 0.00080\n",
            "2025-06-26 08:46:55,778 Epoch 17587: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17588\n",
            "2025-06-26 08:46:55,780 EPOCH 17588\n",
            "INFO:__main__:Epoch 17588: total training loss 0.00081\n",
            "2025-06-26 08:46:55,850 Epoch 17588: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17589\n",
            "2025-06-26 08:46:55,853 EPOCH 17589\n",
            "INFO:__main__:Epoch 17589: total training loss 0.00083\n",
            "2025-06-26 08:46:55,922 Epoch 17589: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17590\n",
            "2025-06-26 08:46:55,924 EPOCH 17590\n",
            "INFO:__main__:Epoch 17590: total training loss 0.00088\n",
            "2025-06-26 08:46:55,996 Epoch 17590: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17591\n",
            "2025-06-26 08:46:55,998 EPOCH 17591\n",
            "INFO:__main__:Epoch 17591: total training loss 0.00083\n",
            "2025-06-26 08:46:56,067 Epoch 17591: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17592\n",
            "2025-06-26 08:46:56,069 EPOCH 17592\n",
            "INFO:__main__:Epoch 17592: total training loss 0.00089\n",
            "2025-06-26 08:46:56,140 Epoch 17592: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17593\n",
            "2025-06-26 08:46:56,142 EPOCH 17593\n",
            "INFO:__main__:Epoch 17593: total training loss 0.00087\n",
            "2025-06-26 08:46:56,215 Epoch 17593: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17594\n",
            "2025-06-26 08:46:56,217 EPOCH 17594\n",
            "INFO:__main__:Epoch 17594: total training loss 0.00082\n",
            "2025-06-26 08:46:56,289 Epoch 17594: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17595\n",
            "2025-06-26 08:46:56,291 EPOCH 17595\n",
            "INFO:__main__:Epoch 17595: total training loss 0.00080\n",
            "2025-06-26 08:46:56,368 Epoch 17595: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17596\n",
            "2025-06-26 08:46:56,373 EPOCH 17596\n",
            "INFO:__main__:Epoch 17596: total training loss 0.00079\n",
            "2025-06-26 08:46:56,462 Epoch 17596: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17597\n",
            "2025-06-26 08:46:56,464 EPOCH 17597\n",
            "INFO:__main__:Epoch 17597: total training loss 0.00079\n",
            "2025-06-26 08:46:56,536 Epoch 17597: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17598\n",
            "2025-06-26 08:46:56,539 EPOCH 17598\n",
            "INFO:__main__:Epoch 17598: total training loss 0.00079\n",
            "2025-06-26 08:46:56,613 Epoch 17598: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17599\n",
            "2025-06-26 08:46:56,616 EPOCH 17599\n",
            "INFO:__main__:Epoch 17599: total training loss 0.00077\n",
            "2025-06-26 08:46:56,688 Epoch 17599: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17600\n",
            "2025-06-26 08:46:56,691 EPOCH 17600\n",
            "INFO:__main__:Epoch 17600: total training loss 0.00085\n",
            "2025-06-26 08:46:56,764 Epoch 17600: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17601\n",
            "2025-06-26 08:46:56,768 EPOCH 17601\n",
            "INFO:__main__:Epoch 17601: total training loss 0.00086\n",
            "2025-06-26 08:46:56,842 Epoch 17601: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17602\n",
            "2025-06-26 08:46:56,845 EPOCH 17602\n",
            "INFO:__main__:Epoch 17602: total training loss 0.00080\n",
            "2025-06-26 08:46:56,919 Epoch 17602: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17603\n",
            "2025-06-26 08:46:56,922 EPOCH 17603\n",
            "INFO:__main__:Epoch 17603: total training loss 0.00080\n",
            "2025-06-26 08:46:56,995 Epoch 17603: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17604\n",
            "2025-06-26 08:46:56,998 EPOCH 17604\n",
            "INFO:__main__:Epoch 17604: total training loss 0.00079\n",
            "2025-06-26 08:46:57,072 Epoch 17604: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17605\n",
            "2025-06-26 08:46:57,077 EPOCH 17605\n",
            "INFO:__main__:Epoch 17605: total training loss 0.00077\n",
            "2025-06-26 08:46:57,155 Epoch 17605: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17606\n",
            "2025-06-26 08:46:57,157 EPOCH 17606\n",
            "INFO:__main__:Epoch 17606: total training loss 0.00075\n",
            "2025-06-26 08:46:57,237 Epoch 17606: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 17607\n",
            "2025-06-26 08:46:57,239 EPOCH 17607\n",
            "INFO:__main__:Epoch 17607: total training loss 0.00077\n",
            "2025-06-26 08:46:57,311 Epoch 17607: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17608\n",
            "2025-06-26 08:46:57,313 EPOCH 17608\n",
            "INFO:__main__:Epoch 17608: total training loss 0.00075\n",
            "2025-06-26 08:46:57,402 Epoch 17608: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 17609\n",
            "2025-06-26 08:46:57,404 EPOCH 17609\n",
            "INFO:__main__:Epoch 17609: total training loss 0.00076\n",
            "2025-06-26 08:46:57,495 Epoch 17609: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17610\n",
            "2025-06-26 08:46:57,498 EPOCH 17610\n",
            "INFO:__main__:Epoch 17610: total training loss 0.00077\n",
            "2025-06-26 08:46:57,591 Epoch 17610: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17611\n",
            "2025-06-26 08:46:57,595 EPOCH 17611\n",
            "INFO:__main__:Epoch 17611: total training loss 0.00082\n",
            "2025-06-26 08:46:57,682 Epoch 17611: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17612\n",
            "2025-06-26 08:46:57,687 EPOCH 17612\n",
            "INFO:__main__:Epoch 17612: total training loss 0.00091\n",
            "2025-06-26 08:46:57,772 Epoch 17612: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17613\n",
            "2025-06-26 08:46:57,778 EPOCH 17613\n",
            "INFO:__main__:Epoch 17613: total training loss 0.00103\n",
            "2025-06-26 08:46:57,864 Epoch 17613: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17614\n",
            "2025-06-26 08:46:57,868 EPOCH 17614\n",
            "INFO:__main__:Epoch 17614: total training loss 0.00103\n",
            "2025-06-26 08:46:57,941 Epoch 17614: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 17615\n",
            "2025-06-26 08:46:57,945 EPOCH 17615\n",
            "INFO:__main__:Epoch 17615: total training loss 0.00091\n",
            "2025-06-26 08:46:58,043 Epoch 17615: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17616\n",
            "2025-06-26 08:46:58,045 EPOCH 17616\n",
            "INFO:__main__:Epoch 17616: total training loss 0.00091\n",
            "2025-06-26 08:46:58,145 Epoch 17616: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17617\n",
            "2025-06-26 08:46:58,148 EPOCH 17617\n",
            "INFO:__main__:Epoch 17617: total training loss 0.00090\n",
            "2025-06-26 08:46:58,227 Epoch 17617: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17618\n",
            "2025-06-26 08:46:58,229 EPOCH 17618\n",
            "INFO:__main__:Epoch 17618: total training loss 0.00086\n",
            "2025-06-26 08:46:58,302 Epoch 17618: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17619\n",
            "2025-06-26 08:46:58,306 EPOCH 17619\n",
            "INFO:__main__:Epoch 17619: total training loss 0.00093\n",
            "2025-06-26 08:46:58,383 Epoch 17619: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17620\n",
            "2025-06-26 08:46:58,387 EPOCH 17620\n",
            "INFO:__main__:Epoch 17620: total training loss 0.00086\n",
            "2025-06-26 08:46:58,467 Epoch 17620: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17621\n",
            "2025-06-26 08:46:58,469 EPOCH 17621\n",
            "INFO:__main__:Epoch 17621: total training loss 0.00090\n",
            "2025-06-26 08:46:58,538 Epoch 17621: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17622\n",
            "2025-06-26 08:46:58,540 EPOCH 17622\n",
            "INFO:__main__:Epoch 17622: total training loss 0.00088\n",
            "2025-06-26 08:46:58,625 Epoch 17622: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17623\n",
            "2025-06-26 08:46:58,627 EPOCH 17623\n",
            "INFO:__main__:Epoch 17623: total training loss 0.00088\n",
            "2025-06-26 08:46:58,718 Epoch 17623: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17624\n",
            "2025-06-26 08:46:58,722 EPOCH 17624\n",
            "INFO:__main__:Epoch 17624: total training loss 0.00089\n",
            "2025-06-26 08:46:58,821 Epoch 17624: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17625\n",
            "2025-06-26 08:46:58,823 EPOCH 17625\n",
            "INFO:__main__:Epoch 17625: total training loss 0.00088\n",
            "2025-06-26 08:46:58,924 Epoch 17625: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17626\n",
            "2025-06-26 08:46:58,926 EPOCH 17626\n",
            "INFO:__main__:Epoch 17626: total training loss 0.00085\n",
            "2025-06-26 08:46:59,035 Epoch 17626: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17627\n",
            "2025-06-26 08:46:59,039 EPOCH 17627\n",
            "INFO:__main__:Epoch 17627: total training loss 0.00087\n",
            "2025-06-26 08:46:59,122 Epoch 17627: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17628\n",
            "2025-06-26 08:46:59,125 EPOCH 17628\n",
            "INFO:__main__:Epoch 17628: total training loss 0.00083\n",
            "2025-06-26 08:46:59,198 Epoch 17628: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17629\n",
            "2025-06-26 08:46:59,203 EPOCH 17629\n",
            "INFO:__main__:Epoch 17629: total training loss 0.00083\n",
            "2025-06-26 08:46:59,312 Epoch 17629: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17630\n",
            "2025-06-26 08:46:59,316 EPOCH 17630\n",
            "INFO:__main__:Epoch 17630: total training loss 0.00086\n",
            "2025-06-26 08:46:59,410 Epoch 17630: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17631\n",
            "2025-06-26 08:46:59,417 EPOCH 17631\n",
            "INFO:__main__:Epoch 17631: total training loss 0.00084\n",
            "2025-06-26 08:46:59,516 Epoch 17631: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17632\n",
            "2025-06-26 08:46:59,518 EPOCH 17632\n",
            "INFO:__main__:Epoch 17632: total training loss 0.00084\n",
            "2025-06-26 08:46:59,618 Epoch 17632: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17633\n",
            "2025-06-26 08:46:59,620 EPOCH 17633\n",
            "INFO:__main__:Epoch 17633: total training loss 0.00086\n",
            "2025-06-26 08:46:59,728 Epoch 17633: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17634\n",
            "2025-06-26 08:46:59,730 EPOCH 17634\n",
            "INFO:__main__:Epoch 17634: total training loss 0.00084\n",
            "2025-06-26 08:46:59,818 Epoch 17634: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17635\n",
            "2025-06-26 08:46:59,824 EPOCH 17635\n",
            "INFO:__main__:Epoch 17635: total training loss 0.00081\n",
            "2025-06-26 08:46:59,907 Epoch 17635: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17636\n",
            "2025-06-26 08:46:59,909 EPOCH 17636\n",
            "INFO:__main__:Epoch 17636: total training loss 0.00085\n",
            "2025-06-26 08:47:00,014 Epoch 17636: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17637\n",
            "2025-06-26 08:47:00,018 EPOCH 17637\n",
            "INFO:__main__:Epoch 17637: total training loss 0.00091\n",
            "2025-06-26 08:47:00,123 Epoch 17637: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17638\n",
            "2025-06-26 08:47:00,125 EPOCH 17638\n",
            "INFO:__main__:Epoch 17638: total training loss 0.00088\n",
            "2025-06-26 08:47:00,228 Epoch 17638: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17639\n",
            "2025-06-26 08:47:00,230 EPOCH 17639\n",
            "INFO:__main__:Epoch 17639: total training loss 0.00083\n",
            "2025-06-26 08:47:00,353 Epoch 17639: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17640\n",
            "2025-06-26 08:47:00,355 EPOCH 17640\n",
            "INFO:__main__:Epoch 17640: total training loss 0.00087\n",
            "2025-06-26 08:47:00,474 Epoch 17640: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17641\n",
            "2025-06-26 08:47:00,476 EPOCH 17641\n",
            "INFO:__main__:Epoch 17641: total training loss 0.00088\n",
            "2025-06-26 08:47:00,590 Epoch 17641: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17642\n",
            "2025-06-26 08:47:00,592 EPOCH 17642\n",
            "INFO:__main__:Epoch 17642: total training loss 0.00088\n",
            "2025-06-26 08:47:00,690 Epoch 17642: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17643\n",
            "2025-06-26 08:47:00,692 EPOCH 17643\n",
            "INFO:__main__:Epoch 17643: total training loss 0.00090\n",
            "2025-06-26 08:47:00,765 Epoch 17643: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17644\n",
            "2025-06-26 08:47:00,767 EPOCH 17644\n",
            "INFO:__main__:Epoch 17644: total training loss 0.00096\n",
            "2025-06-26 08:47:00,874 Epoch 17644: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17645\n",
            "2025-06-26 08:47:00,876 EPOCH 17645\n",
            "INFO:__main__:Epoch 17645: total training loss 0.00100\n",
            "2025-06-26 08:47:00,968 Epoch 17645: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17646\n",
            "2025-06-26 08:47:00,975 EPOCH 17646\n",
            "INFO:__main__:Epoch 17646: total training loss 0.00099\n",
            "2025-06-26 08:47:01,047 Epoch 17646: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17647\n",
            "2025-06-26 08:47:01,053 EPOCH 17647\n",
            "INFO:__main__:Epoch 17647: total training loss 0.00119\n",
            "2025-06-26 08:47:01,138 Epoch 17647: total training loss 0.00119\n",
            "INFO:__main__:EPOCH 17648\n",
            "2025-06-26 08:47:01,140 EPOCH 17648\n",
            "INFO:__main__:Epoch 17648: total training loss 0.00100\n",
            "2025-06-26 08:47:01,258 Epoch 17648: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17649\n",
            "2025-06-26 08:47:01,260 EPOCH 17649\n",
            "INFO:__main__:Epoch 17649: total training loss 0.00102\n",
            "2025-06-26 08:47:01,363 Epoch 17649: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 17650\n",
            "2025-06-26 08:47:01,365 EPOCH 17650\n",
            "INFO:__main__:Epoch 17650: total training loss 0.00096\n",
            "2025-06-26 08:47:01,461 Epoch 17650: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17651\n",
            "2025-06-26 08:47:01,463 EPOCH 17651\n",
            "INFO:__main__:Epoch 17651: total training loss 0.00098\n",
            "2025-06-26 08:47:01,559 Epoch 17651: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17652\n",
            "2025-06-26 08:47:01,562 EPOCH 17652\n",
            "INFO:__main__:Epoch 17652: total training loss 0.00094\n",
            "2025-06-26 08:47:01,648 Epoch 17652: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17653\n",
            "2025-06-26 08:47:01,653 EPOCH 17653\n",
            "INFO:__main__:Epoch 17653: total training loss 0.00094\n",
            "2025-06-26 08:47:01,749 Epoch 17653: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17654\n",
            "2025-06-26 08:47:01,751 EPOCH 17654\n",
            "INFO:__main__:Epoch 17654: total training loss 0.00094\n",
            "2025-06-26 08:47:01,837 Epoch 17654: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17655\n",
            "2025-06-26 08:47:01,839 EPOCH 17655\n",
            "INFO:__main__:Epoch 17655: total training loss 0.00089\n",
            "2025-06-26 08:47:01,928 Epoch 17655: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17656\n",
            "2025-06-26 08:47:01,930 EPOCH 17656\n",
            "INFO:__main__:Epoch 17656: total training loss 0.00099\n",
            "2025-06-26 08:47:02,030 Epoch 17656: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 17657\n",
            "2025-06-26 08:47:02,035 EPOCH 17657\n",
            "INFO:__main__:Epoch 17657: total training loss 0.00091\n",
            "2025-06-26 08:47:02,137 Epoch 17657: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17658\n",
            "2025-06-26 08:47:02,145 EPOCH 17658\n",
            "INFO:__main__:Epoch 17658: total training loss 0.00090\n",
            "2025-06-26 08:47:02,239 Epoch 17658: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17659\n",
            "2025-06-26 08:47:02,243 EPOCH 17659\n",
            "INFO:__main__:Epoch 17659: total training loss 0.00087\n",
            "2025-06-26 08:47:02,334 Epoch 17659: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17660\n",
            "2025-06-26 08:47:02,336 EPOCH 17660\n",
            "INFO:__main__:Epoch 17660: total training loss 0.00083\n",
            "2025-06-26 08:47:02,423 Epoch 17660: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17661\n",
            "2025-06-26 08:47:02,428 EPOCH 17661\n",
            "INFO:__main__:Epoch 17661: total training loss 0.00087\n",
            "2025-06-26 08:47:02,520 Epoch 17661: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17662\n",
            "2025-06-26 08:47:02,522 EPOCH 17662\n",
            "INFO:__main__:Epoch 17662: total training loss 0.00085\n",
            "2025-06-26 08:47:02,641 Epoch 17662: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17663\n",
            "2025-06-26 08:47:02,644 EPOCH 17663\n",
            "INFO:__main__:Epoch 17663: total training loss 0.00090\n",
            "2025-06-26 08:47:02,741 Epoch 17663: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17664\n",
            "2025-06-26 08:47:02,747 EPOCH 17664\n",
            "INFO:__main__:Epoch 17664: total training loss 0.00083\n",
            "2025-06-26 08:47:02,846 Epoch 17664: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17665\n",
            "2025-06-26 08:47:02,848 EPOCH 17665\n",
            "INFO:__main__:Epoch 17665: total training loss 0.00085\n",
            "2025-06-26 08:47:02,946 Epoch 17665: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17666\n",
            "2025-06-26 08:47:02,948 EPOCH 17666\n",
            "INFO:__main__:Epoch 17666: total training loss 0.00085\n",
            "2025-06-26 08:47:03,029 Epoch 17666: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17667\n",
            "2025-06-26 08:47:03,032 EPOCH 17667\n",
            "INFO:__main__:Epoch 17667: total training loss 0.00079\n",
            "2025-06-26 08:47:03,105 Epoch 17667: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17668\n",
            "2025-06-26 08:47:03,106 EPOCH 17668\n",
            "INFO:__main__:Epoch 17668: total training loss 0.00082\n",
            "2025-06-26 08:47:03,176 Epoch 17668: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17669\n",
            "2025-06-26 08:47:03,178 EPOCH 17669\n",
            "INFO:__main__:Epoch 17669: total training loss 0.00084\n",
            "2025-06-26 08:47:03,259 Epoch 17669: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17670\n",
            "2025-06-26 08:47:03,262 EPOCH 17670\n",
            "INFO:__main__:Epoch 17670: total training loss 0.00082\n",
            "2025-06-26 08:47:03,337 Epoch 17670: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17671\n",
            "2025-06-26 08:47:03,339 EPOCH 17671\n",
            "INFO:__main__:Epoch 17671: total training loss 0.00079\n",
            "2025-06-26 08:47:03,412 Epoch 17671: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17672\n",
            "2025-06-26 08:47:03,414 EPOCH 17672\n",
            "INFO:__main__:Epoch 17672: total training loss 0.00078\n",
            "2025-06-26 08:47:03,486 Epoch 17672: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17673\n",
            "2025-06-26 08:47:03,488 EPOCH 17673\n",
            "INFO:__main__:Epoch 17673: total training loss 0.00076\n",
            "2025-06-26 08:47:03,566 Epoch 17673: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17674\n",
            "2025-06-26 08:47:03,568 EPOCH 17674\n",
            "INFO:__main__:Epoch 17674: total training loss 0.00081\n",
            "2025-06-26 08:47:03,643 Epoch 17674: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17675\n",
            "2025-06-26 08:47:03,645 EPOCH 17675\n",
            "INFO:__main__:Epoch 17675: total training loss 0.00081\n",
            "2025-06-26 08:47:03,715 Epoch 17675: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17676\n",
            "2025-06-26 08:47:03,717 EPOCH 17676\n",
            "INFO:__main__:Epoch 17676: total training loss 0.00081\n",
            "2025-06-26 08:47:03,786 Epoch 17676: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17677\n",
            "2025-06-26 08:47:03,788 EPOCH 17677\n",
            "INFO:__main__:Epoch 17677: total training loss 0.00085\n",
            "2025-06-26 08:47:03,859 Epoch 17677: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17678\n",
            "2025-06-26 08:47:03,861 EPOCH 17678\n",
            "INFO:__main__:Epoch 17678: total training loss 0.00084\n",
            "2025-06-26 08:47:03,935 Epoch 17678: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17679\n",
            "2025-06-26 08:47:03,937 EPOCH 17679\n",
            "INFO:__main__:Epoch 17679: total training loss 0.00087\n",
            "2025-06-26 08:47:04,016 Epoch 17679: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17680\n",
            "2025-06-26 08:47:04,018 EPOCH 17680\n",
            "INFO:__main__:Epoch 17680: total training loss 0.00083\n",
            "2025-06-26 08:47:04,099 Epoch 17680: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17681\n",
            "2025-06-26 08:47:04,101 EPOCH 17681\n",
            "INFO:__main__:Epoch 17681: total training loss 0.00085\n",
            "2025-06-26 08:47:04,171 Epoch 17681: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17682\n",
            "2025-06-26 08:47:04,173 EPOCH 17682\n",
            "INFO:__main__:Epoch 17682: total training loss 0.00088\n",
            "2025-06-26 08:47:04,250 Epoch 17682: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17683\n",
            "2025-06-26 08:47:04,252 EPOCH 17683\n",
            "INFO:__main__:Epoch 17683: total training loss 0.00090\n",
            "2025-06-26 08:47:04,330 Epoch 17683: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17684\n",
            "2025-06-26 08:47:04,332 EPOCH 17684\n",
            "INFO:__main__:Epoch 17684: total training loss 0.00082\n",
            "2025-06-26 08:47:04,402 Epoch 17684: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17685\n",
            "2025-06-26 08:47:04,404 EPOCH 17685\n",
            "INFO:__main__:Epoch 17685: total training loss 0.00084\n",
            "2025-06-26 08:47:04,484 Epoch 17685: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17686\n",
            "2025-06-26 08:47:04,486 EPOCH 17686\n",
            "INFO:__main__:Epoch 17686: total training loss 0.00087\n",
            "2025-06-26 08:47:04,562 Epoch 17686: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17687\n",
            "2025-06-26 08:47:04,564 EPOCH 17687\n",
            "INFO:__main__:Epoch 17687: total training loss 0.00086\n",
            "2025-06-26 08:47:04,643 Epoch 17687: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17688\n",
            "2025-06-26 08:47:04,645 EPOCH 17688\n",
            "INFO:__main__:Epoch 17688: total training loss 0.00081\n",
            "2025-06-26 08:47:04,722 Epoch 17688: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17689\n",
            "2025-06-26 08:47:04,725 EPOCH 17689\n",
            "INFO:__main__:Epoch 17689: total training loss 0.00081\n",
            "2025-06-26 08:47:04,806 Epoch 17689: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17690\n",
            "2025-06-26 08:47:04,808 EPOCH 17690\n",
            "INFO:__main__:Epoch 17690: total training loss 0.00088\n",
            "2025-06-26 08:47:04,883 Epoch 17690: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17691\n",
            "2025-06-26 08:47:04,885 EPOCH 17691\n",
            "INFO:__main__:Epoch 17691: total training loss 0.00084\n",
            "2025-06-26 08:47:04,954 Epoch 17691: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17692\n",
            "2025-06-26 08:47:04,956 EPOCH 17692\n",
            "INFO:__main__:Epoch 17692: total training loss 0.00088\n",
            "2025-06-26 08:47:05,026 Epoch 17692: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17693\n",
            "2025-06-26 08:47:05,030 EPOCH 17693\n",
            "INFO:__main__:Epoch 17693: total training loss 0.00082\n",
            "2025-06-26 08:47:05,134 Epoch 17693: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17694\n",
            "2025-06-26 08:47:05,136 EPOCH 17694\n",
            "INFO:__main__:Epoch 17694: total training loss 0.00077\n",
            "2025-06-26 08:47:05,215 Epoch 17694: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17695\n",
            "2025-06-26 08:47:05,222 EPOCH 17695\n",
            "INFO:__main__:Epoch 17695: total training loss 0.00080\n",
            "2025-06-26 08:47:05,295 Epoch 17695: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17696\n",
            "2025-06-26 08:47:05,297 EPOCH 17696\n",
            "INFO:__main__:Epoch 17696: total training loss 0.00080\n",
            "2025-06-26 08:47:05,375 Epoch 17696: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17697\n",
            "2025-06-26 08:47:05,377 EPOCH 17697\n",
            "INFO:__main__:Epoch 17697: total training loss 0.00080\n",
            "2025-06-26 08:47:05,450 Epoch 17697: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17698\n",
            "2025-06-26 08:47:05,452 EPOCH 17698\n",
            "INFO:__main__:Epoch 17698: total training loss 0.00084\n",
            "2025-06-26 08:47:05,536 Epoch 17698: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17699\n",
            "2025-06-26 08:47:05,539 EPOCH 17699\n",
            "INFO:__main__:Epoch 17699: total training loss 0.00083\n",
            "2025-06-26 08:47:05,623 Epoch 17699: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17700\n",
            "2025-06-26 08:47:05,625 EPOCH 17700\n",
            "INFO:__main__:Epoch 17700: total training loss 0.00090\n",
            "2025-06-26 08:47:05,695 Epoch 17700: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17701\n",
            "2025-06-26 08:47:05,697 EPOCH 17701\n",
            "INFO:__main__:Epoch 17701: total training loss 0.00087\n",
            "2025-06-26 08:47:05,764 Epoch 17701: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17702\n",
            "2025-06-26 08:47:05,766 EPOCH 17702\n",
            "INFO:__main__:Epoch 17702: total training loss 0.00091\n",
            "2025-06-26 08:47:05,839 Epoch 17702: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17703\n",
            "2025-06-26 08:47:05,841 EPOCH 17703\n",
            "INFO:__main__:Epoch 17703: total training loss 0.00091\n",
            "2025-06-26 08:47:05,912 Epoch 17703: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17704\n",
            "2025-06-26 08:47:05,914 EPOCH 17704\n",
            "INFO:__main__:Epoch 17704: total training loss 0.00091\n",
            "2025-06-26 08:47:05,990 Epoch 17704: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17705\n",
            "2025-06-26 08:47:05,992 EPOCH 17705\n",
            "INFO:__main__:Epoch 17705: total training loss 0.00085\n",
            "2025-06-26 08:47:06,067 Epoch 17705: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17706\n",
            "2025-06-26 08:47:06,070 EPOCH 17706\n",
            "INFO:__main__:Epoch 17706: total training loss 0.00093\n",
            "2025-06-26 08:47:06,148 Epoch 17706: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17707\n",
            "2025-06-26 08:47:06,150 EPOCH 17707\n",
            "INFO:__main__:Epoch 17707: total training loss 0.00096\n",
            "2025-06-26 08:47:06,244 Epoch 17707: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17708\n",
            "2025-06-26 08:47:06,247 EPOCH 17708\n",
            "INFO:__main__:Epoch 17708: total training loss 0.00094\n",
            "2025-06-26 08:47:06,321 Epoch 17708: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17709\n",
            "2025-06-26 08:47:06,325 EPOCH 17709\n",
            "INFO:__main__:Epoch 17709: total training loss 0.00088\n",
            "2025-06-26 08:47:06,401 Epoch 17709: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17710\n",
            "2025-06-26 08:47:06,403 EPOCH 17710\n",
            "INFO:__main__:Epoch 17710: total training loss 0.00088\n",
            "2025-06-26 08:47:06,479 Epoch 17710: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17711\n",
            "2025-06-26 08:47:06,482 EPOCH 17711\n",
            "INFO:__main__:Epoch 17711: total training loss 0.00090\n",
            "2025-06-26 08:47:06,553 Epoch 17711: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17712\n",
            "2025-06-26 08:47:06,555 EPOCH 17712\n",
            "INFO:__main__:Epoch 17712: total training loss 0.00090\n",
            "2025-06-26 08:47:06,629 Epoch 17712: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17713\n",
            "2025-06-26 08:47:06,631 EPOCH 17713\n",
            "INFO:__main__:Epoch 17713: total training loss 0.00084\n",
            "2025-06-26 08:47:06,706 Epoch 17713: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17714\n",
            "2025-06-26 08:47:06,708 EPOCH 17714\n",
            "INFO:__main__:Epoch 17714: total training loss 0.00085\n",
            "2025-06-26 08:47:06,779 Epoch 17714: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17715\n",
            "2025-06-26 08:47:06,781 EPOCH 17715\n",
            "INFO:__main__:Epoch 17715: total training loss 0.00088\n",
            "2025-06-26 08:47:06,853 Epoch 17715: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17716\n",
            "2025-06-26 08:47:06,856 EPOCH 17716\n",
            "INFO:__main__:Epoch 17716: total training loss 0.00089\n",
            "2025-06-26 08:47:06,925 Epoch 17716: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17717\n",
            "2025-06-26 08:47:06,927 EPOCH 17717\n",
            "INFO:__main__:Epoch 17717: total training loss 0.00083\n",
            "2025-06-26 08:47:06,995 Epoch 17717: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17718\n",
            "2025-06-26 08:47:06,999 EPOCH 17718\n",
            "INFO:__main__:Epoch 17718: total training loss 0.00083\n",
            "2025-06-26 08:47:07,069 Epoch 17718: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17719\n",
            "2025-06-26 08:47:07,071 EPOCH 17719\n",
            "INFO:__main__:Epoch 17719: total training loss 0.00085\n",
            "2025-06-26 08:47:07,144 Epoch 17719: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17720\n",
            "2025-06-26 08:47:07,147 EPOCH 17720\n",
            "INFO:__main__:Epoch 17720: total training loss 0.00077\n",
            "2025-06-26 08:47:07,222 Epoch 17720: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17721\n",
            "2025-06-26 08:47:07,224 EPOCH 17721\n",
            "INFO:__main__:Epoch 17721: total training loss 0.00082\n",
            "2025-06-26 08:47:07,312 Epoch 17721: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17722\n",
            "2025-06-26 08:47:07,314 EPOCH 17722\n",
            "INFO:__main__:Epoch 17722: total training loss 0.00079\n",
            "2025-06-26 08:47:07,387 Epoch 17722: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17723\n",
            "2025-06-26 08:47:07,389 EPOCH 17723\n",
            "INFO:__main__:Epoch 17723: total training loss 0.00077\n",
            "2025-06-26 08:47:07,462 Epoch 17723: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17724\n",
            "2025-06-26 08:47:07,464 EPOCH 17724\n",
            "INFO:__main__:Epoch 17724: total training loss 0.00080\n",
            "2025-06-26 08:47:07,540 Epoch 17724: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17725\n",
            "2025-06-26 08:47:07,542 EPOCH 17725\n",
            "INFO:__main__:Epoch 17725: total training loss 0.00085\n",
            "2025-06-26 08:47:07,615 Epoch 17725: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17726\n",
            "2025-06-26 08:47:07,617 EPOCH 17726\n",
            "INFO:__main__:Epoch 17726: total training loss 0.00083\n",
            "2025-06-26 08:47:07,690 Epoch 17726: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17727\n",
            "2025-06-26 08:47:07,693 EPOCH 17727\n",
            "INFO:__main__:Epoch 17727: total training loss 0.00087\n",
            "2025-06-26 08:47:07,765 Epoch 17727: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17728\n",
            "2025-06-26 08:47:07,766 EPOCH 17728\n",
            "INFO:__main__:Epoch 17728: total training loss 0.00089\n",
            "2025-06-26 08:47:07,840 Epoch 17728: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17729\n",
            "2025-06-26 08:47:07,842 EPOCH 17729\n",
            "INFO:__main__:Epoch 17729: total training loss 0.00090\n",
            "2025-06-26 08:47:07,915 Epoch 17729: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17730\n",
            "2025-06-26 08:47:07,917 EPOCH 17730\n",
            "INFO:__main__:Epoch 17730: total training loss 0.00087\n",
            "2025-06-26 08:47:07,987 Epoch 17730: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17731\n",
            "2025-06-26 08:47:07,989 EPOCH 17731\n",
            "INFO:__main__:Epoch 17731: total training loss 0.00098\n",
            "2025-06-26 08:47:08,058 Epoch 17731: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17732\n",
            "2025-06-26 08:47:08,060 EPOCH 17732\n",
            "INFO:__main__:Epoch 17732: total training loss 0.00093\n",
            "2025-06-26 08:47:08,129 Epoch 17732: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17733\n",
            "2025-06-26 08:47:08,131 EPOCH 17733\n",
            "INFO:__main__:Epoch 17733: total training loss 0.00092\n",
            "2025-06-26 08:47:08,209 Epoch 17733: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17734\n",
            "2025-06-26 08:47:08,211 EPOCH 17734\n",
            "INFO:__main__:Epoch 17734: total training loss 0.00096\n",
            "2025-06-26 08:47:08,280 Epoch 17734: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17735\n",
            "2025-06-26 08:47:08,286 EPOCH 17735\n",
            "INFO:__main__:Epoch 17735: total training loss 0.00094\n",
            "2025-06-26 08:47:08,377 Epoch 17735: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17736\n",
            "2025-06-26 08:47:08,379 EPOCH 17736\n",
            "INFO:__main__:Epoch 17736: total training loss 0.00090\n",
            "2025-06-26 08:47:08,450 Epoch 17736: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17737\n",
            "2025-06-26 08:47:08,452 EPOCH 17737\n",
            "INFO:__main__:Epoch 17737: total training loss 0.00095\n",
            "2025-06-26 08:47:08,526 Epoch 17737: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17738\n",
            "2025-06-26 08:47:08,528 EPOCH 17738\n",
            "INFO:__main__:Epoch 17738: total training loss 0.00087\n",
            "2025-06-26 08:47:08,601 Epoch 17738: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17739\n",
            "2025-06-26 08:47:08,603 EPOCH 17739\n",
            "INFO:__main__:Epoch 17739: total training loss 0.00085\n",
            "2025-06-26 08:47:08,672 Epoch 17739: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17740\n",
            "2025-06-26 08:47:08,674 EPOCH 17740\n",
            "INFO:__main__:Epoch 17740: total training loss 0.00087\n",
            "2025-06-26 08:47:08,747 Epoch 17740: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17741\n",
            "2025-06-26 08:47:08,749 EPOCH 17741\n",
            "INFO:__main__:Epoch 17741: total training loss 0.00081\n",
            "2025-06-26 08:47:08,820 Epoch 17741: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17742\n",
            "2025-06-26 08:47:08,822 EPOCH 17742\n",
            "INFO:__main__:Epoch 17742: total training loss 0.00082\n",
            "2025-06-26 08:47:08,892 Epoch 17742: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17743\n",
            "2025-06-26 08:47:08,894 EPOCH 17743\n",
            "INFO:__main__:Epoch 17743: total training loss 0.00081\n",
            "2025-06-26 08:47:08,964 Epoch 17743: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17744\n",
            "2025-06-26 08:47:08,966 EPOCH 17744\n",
            "INFO:__main__:Epoch 17744: total training loss 0.00081\n",
            "2025-06-26 08:47:09,040 Epoch 17744: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17745\n",
            "2025-06-26 08:47:09,042 EPOCH 17745\n",
            "INFO:__main__:Epoch 17745: total training loss 0.00076\n",
            "2025-06-26 08:47:09,112 Epoch 17745: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17746\n",
            "2025-06-26 08:47:09,114 EPOCH 17746\n",
            "INFO:__main__:Epoch 17746: total training loss 0.00075\n",
            "2025-06-26 08:47:09,183 Epoch 17746: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 17747\n",
            "2025-06-26 08:47:09,187 EPOCH 17747\n",
            "INFO:__main__:Epoch 17747: total training loss 0.00075\n",
            "2025-06-26 08:47:09,256 Epoch 17747: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 17748\n",
            "2025-06-26 08:47:09,257 EPOCH 17748\n",
            "INFO:__main__:Epoch 17748: total training loss 0.00074\n",
            "2025-06-26 08:47:09,332 Epoch 17748: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 17749\n",
            "2025-06-26 08:47:09,334 EPOCH 17749\n",
            "INFO:__main__:Epoch 17749: total training loss 0.00078\n",
            "2025-06-26 08:47:09,410 Epoch 17749: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17750\n",
            "2025-06-26 08:47:09,412 EPOCH 17750\n",
            "INFO:__main__:Epoch 17750 Step:    17750 Batch Loss:     0.000826 Tokens per Sec:  1664752, Lr: 0.001000\n",
            "2025-06-26 08:47:09,498 Epoch 17750 Step:    17750 Batch Loss:     0.000826 Tokens per Sec:  1664752, Lr: 0.001000\n",
            "INFO:__main__:Epoch 17750: total training loss 0.00083\n",
            "2025-06-26 08:47:09,500 Epoch 17750: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17751\n",
            "2025-06-26 08:47:09,501 EPOCH 17751\n",
            "INFO:__main__:Epoch 17751: total training loss 0.00094\n",
            "2025-06-26 08:47:09,572 Epoch 17751: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17752\n",
            "2025-06-26 08:47:09,574 EPOCH 17752\n",
            "INFO:__main__:Epoch 17752: total training loss 0.00097\n",
            "2025-06-26 08:47:09,645 Epoch 17752: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17753\n",
            "2025-06-26 08:47:09,647 EPOCH 17753\n",
            "INFO:__main__:Epoch 17753: total training loss 0.00100\n",
            "2025-06-26 08:47:09,717 Epoch 17753: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 17754\n",
            "2025-06-26 08:47:09,719 EPOCH 17754\n",
            "INFO:__main__:Epoch 17754: total training loss 0.00094\n",
            "2025-06-26 08:47:09,792 Epoch 17754: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17755\n",
            "2025-06-26 08:47:09,796 EPOCH 17755\n",
            "INFO:__main__:Epoch 17755: total training loss 0.00091\n",
            "2025-06-26 08:47:09,868 Epoch 17755: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17756\n",
            "2025-06-26 08:47:09,870 EPOCH 17756\n",
            "INFO:__main__:Epoch 17756: total training loss 0.00091\n",
            "2025-06-26 08:47:09,948 Epoch 17756: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17757\n",
            "2025-06-26 08:47:09,951 EPOCH 17757\n",
            "INFO:__main__:Epoch 17757: total training loss 0.00085\n",
            "2025-06-26 08:47:10,022 Epoch 17757: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17758\n",
            "2025-06-26 08:47:10,024 EPOCH 17758\n",
            "INFO:__main__:Epoch 17758: total training loss 0.00089\n",
            "2025-06-26 08:47:10,105 Epoch 17758: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17759\n",
            "2025-06-26 08:47:10,107 EPOCH 17759\n",
            "INFO:__main__:Epoch 17759: total training loss 0.00091\n",
            "2025-06-26 08:47:10,208 Epoch 17759: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17760\n",
            "2025-06-26 08:47:10,210 EPOCH 17760\n",
            "INFO:__main__:Epoch 17760: total training loss 0.00084\n",
            "2025-06-26 08:47:10,281 Epoch 17760: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17761\n",
            "2025-06-26 08:47:10,283 EPOCH 17761\n",
            "INFO:__main__:Epoch 17761: total training loss 0.00086\n",
            "2025-06-26 08:47:10,352 Epoch 17761: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17762\n",
            "2025-06-26 08:47:10,354 EPOCH 17762\n",
            "INFO:__main__:Epoch 17762: total training loss 0.00081\n",
            "2025-06-26 08:47:10,426 Epoch 17762: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17763\n",
            "2025-06-26 08:47:10,428 EPOCH 17763\n",
            "INFO:__main__:Epoch 17763: total training loss 0.00082\n",
            "2025-06-26 08:47:10,507 Epoch 17763: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17764\n",
            "2025-06-26 08:47:10,509 EPOCH 17764\n",
            "INFO:__main__:Epoch 17764: total training loss 0.00084\n",
            "2025-06-26 08:47:10,605 Epoch 17764: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17765\n",
            "2025-06-26 08:47:10,607 EPOCH 17765\n",
            "INFO:__main__:Epoch 17765: total training loss 0.00087\n",
            "2025-06-26 08:47:10,681 Epoch 17765: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17766\n",
            "2025-06-26 08:47:10,685 EPOCH 17766\n",
            "INFO:__main__:Epoch 17766: total training loss 0.00084\n",
            "2025-06-26 08:47:10,761 Epoch 17766: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17767\n",
            "2025-06-26 08:47:10,763 EPOCH 17767\n",
            "INFO:__main__:Epoch 17767: total training loss 0.00085\n",
            "2025-06-26 08:47:10,839 Epoch 17767: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17768\n",
            "2025-06-26 08:47:10,841 EPOCH 17768\n",
            "INFO:__main__:Epoch 17768: total training loss 0.00081\n",
            "2025-06-26 08:47:10,913 Epoch 17768: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17769\n",
            "2025-06-26 08:47:10,917 EPOCH 17769\n",
            "INFO:__main__:Epoch 17769: total training loss 0.00084\n",
            "2025-06-26 08:47:10,987 Epoch 17769: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17770\n",
            "2025-06-26 08:47:10,989 EPOCH 17770\n",
            "INFO:__main__:Epoch 17770: total training loss 0.00087\n",
            "2025-06-26 08:47:11,063 Epoch 17770: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17771\n",
            "2025-06-26 08:47:11,066 EPOCH 17771\n",
            "INFO:__main__:Epoch 17771: total training loss 0.00084\n",
            "2025-06-26 08:47:11,136 Epoch 17771: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17772\n",
            "2025-06-26 08:47:11,140 EPOCH 17772\n",
            "INFO:__main__:Epoch 17772: total training loss 0.00082\n",
            "2025-06-26 08:47:11,214 Epoch 17772: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17773\n",
            "2025-06-26 08:47:11,216 EPOCH 17773\n",
            "INFO:__main__:Epoch 17773: total training loss 0.00086\n",
            "2025-06-26 08:47:11,291 Epoch 17773: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17774\n",
            "2025-06-26 08:47:11,294 EPOCH 17774\n",
            "INFO:__main__:Epoch 17774: total training loss 0.00088\n",
            "2025-06-26 08:47:11,369 Epoch 17774: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17775\n",
            "2025-06-26 08:47:11,372 EPOCH 17775\n",
            "INFO:__main__:Epoch 17775: total training loss 0.00089\n",
            "2025-06-26 08:47:11,444 Epoch 17775: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17776\n",
            "2025-06-26 08:47:11,447 EPOCH 17776\n",
            "INFO:__main__:Epoch 17776: total training loss 0.00090\n",
            "2025-06-26 08:47:11,522 Epoch 17776: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17777\n",
            "2025-06-26 08:47:11,526 EPOCH 17777\n",
            "INFO:__main__:Epoch 17777: total training loss 0.00092\n",
            "2025-06-26 08:47:11,604 Epoch 17777: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17778\n",
            "2025-06-26 08:47:11,606 EPOCH 17778\n",
            "INFO:__main__:Epoch 17778: total training loss 0.00090\n",
            "2025-06-26 08:47:11,684 Epoch 17778: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17779\n",
            "2025-06-26 08:47:11,687 EPOCH 17779\n",
            "INFO:__main__:Epoch 17779: total training loss 0.00092\n",
            "2025-06-26 08:47:11,760 Epoch 17779: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17780\n",
            "2025-06-26 08:47:11,762 EPOCH 17780\n",
            "INFO:__main__:Epoch 17780: total training loss 0.00089\n",
            "2025-06-26 08:47:11,838 Epoch 17780: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17781\n",
            "2025-06-26 08:47:11,841 EPOCH 17781\n",
            "INFO:__main__:Epoch 17781: total training loss 0.00084\n",
            "2025-06-26 08:47:11,912 Epoch 17781: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17782\n",
            "2025-06-26 08:47:11,915 EPOCH 17782\n",
            "INFO:__main__:Epoch 17782: total training loss 0.00087\n",
            "2025-06-26 08:47:11,989 Epoch 17782: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17783\n",
            "2025-06-26 08:47:11,991 EPOCH 17783\n",
            "INFO:__main__:Epoch 17783: total training loss 0.00083\n",
            "2025-06-26 08:47:12,065 Epoch 17783: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17784\n",
            "2025-06-26 08:47:12,067 EPOCH 17784\n",
            "INFO:__main__:Epoch 17784: total training loss 0.00086\n",
            "2025-06-26 08:47:12,139 Epoch 17784: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17785\n",
            "2025-06-26 08:47:12,141 EPOCH 17785\n",
            "INFO:__main__:Epoch 17785: total training loss 0.00086\n",
            "2025-06-26 08:47:12,217 Epoch 17785: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17786\n",
            "2025-06-26 08:47:12,219 EPOCH 17786\n",
            "INFO:__main__:Epoch 17786: total training loss 0.00083\n",
            "2025-06-26 08:47:12,296 Epoch 17786: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17787\n",
            "2025-06-26 08:47:12,299 EPOCH 17787\n",
            "INFO:__main__:Epoch 17787: total training loss 0.00083\n",
            "2025-06-26 08:47:12,369 Epoch 17787: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17788\n",
            "2025-06-26 08:47:12,371 EPOCH 17788\n",
            "INFO:__main__:Epoch 17788: total training loss 0.00084\n",
            "2025-06-26 08:47:12,444 Epoch 17788: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17789\n",
            "2025-06-26 08:47:12,447 EPOCH 17789\n",
            "INFO:__main__:Epoch 17789: total training loss 0.00080\n",
            "2025-06-26 08:47:12,522 Epoch 17789: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17790\n",
            "2025-06-26 08:47:12,524 EPOCH 17790\n",
            "INFO:__main__:Epoch 17790: total training loss 0.00085\n",
            "2025-06-26 08:47:12,597 Epoch 17790: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17791\n",
            "2025-06-26 08:47:12,599 EPOCH 17791\n",
            "INFO:__main__:Epoch 17791: total training loss 0.00080\n",
            "2025-06-26 08:47:12,677 Epoch 17791: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17792\n",
            "2025-06-26 08:47:12,679 EPOCH 17792\n",
            "INFO:__main__:Epoch 17792: total training loss 0.00078\n",
            "2025-06-26 08:47:12,756 Epoch 17792: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17793\n",
            "2025-06-26 08:47:12,760 EPOCH 17793\n",
            "INFO:__main__:Epoch 17793: total training loss 0.00082\n",
            "2025-06-26 08:47:12,833 Epoch 17793: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17794\n",
            "2025-06-26 08:47:12,835 EPOCH 17794\n",
            "INFO:__main__:Epoch 17794: total training loss 0.00082\n",
            "2025-06-26 08:47:12,909 Epoch 17794: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17795\n",
            "2025-06-26 08:47:12,913 EPOCH 17795\n",
            "INFO:__main__:Epoch 17795: total training loss 0.00086\n",
            "2025-06-26 08:47:12,995 Epoch 17795: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17796\n",
            "2025-06-26 08:47:12,998 EPOCH 17796\n",
            "INFO:__main__:Epoch 17796: total training loss 0.00084\n",
            "2025-06-26 08:47:13,079 Epoch 17796: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17797\n",
            "2025-06-26 08:47:13,082 EPOCH 17797\n",
            "INFO:__main__:Epoch 17797: total training loss 0.00082\n",
            "2025-06-26 08:47:13,170 Epoch 17797: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17798\n",
            "2025-06-26 08:47:13,172 EPOCH 17798\n",
            "INFO:__main__:Epoch 17798: total training loss 0.00087\n",
            "2025-06-26 08:47:13,263 Epoch 17798: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17799\n",
            "2025-06-26 08:47:13,265 EPOCH 17799\n",
            "INFO:__main__:Epoch 17799: total training loss 0.00092\n",
            "2025-06-26 08:47:13,344 Epoch 17799: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17800\n",
            "2025-06-26 08:47:13,346 EPOCH 17800\n",
            "INFO:__main__:Epoch 17800: total training loss 0.00086\n",
            "2025-06-26 08:47:13,420 Epoch 17800: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17801\n",
            "2025-06-26 08:47:13,422 EPOCH 17801\n",
            "INFO:__main__:Epoch 17801: total training loss 0.00085\n",
            "2025-06-26 08:47:13,514 Epoch 17801: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17802\n",
            "2025-06-26 08:47:13,516 EPOCH 17802\n",
            "INFO:__main__:Epoch 17802: total training loss 0.00081\n",
            "2025-06-26 08:47:13,597 Epoch 17802: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17803\n",
            "2025-06-26 08:47:13,599 EPOCH 17803\n",
            "INFO:__main__:Epoch 17803: total training loss 0.00082\n",
            "2025-06-26 08:47:13,672 Epoch 17803: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17804\n",
            "2025-06-26 08:47:13,674 EPOCH 17804\n",
            "INFO:__main__:Epoch 17804: total training loss 0.00091\n",
            "2025-06-26 08:47:13,747 Epoch 17804: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17805\n",
            "2025-06-26 08:47:13,750 EPOCH 17805\n",
            "INFO:__main__:Epoch 17805: total training loss 0.00086\n",
            "2025-06-26 08:47:13,841 Epoch 17805: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17806\n",
            "2025-06-26 08:47:13,843 EPOCH 17806\n",
            "INFO:__main__:Epoch 17806: total training loss 0.00092\n",
            "2025-06-26 08:47:13,920 Epoch 17806: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17807\n",
            "2025-06-26 08:47:13,923 EPOCH 17807\n",
            "INFO:__main__:Epoch 17807: total training loss 0.00085\n",
            "2025-06-26 08:47:13,994 Epoch 17807: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17808\n",
            "2025-06-26 08:47:13,996 EPOCH 17808\n",
            "INFO:__main__:Epoch 17808: total training loss 0.00082\n",
            "2025-06-26 08:47:14,069 Epoch 17808: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17809\n",
            "2025-06-26 08:47:14,071 EPOCH 17809\n",
            "INFO:__main__:Epoch 17809: total training loss 0.00086\n",
            "2025-06-26 08:47:14,141 Epoch 17809: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17810\n",
            "2025-06-26 08:47:14,143 EPOCH 17810\n",
            "INFO:__main__:Epoch 17810: total training loss 0.00080\n",
            "2025-06-26 08:47:14,220 Epoch 17810: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17811\n",
            "2025-06-26 08:47:14,223 EPOCH 17811\n",
            "INFO:__main__:Epoch 17811: total training loss 0.00083\n",
            "2025-06-26 08:47:14,314 Epoch 17811: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17812\n",
            "2025-06-26 08:47:14,320 EPOCH 17812\n",
            "INFO:__main__:Epoch 17812: total training loss 0.00081\n",
            "2025-06-26 08:47:14,411 Epoch 17812: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17813\n",
            "2025-06-26 08:47:14,414 EPOCH 17813\n",
            "INFO:__main__:Epoch 17813: total training loss 0.00081\n",
            "2025-06-26 08:47:14,486 Epoch 17813: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17814\n",
            "2025-06-26 08:47:14,488 EPOCH 17814\n",
            "INFO:__main__:Epoch 17814: total training loss 0.00078\n",
            "2025-06-26 08:47:14,570 Epoch 17814: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17815\n",
            "2025-06-26 08:47:14,572 EPOCH 17815\n",
            "INFO:__main__:Epoch 17815: total training loss 0.00079\n",
            "2025-06-26 08:47:14,645 Epoch 17815: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17816\n",
            "2025-06-26 08:47:14,648 EPOCH 17816\n",
            "INFO:__main__:Epoch 17816: total training loss 0.00076\n",
            "2025-06-26 08:47:14,720 Epoch 17816: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17817\n",
            "2025-06-26 08:47:14,723 EPOCH 17817\n",
            "INFO:__main__:Epoch 17817: total training loss 0.00078\n",
            "2025-06-26 08:47:14,795 Epoch 17817: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17818\n",
            "2025-06-26 08:47:14,797 EPOCH 17818\n",
            "INFO:__main__:Epoch 17818: total training loss 0.00084\n",
            "2025-06-26 08:47:14,878 Epoch 17818: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17819\n",
            "2025-06-26 08:47:14,882 EPOCH 17819\n",
            "INFO:__main__:Epoch 17819: total training loss 0.00088\n",
            "2025-06-26 08:47:14,979 Epoch 17819: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17820\n",
            "2025-06-26 08:47:14,983 EPOCH 17820\n",
            "INFO:__main__:Epoch 17820: total training loss 0.00084\n",
            "2025-06-26 08:47:15,076 Epoch 17820: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17821\n",
            "2025-06-26 08:47:15,079 EPOCH 17821\n",
            "INFO:__main__:Epoch 17821: total training loss 0.00082\n",
            "2025-06-26 08:47:15,176 Epoch 17821: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17822\n",
            "2025-06-26 08:47:15,179 EPOCH 17822\n",
            "INFO:__main__:Epoch 17822: total training loss 0.00083\n",
            "2025-06-26 08:47:15,260 Epoch 17822: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17823\n",
            "2025-06-26 08:47:15,262 EPOCH 17823\n",
            "INFO:__main__:Epoch 17823: total training loss 0.00090\n",
            "2025-06-26 08:47:15,351 Epoch 17823: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17824\n",
            "2025-06-26 08:47:15,353 EPOCH 17824\n",
            "INFO:__main__:Epoch 17824: total training loss 0.00088\n",
            "2025-06-26 08:47:15,439 Epoch 17824: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17825\n",
            "2025-06-26 08:47:15,441 EPOCH 17825\n",
            "INFO:__main__:Epoch 17825: total training loss 0.00090\n",
            "2025-06-26 08:47:15,556 Epoch 17825: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17826\n",
            "2025-06-26 08:47:15,558 EPOCH 17826\n",
            "INFO:__main__:Epoch 17826: total training loss 0.00090\n",
            "2025-06-26 08:47:15,668 Epoch 17826: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17827\n",
            "2025-06-26 08:47:15,670 EPOCH 17827\n",
            "INFO:__main__:Epoch 17827: total training loss 0.00097\n",
            "2025-06-26 08:47:15,782 Epoch 17827: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17828\n",
            "2025-06-26 08:47:15,786 EPOCH 17828\n",
            "INFO:__main__:Epoch 17828: total training loss 0.00096\n",
            "2025-06-26 08:47:15,895 Epoch 17828: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17829\n",
            "2025-06-26 08:47:15,897 EPOCH 17829\n",
            "INFO:__main__:Epoch 17829: total training loss 0.00097\n",
            "2025-06-26 08:47:16,007 Epoch 17829: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17830\n",
            "2025-06-26 08:47:16,009 EPOCH 17830\n",
            "INFO:__main__:Epoch 17830: total training loss 0.00091\n",
            "2025-06-26 08:47:16,114 Epoch 17830: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17831\n",
            "2025-06-26 08:47:16,116 EPOCH 17831\n",
            "INFO:__main__:Epoch 17831: total training loss 0.00083\n",
            "2025-06-26 08:47:16,209 Epoch 17831: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17832\n",
            "2025-06-26 08:47:16,210 EPOCH 17832\n",
            "INFO:__main__:Epoch 17832: total training loss 0.00090\n",
            "2025-06-26 08:47:16,307 Epoch 17832: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17833\n",
            "2025-06-26 08:47:16,311 EPOCH 17833\n",
            "INFO:__main__:Epoch 17833: total training loss 0.00094\n",
            "2025-06-26 08:47:16,414 Epoch 17833: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17834\n",
            "2025-06-26 08:47:16,415 EPOCH 17834\n",
            "INFO:__main__:Epoch 17834: total training loss 0.00091\n",
            "2025-06-26 08:47:16,505 Epoch 17834: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17835\n",
            "2025-06-26 08:47:16,510 EPOCH 17835\n",
            "INFO:__main__:Epoch 17835: total training loss 0.00084\n",
            "2025-06-26 08:47:16,597 Epoch 17835: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17836\n",
            "2025-06-26 08:47:16,598 EPOCH 17836\n",
            "INFO:__main__:Epoch 17836: total training loss 0.00083\n",
            "2025-06-26 08:47:16,691 Epoch 17836: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17837\n",
            "2025-06-26 08:47:16,693 EPOCH 17837\n",
            "INFO:__main__:Epoch 17837: total training loss 0.00089\n",
            "2025-06-26 08:47:16,779 Epoch 17837: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17838\n",
            "2025-06-26 08:47:16,781 EPOCH 17838\n",
            "INFO:__main__:Epoch 17838: total training loss 0.00086\n",
            "2025-06-26 08:47:16,882 Epoch 17838: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17839\n",
            "2025-06-26 08:47:16,884 EPOCH 17839\n",
            "INFO:__main__:Epoch 17839: total training loss 0.00085\n",
            "2025-06-26 08:47:17,010 Epoch 17839: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17840\n",
            "2025-06-26 08:47:17,012 EPOCH 17840\n",
            "INFO:__main__:Epoch 17840: total training loss 0.00084\n",
            "2025-06-26 08:47:17,130 Epoch 17840: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17841\n",
            "2025-06-26 08:47:17,132 EPOCH 17841\n",
            "INFO:__main__:Epoch 17841: total training loss 0.00084\n",
            "2025-06-26 08:47:17,238 Epoch 17841: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17842\n",
            "2025-06-26 08:47:17,240 EPOCH 17842\n",
            "INFO:__main__:Epoch 17842: total training loss 0.00080\n",
            "2025-06-26 08:47:17,354 Epoch 17842: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17843\n",
            "2025-06-26 08:47:17,358 EPOCH 17843\n",
            "INFO:__main__:Epoch 17843: total training loss 0.00080\n",
            "2025-06-26 08:47:17,474 Epoch 17843: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17844\n",
            "2025-06-26 08:47:17,476 EPOCH 17844\n",
            "INFO:__main__:Epoch 17844: total training loss 0.00081\n",
            "2025-06-26 08:47:17,593 Epoch 17844: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17845\n",
            "2025-06-26 08:47:17,597 EPOCH 17845\n",
            "INFO:__main__:Epoch 17845: total training loss 0.00080\n",
            "2025-06-26 08:47:17,731 Epoch 17845: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17846\n",
            "2025-06-26 08:47:17,736 EPOCH 17846\n",
            "INFO:__main__:Epoch 17846: total training loss 0.00082\n",
            "2025-06-26 08:47:17,860 Epoch 17846: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17847\n",
            "2025-06-26 08:47:17,865 EPOCH 17847\n",
            "INFO:__main__:Epoch 17847: total training loss 0.00083\n",
            "2025-06-26 08:47:17,978 Epoch 17847: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17848\n",
            "2025-06-26 08:47:17,981 EPOCH 17848\n",
            "INFO:__main__:Epoch 17848: total training loss 0.00084\n",
            "2025-06-26 08:47:18,100 Epoch 17848: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17849\n",
            "2025-06-26 08:47:18,103 EPOCH 17849\n",
            "INFO:__main__:Epoch 17849: total training loss 0.00089\n",
            "2025-06-26 08:47:18,222 Epoch 17849: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17850\n",
            "2025-06-26 08:47:18,226 EPOCH 17850\n",
            "INFO:__main__:Epoch 17850: total training loss 0.00097\n",
            "2025-06-26 08:47:18,339 Epoch 17850: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17851\n",
            "2025-06-26 08:47:18,343 EPOCH 17851\n",
            "INFO:__main__:Epoch 17851: total training loss 0.00097\n",
            "2025-06-26 08:47:18,477 Epoch 17851: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 17852\n",
            "2025-06-26 08:47:18,479 EPOCH 17852\n",
            "INFO:__main__:Epoch 17852: total training loss 0.00095\n",
            "2025-06-26 08:47:18,586 Epoch 17852: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17853\n",
            "2025-06-26 08:47:18,590 EPOCH 17853\n",
            "INFO:__main__:Epoch 17853: total training loss 0.00089\n",
            "2025-06-26 08:47:18,674 Epoch 17853: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17854\n",
            "2025-06-26 08:47:18,677 EPOCH 17854\n",
            "INFO:__main__:Epoch 17854: total training loss 0.00094\n",
            "2025-06-26 08:47:18,758 Epoch 17854: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17855\n",
            "2025-06-26 08:47:18,761 EPOCH 17855\n",
            "INFO:__main__:Epoch 17855: total training loss 0.00090\n",
            "2025-06-26 08:47:18,833 Epoch 17855: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17856\n",
            "2025-06-26 08:47:18,835 EPOCH 17856\n",
            "INFO:__main__:Epoch 17856: total training loss 0.00096\n",
            "2025-06-26 08:47:18,909 Epoch 17856: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17857\n",
            "2025-06-26 08:47:18,911 EPOCH 17857\n",
            "INFO:__main__:Epoch 17857: total training loss 0.00089\n",
            "2025-06-26 08:47:18,980 Epoch 17857: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17858\n",
            "2025-06-26 08:47:18,982 EPOCH 17858\n",
            "INFO:__main__:Epoch 17858: total training loss 0.00085\n",
            "2025-06-26 08:47:19,053 Epoch 17858: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17859\n",
            "2025-06-26 08:47:19,055 EPOCH 17859\n",
            "INFO:__main__:Epoch 17859: total training loss 0.00091\n",
            "2025-06-26 08:47:19,124 Epoch 17859: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17860\n",
            "2025-06-26 08:47:19,126 EPOCH 17860\n",
            "INFO:__main__:Epoch 17860: total training loss 0.00093\n",
            "2025-06-26 08:47:19,201 Epoch 17860: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17861\n",
            "2025-06-26 08:47:19,202 EPOCH 17861\n",
            "INFO:__main__:Epoch 17861: total training loss 0.00089\n",
            "2025-06-26 08:47:19,295 Epoch 17861: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17862\n",
            "2025-06-26 08:47:19,298 EPOCH 17862\n",
            "INFO:__main__:Epoch 17862: total training loss 0.00090\n",
            "2025-06-26 08:47:19,376 Epoch 17862: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17863\n",
            "2025-06-26 08:47:19,378 EPOCH 17863\n",
            "INFO:__main__:Epoch 17863: total training loss 0.00087\n",
            "2025-06-26 08:47:19,448 Epoch 17863: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17864\n",
            "2025-06-26 08:47:19,450 EPOCH 17864\n",
            "INFO:__main__:Epoch 17864: total training loss 0.00089\n",
            "2025-06-26 08:47:19,521 Epoch 17864: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17865\n",
            "2025-06-26 08:47:19,525 EPOCH 17865\n",
            "INFO:__main__:Epoch 17865: total training loss 0.00089\n",
            "2025-06-26 08:47:19,603 Epoch 17865: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17866\n",
            "2025-06-26 08:47:19,605 EPOCH 17866\n",
            "INFO:__main__:Epoch 17866: total training loss 0.00089\n",
            "2025-06-26 08:47:19,678 Epoch 17866: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17867\n",
            "2025-06-26 08:47:19,680 EPOCH 17867\n",
            "INFO:__main__:Epoch 17867: total training loss 0.00090\n",
            "2025-06-26 08:47:19,758 Epoch 17867: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17868\n",
            "2025-06-26 08:47:19,760 EPOCH 17868\n",
            "INFO:__main__:Epoch 17868: total training loss 0.00083\n",
            "2025-06-26 08:47:19,833 Epoch 17868: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17869\n",
            "2025-06-26 08:47:19,835 EPOCH 17869\n",
            "INFO:__main__:Epoch 17869: total training loss 0.00087\n",
            "2025-06-26 08:47:19,911 Epoch 17869: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17870\n",
            "2025-06-26 08:47:19,913 EPOCH 17870\n",
            "INFO:__main__:Epoch 17870: total training loss 0.00091\n",
            "2025-06-26 08:47:19,985 Epoch 17870: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17871\n",
            "2025-06-26 08:47:19,988 EPOCH 17871\n",
            "INFO:__main__:Epoch 17871: total training loss 0.00089\n",
            "2025-06-26 08:47:20,068 Epoch 17871: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17872\n",
            "2025-06-26 08:47:20,070 EPOCH 17872\n",
            "INFO:__main__:Epoch 17872: total training loss 0.00089\n",
            "2025-06-26 08:47:20,141 Epoch 17872: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17873\n",
            "2025-06-26 08:47:20,143 EPOCH 17873\n",
            "INFO:__main__:Epoch 17873: total training loss 0.00089\n",
            "2025-06-26 08:47:20,225 Epoch 17873: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17874\n",
            "2025-06-26 08:47:20,226 EPOCH 17874\n",
            "INFO:__main__:Epoch 17874: total training loss 0.00095\n",
            "2025-06-26 08:47:20,321 Epoch 17874: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 17875\n",
            "2025-06-26 08:47:20,323 EPOCH 17875\n",
            "INFO:__main__:Epoch 17875: total training loss 0.00090\n",
            "2025-06-26 08:47:20,408 Epoch 17875: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17876\n",
            "2025-06-26 08:47:20,410 EPOCH 17876\n",
            "INFO:__main__:Epoch 17876: total training loss 0.00090\n",
            "2025-06-26 08:47:20,483 Epoch 17876: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17877\n",
            "2025-06-26 08:47:20,485 EPOCH 17877\n",
            "INFO:__main__:Epoch 17877: total training loss 0.00087\n",
            "2025-06-26 08:47:20,558 Epoch 17877: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17878\n",
            "2025-06-26 08:47:20,560 EPOCH 17878\n",
            "INFO:__main__:Epoch 17878: total training loss 0.00087\n",
            "2025-06-26 08:47:20,632 Epoch 17878: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17879\n",
            "2025-06-26 08:47:20,634 EPOCH 17879\n",
            "INFO:__main__:Epoch 17879: total training loss 0.00083\n",
            "2025-06-26 08:47:20,717 Epoch 17879: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17880\n",
            "2025-06-26 08:47:20,719 EPOCH 17880\n",
            "INFO:__main__:Epoch 17880: total training loss 0.00085\n",
            "2025-06-26 08:47:20,799 Epoch 17880: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17881\n",
            "2025-06-26 08:47:20,801 EPOCH 17881\n",
            "INFO:__main__:Epoch 17881: total training loss 0.00083\n",
            "2025-06-26 08:47:20,879 Epoch 17881: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17882\n",
            "2025-06-26 08:47:20,881 EPOCH 17882\n",
            "INFO:__main__:Epoch 17882: total training loss 0.00080\n",
            "2025-06-26 08:47:20,955 Epoch 17882: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17883\n",
            "2025-06-26 08:47:20,956 EPOCH 17883\n",
            "INFO:__main__:Epoch 17883: total training loss 0.00083\n",
            "2025-06-26 08:47:21,029 Epoch 17883: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17884\n",
            "2025-06-26 08:47:21,031 EPOCH 17884\n",
            "INFO:__main__:Epoch 17884: total training loss 0.00078\n",
            "2025-06-26 08:47:21,115 Epoch 17884: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17885\n",
            "2025-06-26 08:47:21,117 EPOCH 17885\n",
            "INFO:__main__:Epoch 17885: total training loss 0.00080\n",
            "2025-06-26 08:47:21,193 Epoch 17885: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17886\n",
            "2025-06-26 08:47:21,196 EPOCH 17886\n",
            "INFO:__main__:Epoch 17886: total training loss 0.00077\n",
            "2025-06-26 08:47:21,269 Epoch 17886: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17887\n",
            "2025-06-26 08:47:21,271 EPOCH 17887\n",
            "INFO:__main__:Epoch 17887: total training loss 0.00079\n",
            "2025-06-26 08:47:21,343 Epoch 17887: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17888\n",
            "2025-06-26 08:47:21,349 EPOCH 17888\n",
            "INFO:__main__:Epoch 17888: total training loss 0.00078\n",
            "2025-06-26 08:47:21,437 Epoch 17888: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17889\n",
            "2025-06-26 08:47:21,439 EPOCH 17889\n",
            "INFO:__main__:Epoch 17889: total training loss 0.00083\n",
            "2025-06-26 08:47:21,509 Epoch 17889: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17890\n",
            "2025-06-26 08:47:21,511 EPOCH 17890\n",
            "INFO:__main__:Epoch 17890: total training loss 0.00086\n",
            "2025-06-26 08:47:21,581 Epoch 17890: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17891\n",
            "2025-06-26 08:47:21,583 EPOCH 17891\n",
            "INFO:__main__:Epoch 17891: total training loss 0.00082\n",
            "2025-06-26 08:47:21,653 Epoch 17891: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17892\n",
            "2025-06-26 08:47:21,655 EPOCH 17892\n",
            "INFO:__main__:Epoch 17892: total training loss 0.00082\n",
            "2025-06-26 08:47:21,725 Epoch 17892: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17893\n",
            "2025-06-26 08:47:21,727 EPOCH 17893\n",
            "INFO:__main__:Epoch 17893: total training loss 0.00082\n",
            "2025-06-26 08:47:21,800 Epoch 17893: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17894\n",
            "2025-06-26 08:47:21,801 EPOCH 17894\n",
            "INFO:__main__:Epoch 17894: total training loss 0.00085\n",
            "2025-06-26 08:47:21,879 Epoch 17894: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17895\n",
            "2025-06-26 08:47:21,887 EPOCH 17895\n",
            "INFO:__main__:Epoch 17895: total training loss 0.00084\n",
            "2025-06-26 08:47:21,962 Epoch 17895: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17896\n",
            "2025-06-26 08:47:21,964 EPOCH 17896\n",
            "INFO:__main__:Epoch 17896: total training loss 0.00083\n",
            "2025-06-26 08:47:22,058 Epoch 17896: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17897\n",
            "2025-06-26 08:47:22,060 EPOCH 17897\n",
            "INFO:__main__:Epoch 17897: total training loss 0.00080\n",
            "2025-06-26 08:47:22,135 Epoch 17897: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17898\n",
            "2025-06-26 08:47:22,139 EPOCH 17898\n",
            "INFO:__main__:Epoch 17898: total training loss 0.00079\n",
            "2025-06-26 08:47:22,215 Epoch 17898: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17899\n",
            "2025-06-26 08:47:22,217 EPOCH 17899\n",
            "INFO:__main__:Epoch 17899: total training loss 0.00078\n",
            "2025-06-26 08:47:22,295 Epoch 17899: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17900\n",
            "2025-06-26 08:47:22,297 EPOCH 17900\n",
            "INFO:__main__:Epoch 17900: total training loss 0.00079\n",
            "2025-06-26 08:47:22,367 Epoch 17900: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17901\n",
            "2025-06-26 08:47:22,369 EPOCH 17901\n",
            "INFO:__main__:Epoch 17901: total training loss 0.00080\n",
            "2025-06-26 08:47:22,448 Epoch 17901: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17902\n",
            "2025-06-26 08:47:22,450 EPOCH 17902\n",
            "INFO:__main__:Epoch 17902: total training loss 0.00081\n",
            "2025-06-26 08:47:22,539 Epoch 17902: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17903\n",
            "2025-06-26 08:47:22,541 EPOCH 17903\n",
            "INFO:__main__:Epoch 17903: total training loss 0.00078\n",
            "2025-06-26 08:47:22,615 Epoch 17903: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17904\n",
            "2025-06-26 08:47:22,618 EPOCH 17904\n",
            "INFO:__main__:Epoch 17904: total training loss 0.00081\n",
            "2025-06-26 08:47:22,687 Epoch 17904: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17905\n",
            "2025-06-26 08:47:22,689 EPOCH 17905\n",
            "INFO:__main__:Epoch 17905: total training loss 0.00078\n",
            "2025-06-26 08:47:22,761 Epoch 17905: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17906\n",
            "2025-06-26 08:47:22,763 EPOCH 17906\n",
            "INFO:__main__:Epoch 17906: total training loss 0.00076\n",
            "2025-06-26 08:47:22,839 Epoch 17906: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17907\n",
            "2025-06-26 08:47:22,841 EPOCH 17907\n",
            "INFO:__main__:Epoch 17907: total training loss 0.00082\n",
            "2025-06-26 08:47:22,912 Epoch 17907: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17908\n",
            "2025-06-26 08:47:22,914 EPOCH 17908\n",
            "INFO:__main__:Epoch 17908: total training loss 0.00082\n",
            "2025-06-26 08:47:22,985 Epoch 17908: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17909\n",
            "2025-06-26 08:47:22,987 EPOCH 17909\n",
            "INFO:__main__:Epoch 17909: total training loss 0.00080\n",
            "2025-06-26 08:47:23,057 Epoch 17909: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17910\n",
            "2025-06-26 08:47:23,060 EPOCH 17910\n",
            "INFO:__main__:Epoch 17910: total training loss 0.00082\n",
            "2025-06-26 08:47:23,139 Epoch 17910: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17911\n",
            "2025-06-26 08:47:23,141 EPOCH 17911\n",
            "INFO:__main__:Epoch 17911: total training loss 0.00074\n",
            "2025-06-26 08:47:23,229 Epoch 17911: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 17912\n",
            "2025-06-26 08:47:23,230 EPOCH 17912\n",
            "INFO:__main__:Epoch 17912: total training loss 0.00077\n",
            "2025-06-26 08:47:23,303 Epoch 17912: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17913\n",
            "2025-06-26 08:47:23,305 EPOCH 17913\n",
            "INFO:__main__:Epoch 17913: total training loss 0.00088\n",
            "2025-06-26 08:47:23,376 Epoch 17913: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17914\n",
            "2025-06-26 08:47:23,378 EPOCH 17914\n",
            "INFO:__main__:Epoch 17914: total training loss 0.00092\n",
            "2025-06-26 08:47:23,448 Epoch 17914: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17915\n",
            "2025-06-26 08:47:23,450 EPOCH 17915\n",
            "INFO:__main__:Epoch 17915: total training loss 0.00094\n",
            "2025-06-26 08:47:23,538 Epoch 17915: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 17916\n",
            "2025-06-26 08:47:23,539 EPOCH 17916\n",
            "INFO:__main__:Epoch 17916: total training loss 0.00093\n",
            "2025-06-26 08:47:23,616 Epoch 17916: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 17917\n",
            "2025-06-26 08:47:23,618 EPOCH 17917\n",
            "INFO:__main__:Epoch 17917: total training loss 0.00096\n",
            "2025-06-26 08:47:23,696 Epoch 17917: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17918\n",
            "2025-06-26 08:47:23,700 EPOCH 17918\n",
            "INFO:__main__:Epoch 17918: total training loss 0.00092\n",
            "2025-06-26 08:47:23,791 Epoch 17918: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 17919\n",
            "2025-06-26 08:47:23,794 EPOCH 17919\n",
            "INFO:__main__:Epoch 17919: total training loss 0.00085\n",
            "2025-06-26 08:47:23,869 Epoch 17919: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17920\n",
            "2025-06-26 08:47:23,871 EPOCH 17920\n",
            "INFO:__main__:Epoch 17920: total training loss 0.00087\n",
            "2025-06-26 08:47:23,946 Epoch 17920: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17921\n",
            "2025-06-26 08:47:23,950 EPOCH 17921\n",
            "INFO:__main__:Epoch 17921: total training loss 0.00089\n",
            "2025-06-26 08:47:24,033 Epoch 17921: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17922\n",
            "2025-06-26 08:47:24,035 EPOCH 17922\n",
            "INFO:__main__:Epoch 17922: total training loss 0.00080\n",
            "2025-06-26 08:47:24,117 Epoch 17922: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17923\n",
            "2025-06-26 08:47:24,121 EPOCH 17923\n",
            "INFO:__main__:Epoch 17923: total training loss 0.00084\n",
            "2025-06-26 08:47:24,194 Epoch 17923: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17924\n",
            "2025-06-26 08:47:24,198 EPOCH 17924\n",
            "INFO:__main__:Epoch 17924: total training loss 0.00079\n",
            "2025-06-26 08:47:24,272 Epoch 17924: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17925\n",
            "2025-06-26 08:47:24,274 EPOCH 17925\n",
            "INFO:__main__:Epoch 17925: total training loss 0.00078\n",
            "2025-06-26 08:47:24,352 Epoch 17925: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17926\n",
            "2025-06-26 08:47:24,354 EPOCH 17926\n",
            "INFO:__main__:Epoch 17926: total training loss 0.00081\n",
            "2025-06-26 08:47:24,437 Epoch 17926: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17927\n",
            "2025-06-26 08:47:24,440 EPOCH 17927\n",
            "INFO:__main__:Epoch 17927: total training loss 0.00080\n",
            "2025-06-26 08:47:24,513 Epoch 17927: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17928\n",
            "2025-06-26 08:47:24,516 EPOCH 17928\n",
            "INFO:__main__:Epoch 17928: total training loss 0.00083\n",
            "2025-06-26 08:47:24,603 Epoch 17928: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17929\n",
            "2025-06-26 08:47:24,606 EPOCH 17929\n",
            "INFO:__main__:Epoch 17929: total training loss 0.00084\n",
            "2025-06-26 08:47:24,685 Epoch 17929: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17930\n",
            "2025-06-26 08:47:24,687 EPOCH 17930\n",
            "INFO:__main__:Epoch 17930: total training loss 0.00080\n",
            "2025-06-26 08:47:24,759 Epoch 17930: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17931\n",
            "2025-06-26 08:47:24,761 EPOCH 17931\n",
            "INFO:__main__:Epoch 17931: total training loss 0.00083\n",
            "2025-06-26 08:47:24,832 Epoch 17931: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17932\n",
            "2025-06-26 08:47:24,834 EPOCH 17932\n",
            "INFO:__main__:Epoch 17932: total training loss 0.00083\n",
            "2025-06-26 08:47:24,906 Epoch 17932: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17933\n",
            "2025-06-26 08:47:24,908 EPOCH 17933\n",
            "INFO:__main__:Epoch 17933: total training loss 0.00081\n",
            "2025-06-26 08:47:24,985 Epoch 17933: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17934\n",
            "2025-06-26 08:47:24,987 EPOCH 17934\n",
            "INFO:__main__:Epoch 17934: total training loss 0.00074\n",
            "2025-06-26 08:47:25,057 Epoch 17934: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 17935\n",
            "2025-06-26 08:47:25,060 EPOCH 17935\n",
            "INFO:__main__:Epoch 17935: total training loss 0.00079\n",
            "2025-06-26 08:47:25,130 Epoch 17935: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17936\n",
            "2025-06-26 08:47:25,132 EPOCH 17936\n",
            "INFO:__main__:Epoch 17936: total training loss 0.00084\n",
            "2025-06-26 08:47:25,205 Epoch 17936: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17937\n",
            "2025-06-26 08:47:25,207 EPOCH 17937\n",
            "INFO:__main__:Epoch 17937: total training loss 0.00085\n",
            "2025-06-26 08:47:25,283 Epoch 17937: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17938\n",
            "2025-06-26 08:47:25,286 EPOCH 17938\n",
            "INFO:__main__:Epoch 17938: total training loss 0.00080\n",
            "2025-06-26 08:47:25,356 Epoch 17938: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17939\n",
            "2025-06-26 08:47:25,358 EPOCH 17939\n",
            "INFO:__main__:Epoch 17939: total training loss 0.00082\n",
            "2025-06-26 08:47:25,429 Epoch 17939: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17940\n",
            "2025-06-26 08:47:25,433 EPOCH 17940\n",
            "INFO:__main__:Epoch 17940: total training loss 0.00082\n",
            "2025-06-26 08:47:25,523 Epoch 17940: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17941\n",
            "2025-06-26 08:47:25,526 EPOCH 17941\n",
            "INFO:__main__:Epoch 17941: total training loss 0.00087\n",
            "2025-06-26 08:47:25,598 Epoch 17941: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17942\n",
            "2025-06-26 08:47:25,601 EPOCH 17942\n",
            "INFO:__main__:Epoch 17942: total training loss 0.00088\n",
            "2025-06-26 08:47:25,687 Epoch 17942: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17943\n",
            "2025-06-26 08:47:25,689 EPOCH 17943\n",
            "INFO:__main__:Epoch 17943: total training loss 0.00085\n",
            "2025-06-26 08:47:25,762 Epoch 17943: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17944\n",
            "2025-06-26 08:47:25,764 EPOCH 17944\n",
            "INFO:__main__:Epoch 17944: total training loss 0.00090\n",
            "2025-06-26 08:47:25,839 Epoch 17944: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17945\n",
            "2025-06-26 08:47:25,841 EPOCH 17945\n",
            "INFO:__main__:Epoch 17945: total training loss 0.00090\n",
            "2025-06-26 08:47:25,911 Epoch 17945: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17946\n",
            "2025-06-26 08:47:25,913 EPOCH 17946\n",
            "INFO:__main__:Epoch 17946: total training loss 0.00084\n",
            "2025-06-26 08:47:25,983 Epoch 17946: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17947\n",
            "2025-06-26 08:47:25,985 EPOCH 17947\n",
            "INFO:__main__:Epoch 17947: total training loss 0.00089\n",
            "2025-06-26 08:47:26,054 Epoch 17947: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17948\n",
            "2025-06-26 08:47:26,056 EPOCH 17948\n",
            "INFO:__main__:Epoch 17948: total training loss 0.00089\n",
            "2025-06-26 08:47:26,127 Epoch 17948: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 17949\n",
            "2025-06-26 08:47:26,130 EPOCH 17949\n",
            "INFO:__main__:Epoch 17949: total training loss 0.00087\n",
            "2025-06-26 08:47:26,205 Epoch 17949: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17950\n",
            "2025-06-26 08:47:26,208 EPOCH 17950\n",
            "INFO:__main__:Epoch 17950: total training loss 0.00088\n",
            "2025-06-26 08:47:26,282 Epoch 17950: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 17951\n",
            "2025-06-26 08:47:26,285 EPOCH 17951\n",
            "INFO:__main__:Epoch 17951: total training loss 0.00083\n",
            "2025-06-26 08:47:26,356 Epoch 17951: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17952\n",
            "2025-06-26 08:47:26,358 EPOCH 17952\n",
            "INFO:__main__:Epoch 17952: total training loss 0.00082\n",
            "2025-06-26 08:47:26,431 Epoch 17952: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17953\n",
            "2025-06-26 08:47:26,434 EPOCH 17953\n",
            "INFO:__main__:Epoch 17953: total training loss 0.00087\n",
            "2025-06-26 08:47:26,508 Epoch 17953: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17954\n",
            "2025-06-26 08:47:26,511 EPOCH 17954\n",
            "INFO:__main__:Epoch 17954: total training loss 0.00085\n",
            "2025-06-26 08:47:26,586 Epoch 17954: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17955\n",
            "2025-06-26 08:47:26,589 EPOCH 17955\n",
            "INFO:__main__:Epoch 17955: total training loss 0.00082\n",
            "2025-06-26 08:47:26,666 Epoch 17955: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17956\n",
            "2025-06-26 08:47:26,668 EPOCH 17956\n",
            "INFO:__main__:Epoch 17956: total training loss 0.00084\n",
            "2025-06-26 08:47:26,752 Epoch 17956: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17957\n",
            "2025-06-26 08:47:26,754 EPOCH 17957\n",
            "INFO:__main__:Epoch 17957: total training loss 0.00083\n",
            "2025-06-26 08:47:26,834 Epoch 17957: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 17958\n",
            "2025-06-26 08:47:26,838 EPOCH 17958\n",
            "INFO:__main__:Epoch 17958: total training loss 0.00078\n",
            "2025-06-26 08:47:26,910 Epoch 17958: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17959\n",
            "2025-06-26 08:47:26,912 EPOCH 17959\n",
            "INFO:__main__:Epoch 17959: total training loss 0.00078\n",
            "2025-06-26 08:47:26,986 Epoch 17959: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17960\n",
            "2025-06-26 08:47:26,988 EPOCH 17960\n",
            "INFO:__main__:Epoch 17960: total training loss 0.00078\n",
            "2025-06-26 08:47:27,066 Epoch 17960: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17961\n",
            "2025-06-26 08:47:27,069 EPOCH 17961\n",
            "INFO:__main__:Epoch 17961: total training loss 0.00079\n",
            "2025-06-26 08:47:27,140 Epoch 17961: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17962\n",
            "2025-06-26 08:47:27,142 EPOCH 17962\n",
            "INFO:__main__:Epoch 17962: total training loss 0.00077\n",
            "2025-06-26 08:47:27,218 Epoch 17962: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17963\n",
            "2025-06-26 08:47:27,220 EPOCH 17963\n",
            "INFO:__main__:Epoch 17963: total training loss 0.00077\n",
            "2025-06-26 08:47:27,294 Epoch 17963: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17964\n",
            "2025-06-26 08:47:27,296 EPOCH 17964\n",
            "INFO:__main__:Epoch 17964: total training loss 0.00076\n",
            "2025-06-26 08:47:27,372 Epoch 17964: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17965\n",
            "2025-06-26 08:47:27,374 EPOCH 17965\n",
            "INFO:__main__:Epoch 17965: total training loss 0.00075\n",
            "2025-06-26 08:47:27,445 Epoch 17965: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 17966\n",
            "2025-06-26 08:47:27,447 EPOCH 17966\n",
            "INFO:__main__:Epoch 17966: total training loss 0.00077\n",
            "2025-06-26 08:47:27,517 Epoch 17966: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17967\n",
            "2025-06-26 08:47:27,519 EPOCH 17967\n",
            "INFO:__main__:Epoch 17967: total training loss 0.00077\n",
            "2025-06-26 08:47:27,592 Epoch 17967: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17968\n",
            "2025-06-26 08:47:27,595 EPOCH 17968\n",
            "INFO:__main__:Epoch 17968: total training loss 0.00081\n",
            "2025-06-26 08:47:27,664 Epoch 17968: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17969\n",
            "2025-06-26 08:47:27,666 EPOCH 17969\n",
            "INFO:__main__:Epoch 17969: total training loss 0.00081\n",
            "2025-06-26 08:47:27,737 Epoch 17969: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17970\n",
            "2025-06-26 08:47:27,739 EPOCH 17970\n",
            "INFO:__main__:Epoch 17970: total training loss 0.00087\n",
            "2025-06-26 08:47:27,820 Epoch 17970: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 17971\n",
            "2025-06-26 08:47:27,823 EPOCH 17971\n",
            "INFO:__main__:Epoch 17971: total training loss 0.00096\n",
            "2025-06-26 08:47:27,911 Epoch 17971: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 17972\n",
            "2025-06-26 08:47:27,913 EPOCH 17972\n",
            "INFO:__main__:Epoch 17972: total training loss 0.00098\n",
            "2025-06-26 08:47:27,993 Epoch 17972: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 17973\n",
            "2025-06-26 08:47:27,995 EPOCH 17973\n",
            "INFO:__main__:Epoch 17973: total training loss 0.00091\n",
            "2025-06-26 08:47:28,068 Epoch 17973: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 17974\n",
            "2025-06-26 08:47:28,072 EPOCH 17974\n",
            "INFO:__main__:Epoch 17974: total training loss 0.00085\n",
            "2025-06-26 08:47:28,148 Epoch 17974: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17975\n",
            "2025-06-26 08:47:28,151 EPOCH 17975\n",
            "INFO:__main__:Epoch 17975: total training loss 0.00085\n",
            "2025-06-26 08:47:28,230 Epoch 17975: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17976\n",
            "2025-06-26 08:47:28,233 EPOCH 17976\n",
            "INFO:__main__:Epoch 17976: total training loss 0.00090\n",
            "2025-06-26 08:47:28,306 Epoch 17976: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 17977\n",
            "2025-06-26 08:47:28,308 EPOCH 17977\n",
            "INFO:__main__:Epoch 17977: total training loss 0.00084\n",
            "2025-06-26 08:47:28,382 Epoch 17977: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17978\n",
            "2025-06-26 08:47:28,384 EPOCH 17978\n",
            "INFO:__main__:Epoch 17978: total training loss 0.00084\n",
            "2025-06-26 08:47:28,457 Epoch 17978: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17979\n",
            "2025-06-26 08:47:28,459 EPOCH 17979\n",
            "INFO:__main__:Epoch 17979: total training loss 0.00082\n",
            "2025-06-26 08:47:28,532 Epoch 17979: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17980\n",
            "2025-06-26 08:47:28,538 EPOCH 17980\n",
            "INFO:__main__:Epoch 17980: total training loss 0.00081\n",
            "2025-06-26 08:47:28,611 Epoch 17980: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17981\n",
            "2025-06-26 08:47:28,613 EPOCH 17981\n",
            "INFO:__main__:Epoch 17981: total training loss 0.00079\n",
            "2025-06-26 08:47:28,686 Epoch 17981: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17982\n",
            "2025-06-26 08:47:28,688 EPOCH 17982\n",
            "INFO:__main__:Epoch 17982: total training loss 0.00081\n",
            "2025-06-26 08:47:28,768 Epoch 17982: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 17983\n",
            "2025-06-26 08:47:28,771 EPOCH 17983\n",
            "INFO:__main__:Epoch 17983: total training loss 0.00078\n",
            "2025-06-26 08:47:28,856 Epoch 17983: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17984\n",
            "2025-06-26 08:47:28,858 EPOCH 17984\n",
            "INFO:__main__:Epoch 17984: total training loss 0.00077\n",
            "2025-06-26 08:47:28,974 Epoch 17984: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 17985\n",
            "2025-06-26 08:47:28,976 EPOCH 17985\n",
            "INFO:__main__:Epoch 17985: total training loss 0.00079\n",
            "2025-06-26 08:47:29,068 Epoch 17985: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17986\n",
            "2025-06-26 08:47:29,071 EPOCH 17986\n",
            "INFO:__main__:Epoch 17986: total training loss 0.00084\n",
            "2025-06-26 08:47:29,158 Epoch 17986: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17987\n",
            "2025-06-26 08:47:29,161 EPOCH 17987\n",
            "INFO:__main__:Epoch 17987: total training loss 0.00078\n",
            "2025-06-26 08:47:29,236 Epoch 17987: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 17988\n",
            "2025-06-26 08:47:29,241 EPOCH 17988\n",
            "INFO:__main__:Epoch 17988: total training loss 0.00080\n",
            "2025-06-26 08:47:29,345 Epoch 17988: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17989\n",
            "2025-06-26 08:47:29,347 EPOCH 17989\n",
            "INFO:__main__:Epoch 17989: total training loss 0.00082\n",
            "2025-06-26 08:47:29,455 Epoch 17989: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 17990\n",
            "2025-06-26 08:47:29,457 EPOCH 17990\n",
            "INFO:__main__:Epoch 17990: total training loss 0.00086\n",
            "2025-06-26 08:47:29,559 Epoch 17990: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 17991\n",
            "2025-06-26 08:47:29,561 EPOCH 17991\n",
            "INFO:__main__:Epoch 17991: total training loss 0.00080\n",
            "2025-06-26 08:47:29,640 Epoch 17991: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17992\n",
            "2025-06-26 08:47:29,642 EPOCH 17992\n",
            "INFO:__main__:Epoch 17992: total training loss 0.00085\n",
            "2025-06-26 08:47:29,716 Epoch 17992: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 17993\n",
            "2025-06-26 08:47:29,718 EPOCH 17993\n",
            "INFO:__main__:Epoch 17993: total training loss 0.00079\n",
            "2025-06-26 08:47:29,792 Epoch 17993: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17994\n",
            "2025-06-26 08:47:29,796 EPOCH 17994\n",
            "INFO:__main__:Epoch 17994: total training loss 0.00084\n",
            "2025-06-26 08:47:29,872 Epoch 17994: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 17995\n",
            "2025-06-26 08:47:29,874 EPOCH 17995\n",
            "INFO:__main__:Epoch 17995: total training loss 0.00079\n",
            "2025-06-26 08:47:29,944 Epoch 17995: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17996\n",
            "2025-06-26 08:47:29,946 EPOCH 17996\n",
            "INFO:__main__:Epoch 17996: total training loss 0.00079\n",
            "2025-06-26 08:47:30,021 Epoch 17996: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 17997\n",
            "2025-06-26 08:47:30,025 EPOCH 17997\n",
            "INFO:__main__:Epoch 17997: total training loss 0.00080\n",
            "2025-06-26 08:47:30,117 Epoch 17997: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 17998\n",
            "2025-06-26 08:47:30,120 EPOCH 17998\n",
            "INFO:__main__:Epoch 17998: total training loss 0.00076\n",
            "2025-06-26 08:47:30,198 Epoch 17998: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 17999\n",
            "2025-06-26 08:47:30,200 EPOCH 17999\n",
            "INFO:__main__:Epoch 17999: total training loss 0.00079\n",
            "2025-06-26 08:47:30,278 Epoch 17999: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18000\n",
            "2025-06-26 08:47:30,280 EPOCH 18000\n",
            "INFO:__main__:Epoch 18000 Step:    18000 Batch Loss:     0.000806 Tokens per Sec:  2073922, Lr: 0.001000\n",
            "2025-06-26 08:47:30,350 Epoch 18000 Step:    18000 Batch Loss:     0.000806 Tokens per Sec:  2073922, Lr: 0.001000\n",
            "INFO:__main__:Hooray! New best validation result [dtw]!\n",
            "2025-06-26 08:47:31,314 Hooray! New best validation result [dtw]!\n",
            "INFO:__main__:Saving new checkpoint.\n",
            "2025-06-26 08:47:31,316 Saving new checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev/11August_2010_Wednesday_tagesschau-2    dtw: 14.99\n",
            "dev/11August_2010_Wednesday_tagesschau-3    dtw: 10.58\n",
            "dev/11August_2010_Wednesday_tagesschau-8    dtw: 13.20\n",
            "dev/25October_2010_Monday_tagesschau-22    dtw: 15.73\n",
            "dev/05May_2011_Thursday_tagesschau-25    dtw: 10.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:__main__:EPOCH 18755\n",
            "2025-06-26 08:49:02,174 EPOCH 18755\n",
            "INFO:__main__:Epoch 18755: total training loss 0.00082\n",
            "2025-06-26 08:49:02,245 Epoch 18755: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18756\n",
            "2025-06-26 08:49:02,247 EPOCH 18756\n",
            "INFO:__main__:Epoch 18756: total training loss 0.00085\n",
            "2025-06-26 08:49:02,336 Epoch 18756: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18757\n",
            "2025-06-26 08:49:02,338 EPOCH 18757\n",
            "INFO:__main__:Epoch 18757: total training loss 0.00082\n",
            "2025-06-26 08:49:02,419 Epoch 18757: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18758\n",
            "2025-06-26 08:49:02,421 EPOCH 18758\n",
            "INFO:__main__:Epoch 18758: total training loss 0.00081\n",
            "2025-06-26 08:49:02,495 Epoch 18758: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18759\n",
            "2025-06-26 08:49:02,497 EPOCH 18759\n",
            "INFO:__main__:Epoch 18759: total training loss 0.00077\n",
            "2025-06-26 08:49:02,567 Epoch 18759: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18760\n",
            "2025-06-26 08:49:02,569 EPOCH 18760\n",
            "INFO:__main__:Epoch 18760: total training loss 0.00079\n",
            "2025-06-26 08:49:02,646 Epoch 18760: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18761\n",
            "2025-06-26 08:49:02,648 EPOCH 18761\n",
            "INFO:__main__:Epoch 18761: total training loss 0.00079\n",
            "2025-06-26 08:49:02,730 Epoch 18761: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18762\n",
            "2025-06-26 08:49:02,732 EPOCH 18762\n",
            "INFO:__main__:Epoch 18762: total training loss 0.00078\n",
            "2025-06-26 08:49:02,807 Epoch 18762: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18763\n",
            "2025-06-26 08:49:02,809 EPOCH 18763\n",
            "INFO:__main__:Epoch 18763: total training loss 0.00081\n",
            "2025-06-26 08:49:02,883 Epoch 18763: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18764\n",
            "2025-06-26 08:49:02,885 EPOCH 18764\n",
            "INFO:__main__:Epoch 18764: total training loss 0.00079\n",
            "2025-06-26 08:49:02,961 Epoch 18764: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18765\n",
            "2025-06-26 08:49:02,964 EPOCH 18765\n",
            "INFO:__main__:Epoch 18765: total training loss 0.00078\n",
            "2025-06-26 08:49:03,035 Epoch 18765: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18766\n",
            "2025-06-26 08:49:03,038 EPOCH 18766\n",
            "INFO:__main__:Epoch 18766: total training loss 0.00077\n",
            "2025-06-26 08:49:03,118 Epoch 18766: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18767\n",
            "2025-06-26 08:49:03,120 EPOCH 18767\n",
            "INFO:__main__:Epoch 18767: total training loss 0.00077\n",
            "2025-06-26 08:49:03,204 Epoch 18767: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18768\n",
            "2025-06-26 08:49:03,207 EPOCH 18768\n",
            "INFO:__main__:Epoch 18768: total training loss 0.00079\n",
            "2025-06-26 08:49:03,289 Epoch 18768: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18769\n",
            "2025-06-26 08:49:03,292 EPOCH 18769\n",
            "INFO:__main__:Epoch 18769: total training loss 0.00089\n",
            "2025-06-26 08:49:03,385 Epoch 18769: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 18770\n",
            "2025-06-26 08:49:03,388 EPOCH 18770\n",
            "INFO:__main__:Epoch 18770: total training loss 0.00098\n",
            "2025-06-26 08:49:03,483 Epoch 18770: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 18771\n",
            "2025-06-26 08:49:03,491 EPOCH 18771\n",
            "INFO:__main__:Epoch 18771: total training loss 0.00090\n",
            "2025-06-26 08:49:03,602 Epoch 18771: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 18772\n",
            "2025-06-26 08:49:03,604 EPOCH 18772\n",
            "INFO:__main__:Epoch 18772: total training loss 0.00088\n",
            "2025-06-26 08:49:03,722 Epoch 18772: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18773\n",
            "2025-06-26 08:49:03,729 EPOCH 18773\n",
            "INFO:__main__:Epoch 18773: total training loss 0.00095\n",
            "2025-06-26 08:49:03,844 Epoch 18773: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 18774\n",
            "2025-06-26 08:49:03,845 EPOCH 18774\n",
            "INFO:__main__:Epoch 18774: total training loss 0.00095\n",
            "2025-06-26 08:49:03,970 Epoch 18774: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 18775\n",
            "2025-06-26 08:49:03,974 EPOCH 18775\n",
            "INFO:__main__:Epoch 18775: total training loss 0.00085\n",
            "2025-06-26 08:49:04,096 Epoch 18775: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18776\n",
            "2025-06-26 08:49:04,102 EPOCH 18776\n",
            "INFO:__main__:Epoch 18776: total training loss 0.00088\n",
            "2025-06-26 08:49:04,227 Epoch 18776: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18777\n",
            "2025-06-26 08:49:04,229 EPOCH 18777\n",
            "INFO:__main__:Epoch 18777: total training loss 0.00087\n",
            "2025-06-26 08:49:04,333 Epoch 18777: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18778\n",
            "2025-06-26 08:49:04,340 EPOCH 18778\n",
            "INFO:__main__:Epoch 18778: total training loss 0.00088\n",
            "2025-06-26 08:49:04,444 Epoch 18778: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18779\n",
            "2025-06-26 08:49:04,446 EPOCH 18779\n",
            "INFO:__main__:Epoch 18779: total training loss 0.00087\n",
            "2025-06-26 08:49:04,524 Epoch 18779: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18780\n",
            "2025-06-26 08:49:04,526 EPOCH 18780\n",
            "INFO:__main__:Epoch 18780: total training loss 0.00086\n",
            "2025-06-26 08:49:04,611 Epoch 18780: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18781\n",
            "2025-06-26 08:49:04,616 EPOCH 18781\n",
            "INFO:__main__:Epoch 18781: total training loss 0.00086\n",
            "2025-06-26 08:49:04,699 Epoch 18781: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18782\n",
            "2025-06-26 08:49:04,705 EPOCH 18782\n",
            "INFO:__main__:Epoch 18782: total training loss 0.00083\n",
            "2025-06-26 08:49:04,806 Epoch 18782: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18783\n",
            "2025-06-26 08:49:04,809 EPOCH 18783\n",
            "INFO:__main__:Epoch 18783: total training loss 0.00086\n",
            "2025-06-26 08:49:04,881 Epoch 18783: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18784\n",
            "2025-06-26 08:49:04,887 EPOCH 18784\n",
            "INFO:__main__:Epoch 18784: total training loss 0.00082\n",
            "2025-06-26 08:49:04,964 Epoch 18784: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18785\n",
            "2025-06-26 08:49:04,970 EPOCH 18785\n",
            "INFO:__main__:Epoch 18785: total training loss 0.00081\n",
            "2025-06-26 08:49:05,056 Epoch 18785: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18786\n",
            "2025-06-26 08:49:05,063 EPOCH 18786\n",
            "INFO:__main__:Epoch 18786: total training loss 0.00081\n",
            "2025-06-26 08:49:05,163 Epoch 18786: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18787\n",
            "2025-06-26 08:49:05,166 EPOCH 18787\n",
            "INFO:__main__:Epoch 18787: total training loss 0.00083\n",
            "2025-06-26 08:49:05,258 Epoch 18787: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18788\n",
            "2025-06-26 08:49:05,260 EPOCH 18788\n",
            "INFO:__main__:Epoch 18788: total training loss 0.00083\n",
            "2025-06-26 08:49:05,352 Epoch 18788: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18789\n",
            "2025-06-26 08:49:05,354 EPOCH 18789\n",
            "INFO:__main__:Epoch 18789: total training loss 0.00078\n",
            "2025-06-26 08:49:05,445 Epoch 18789: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18790\n",
            "2025-06-26 08:49:05,448 EPOCH 18790\n",
            "INFO:__main__:Epoch 18790: total training loss 0.00076\n",
            "2025-06-26 08:49:05,534 Epoch 18790: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18791\n",
            "2025-06-26 08:49:05,537 EPOCH 18791\n",
            "INFO:__main__:Epoch 18791: total training loss 0.00075\n",
            "2025-06-26 08:49:05,634 Epoch 18791: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18792\n",
            "2025-06-26 08:49:05,638 EPOCH 18792\n",
            "INFO:__main__:Epoch 18792: total training loss 0.00077\n",
            "2025-06-26 08:49:05,722 Epoch 18792: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18793\n",
            "2025-06-26 08:49:05,724 EPOCH 18793\n",
            "INFO:__main__:Epoch 18793: total training loss 0.00078\n",
            "2025-06-26 08:49:05,805 Epoch 18793: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18794\n",
            "2025-06-26 08:49:05,807 EPOCH 18794\n",
            "INFO:__main__:Epoch 18794: total training loss 0.00078\n",
            "2025-06-26 08:49:05,878 Epoch 18794: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18795\n",
            "2025-06-26 08:49:05,880 EPOCH 18795\n",
            "INFO:__main__:Epoch 18795: total training loss 0.00078\n",
            "2025-06-26 08:49:05,952 Epoch 18795: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18796\n",
            "2025-06-26 08:49:05,955 EPOCH 18796\n",
            "INFO:__main__:Epoch 18796: total training loss 0.00082\n",
            "2025-06-26 08:49:06,043 Epoch 18796: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18797\n",
            "2025-06-26 08:49:06,045 EPOCH 18797\n",
            "INFO:__main__:Epoch 18797: total training loss 0.00083\n",
            "2025-06-26 08:49:06,116 Epoch 18797: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18798\n",
            "2025-06-26 08:49:06,118 EPOCH 18798\n",
            "INFO:__main__:Epoch 18798: total training loss 0.00078\n",
            "2025-06-26 08:49:06,192 Epoch 18798: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18799\n",
            "2025-06-26 08:49:06,195 EPOCH 18799\n",
            "INFO:__main__:Epoch 18799: total training loss 0.00076\n",
            "2025-06-26 08:49:06,265 Epoch 18799: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18800\n",
            "2025-06-26 08:49:06,266 EPOCH 18800\n",
            "INFO:__main__:Epoch 18800: total training loss 0.00080\n",
            "2025-06-26 08:49:06,335 Epoch 18800: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18801\n",
            "2025-06-26 08:49:06,337 EPOCH 18801\n",
            "INFO:__main__:Epoch 18801: total training loss 0.00080\n",
            "2025-06-26 08:49:06,408 Epoch 18801: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18802\n",
            "2025-06-26 08:49:06,410 EPOCH 18802\n",
            "INFO:__main__:Epoch 18802: total training loss 0.00081\n",
            "2025-06-26 08:49:06,483 Epoch 18802: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18803\n",
            "2025-06-26 08:49:06,485 EPOCH 18803\n",
            "INFO:__main__:Epoch 18803: total training loss 0.00084\n",
            "2025-06-26 08:49:06,561 Epoch 18803: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18804\n",
            "2025-06-26 08:49:06,564 EPOCH 18804\n",
            "INFO:__main__:Epoch 18804: total training loss 0.00079\n",
            "2025-06-26 08:49:06,649 Epoch 18804: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18805\n",
            "2025-06-26 08:49:06,651 EPOCH 18805\n",
            "INFO:__main__:Epoch 18805: total training loss 0.00081\n",
            "2025-06-26 08:49:06,726 Epoch 18805: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18806\n",
            "2025-06-26 08:49:06,728 EPOCH 18806\n",
            "INFO:__main__:Epoch 18806: total training loss 0.00078\n",
            "2025-06-26 08:49:06,798 Epoch 18806: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18807\n",
            "2025-06-26 08:49:06,800 EPOCH 18807\n",
            "INFO:__main__:Epoch 18807: total training loss 0.00078\n",
            "2025-06-26 08:49:06,867 Epoch 18807: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18808\n",
            "2025-06-26 08:49:06,869 EPOCH 18808\n",
            "INFO:__main__:Epoch 18808: total training loss 0.00078\n",
            "2025-06-26 08:49:06,949 Epoch 18808: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18809\n",
            "2025-06-26 08:49:06,951 EPOCH 18809\n",
            "INFO:__main__:Epoch 18809: total training loss 0.00079\n",
            "2025-06-26 08:49:07,023 Epoch 18809: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18810\n",
            "2025-06-26 08:49:07,026 EPOCH 18810\n",
            "INFO:__main__:Epoch 18810: total training loss 0.00077\n",
            "2025-06-26 08:49:07,097 Epoch 18810: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18811\n",
            "2025-06-26 08:49:07,099 EPOCH 18811\n",
            "INFO:__main__:Epoch 18811: total training loss 0.00080\n",
            "2025-06-26 08:49:07,170 Epoch 18811: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18812\n",
            "2025-06-26 08:49:07,172 EPOCH 18812\n",
            "INFO:__main__:Epoch 18812: total training loss 0.00085\n",
            "2025-06-26 08:49:07,253 Epoch 18812: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18813\n",
            "2025-06-26 08:49:07,255 EPOCH 18813\n",
            "INFO:__main__:Epoch 18813: total training loss 0.00083\n",
            "2025-06-26 08:49:07,371 Epoch 18813: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18814\n",
            "2025-06-26 08:49:07,373 EPOCH 18814\n",
            "INFO:__main__:Epoch 18814: total training loss 0.00079\n",
            "2025-06-26 08:49:07,486 Epoch 18814: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18815\n",
            "2025-06-26 08:49:07,488 EPOCH 18815\n",
            "INFO:__main__:Epoch 18815: total training loss 0.00081\n",
            "2025-06-26 08:49:07,580 Epoch 18815: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18816\n",
            "2025-06-26 08:49:07,582 EPOCH 18816\n",
            "INFO:__main__:Epoch 18816: total training loss 0.00078\n",
            "2025-06-26 08:49:07,680 Epoch 18816: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18817\n",
            "2025-06-26 08:49:07,682 EPOCH 18817\n",
            "INFO:__main__:Epoch 18817: total training loss 0.00083\n",
            "2025-06-26 08:49:07,773 Epoch 18817: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18818\n",
            "2025-06-26 08:49:07,778 EPOCH 18818\n",
            "INFO:__main__:Epoch 18818: total training loss 0.00077\n",
            "2025-06-26 08:49:07,888 Epoch 18818: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18819\n",
            "2025-06-26 08:49:07,890 EPOCH 18819\n",
            "INFO:__main__:Epoch 18819: total training loss 0.00074\n",
            "2025-06-26 08:49:07,979 Epoch 18819: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18820\n",
            "2025-06-26 08:49:07,981 EPOCH 18820\n",
            "INFO:__main__:Epoch 18820: total training loss 0.00075\n",
            "2025-06-26 08:49:08,078 Epoch 18820: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18821\n",
            "2025-06-26 08:49:08,080 EPOCH 18821\n",
            "INFO:__main__:Epoch 18821: total training loss 0.00080\n",
            "2025-06-26 08:49:08,178 Epoch 18821: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18822\n",
            "2025-06-26 08:49:08,180 EPOCH 18822\n",
            "INFO:__main__:Epoch 18822: total training loss 0.00077\n",
            "2025-06-26 08:49:08,282 Epoch 18822: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18823\n",
            "2025-06-26 08:49:08,284 EPOCH 18823\n",
            "INFO:__main__:Epoch 18823: total training loss 0.00077\n",
            "2025-06-26 08:49:08,405 Epoch 18823: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18824\n",
            "2025-06-26 08:49:08,409 EPOCH 18824\n",
            "INFO:__main__:Epoch 18824: total training loss 0.00076\n",
            "2025-06-26 08:49:08,534 Epoch 18824: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18825\n",
            "2025-06-26 08:49:08,540 EPOCH 18825\n",
            "INFO:__main__:Epoch 18825: total training loss 0.00078\n",
            "2025-06-26 08:49:08,652 Epoch 18825: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18826\n",
            "2025-06-26 08:49:08,654 EPOCH 18826\n",
            "INFO:__main__:Epoch 18826: total training loss 0.00083\n",
            "2025-06-26 08:49:08,747 Epoch 18826: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18827\n",
            "2025-06-26 08:49:08,750 EPOCH 18827\n",
            "INFO:__main__:Epoch 18827: total training loss 0.00084\n",
            "2025-06-26 08:49:08,852 Epoch 18827: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18828\n",
            "2025-06-26 08:49:08,855 EPOCH 18828\n",
            "INFO:__main__:Epoch 18828: total training loss 0.00086\n",
            "2025-06-26 08:49:08,939 Epoch 18828: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18829\n",
            "2025-06-26 08:49:08,941 EPOCH 18829\n",
            "INFO:__main__:Epoch 18829: total training loss 0.00091\n",
            "2025-06-26 08:49:09,012 Epoch 18829: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 18830\n",
            "2025-06-26 08:49:09,014 EPOCH 18830\n",
            "INFO:__main__:Epoch 18830: total training loss 0.00086\n",
            "2025-06-26 08:49:09,086 Epoch 18830: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18831\n",
            "2025-06-26 08:49:09,089 EPOCH 18831\n",
            "INFO:__main__:Epoch 18831: total training loss 0.00090\n",
            "2025-06-26 08:49:09,158 Epoch 18831: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 18832\n",
            "2025-06-26 08:49:09,160 EPOCH 18832\n",
            "INFO:__main__:Epoch 18832: total training loss 0.00083\n",
            "2025-06-26 08:49:09,246 Epoch 18832: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18833\n",
            "2025-06-26 08:49:09,250 EPOCH 18833\n",
            "INFO:__main__:Epoch 18833: total training loss 0.00085\n",
            "2025-06-26 08:49:09,320 Epoch 18833: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18834\n",
            "2025-06-26 08:49:09,322 EPOCH 18834\n",
            "INFO:__main__:Epoch 18834: total training loss 0.00083\n",
            "2025-06-26 08:49:09,394 Epoch 18834: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18835\n",
            "2025-06-26 08:49:09,398 EPOCH 18835\n",
            "INFO:__main__:Epoch 18835: total training loss 0.00081\n",
            "2025-06-26 08:49:09,480 Epoch 18835: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18836\n",
            "2025-06-26 08:49:09,483 EPOCH 18836\n",
            "INFO:__main__:Epoch 18836: total training loss 0.00082\n",
            "2025-06-26 08:49:09,555 Epoch 18836: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18837\n",
            "2025-06-26 08:49:09,556 EPOCH 18837\n",
            "INFO:__main__:Epoch 18837: total training loss 0.00082\n",
            "2025-06-26 08:49:09,638 Epoch 18837: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18838\n",
            "2025-06-26 08:49:09,640 EPOCH 18838\n",
            "INFO:__main__:Epoch 18838: total training loss 0.00077\n",
            "2025-06-26 08:49:09,713 Epoch 18838: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18839\n",
            "2025-06-26 08:49:09,717 EPOCH 18839\n",
            "INFO:__main__:Epoch 18839: total training loss 0.00079\n",
            "2025-06-26 08:49:09,791 Epoch 18839: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18840\n",
            "2025-06-26 08:49:09,798 EPOCH 18840\n",
            "INFO:__main__:Epoch 18840: total training loss 0.00081\n",
            "2025-06-26 08:49:09,879 Epoch 18840: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18841\n",
            "2025-06-26 08:49:09,881 EPOCH 18841\n",
            "INFO:__main__:Epoch 18841: total training loss 0.00084\n",
            "2025-06-26 08:49:09,967 Epoch 18841: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18842\n",
            "2025-06-26 08:49:09,970 EPOCH 18842\n",
            "INFO:__main__:Epoch 18842: total training loss 0.00079\n",
            "2025-06-26 08:49:10,042 Epoch 18842: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18843\n",
            "2025-06-26 08:49:10,044 EPOCH 18843\n",
            "INFO:__main__:Epoch 18843: total training loss 0.00084\n",
            "2025-06-26 08:49:10,119 Epoch 18843: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18844\n",
            "2025-06-26 08:49:10,122 EPOCH 18844\n",
            "INFO:__main__:Epoch 18844: total training loss 0.00080\n",
            "2025-06-26 08:49:10,196 Epoch 18844: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18845\n",
            "2025-06-26 08:49:10,198 EPOCH 18845\n",
            "INFO:__main__:Epoch 18845: total training loss 0.00083\n",
            "2025-06-26 08:49:10,279 Epoch 18845: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18846\n",
            "2025-06-26 08:49:10,281 EPOCH 18846\n",
            "INFO:__main__:Epoch 18846: total training loss 0.00082\n",
            "2025-06-26 08:49:10,358 Epoch 18846: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18847\n",
            "2025-06-26 08:49:10,360 EPOCH 18847\n",
            "INFO:__main__:Epoch 18847: total training loss 0.00081\n",
            "2025-06-26 08:49:10,430 Epoch 18847: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18848\n",
            "2025-06-26 08:49:10,436 EPOCH 18848\n",
            "INFO:__main__:Epoch 18848: total training loss 0.00079\n",
            "2025-06-26 08:49:10,520 Epoch 18848: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18849\n",
            "2025-06-26 08:49:10,522 EPOCH 18849\n",
            "INFO:__main__:Epoch 18849: total training loss 0.00084\n",
            "2025-06-26 08:49:10,596 Epoch 18849: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18850\n",
            "2025-06-26 08:49:10,598 EPOCH 18850\n",
            "INFO:__main__:Epoch 18850: total training loss 0.00081\n",
            "2025-06-26 08:49:10,684 Epoch 18850: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18851\n",
            "2025-06-26 08:49:10,687 EPOCH 18851\n",
            "INFO:__main__:Epoch 18851: total training loss 0.00077\n",
            "2025-06-26 08:49:10,760 Epoch 18851: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18852\n",
            "2025-06-26 08:49:10,763 EPOCH 18852\n",
            "INFO:__main__:Epoch 18852: total training loss 0.00076\n",
            "2025-06-26 08:49:10,844 Epoch 18852: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18853\n",
            "2025-06-26 08:49:10,847 EPOCH 18853\n",
            "INFO:__main__:Epoch 18853: total training loss 0.00076\n",
            "2025-06-26 08:49:10,922 Epoch 18853: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18854\n",
            "2025-06-26 08:49:10,926 EPOCH 18854\n",
            "INFO:__main__:Epoch 18854: total training loss 0.00074\n",
            "2025-06-26 08:49:11,017 Epoch 18854: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18855\n",
            "2025-06-26 08:49:11,021 EPOCH 18855\n",
            "INFO:__main__:Epoch 18855: total training loss 0.00075\n",
            "2025-06-26 08:49:11,096 Epoch 18855: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18856\n",
            "2025-06-26 08:49:11,098 EPOCH 18856\n",
            "INFO:__main__:Epoch 18856: total training loss 0.00076\n",
            "2025-06-26 08:49:11,170 Epoch 18856: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18857\n",
            "2025-06-26 08:49:11,173 EPOCH 18857\n",
            "INFO:__main__:Epoch 18857: total training loss 0.00079\n",
            "2025-06-26 08:49:11,251 Epoch 18857: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18858\n",
            "2025-06-26 08:49:11,254 EPOCH 18858\n",
            "INFO:__main__:Epoch 18858: total training loss 0.00078\n",
            "2025-06-26 08:49:11,325 Epoch 18858: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18859\n",
            "2025-06-26 08:49:11,328 EPOCH 18859\n",
            "INFO:__main__:Epoch 18859: total training loss 0.00074\n",
            "2025-06-26 08:49:11,396 Epoch 18859: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18860\n",
            "2025-06-26 08:49:11,398 EPOCH 18860\n",
            "INFO:__main__:Epoch 18860: total training loss 0.00076\n",
            "2025-06-26 08:49:11,468 Epoch 18860: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18861\n",
            "2025-06-26 08:49:11,470 EPOCH 18861\n",
            "INFO:__main__:Epoch 18861: total training loss 0.00077\n",
            "2025-06-26 08:49:11,542 Epoch 18861: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18862\n",
            "2025-06-26 08:49:11,544 EPOCH 18862\n",
            "INFO:__main__:Epoch 18862: total training loss 0.00079\n",
            "2025-06-26 08:49:11,618 Epoch 18862: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18863\n",
            "2025-06-26 08:49:11,620 EPOCH 18863\n",
            "INFO:__main__:Epoch 18863: total training loss 0.00085\n",
            "2025-06-26 08:49:11,690 Epoch 18863: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18864\n",
            "2025-06-26 08:49:11,696 EPOCH 18864\n",
            "INFO:__main__:Epoch 18864: total training loss 0.00092\n",
            "2025-06-26 08:49:11,773 Epoch 18864: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 18865\n",
            "2025-06-26 08:49:11,779 EPOCH 18865\n",
            "INFO:__main__:Epoch 18865: total training loss 0.00092\n",
            "2025-06-26 08:49:11,852 Epoch 18865: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 18866\n",
            "2025-06-26 08:49:11,854 EPOCH 18866\n",
            "INFO:__main__:Epoch 18866: total training loss 0.00096\n",
            "2025-06-26 08:49:11,923 Epoch 18866: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 18867\n",
            "2025-06-26 08:49:11,924 EPOCH 18867\n",
            "INFO:__main__:Epoch 18867: total training loss 0.00095\n",
            "2025-06-26 08:49:11,998 Epoch 18867: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 18868\n",
            "2025-06-26 08:49:11,999 EPOCH 18868\n",
            "INFO:__main__:Epoch 18868: total training loss 0.00090\n",
            "2025-06-26 08:49:12,080 Epoch 18868: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 18869\n",
            "2025-06-26 08:49:12,082 EPOCH 18869\n",
            "INFO:__main__:Epoch 18869: total training loss 0.00082\n",
            "2025-06-26 08:49:12,162 Epoch 18869: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18870\n",
            "2025-06-26 08:49:12,164 EPOCH 18870\n",
            "INFO:__main__:Epoch 18870: total training loss 0.00088\n",
            "2025-06-26 08:49:12,283 Epoch 18870: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18871\n",
            "2025-06-26 08:49:12,285 EPOCH 18871\n",
            "INFO:__main__:Epoch 18871: total training loss 0.00090\n",
            "2025-06-26 08:49:12,363 Epoch 18871: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 18872\n",
            "2025-06-26 08:49:12,365 EPOCH 18872\n",
            "INFO:__main__:Epoch 18872: total training loss 0.00086\n",
            "2025-06-26 08:49:12,448 Epoch 18872: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18873\n",
            "2025-06-26 08:49:12,451 EPOCH 18873\n",
            "INFO:__main__:Epoch 18873: total training loss 0.00085\n",
            "2025-06-26 08:49:12,525 Epoch 18873: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18874\n",
            "2025-06-26 08:49:12,528 EPOCH 18874\n",
            "INFO:__main__:Epoch 18874: total training loss 0.00084\n",
            "2025-06-26 08:49:12,601 Epoch 18874: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18875\n",
            "2025-06-26 08:49:12,603 EPOCH 18875\n",
            "INFO:__main__:Epoch 18875: total training loss 0.00079\n",
            "2025-06-26 08:49:12,676 Epoch 18875: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18876\n",
            "2025-06-26 08:49:12,678 EPOCH 18876\n",
            "INFO:__main__:Epoch 18876: total training loss 0.00081\n",
            "2025-06-26 08:49:12,751 Epoch 18876: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18877\n",
            "2025-06-26 08:49:12,755 EPOCH 18877\n",
            "INFO:__main__:Epoch 18877: total training loss 0.00080\n",
            "2025-06-26 08:49:12,826 Epoch 18877: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18878\n",
            "2025-06-26 08:49:12,829 EPOCH 18878\n",
            "INFO:__main__:Epoch 18878: total training loss 0.00077\n",
            "2025-06-26 08:49:12,899 Epoch 18878: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18879\n",
            "2025-06-26 08:49:12,903 EPOCH 18879\n",
            "INFO:__main__:Epoch 18879: total training loss 0.00078\n",
            "2025-06-26 08:49:12,977 Epoch 18879: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18880\n",
            "2025-06-26 08:49:12,979 EPOCH 18880\n",
            "INFO:__main__:Epoch 18880: total training loss 0.00079\n",
            "2025-06-26 08:49:13,051 Epoch 18880: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18881\n",
            "2025-06-26 08:49:13,054 EPOCH 18881\n",
            "INFO:__main__:Epoch 18881: total training loss 0.00077\n",
            "2025-06-26 08:49:13,131 Epoch 18881: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18882\n",
            "2025-06-26 08:49:13,133 EPOCH 18882\n",
            "INFO:__main__:Epoch 18882: total training loss 0.00076\n",
            "2025-06-26 08:49:13,225 Epoch 18882: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18883\n",
            "2025-06-26 08:49:13,227 EPOCH 18883\n",
            "INFO:__main__:Epoch 18883: total training loss 0.00076\n",
            "2025-06-26 08:49:13,302 Epoch 18883: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18884\n",
            "2025-06-26 08:49:13,304 EPOCH 18884\n",
            "INFO:__main__:Epoch 18884: total training loss 0.00073\n",
            "2025-06-26 08:49:13,382 Epoch 18884: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 18885\n",
            "2025-06-26 08:49:13,385 EPOCH 18885\n",
            "INFO:__main__:Epoch 18885: total training loss 0.00074\n",
            "2025-06-26 08:49:13,458 Epoch 18885: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18886\n",
            "2025-06-26 08:49:13,460 EPOCH 18886\n",
            "INFO:__main__:Epoch 18886: total training loss 0.00072\n",
            "2025-06-26 08:49:13,543 Epoch 18886: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 18887\n",
            "2025-06-26 08:49:13,545 EPOCH 18887\n",
            "INFO:__main__:Epoch 18887: total training loss 0.00073\n",
            "2025-06-26 08:49:13,620 Epoch 18887: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 18888\n",
            "2025-06-26 08:49:13,623 EPOCH 18888\n",
            "INFO:__main__:Epoch 18888: total training loss 0.00081\n",
            "2025-06-26 08:49:13,696 Epoch 18888: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18889\n",
            "2025-06-26 08:49:13,700 EPOCH 18889\n",
            "INFO:__main__:Epoch 18889: total training loss 0.00082\n",
            "2025-06-26 08:49:13,770 Epoch 18889: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18890\n",
            "2025-06-26 08:49:13,772 EPOCH 18890\n",
            "INFO:__main__:Epoch 18890: total training loss 0.00083\n",
            "2025-06-26 08:49:13,856 Epoch 18890: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18891\n",
            "2025-06-26 08:49:13,858 EPOCH 18891\n",
            "INFO:__main__:Epoch 18891: total training loss 0.00087\n",
            "2025-06-26 08:49:13,937 Epoch 18891: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18892\n",
            "2025-06-26 08:49:13,939 EPOCH 18892\n",
            "INFO:__main__:Epoch 18892: total training loss 0.00093\n",
            "2025-06-26 08:49:14,025 Epoch 18892: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 18893\n",
            "2025-06-26 08:49:14,027 EPOCH 18893\n",
            "INFO:__main__:Epoch 18893: total training loss 0.00092\n",
            "2025-06-26 08:49:14,102 Epoch 18893: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 18894\n",
            "2025-06-26 08:49:14,104 EPOCH 18894\n",
            "INFO:__main__:Epoch 18894: total training loss 0.00089\n",
            "2025-06-26 08:49:14,179 Epoch 18894: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 18895\n",
            "2025-06-26 08:49:14,181 EPOCH 18895\n",
            "INFO:__main__:Epoch 18895: total training loss 0.00086\n",
            "2025-06-26 08:49:14,275 Epoch 18895: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18896\n",
            "2025-06-26 08:49:14,279 EPOCH 18896\n",
            "INFO:__main__:Epoch 18896: total training loss 0.00085\n",
            "2025-06-26 08:49:14,363 Epoch 18896: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18897\n",
            "2025-06-26 08:49:14,367 EPOCH 18897\n",
            "INFO:__main__:Epoch 18897: total training loss 0.00086\n",
            "2025-06-26 08:49:14,442 Epoch 18897: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18898\n",
            "2025-06-26 08:49:14,444 EPOCH 18898\n",
            "INFO:__main__:Epoch 18898: total training loss 0.00087\n",
            "2025-06-26 08:49:14,518 Epoch 18898: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18899\n",
            "2025-06-26 08:49:14,520 EPOCH 18899\n",
            "INFO:__main__:Epoch 18899: total training loss 0.00088\n",
            "2025-06-26 08:49:14,590 Epoch 18899: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18900\n",
            "2025-06-26 08:49:14,592 EPOCH 18900\n",
            "INFO:__main__:Epoch 18900: total training loss 0.00083\n",
            "2025-06-26 08:49:14,662 Epoch 18900: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18901\n",
            "2025-06-26 08:49:14,664 EPOCH 18901\n",
            "INFO:__main__:Epoch 18901: total training loss 0.00082\n",
            "2025-06-26 08:49:14,747 Epoch 18901: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18902\n",
            "2025-06-26 08:49:14,749 EPOCH 18902\n",
            "INFO:__main__:Epoch 18902: total training loss 0.00087\n",
            "2025-06-26 08:49:14,822 Epoch 18902: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18903\n",
            "2025-06-26 08:49:14,824 EPOCH 18903\n",
            "INFO:__main__:Epoch 18903: total training loss 0.00086\n",
            "2025-06-26 08:49:14,893 Epoch 18903: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18904\n",
            "2025-06-26 08:49:14,895 EPOCH 18904\n",
            "INFO:__main__:Epoch 18904: total training loss 0.00083\n",
            "2025-06-26 08:49:14,965 Epoch 18904: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18905\n",
            "2025-06-26 08:49:14,967 EPOCH 18905\n",
            "INFO:__main__:Epoch 18905: total training loss 0.00084\n",
            "2025-06-26 08:49:15,038 Epoch 18905: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18906\n",
            "2025-06-26 08:49:15,040 EPOCH 18906\n",
            "INFO:__main__:Epoch 18906: total training loss 0.00082\n",
            "2025-06-26 08:49:15,113 Epoch 18906: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18907\n",
            "2025-06-26 08:49:15,116 EPOCH 18907\n",
            "INFO:__main__:Epoch 18907: total training loss 0.00084\n",
            "2025-06-26 08:49:15,185 Epoch 18907: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18908\n",
            "2025-06-26 08:49:15,188 EPOCH 18908\n",
            "INFO:__main__:Epoch 18908: total training loss 0.00083\n",
            "2025-06-26 08:49:15,277 Epoch 18908: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18909\n",
            "2025-06-26 08:49:15,280 EPOCH 18909\n",
            "INFO:__main__:Epoch 18909: total training loss 0.00088\n",
            "2025-06-26 08:49:15,381 Epoch 18909: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18910\n",
            "2025-06-26 08:49:15,384 EPOCH 18910\n",
            "INFO:__main__:Epoch 18910: total training loss 0.00084\n",
            "2025-06-26 08:49:15,458 Epoch 18910: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18911\n",
            "2025-06-26 08:49:15,462 EPOCH 18911\n",
            "INFO:__main__:Epoch 18911: total training loss 0.00081\n",
            "2025-06-26 08:49:15,540 Epoch 18911: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18912\n",
            "2025-06-26 08:49:15,542 EPOCH 18912\n",
            "INFO:__main__:Epoch 18912: total training loss 0.00087\n",
            "2025-06-26 08:49:15,635 Epoch 18912: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18913\n",
            "2025-06-26 08:49:15,637 EPOCH 18913\n",
            "INFO:__main__:Epoch 18913: total training loss 0.00087\n",
            "2025-06-26 08:49:15,708 Epoch 18913: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18914\n",
            "2025-06-26 08:49:15,711 EPOCH 18914\n",
            "INFO:__main__:Epoch 18914: total training loss 0.00083\n",
            "2025-06-26 08:49:15,786 Epoch 18914: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18915\n",
            "2025-06-26 08:49:15,788 EPOCH 18915\n",
            "INFO:__main__:Epoch 18915: total training loss 0.00080\n",
            "2025-06-26 08:49:15,864 Epoch 18915: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18916\n",
            "2025-06-26 08:49:15,868 EPOCH 18916\n",
            "INFO:__main__:Epoch 18916: total training loss 0.00089\n",
            "2025-06-26 08:49:15,945 Epoch 18916: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 18917\n",
            "2025-06-26 08:49:15,950 EPOCH 18917\n",
            "INFO:__main__:Epoch 18917: total training loss 0.00085\n",
            "2025-06-26 08:49:16,025 Epoch 18917: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18918\n",
            "2025-06-26 08:49:16,027 EPOCH 18918\n",
            "INFO:__main__:Epoch 18918: total training loss 0.00086\n",
            "2025-06-26 08:49:16,102 Epoch 18918: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18919\n",
            "2025-06-26 08:49:16,104 EPOCH 18919\n",
            "INFO:__main__:Epoch 18919: total training loss 0.00085\n",
            "2025-06-26 08:49:16,174 Epoch 18919: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18920\n",
            "2025-06-26 08:49:16,176 EPOCH 18920\n",
            "INFO:__main__:Epoch 18920: total training loss 0.00077\n",
            "2025-06-26 08:49:16,254 Epoch 18920: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18921\n",
            "2025-06-26 08:49:16,257 EPOCH 18921\n",
            "INFO:__main__:Epoch 18921: total training loss 0.00081\n",
            "2025-06-26 08:49:16,328 Epoch 18921: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18922\n",
            "2025-06-26 08:49:16,330 EPOCH 18922\n",
            "INFO:__main__:Epoch 18922: total training loss 0.00086\n",
            "2025-06-26 08:49:16,416 Epoch 18922: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18923\n",
            "2025-06-26 08:49:16,418 EPOCH 18923\n",
            "INFO:__main__:Epoch 18923: total training loss 0.00080\n",
            "2025-06-26 08:49:16,488 Epoch 18923: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18924\n",
            "2025-06-26 08:49:16,490 EPOCH 18924\n",
            "INFO:__main__:Epoch 18924: total training loss 0.00087\n",
            "2025-06-26 08:49:16,563 Epoch 18924: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18925\n",
            "2025-06-26 08:49:16,567 EPOCH 18925\n",
            "INFO:__main__:Epoch 18925: total training loss 0.00082\n",
            "2025-06-26 08:49:16,647 Epoch 18925: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18926\n",
            "2025-06-26 08:49:16,649 EPOCH 18926\n",
            "INFO:__main__:Epoch 18926: total training loss 0.00088\n",
            "2025-06-26 08:49:16,723 Epoch 18926: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18927\n",
            "2025-06-26 08:49:16,725 EPOCH 18927\n",
            "INFO:__main__:Epoch 18927: total training loss 0.00087\n",
            "2025-06-26 08:49:16,800 Epoch 18927: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18928\n",
            "2025-06-26 08:49:16,802 EPOCH 18928\n",
            "INFO:__main__:Epoch 18928: total training loss 0.00086\n",
            "2025-06-26 08:49:16,878 Epoch 18928: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18929\n",
            "2025-06-26 08:49:16,880 EPOCH 18929\n",
            "INFO:__main__:Epoch 18929: total training loss 0.00084\n",
            "2025-06-26 08:49:16,952 Epoch 18929: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18930\n",
            "2025-06-26 08:49:16,954 EPOCH 18930\n",
            "INFO:__main__:Epoch 18930: total training loss 0.00076\n",
            "2025-06-26 08:49:17,025 Epoch 18930: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18931\n",
            "2025-06-26 08:49:17,027 EPOCH 18931\n",
            "INFO:__main__:Epoch 18931: total training loss 0.00082\n",
            "2025-06-26 08:49:17,104 Epoch 18931: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18932\n",
            "2025-06-26 08:49:17,106 EPOCH 18932\n",
            "INFO:__main__:Epoch 18932: total training loss 0.00081\n",
            "2025-06-26 08:49:17,180 Epoch 18932: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18933\n",
            "2025-06-26 08:49:17,182 EPOCH 18933\n",
            "INFO:__main__:Epoch 18933: total training loss 0.00078\n",
            "2025-06-26 08:49:17,255 Epoch 18933: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18934\n",
            "2025-06-26 08:49:17,257 EPOCH 18934\n",
            "INFO:__main__:Epoch 18934: total training loss 0.00078\n",
            "2025-06-26 08:49:17,339 Epoch 18934: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18935\n",
            "2025-06-26 08:49:17,341 EPOCH 18935\n",
            "INFO:__main__:Epoch 18935: total training loss 0.00080\n",
            "2025-06-26 08:49:17,417 Epoch 18935: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18936\n",
            "2025-06-26 08:49:17,421 EPOCH 18936\n",
            "INFO:__main__:Epoch 18936: total training loss 0.00076\n",
            "2025-06-26 08:49:17,515 Epoch 18936: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18937\n",
            "2025-06-26 08:49:17,517 EPOCH 18937\n",
            "INFO:__main__:Epoch 18937: total training loss 0.00073\n",
            "2025-06-26 08:49:17,591 Epoch 18937: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 18938\n",
            "2025-06-26 08:49:17,593 EPOCH 18938\n",
            "INFO:__main__:Epoch 18938: total training loss 0.00075\n",
            "2025-06-26 08:49:17,664 Epoch 18938: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18939\n",
            "2025-06-26 08:49:17,666 EPOCH 18939\n",
            "INFO:__main__:Epoch 18939: total training loss 0.00080\n",
            "2025-06-26 08:49:17,738 Epoch 18939: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18940\n",
            "2025-06-26 08:49:17,740 EPOCH 18940\n",
            "INFO:__main__:Epoch 18940: total training loss 0.00076\n",
            "2025-06-26 08:49:17,812 Epoch 18940: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18941\n",
            "2025-06-26 08:49:17,814 EPOCH 18941\n",
            "INFO:__main__:Epoch 18941: total training loss 0.00077\n",
            "2025-06-26 08:49:17,885 Epoch 18941: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18942\n",
            "2025-06-26 08:49:17,887 EPOCH 18942\n",
            "INFO:__main__:Epoch 18942: total training loss 0.00073\n",
            "2025-06-26 08:49:17,960 Epoch 18942: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 18943\n",
            "2025-06-26 08:49:17,962 EPOCH 18943\n",
            "INFO:__main__:Epoch 18943: total training loss 0.00075\n",
            "2025-06-26 08:49:18,036 Epoch 18943: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18944\n",
            "2025-06-26 08:49:18,039 EPOCH 18944\n",
            "INFO:__main__:Epoch 18944: total training loss 0.00075\n",
            "2025-06-26 08:49:18,114 Epoch 18944: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 18945\n",
            "2025-06-26 08:49:18,123 EPOCH 18945\n",
            "INFO:__main__:Epoch 18945: total training loss 0.00080\n",
            "2025-06-26 08:49:18,210 Epoch 18945: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18946\n",
            "2025-06-26 08:49:18,213 EPOCH 18946\n",
            "INFO:__main__:Epoch 18946: total training loss 0.00082\n",
            "2025-06-26 08:49:18,285 Epoch 18946: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18947\n",
            "2025-06-26 08:49:18,290 EPOCH 18947\n",
            "INFO:__main__:Epoch 18947: total training loss 0.00079\n",
            "2025-06-26 08:49:18,381 Epoch 18947: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18948\n",
            "2025-06-26 08:49:18,384 EPOCH 18948\n",
            "INFO:__main__:Epoch 18948: total training loss 0.00085\n",
            "2025-06-26 08:49:18,458 Epoch 18948: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18949\n",
            "2025-06-26 08:49:18,460 EPOCH 18949\n",
            "INFO:__main__:Epoch 18949: total training loss 0.00091\n",
            "2025-06-26 08:49:18,577 Epoch 18949: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 18950\n",
            "2025-06-26 08:49:18,584 EPOCH 18950\n",
            "INFO:__main__:Epoch 18950: total training loss 0.00092\n",
            "2025-06-26 08:49:18,660 Epoch 18950: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 18951\n",
            "2025-06-26 08:49:18,662 EPOCH 18951\n",
            "INFO:__main__:Epoch 18951: total training loss 0.00089\n",
            "2025-06-26 08:49:18,732 Epoch 18951: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 18952\n",
            "2025-06-26 08:49:18,734 EPOCH 18952\n",
            "INFO:__main__:Epoch 18952: total training loss 0.00086\n",
            "2025-06-26 08:49:18,817 Epoch 18952: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18953\n",
            "2025-06-26 08:49:18,819 EPOCH 18953\n",
            "INFO:__main__:Epoch 18953: total training loss 0.00085\n",
            "2025-06-26 08:49:18,891 Epoch 18953: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18954\n",
            "2025-06-26 08:49:18,893 EPOCH 18954\n",
            "INFO:__main__:Epoch 18954: total training loss 0.00088\n",
            "2025-06-26 08:49:18,970 Epoch 18954: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18955\n",
            "2025-06-26 08:49:18,972 EPOCH 18955\n",
            "INFO:__main__:Epoch 18955: total training loss 0.00084\n",
            "2025-06-26 08:49:19,051 Epoch 18955: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18956\n",
            "2025-06-26 08:49:19,053 EPOCH 18956\n",
            "INFO:__main__:Epoch 18956: total training loss 0.00082\n",
            "2025-06-26 08:49:19,138 Epoch 18956: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18957\n",
            "2025-06-26 08:49:19,140 EPOCH 18957\n",
            "INFO:__main__:Epoch 18957: total training loss 0.00089\n",
            "2025-06-26 08:49:19,231 Epoch 18957: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 18958\n",
            "2025-06-26 08:49:19,238 EPOCH 18958\n",
            "INFO:__main__:Epoch 18958: total training loss 0.00085\n",
            "2025-06-26 08:49:19,327 Epoch 18958: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18959\n",
            "2025-06-26 08:49:19,330 EPOCH 18959\n",
            "INFO:__main__:Epoch 18959: total training loss 0.00079\n",
            "2025-06-26 08:49:19,419 Epoch 18959: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18960\n",
            "2025-06-26 08:49:19,421 EPOCH 18960\n",
            "INFO:__main__:Epoch 18960: total training loss 0.00081\n",
            "2025-06-26 08:49:19,524 Epoch 18960: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 18961\n",
            "2025-06-26 08:49:19,528 EPOCH 18961\n",
            "INFO:__main__:Epoch 18961: total training loss 0.00082\n",
            "2025-06-26 08:49:19,626 Epoch 18961: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18962\n",
            "2025-06-26 08:49:19,628 EPOCH 18962\n",
            "INFO:__main__:Epoch 18962: total training loss 0.00079\n",
            "2025-06-26 08:49:19,721 Epoch 18962: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18963\n",
            "2025-06-26 08:49:19,723 EPOCH 18963\n",
            "INFO:__main__:Epoch 18963: total training loss 0.00079\n",
            "2025-06-26 08:49:19,797 Epoch 18963: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18964\n",
            "2025-06-26 08:49:19,799 EPOCH 18964\n",
            "INFO:__main__:Epoch 18964: total training loss 0.00080\n",
            "2025-06-26 08:49:19,884 Epoch 18964: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18965\n",
            "2025-06-26 08:49:19,886 EPOCH 18965\n",
            "INFO:__main__:Epoch 18965: total training loss 0.00085\n",
            "2025-06-26 08:49:19,983 Epoch 18965: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 18966\n",
            "2025-06-26 08:49:19,985 EPOCH 18966\n",
            "INFO:__main__:Epoch 18966: total training loss 0.00079\n",
            "2025-06-26 08:49:20,107 Epoch 18966: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18967\n",
            "2025-06-26 08:49:20,109 EPOCH 18967\n",
            "INFO:__main__:Epoch 18967: total training loss 0.00074\n",
            "2025-06-26 08:49:20,226 Epoch 18967: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18968\n",
            "2025-06-26 08:49:20,228 EPOCH 18968\n",
            "INFO:__main__:Epoch 18968: total training loss 0.00082\n",
            "2025-06-26 08:49:20,332 Epoch 18968: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18969\n",
            "2025-06-26 08:49:20,334 EPOCH 18969\n",
            "INFO:__main__:Epoch 18969: total training loss 0.00077\n",
            "2025-06-26 08:49:20,410 Epoch 18969: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18970\n",
            "2025-06-26 08:49:20,412 EPOCH 18970\n",
            "INFO:__main__:Epoch 18970: total training loss 0.00077\n",
            "2025-06-26 08:49:20,509 Epoch 18970: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18971\n",
            "2025-06-26 08:49:20,510 EPOCH 18971\n",
            "INFO:__main__:Epoch 18971: total training loss 0.00074\n",
            "2025-06-26 08:49:20,623 Epoch 18971: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 18972\n",
            "2025-06-26 08:49:20,624 EPOCH 18972\n",
            "INFO:__main__:Epoch 18972: total training loss 0.00076\n",
            "2025-06-26 08:49:20,745 Epoch 18972: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18973\n",
            "2025-06-26 08:49:20,746 EPOCH 18973\n",
            "INFO:__main__:Epoch 18973: total training loss 0.00077\n",
            "2025-06-26 08:49:20,863 Epoch 18973: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18974\n",
            "2025-06-26 08:49:20,865 EPOCH 18974\n",
            "INFO:__main__:Epoch 18974: total training loss 0.00076\n",
            "2025-06-26 08:49:20,973 Epoch 18974: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 18975\n",
            "2025-06-26 08:49:20,979 EPOCH 18975\n",
            "INFO:__main__:Epoch 18975: total training loss 0.00082\n",
            "2025-06-26 08:49:21,069 Epoch 18975: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18976\n",
            "2025-06-26 08:49:21,076 EPOCH 18976\n",
            "INFO:__main__:Epoch 18976: total training loss 0.00079\n",
            "2025-06-26 08:49:21,175 Epoch 18976: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18977\n",
            "2025-06-26 08:49:21,178 EPOCH 18977\n",
            "INFO:__main__:Epoch 18977: total training loss 0.00086\n",
            "2025-06-26 08:49:21,306 Epoch 18977: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18978\n",
            "2025-06-26 08:49:21,311 EPOCH 18978\n",
            "INFO:__main__:Epoch 18978: total training loss 0.00088\n",
            "2025-06-26 08:49:21,419 Epoch 18978: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18979\n",
            "2025-06-26 08:49:21,422 EPOCH 18979\n",
            "INFO:__main__:Epoch 18979: total training loss 0.00084\n",
            "2025-06-26 08:49:21,523 Epoch 18979: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18980\n",
            "2025-06-26 08:49:21,524 EPOCH 18980\n",
            "INFO:__main__:Epoch 18980: total training loss 0.00084\n",
            "2025-06-26 08:49:21,637 Epoch 18980: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18981\n",
            "2025-06-26 08:49:21,639 EPOCH 18981\n",
            "INFO:__main__:Epoch 18981: total training loss 0.00087\n",
            "2025-06-26 08:49:21,754 Epoch 18981: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 18982\n",
            "2025-06-26 08:49:21,755 EPOCH 18982\n",
            "INFO:__main__:Epoch 18982: total training loss 0.00084\n",
            "2025-06-26 08:49:21,868 Epoch 18982: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18983\n",
            "2025-06-26 08:49:21,870 EPOCH 18983\n",
            "INFO:__main__:Epoch 18983: total training loss 0.00079\n",
            "2025-06-26 08:49:21,982 Epoch 18983: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18984\n",
            "2025-06-26 08:49:21,986 EPOCH 18984\n",
            "INFO:__main__:Epoch 18984: total training loss 0.00086\n",
            "2025-06-26 08:49:22,084 Epoch 18984: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18985\n",
            "2025-06-26 08:49:22,088 EPOCH 18985\n",
            "INFO:__main__:Epoch 18985: total training loss 0.00090\n",
            "2025-06-26 08:49:22,165 Epoch 18985: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 18986\n",
            "2025-06-26 08:49:22,172 EPOCH 18986\n",
            "INFO:__main__:Epoch 18986: total training loss 0.00083\n",
            "2025-06-26 08:49:22,262 Epoch 18986: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18987\n",
            "2025-06-26 08:49:22,267 EPOCH 18987\n",
            "INFO:__main__:Epoch 18987: total training loss 0.00086\n",
            "2025-06-26 08:49:22,362 Epoch 18987: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18988\n",
            "2025-06-26 08:49:22,368 EPOCH 18988\n",
            "INFO:__main__:Epoch 18988: total training loss 0.00077\n",
            "2025-06-26 08:49:22,441 Epoch 18988: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 18989\n",
            "2025-06-26 08:49:22,449 EPOCH 18989\n",
            "INFO:__main__:Epoch 18989: total training loss 0.00078\n",
            "2025-06-26 08:49:22,529 Epoch 18989: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 18990\n",
            "2025-06-26 08:49:22,535 EPOCH 18990\n",
            "INFO:__main__:Epoch 18990: total training loss 0.00083\n",
            "2025-06-26 08:49:22,623 Epoch 18990: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 18991\n",
            "2025-06-26 08:49:22,627 EPOCH 18991\n",
            "INFO:__main__:Epoch 18991: total training loss 0.00086\n",
            "2025-06-26 08:49:22,735 Epoch 18991: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 18992\n",
            "2025-06-26 08:49:22,737 EPOCH 18992\n",
            "INFO:__main__:Epoch 18992: total training loss 0.00082\n",
            "2025-06-26 08:49:22,854 Epoch 18992: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18993\n",
            "2025-06-26 08:49:22,858 EPOCH 18993\n",
            "INFO:__main__:Epoch 18993: total training loss 0.00088\n",
            "2025-06-26 08:49:22,977 Epoch 18993: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18994\n",
            "2025-06-26 08:49:22,982 EPOCH 18994\n",
            "INFO:__main__:Epoch 18994: total training loss 0.00079\n",
            "2025-06-26 08:49:23,080 Epoch 18994: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 18995\n",
            "2025-06-26 08:49:23,085 EPOCH 18995\n",
            "INFO:__main__:Epoch 18995: total training loss 0.00080\n",
            "2025-06-26 08:49:23,191 Epoch 18995: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 18996\n",
            "2025-06-26 08:49:23,193 EPOCH 18996\n",
            "INFO:__main__:Epoch 18996: total training loss 0.00088\n",
            "2025-06-26 08:49:23,298 Epoch 18996: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 18997\n",
            "2025-06-26 08:49:23,300 EPOCH 18997\n",
            "INFO:__main__:Epoch 18997: total training loss 0.00082\n",
            "2025-06-26 08:49:23,386 Epoch 18997: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 18998\n",
            "2025-06-26 08:49:23,387 EPOCH 18998\n",
            "INFO:__main__:Epoch 18998: total training loss 0.00084\n",
            "2025-06-26 08:49:23,490 Epoch 18998: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 18999\n",
            "2025-06-26 08:49:23,494 EPOCH 18999\n",
            "INFO:__main__:Epoch 18999: total training loss 0.00082\n",
            "2025-06-26 08:49:23,581 Epoch 18999: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19000\n",
            "2025-06-26 08:49:23,584 EPOCH 19000\n",
            "INFO:__main__:Epoch 19000 Step:    19000 Batch Loss:     0.000800 Tokens per Sec:  1302155, Lr: 0.001000\n",
            "2025-06-26 08:49:23,696 Epoch 19000 Step:    19000 Batch Loss:     0.000800 Tokens per Sec:  1302155, Lr: 0.001000\n",
            "INFO:__main__:Epoch 19000: total training loss 0.00080\n",
            "2025-06-26 08:49:23,700 Epoch 19000: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19001\n",
            "2025-06-26 08:49:23,703 EPOCH 19001\n",
            "INFO:__main__:Epoch 19001: total training loss 0.00083\n",
            "2025-06-26 08:49:23,811 Epoch 19001: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19002\n",
            "2025-06-26 08:49:23,816 EPOCH 19002\n",
            "INFO:__main__:Epoch 19002: total training loss 0.00080\n",
            "2025-06-26 08:49:23,910 Epoch 19002: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19003\n",
            "2025-06-26 08:49:23,917 EPOCH 19003\n",
            "INFO:__main__:Epoch 19003: total training loss 0.00075\n",
            "2025-06-26 08:49:24,031 Epoch 19003: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19004\n",
            "2025-06-26 08:49:24,037 EPOCH 19004\n",
            "INFO:__main__:Epoch 19004: total training loss 0.00079\n",
            "2025-06-26 08:49:24,138 Epoch 19004: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19005\n",
            "2025-06-26 08:49:24,144 EPOCH 19005\n",
            "INFO:__main__:Epoch 19005: total training loss 0.00075\n",
            "2025-06-26 08:49:24,220 Epoch 19005: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19006\n",
            "2025-06-26 08:49:24,222 EPOCH 19006\n",
            "INFO:__main__:Epoch 19006: total training loss 0.00076\n",
            "2025-06-26 08:49:24,307 Epoch 19006: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19007\n",
            "2025-06-26 08:49:24,309 EPOCH 19007\n",
            "INFO:__main__:Epoch 19007: total training loss 0.00074\n",
            "2025-06-26 08:49:24,380 Epoch 19007: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19008\n",
            "2025-06-26 08:49:24,383 EPOCH 19008\n",
            "INFO:__main__:Epoch 19008: total training loss 0.00076\n",
            "2025-06-26 08:49:24,453 Epoch 19008: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19009\n",
            "2025-06-26 08:49:24,455 EPOCH 19009\n",
            "INFO:__main__:Epoch 19009: total training loss 0.00074\n",
            "2025-06-26 08:49:24,545 Epoch 19009: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19010\n",
            "2025-06-26 08:49:24,547 EPOCH 19010\n",
            "INFO:__main__:Epoch 19010: total training loss 0.00076\n",
            "2025-06-26 08:49:24,622 Epoch 19010: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19011\n",
            "2025-06-26 08:49:24,626 EPOCH 19011\n",
            "INFO:__main__:Epoch 19011: total training loss 0.00079\n",
            "2025-06-26 08:49:24,699 Epoch 19011: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19012\n",
            "2025-06-26 08:49:24,702 EPOCH 19012\n",
            "INFO:__main__:Epoch 19012: total training loss 0.00084\n",
            "2025-06-26 08:49:24,774 Epoch 19012: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19013\n",
            "2025-06-26 08:49:24,777 EPOCH 19013\n",
            "INFO:__main__:Epoch 19013: total training loss 0.00089\n",
            "2025-06-26 08:49:24,849 Epoch 19013: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19014\n",
            "2025-06-26 08:49:24,851 EPOCH 19014\n",
            "INFO:__main__:Epoch 19014: total training loss 0.00087\n",
            "2025-06-26 08:49:24,922 Epoch 19014: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19015\n",
            "2025-06-26 08:49:24,924 EPOCH 19015\n",
            "INFO:__main__:Epoch 19015: total training loss 0.00080\n",
            "2025-06-26 08:49:24,999 Epoch 19015: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19016\n",
            "2025-06-26 08:49:25,001 EPOCH 19016\n",
            "INFO:__main__:Epoch 19016: total training loss 0.00083\n",
            "2025-06-26 08:49:25,089 Epoch 19016: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19017\n",
            "2025-06-26 08:49:25,093 EPOCH 19017\n",
            "INFO:__main__:Epoch 19017: total training loss 0.00088\n",
            "2025-06-26 08:49:25,171 Epoch 19017: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19018\n",
            "2025-06-26 08:49:25,173 EPOCH 19018\n",
            "INFO:__main__:Epoch 19018: total training loss 0.00085\n",
            "2025-06-26 08:49:25,247 Epoch 19018: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19019\n",
            "2025-06-26 08:49:25,249 EPOCH 19019\n",
            "INFO:__main__:Epoch 19019: total training loss 0.00085\n",
            "2025-06-26 08:49:25,339 Epoch 19019: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19020\n",
            "2025-06-26 08:49:25,342 EPOCH 19020\n",
            "INFO:__main__:Epoch 19020: total training loss 0.00083\n",
            "2025-06-26 08:49:25,415 Epoch 19020: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19021\n",
            "2025-06-26 08:49:25,419 EPOCH 19021\n",
            "INFO:__main__:Epoch 19021: total training loss 0.00089\n",
            "2025-06-26 08:49:25,489 Epoch 19021: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19022\n",
            "2025-06-26 08:49:25,491 EPOCH 19022\n",
            "INFO:__main__:Epoch 19022: total training loss 0.00086\n",
            "2025-06-26 08:49:25,563 Epoch 19022: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19023\n",
            "2025-06-26 08:49:25,565 EPOCH 19023\n",
            "INFO:__main__:Epoch 19023: total training loss 0.00087\n",
            "2025-06-26 08:49:25,637 Epoch 19023: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19024\n",
            "2025-06-26 08:49:25,639 EPOCH 19024\n",
            "INFO:__main__:Epoch 19024: total training loss 0.00085\n",
            "2025-06-26 08:49:25,713 Epoch 19024: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19025\n",
            "2025-06-26 08:49:25,716 EPOCH 19025\n",
            "INFO:__main__:Epoch 19025: total training loss 0.00086\n",
            "2025-06-26 08:49:25,788 Epoch 19025: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19026\n",
            "2025-06-26 08:49:25,791 EPOCH 19026\n",
            "INFO:__main__:Epoch 19026: total training loss 0.00089\n",
            "2025-06-26 08:49:25,866 Epoch 19026: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19027\n",
            "2025-06-26 08:49:25,869 EPOCH 19027\n",
            "INFO:__main__:Epoch 19027: total training loss 0.00086\n",
            "2025-06-26 08:49:25,954 Epoch 19027: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19028\n",
            "2025-06-26 08:49:25,956 EPOCH 19028\n",
            "INFO:__main__:Epoch 19028: total training loss 0.00087\n",
            "2025-06-26 08:49:26,031 Epoch 19028: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19029\n",
            "2025-06-26 08:49:26,035 EPOCH 19029\n",
            "INFO:__main__:Epoch 19029: total training loss 0.00083\n",
            "2025-06-26 08:49:26,118 Epoch 19029: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19030\n",
            "2025-06-26 08:49:26,121 EPOCH 19030\n",
            "INFO:__main__:Epoch 19030: total training loss 0.00092\n",
            "2025-06-26 08:49:26,210 Epoch 19030: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19031\n",
            "2025-06-26 08:49:26,212 EPOCH 19031\n",
            "INFO:__main__:Epoch 19031: total training loss 0.00097\n",
            "2025-06-26 08:49:26,289 Epoch 19031: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 19032\n",
            "2025-06-26 08:49:26,292 EPOCH 19032\n",
            "INFO:__main__:Epoch 19032: total training loss 0.00093\n",
            "2025-06-26 08:49:26,368 Epoch 19032: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19033\n",
            "2025-06-26 08:49:26,370 EPOCH 19033\n",
            "INFO:__main__:Epoch 19033: total training loss 0.00094\n",
            "2025-06-26 08:49:26,443 Epoch 19033: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 19034\n",
            "2025-06-26 08:49:26,445 EPOCH 19034\n",
            "INFO:__main__:Epoch 19034: total training loss 0.00091\n",
            "2025-06-26 08:49:26,519 Epoch 19034: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19035\n",
            "2025-06-26 08:49:26,523 EPOCH 19035\n",
            "INFO:__main__:Epoch 19035: total training loss 0.00095\n",
            "2025-06-26 08:49:26,595 Epoch 19035: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19036\n",
            "2025-06-26 08:49:26,599 EPOCH 19036\n",
            "INFO:__main__:Epoch 19036: total training loss 0.00091\n",
            "2025-06-26 08:49:26,671 Epoch 19036: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19037\n",
            "2025-06-26 08:49:26,673 EPOCH 19037\n",
            "INFO:__main__:Epoch 19037: total training loss 0.00092\n",
            "2025-06-26 08:49:26,754 Epoch 19037: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19038\n",
            "2025-06-26 08:49:26,756 EPOCH 19038\n",
            "INFO:__main__:Epoch 19038: total training loss 0.00095\n",
            "2025-06-26 08:49:26,841 Epoch 19038: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19039\n",
            "2025-06-26 08:49:26,843 EPOCH 19039\n",
            "INFO:__main__:Epoch 19039: total training loss 0.00095\n",
            "2025-06-26 08:49:26,924 Epoch 19039: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19040\n",
            "2025-06-26 08:49:26,926 EPOCH 19040\n",
            "INFO:__main__:Epoch 19040: total training loss 0.00099\n",
            "2025-06-26 08:49:27,000 Epoch 19040: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 19041\n",
            "2025-06-26 08:49:27,004 EPOCH 19041\n",
            "INFO:__main__:Epoch 19041: total training loss 0.00091\n",
            "2025-06-26 08:49:27,080 Epoch 19041: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19042\n",
            "2025-06-26 08:49:27,083 EPOCH 19042\n",
            "INFO:__main__:Epoch 19042: total training loss 0.00088\n",
            "2025-06-26 08:49:27,185 Epoch 19042: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19043\n",
            "2025-06-26 08:49:27,187 EPOCH 19043\n",
            "INFO:__main__:Epoch 19043: total training loss 0.00092\n",
            "2025-06-26 08:49:27,268 Epoch 19043: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19044\n",
            "2025-06-26 08:49:27,275 EPOCH 19044\n",
            "INFO:__main__:Epoch 19044: total training loss 0.00088\n",
            "2025-06-26 08:49:27,360 Epoch 19044: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19045\n",
            "2025-06-26 08:49:27,362 EPOCH 19045\n",
            "INFO:__main__:Epoch 19045: total training loss 0.00091\n",
            "2025-06-26 08:49:27,438 Epoch 19045: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19046\n",
            "2025-06-26 08:49:27,442 EPOCH 19046\n",
            "INFO:__main__:Epoch 19046: total training loss 0.00085\n",
            "2025-06-26 08:49:27,528 Epoch 19046: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19047\n",
            "2025-06-26 08:49:27,530 EPOCH 19047\n",
            "INFO:__main__:Epoch 19047: total training loss 0.00086\n",
            "2025-06-26 08:49:27,608 Epoch 19047: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19048\n",
            "2025-06-26 08:49:27,613 EPOCH 19048\n",
            "INFO:__main__:Epoch 19048: total training loss 0.00088\n",
            "2025-06-26 08:49:27,689 Epoch 19048: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19049\n",
            "2025-06-26 08:49:27,693 EPOCH 19049\n",
            "INFO:__main__:Epoch 19049: total training loss 0.00088\n",
            "2025-06-26 08:49:27,783 Epoch 19049: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19050\n",
            "2025-06-26 08:49:27,785 EPOCH 19050\n",
            "INFO:__main__:Epoch 19050: total training loss 0.00090\n",
            "2025-06-26 08:49:27,861 Epoch 19050: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19051\n",
            "2025-06-26 08:49:27,866 EPOCH 19051\n",
            "INFO:__main__:Epoch 19051: total training loss 0.00089\n",
            "2025-06-26 08:49:27,955 Epoch 19051: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19052\n",
            "2025-06-26 08:49:27,957 EPOCH 19052\n",
            "INFO:__main__:Epoch 19052: total training loss 0.00086\n",
            "2025-06-26 08:49:28,033 Epoch 19052: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19053\n",
            "2025-06-26 08:49:28,035 EPOCH 19053\n",
            "INFO:__main__:Epoch 19053: total training loss 0.00080\n",
            "2025-06-26 08:49:28,105 Epoch 19053: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19054\n",
            "2025-06-26 08:49:28,106 EPOCH 19054\n",
            "INFO:__main__:Epoch 19054: total training loss 0.00087\n",
            "2025-06-26 08:49:28,189 Epoch 19054: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19055\n",
            "2025-06-26 08:49:28,191 EPOCH 19055\n",
            "INFO:__main__:Epoch 19055: total training loss 0.00092\n",
            "2025-06-26 08:49:28,282 Epoch 19055: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19056\n",
            "2025-06-26 08:49:28,284 EPOCH 19056\n",
            "INFO:__main__:Epoch 19056: total training loss 0.00101\n",
            "2025-06-26 08:49:28,368 Epoch 19056: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 19057\n",
            "2025-06-26 08:49:28,370 EPOCH 19057\n",
            "INFO:__main__:Epoch 19057: total training loss 0.00099\n",
            "2025-06-26 08:49:28,443 Epoch 19057: total training loss 0.00099\n",
            "INFO:__main__:EPOCH 19058\n",
            "2025-06-26 08:49:28,445 EPOCH 19058\n",
            "INFO:__main__:Epoch 19058: total training loss 0.00098\n",
            "2025-06-26 08:49:28,516 Epoch 19058: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 19059\n",
            "2025-06-26 08:49:28,518 EPOCH 19059\n",
            "INFO:__main__:Epoch 19059: total training loss 0.00096\n",
            "2025-06-26 08:49:28,601 Epoch 19059: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19060\n",
            "2025-06-26 08:49:28,603 EPOCH 19060\n",
            "INFO:__main__:Epoch 19060: total training loss 0.00090\n",
            "2025-06-26 08:49:28,673 Epoch 19060: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19061\n",
            "2025-06-26 08:49:28,677 EPOCH 19061\n",
            "INFO:__main__:Epoch 19061: total training loss 0.00096\n",
            "2025-06-26 08:49:28,748 Epoch 19061: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19062\n",
            "2025-06-26 08:49:28,754 EPOCH 19062\n",
            "INFO:__main__:Epoch 19062: total training loss 0.00086\n",
            "2025-06-26 08:49:28,830 Epoch 19062: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19063\n",
            "2025-06-26 08:49:28,831 EPOCH 19063\n",
            "INFO:__main__:Epoch 19063: total training loss 0.00083\n",
            "2025-06-26 08:49:28,909 Epoch 19063: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19064\n",
            "2025-06-26 08:49:28,911 EPOCH 19064\n",
            "INFO:__main__:Epoch 19064: total training loss 0.00089\n",
            "2025-06-26 08:49:28,985 Epoch 19064: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19065\n",
            "2025-06-26 08:49:28,989 EPOCH 19065\n",
            "INFO:__main__:Epoch 19065: total training loss 0.00088\n",
            "2025-06-26 08:49:29,063 Epoch 19065: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19066\n",
            "2025-06-26 08:49:29,066 EPOCH 19066\n",
            "INFO:__main__:Epoch 19066: total training loss 0.00090\n",
            "2025-06-26 08:49:29,135 Epoch 19066: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19067\n",
            "2025-06-26 08:49:29,138 EPOCH 19067\n",
            "INFO:__main__:Epoch 19067: total training loss 0.00080\n",
            "2025-06-26 08:49:29,210 Epoch 19067: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19068\n",
            "2025-06-26 08:49:29,212 EPOCH 19068\n",
            "INFO:__main__:Epoch 19068: total training loss 0.00083\n",
            "2025-06-26 08:49:29,288 Epoch 19068: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19069\n",
            "2025-06-26 08:49:29,290 EPOCH 19069\n",
            "INFO:__main__:Epoch 19069: total training loss 0.00090\n",
            "2025-06-26 08:49:29,377 Epoch 19069: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19070\n",
            "2025-06-26 08:49:29,379 EPOCH 19070\n",
            "INFO:__main__:Epoch 19070: total training loss 0.00089\n",
            "2025-06-26 08:49:29,451 Epoch 19070: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19071\n",
            "2025-06-26 08:49:29,453 EPOCH 19071\n",
            "INFO:__main__:Epoch 19071: total training loss 0.00089\n",
            "2025-06-26 08:49:29,525 Epoch 19071: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19072\n",
            "2025-06-26 08:49:29,528 EPOCH 19072\n",
            "INFO:__main__:Epoch 19072: total training loss 0.00085\n",
            "2025-06-26 08:49:29,601 Epoch 19072: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19073\n",
            "2025-06-26 08:49:29,603 EPOCH 19073\n",
            "INFO:__main__:Epoch 19073: total training loss 0.00083\n",
            "2025-06-26 08:49:29,673 Epoch 19073: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19074\n",
            "2025-06-26 08:49:29,675 EPOCH 19074\n",
            "INFO:__main__:Epoch 19074: total training loss 0.00088\n",
            "2025-06-26 08:49:29,744 Epoch 19074: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19075\n",
            "2025-06-26 08:49:29,746 EPOCH 19075\n",
            "INFO:__main__:Epoch 19075: total training loss 0.00084\n",
            "2025-06-26 08:49:29,821 Epoch 19075: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19076\n",
            "2025-06-26 08:49:29,824 EPOCH 19076\n",
            "INFO:__main__:Epoch 19076: total training loss 0.00077\n",
            "2025-06-26 08:49:29,894 Epoch 19076: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19077\n",
            "2025-06-26 08:49:29,896 EPOCH 19077\n",
            "INFO:__main__:Epoch 19077: total training loss 0.00086\n",
            "2025-06-26 08:49:29,969 Epoch 19077: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19078\n",
            "2025-06-26 08:49:29,977 EPOCH 19078\n",
            "INFO:__main__:Epoch 19078: total training loss 0.00082\n",
            "2025-06-26 08:49:30,056 Epoch 19078: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19079\n",
            "2025-06-26 08:49:30,058 EPOCH 19079\n",
            "INFO:__main__:Epoch 19079: total training loss 0.00084\n",
            "2025-06-26 08:49:30,130 Epoch 19079: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19080\n",
            "2025-06-26 08:49:30,132 EPOCH 19080\n",
            "INFO:__main__:Epoch 19080: total training loss 0.00079\n",
            "2025-06-26 08:49:30,209 Epoch 19080: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19081\n",
            "2025-06-26 08:49:30,211 EPOCH 19081\n",
            "INFO:__main__:Epoch 19081: total training loss 0.00079\n",
            "2025-06-26 08:49:30,285 Epoch 19081: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19082\n",
            "2025-06-26 08:49:30,287 EPOCH 19082\n",
            "INFO:__main__:Epoch 19082: total training loss 0.00084\n",
            "2025-06-26 08:49:30,361 Epoch 19082: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19083\n",
            "2025-06-26 08:49:30,363 EPOCH 19083\n",
            "INFO:__main__:Epoch 19083: total training loss 0.00081\n",
            "2025-06-26 08:49:30,467 Epoch 19083: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19084\n",
            "2025-06-26 08:49:30,469 EPOCH 19084\n",
            "INFO:__main__:Epoch 19084: total training loss 0.00076\n",
            "2025-06-26 08:49:30,545 Epoch 19084: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19085\n",
            "2025-06-26 08:49:30,547 EPOCH 19085\n",
            "INFO:__main__:Epoch 19085: total training loss 0.00079\n",
            "2025-06-26 08:49:30,621 Epoch 19085: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19086\n",
            "2025-06-26 08:49:30,623 EPOCH 19086\n",
            "INFO:__main__:Epoch 19086: total training loss 0.00081\n",
            "2025-06-26 08:49:30,696 Epoch 19086: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19087\n",
            "2025-06-26 08:49:30,698 EPOCH 19087\n",
            "INFO:__main__:Epoch 19087: total training loss 0.00082\n",
            "2025-06-26 08:49:30,770 Epoch 19087: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19088\n",
            "2025-06-26 08:49:30,772 EPOCH 19088\n",
            "INFO:__main__:Epoch 19088: total training loss 0.00075\n",
            "2025-06-26 08:49:30,851 Epoch 19088: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19089\n",
            "2025-06-26 08:49:30,853 EPOCH 19089\n",
            "INFO:__main__:Epoch 19089: total training loss 0.00079\n",
            "2025-06-26 08:49:30,926 Epoch 19089: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19090\n",
            "2025-06-26 08:49:30,929 EPOCH 19090\n",
            "INFO:__main__:Epoch 19090: total training loss 0.00081\n",
            "2025-06-26 08:49:31,010 Epoch 19090: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19091\n",
            "2025-06-26 08:49:31,013 EPOCH 19091\n",
            "INFO:__main__:Epoch 19091: total training loss 0.00076\n",
            "2025-06-26 08:49:31,086 Epoch 19091: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19092\n",
            "2025-06-26 08:49:31,089 EPOCH 19092\n",
            "INFO:__main__:Epoch 19092: total training loss 0.00078\n",
            "2025-06-26 08:49:31,162 Epoch 19092: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19093\n",
            "2025-06-26 08:49:31,164 EPOCH 19093\n",
            "INFO:__main__:Epoch 19093: total training loss 0.00078\n",
            "2025-06-26 08:49:31,244 Epoch 19093: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19094\n",
            "2025-06-26 08:49:31,249 EPOCH 19094\n",
            "INFO:__main__:Epoch 19094: total training loss 0.00078\n",
            "2025-06-26 08:49:31,330 Epoch 19094: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19095\n",
            "2025-06-26 08:49:31,338 EPOCH 19095\n",
            "INFO:__main__:Epoch 19095: total training loss 0.00083\n",
            "2025-06-26 08:49:31,410 Epoch 19095: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19096\n",
            "2025-06-26 08:49:31,412 EPOCH 19096\n",
            "INFO:__main__:Epoch 19096: total training loss 0.00083\n",
            "2025-06-26 08:49:31,494 Epoch 19096: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19097\n",
            "2025-06-26 08:49:31,496 EPOCH 19097\n",
            "INFO:__main__:Epoch 19097: total training loss 0.00077\n",
            "2025-06-26 08:49:31,574 Epoch 19097: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19098\n",
            "2025-06-26 08:49:31,576 EPOCH 19098\n",
            "INFO:__main__:Epoch 19098: total training loss 0.00079\n",
            "2025-06-26 08:49:31,664 Epoch 19098: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19099\n",
            "2025-06-26 08:49:31,666 EPOCH 19099\n",
            "INFO:__main__:Epoch 19099: total training loss 0.00081\n",
            "2025-06-26 08:49:31,744 Epoch 19099: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19100\n",
            "2025-06-26 08:49:31,746 EPOCH 19100\n",
            "INFO:__main__:Epoch 19100: total training loss 0.00080\n",
            "2025-06-26 08:49:31,839 Epoch 19100: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19101\n",
            "2025-06-26 08:49:31,840 EPOCH 19101\n",
            "INFO:__main__:Epoch 19101: total training loss 0.00079\n",
            "2025-06-26 08:49:31,917 Epoch 19101: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19102\n",
            "2025-06-26 08:49:31,921 EPOCH 19102\n",
            "INFO:__main__:Epoch 19102: total training loss 0.00081\n",
            "2025-06-26 08:49:31,994 Epoch 19102: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19103\n",
            "2025-06-26 08:49:31,996 EPOCH 19103\n",
            "INFO:__main__:Epoch 19103: total training loss 0.00083\n",
            "2025-06-26 08:49:32,076 Epoch 19103: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19104\n",
            "2025-06-26 08:49:32,078 EPOCH 19104\n",
            "INFO:__main__:Epoch 19104: total training loss 0.00088\n",
            "2025-06-26 08:49:32,151 Epoch 19104: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19105\n",
            "2025-06-26 08:49:32,155 EPOCH 19105\n",
            "INFO:__main__:Epoch 19105: total training loss 0.00087\n",
            "2025-06-26 08:49:32,230 Epoch 19105: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19106\n",
            "2025-06-26 08:49:32,233 EPOCH 19106\n",
            "INFO:__main__:Epoch 19106: total training loss 0.00089\n",
            "2025-06-26 08:49:32,306 Epoch 19106: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19107\n",
            "2025-06-26 08:49:32,308 EPOCH 19107\n",
            "INFO:__main__:Epoch 19107: total training loss 0.00082\n",
            "2025-06-26 08:49:32,386 Epoch 19107: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19108\n",
            "2025-06-26 08:49:32,389 EPOCH 19108\n",
            "INFO:__main__:Epoch 19108: total training loss 0.00090\n",
            "2025-06-26 08:49:32,460 Epoch 19108: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19109\n",
            "2025-06-26 08:49:32,463 EPOCH 19109\n",
            "INFO:__main__:Epoch 19109: total training loss 0.00088\n",
            "2025-06-26 08:49:32,546 Epoch 19109: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19110\n",
            "2025-06-26 08:49:32,548 EPOCH 19110\n",
            "INFO:__main__:Epoch 19110: total training loss 0.00083\n",
            "2025-06-26 08:49:32,623 Epoch 19110: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19111\n",
            "2025-06-26 08:49:32,625 EPOCH 19111\n",
            "INFO:__main__:Epoch 19111: total training loss 0.00077\n",
            "2025-06-26 08:49:32,701 Epoch 19111: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19112\n",
            "2025-06-26 08:49:32,703 EPOCH 19112\n",
            "INFO:__main__:Epoch 19112: total training loss 0.00084\n",
            "2025-06-26 08:49:32,783 Epoch 19112: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19113\n",
            "2025-06-26 08:49:32,788 EPOCH 19113\n",
            "INFO:__main__:Epoch 19113: total training loss 0.00078\n",
            "2025-06-26 08:49:32,875 Epoch 19113: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19114\n",
            "2025-06-26 08:49:32,877 EPOCH 19114\n",
            "INFO:__main__:Epoch 19114: total training loss 0.00077\n",
            "2025-06-26 08:49:32,951 Epoch 19114: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19115\n",
            "2025-06-26 08:49:32,953 EPOCH 19115\n",
            "INFO:__main__:Epoch 19115: total training loss 0.00080\n",
            "2025-06-26 08:49:33,026 Epoch 19115: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19116\n",
            "2025-06-26 08:49:33,028 EPOCH 19116\n",
            "INFO:__main__:Epoch 19116: total training loss 0.00075\n",
            "2025-06-26 08:49:33,110 Epoch 19116: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19117\n",
            "2025-06-26 08:49:33,112 EPOCH 19117\n",
            "INFO:__main__:Epoch 19117: total training loss 0.00079\n",
            "2025-06-26 08:49:33,190 Epoch 19117: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19118\n",
            "2025-06-26 08:49:33,194 EPOCH 19118\n",
            "INFO:__main__:Epoch 19118: total training loss 0.00081\n",
            "2025-06-26 08:49:33,270 Epoch 19118: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19119\n",
            "2025-06-26 08:49:33,273 EPOCH 19119\n",
            "INFO:__main__:Epoch 19119: total training loss 0.00078\n",
            "2025-06-26 08:49:33,346 Epoch 19119: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19120\n",
            "2025-06-26 08:49:33,349 EPOCH 19120\n",
            "INFO:__main__:Epoch 19120: total training loss 0.00073\n",
            "2025-06-26 08:49:33,422 Epoch 19120: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19121\n",
            "2025-06-26 08:49:33,425 EPOCH 19121\n",
            "INFO:__main__:Epoch 19121: total training loss 0.00073\n",
            "2025-06-26 08:49:33,497 Epoch 19121: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19122\n",
            "2025-06-26 08:49:33,501 EPOCH 19122\n",
            "INFO:__main__:Epoch 19122: total training loss 0.00073\n",
            "2025-06-26 08:49:33,576 Epoch 19122: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19123\n",
            "2025-06-26 08:49:33,578 EPOCH 19123\n",
            "INFO:__main__:Epoch 19123: total training loss 0.00071\n",
            "2025-06-26 08:49:33,670 Epoch 19123: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19124\n",
            "2025-06-26 08:49:33,675 EPOCH 19124\n",
            "INFO:__main__:Epoch 19124: total training loss 0.00077\n",
            "2025-06-26 08:49:33,755 Epoch 19124: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19125\n",
            "2025-06-26 08:49:33,757 EPOCH 19125\n",
            "INFO:__main__:Epoch 19125: total training loss 0.00080\n",
            "2025-06-26 08:49:33,828 Epoch 19125: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19126\n",
            "2025-06-26 08:49:33,832 EPOCH 19126\n",
            "INFO:__main__:Epoch 19126: total training loss 0.00074\n",
            "2025-06-26 08:49:33,920 Epoch 19126: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19127\n",
            "2025-06-26 08:49:33,924 EPOCH 19127\n",
            "INFO:__main__:Epoch 19127: total training loss 0.00072\n",
            "2025-06-26 08:49:33,999 Epoch 19127: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19128\n",
            "2025-06-26 08:49:34,001 EPOCH 19128\n",
            "INFO:__main__:Epoch 19128: total training loss 0.00080\n",
            "2025-06-26 08:49:34,078 Epoch 19128: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19129\n",
            "2025-06-26 08:49:34,083 EPOCH 19129\n",
            "INFO:__main__:Epoch 19129: total training loss 0.00084\n",
            "2025-06-26 08:49:34,159 Epoch 19129: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19130\n",
            "2025-06-26 08:49:34,162 EPOCH 19130\n",
            "INFO:__main__:Epoch 19130: total training loss 0.00082\n",
            "2025-06-26 08:49:34,257 Epoch 19130: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19131\n",
            "2025-06-26 08:49:34,264 EPOCH 19131\n",
            "INFO:__main__:Epoch 19131: total training loss 0.00081\n",
            "2025-06-26 08:49:34,353 Epoch 19131: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19132\n",
            "2025-06-26 08:49:34,357 EPOCH 19132\n",
            "INFO:__main__:Epoch 19132: total training loss 0.00083\n",
            "2025-06-26 08:49:34,444 Epoch 19132: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19133\n",
            "2025-06-26 08:49:34,446 EPOCH 19133\n",
            "INFO:__main__:Epoch 19133: total training loss 0.00083\n",
            "2025-06-26 08:49:34,523 Epoch 19133: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19134\n",
            "2025-06-26 08:49:34,527 EPOCH 19134\n",
            "INFO:__main__:Epoch 19134: total training loss 0.00083\n",
            "2025-06-26 08:49:34,612 Epoch 19134: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19135\n",
            "2025-06-26 08:49:34,614 EPOCH 19135\n",
            "INFO:__main__:Epoch 19135: total training loss 0.00083\n",
            "2025-06-26 08:49:34,737 Epoch 19135: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19136\n",
            "2025-06-26 08:49:34,739 EPOCH 19136\n",
            "INFO:__main__:Epoch 19136: total training loss 0.00085\n",
            "2025-06-26 08:49:34,870 Epoch 19136: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19137\n",
            "2025-06-26 08:49:34,872 EPOCH 19137\n",
            "INFO:__main__:Epoch 19137: total training loss 0.00080\n",
            "2025-06-26 08:49:34,986 Epoch 19137: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19138\n",
            "2025-06-26 08:49:34,988 EPOCH 19138\n",
            "INFO:__main__:Epoch 19138: total training loss 0.00080\n",
            "2025-06-26 08:49:35,104 Epoch 19138: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19139\n",
            "2025-06-26 08:49:35,106 EPOCH 19139\n",
            "INFO:__main__:Epoch 19139: total training loss 0.00080\n",
            "2025-06-26 08:49:35,204 Epoch 19139: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19140\n",
            "2025-06-26 08:49:35,209 EPOCH 19140\n",
            "INFO:__main__:Epoch 19140: total training loss 0.00078\n",
            "2025-06-26 08:49:35,311 Epoch 19140: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19141\n",
            "2025-06-26 08:49:35,316 EPOCH 19141\n",
            "INFO:__main__:Epoch 19141: total training loss 0.00081\n",
            "2025-06-26 08:49:35,426 Epoch 19141: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19142\n",
            "2025-06-26 08:49:35,430 EPOCH 19142\n",
            "INFO:__main__:Epoch 19142: total training loss 0.00076\n",
            "2025-06-26 08:49:35,546 Epoch 19142: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19143\n",
            "2025-06-26 08:49:35,548 EPOCH 19143\n",
            "INFO:__main__:Epoch 19143: total training loss 0.00077\n",
            "2025-06-26 08:49:35,661 Epoch 19143: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19144\n",
            "2025-06-26 08:49:35,665 EPOCH 19144\n",
            "INFO:__main__:Epoch 19144: total training loss 0.00073\n",
            "2025-06-26 08:49:35,772 Epoch 19144: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19145\n",
            "2025-06-26 08:49:35,774 EPOCH 19145\n",
            "INFO:__main__:Epoch 19145: total training loss 0.00074\n",
            "2025-06-26 08:49:35,891 Epoch 19145: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19146\n",
            "2025-06-26 08:49:35,897 EPOCH 19146\n",
            "INFO:__main__:Epoch 19146: total training loss 0.00072\n",
            "2025-06-26 08:49:36,016 Epoch 19146: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19147\n",
            "2025-06-26 08:49:36,019 EPOCH 19147\n",
            "INFO:__main__:Epoch 19147: total training loss 0.00073\n",
            "2025-06-26 08:49:36,118 Epoch 19147: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19148\n",
            "2025-06-26 08:49:36,122 EPOCH 19148\n",
            "INFO:__main__:Epoch 19148: total training loss 0.00072\n",
            "2025-06-26 08:49:36,209 Epoch 19148: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19149\n",
            "2025-06-26 08:49:36,212 EPOCH 19149\n",
            "INFO:__main__:Epoch 19149: total training loss 0.00072\n",
            "2025-06-26 08:49:36,304 Epoch 19149: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19150\n",
            "2025-06-26 08:49:36,308 EPOCH 19150\n",
            "INFO:__main__:Epoch 19150: total training loss 0.00073\n",
            "2025-06-26 08:49:36,384 Epoch 19150: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19151\n",
            "2025-06-26 08:49:36,387 EPOCH 19151\n",
            "INFO:__main__:Epoch 19151: total training loss 0.00073\n",
            "2025-06-26 08:49:36,462 Epoch 19151: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19152\n",
            "2025-06-26 08:49:36,465 EPOCH 19152\n",
            "INFO:__main__:Epoch 19152: total training loss 0.00075\n",
            "2025-06-26 08:49:36,551 Epoch 19152: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19153\n",
            "2025-06-26 08:49:36,553 EPOCH 19153\n",
            "INFO:__main__:Epoch 19153: total training loss 0.00075\n",
            "2025-06-26 08:49:36,632 Epoch 19153: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19154\n",
            "2025-06-26 08:49:36,638 EPOCH 19154\n",
            "INFO:__main__:Epoch 19154: total training loss 0.00077\n",
            "2025-06-26 08:49:36,740 Epoch 19154: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19155\n",
            "2025-06-26 08:49:36,742 EPOCH 19155\n",
            "INFO:__main__:Epoch 19155: total training loss 0.00080\n",
            "2025-06-26 08:49:36,862 Epoch 19155: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19156\n",
            "2025-06-26 08:49:36,864 EPOCH 19156\n",
            "INFO:__main__:Epoch 19156: total training loss 0.00082\n",
            "2025-06-26 08:49:36,980 Epoch 19156: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19157\n",
            "2025-06-26 08:49:36,983 EPOCH 19157\n",
            "INFO:__main__:Epoch 19157: total training loss 0.00083\n",
            "2025-06-26 08:49:37,103 Epoch 19157: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19158\n",
            "2025-06-26 08:49:37,106 EPOCH 19158\n",
            "INFO:__main__:Epoch 19158: total training loss 0.00081\n",
            "2025-06-26 08:49:37,197 Epoch 19158: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19159\n",
            "2025-06-26 08:49:37,199 EPOCH 19159\n",
            "INFO:__main__:Epoch 19159: total training loss 0.00084\n",
            "2025-06-26 08:49:37,274 Epoch 19159: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19160\n",
            "2025-06-26 08:49:37,277 EPOCH 19160\n",
            "INFO:__main__:Epoch 19160: total training loss 0.00089\n",
            "2025-06-26 08:49:37,382 Epoch 19160: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19161\n",
            "2025-06-26 08:49:37,384 EPOCH 19161\n",
            "INFO:__main__:Epoch 19161: total training loss 0.00095\n",
            "2025-06-26 08:49:37,495 Epoch 19161: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19162\n",
            "2025-06-26 08:49:37,497 EPOCH 19162\n",
            "INFO:__main__:Epoch 19162: total training loss 0.00087\n",
            "2025-06-26 08:49:37,606 Epoch 19162: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19163\n",
            "2025-06-26 08:49:37,609 EPOCH 19163\n",
            "INFO:__main__:Epoch 19163: total training loss 0.00089\n",
            "2025-06-26 08:49:37,722 Epoch 19163: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19164\n",
            "2025-06-26 08:49:37,724 EPOCH 19164\n",
            "INFO:__main__:Epoch 19164: total training loss 0.00095\n",
            "2025-06-26 08:49:37,835 Epoch 19164: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19165\n",
            "2025-06-26 08:49:37,839 EPOCH 19165\n",
            "INFO:__main__:Epoch 19165: total training loss 0.00082\n",
            "2025-06-26 08:49:37,946 Epoch 19165: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19166\n",
            "2025-06-26 08:49:37,949 EPOCH 19166\n",
            "INFO:__main__:Epoch 19166: total training loss 0.00093\n",
            "2025-06-26 08:49:38,038 Epoch 19166: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19167\n",
            "2025-06-26 08:49:38,041 EPOCH 19167\n",
            "INFO:__main__:Epoch 19167: total training loss 0.00080\n",
            "2025-06-26 08:49:38,145 Epoch 19167: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19168\n",
            "2025-06-26 08:49:38,147 EPOCH 19168\n",
            "INFO:__main__:Epoch 19168: total training loss 0.00087\n",
            "2025-06-26 08:49:38,269 Epoch 19168: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19169\n",
            "2025-06-26 08:49:38,271 EPOCH 19169\n",
            "INFO:__main__:Epoch 19169: total training loss 0.00082\n",
            "2025-06-26 08:49:38,345 Epoch 19169: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19170\n",
            "2025-06-26 08:49:38,350 EPOCH 19170\n",
            "INFO:__main__:Epoch 19170: total training loss 0.00088\n",
            "2025-06-26 08:49:38,439 Epoch 19170: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19171\n",
            "2025-06-26 08:49:38,441 EPOCH 19171\n",
            "INFO:__main__:Epoch 19171: total training loss 0.00083\n",
            "2025-06-26 08:49:38,531 Epoch 19171: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19172\n",
            "2025-06-26 08:49:38,537 EPOCH 19172\n",
            "INFO:__main__:Epoch 19172: total training loss 0.00083\n",
            "2025-06-26 08:49:38,642 Epoch 19172: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19173\n",
            "2025-06-26 08:49:38,645 EPOCH 19173\n",
            "INFO:__main__:Epoch 19173: total training loss 0.00081\n",
            "2025-06-26 08:49:38,740 Epoch 19173: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19174\n",
            "2025-06-26 08:49:38,742 EPOCH 19174\n",
            "INFO:__main__:Epoch 19174: total training loss 0.00082\n",
            "2025-06-26 08:49:38,835 Epoch 19174: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19175\n",
            "2025-06-26 08:49:38,841 EPOCH 19175\n",
            "INFO:__main__:Epoch 19175: total training loss 0.00082\n",
            "2025-06-26 08:49:38,947 Epoch 19175: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19176\n",
            "2025-06-26 08:49:38,953 EPOCH 19176\n",
            "INFO:__main__:Epoch 19176: total training loss 0.00085\n",
            "2025-06-26 08:49:39,052 Epoch 19176: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19177\n",
            "2025-06-26 08:49:39,055 EPOCH 19177\n",
            "INFO:__main__:Epoch 19177: total training loss 0.00086\n",
            "2025-06-26 08:49:39,143 Epoch 19177: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19178\n",
            "2025-06-26 08:49:39,148 EPOCH 19178\n",
            "INFO:__main__:Epoch 19178: total training loss 0.00092\n",
            "2025-06-26 08:49:39,257 Epoch 19178: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19179\n",
            "2025-06-26 08:49:39,260 EPOCH 19179\n",
            "INFO:__main__:Epoch 19179: total training loss 0.00090\n",
            "2025-06-26 08:49:39,341 Epoch 19179: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19180\n",
            "2025-06-26 08:49:39,345 EPOCH 19180\n",
            "INFO:__main__:Epoch 19180: total training loss 0.00089\n",
            "2025-06-26 08:49:39,426 Epoch 19180: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19181\n",
            "2025-06-26 08:49:39,428 EPOCH 19181\n",
            "INFO:__main__:Epoch 19181: total training loss 0.00090\n",
            "2025-06-26 08:49:39,500 Epoch 19181: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19182\n",
            "2025-06-26 08:49:39,502 EPOCH 19182\n",
            "INFO:__main__:Epoch 19182: total training loss 0.00083\n",
            "2025-06-26 08:49:39,575 Epoch 19182: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19183\n",
            "2025-06-26 08:49:39,577 EPOCH 19183\n",
            "INFO:__main__:Epoch 19183: total training loss 0.00084\n",
            "2025-06-26 08:49:39,645 Epoch 19183: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19184\n",
            "2025-06-26 08:49:39,647 EPOCH 19184\n",
            "INFO:__main__:Epoch 19184: total training loss 0.00087\n",
            "2025-06-26 08:49:39,715 Epoch 19184: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19185\n",
            "2025-06-26 08:49:39,717 EPOCH 19185\n",
            "INFO:__main__:Epoch 19185: total training loss 0.00082\n",
            "2025-06-26 08:49:39,786 Epoch 19185: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19186\n",
            "2025-06-26 08:49:39,789 EPOCH 19186\n",
            "INFO:__main__:Epoch 19186: total training loss 0.00082\n",
            "2025-06-26 08:49:39,870 Epoch 19186: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19187\n",
            "2025-06-26 08:49:39,872 EPOCH 19187\n",
            "INFO:__main__:Epoch 19187: total training loss 0.00088\n",
            "2025-06-26 08:49:39,941 Epoch 19187: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19188\n",
            "2025-06-26 08:49:39,943 EPOCH 19188\n",
            "INFO:__main__:Epoch 19188: total training loss 0.00083\n",
            "2025-06-26 08:49:40,013 Epoch 19188: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19189\n",
            "2025-06-26 08:49:40,018 EPOCH 19189\n",
            "INFO:__main__:Epoch 19189: total training loss 0.00079\n",
            "2025-06-26 08:49:40,115 Epoch 19189: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19190\n",
            "2025-06-26 08:49:40,117 EPOCH 19190\n",
            "INFO:__main__:Epoch 19190: total training loss 0.00083\n",
            "2025-06-26 08:49:40,194 Epoch 19190: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19191\n",
            "2025-06-26 08:49:40,198 EPOCH 19191\n",
            "INFO:__main__:Epoch 19191: total training loss 0.00078\n",
            "2025-06-26 08:49:40,270 Epoch 19191: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19192\n",
            "2025-06-26 08:49:40,273 EPOCH 19192\n",
            "INFO:__main__:Epoch 19192: total training loss 0.00080\n",
            "2025-06-26 08:49:40,345 Epoch 19192: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19193\n",
            "2025-06-26 08:49:40,347 EPOCH 19193\n",
            "INFO:__main__:Epoch 19193: total training loss 0.00086\n",
            "2025-06-26 08:49:40,421 Epoch 19193: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19194\n",
            "2025-06-26 08:49:40,423 EPOCH 19194\n",
            "INFO:__main__:Epoch 19194: total training loss 0.00078\n",
            "2025-06-26 08:49:40,496 Epoch 19194: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19195\n",
            "2025-06-26 08:49:40,500 EPOCH 19195\n",
            "INFO:__main__:Epoch 19195: total training loss 0.00075\n",
            "2025-06-26 08:49:40,572 Epoch 19195: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19196\n",
            "2025-06-26 08:49:40,575 EPOCH 19196\n",
            "INFO:__main__:Epoch 19196: total training loss 0.00079\n",
            "2025-06-26 08:49:40,648 Epoch 19196: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19197\n",
            "2025-06-26 08:49:40,651 EPOCH 19197\n",
            "INFO:__main__:Epoch 19197: total training loss 0.00082\n",
            "2025-06-26 08:49:40,727 Epoch 19197: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19198\n",
            "2025-06-26 08:49:40,729 EPOCH 19198\n",
            "INFO:__main__:Epoch 19198: total training loss 0.00080\n",
            "2025-06-26 08:49:40,804 Epoch 19198: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19199\n",
            "2025-06-26 08:49:40,806 EPOCH 19199\n",
            "INFO:__main__:Epoch 19199: total training loss 0.00081\n",
            "2025-06-26 08:49:40,880 Epoch 19199: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19200\n",
            "2025-06-26 08:49:40,882 EPOCH 19200\n",
            "INFO:__main__:Epoch 19200: total training loss 0.00077\n",
            "2025-06-26 08:49:40,957 Epoch 19200: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19201\n",
            "2025-06-26 08:49:40,959 EPOCH 19201\n",
            "INFO:__main__:Epoch 19201: total training loss 0.00088\n",
            "2025-06-26 08:49:41,034 Epoch 19201: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19202\n",
            "2025-06-26 08:49:41,036 EPOCH 19202\n",
            "INFO:__main__:Epoch 19202: total training loss 0.00086\n",
            "2025-06-26 08:49:41,115 Epoch 19202: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19203\n",
            "2025-06-26 08:49:41,117 EPOCH 19203\n",
            "INFO:__main__:Epoch 19203: total training loss 0.00084\n",
            "2025-06-26 08:49:41,212 Epoch 19203: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19204\n",
            "2025-06-26 08:49:41,216 EPOCH 19204\n",
            "INFO:__main__:Epoch 19204: total training loss 0.00082\n",
            "2025-06-26 08:49:41,288 Epoch 19204: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19205\n",
            "2025-06-26 08:49:41,290 EPOCH 19205\n",
            "INFO:__main__:Epoch 19205: total training loss 0.00076\n",
            "2025-06-26 08:49:41,364 Epoch 19205: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19206\n",
            "2025-06-26 08:49:41,368 EPOCH 19206\n",
            "INFO:__main__:Epoch 19206: total training loss 0.00087\n",
            "2025-06-26 08:49:41,452 Epoch 19206: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19207\n",
            "2025-06-26 08:49:41,454 EPOCH 19207\n",
            "INFO:__main__:Epoch 19207: total training loss 0.00084\n",
            "2025-06-26 08:49:41,528 Epoch 19207: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19208\n",
            "2025-06-26 08:49:41,530 EPOCH 19208\n",
            "INFO:__main__:Epoch 19208: total training loss 0.00082\n",
            "2025-06-26 08:49:41,603 Epoch 19208: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19209\n",
            "2025-06-26 08:49:41,605 EPOCH 19209\n",
            "INFO:__main__:Epoch 19209: total training loss 0.00085\n",
            "2025-06-26 08:49:41,675 Epoch 19209: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19210\n",
            "2025-06-26 08:49:41,677 EPOCH 19210\n",
            "INFO:__main__:Epoch 19210: total training loss 0.00091\n",
            "2025-06-26 08:49:41,748 Epoch 19210: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19211\n",
            "2025-06-26 08:49:41,750 EPOCH 19211\n",
            "INFO:__main__:Epoch 19211: total training loss 0.00091\n",
            "2025-06-26 08:49:41,825 Epoch 19211: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19212\n",
            "2025-06-26 08:49:41,827 EPOCH 19212\n",
            "INFO:__main__:Epoch 19212: total training loss 0.00084\n",
            "2025-06-26 08:49:41,901 Epoch 19212: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19213\n",
            "2025-06-26 08:49:41,903 EPOCH 19213\n",
            "INFO:__main__:Epoch 19213: total training loss 0.00078\n",
            "2025-06-26 08:49:41,977 Epoch 19213: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19214\n",
            "2025-06-26 08:49:41,979 EPOCH 19214\n",
            "INFO:__main__:Epoch 19214: total training loss 0.00083\n",
            "2025-06-26 08:49:42,053 Epoch 19214: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19215\n",
            "2025-06-26 08:49:42,055 EPOCH 19215\n",
            "INFO:__main__:Epoch 19215: total training loss 0.00086\n",
            "2025-06-26 08:49:42,141 Epoch 19215: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19216\n",
            "2025-06-26 08:49:42,143 EPOCH 19216\n",
            "INFO:__main__:Epoch 19216: total training loss 0.00078\n",
            "2025-06-26 08:49:42,216 Epoch 19216: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19217\n",
            "2025-06-26 08:49:42,217 EPOCH 19217\n",
            "INFO:__main__:Epoch 19217: total training loss 0.00082\n",
            "2025-06-26 08:49:42,328 Epoch 19217: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19218\n",
            "2025-06-26 08:49:42,330 EPOCH 19218\n",
            "INFO:__main__:Epoch 19218: total training loss 0.00076\n",
            "2025-06-26 08:49:42,401 Epoch 19218: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19219\n",
            "2025-06-26 08:49:42,404 EPOCH 19219\n",
            "INFO:__main__:Epoch 19219: total training loss 0.00077\n",
            "2025-06-26 08:49:42,472 Epoch 19219: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19220\n",
            "2025-06-26 08:49:42,474 EPOCH 19220\n",
            "INFO:__main__:Epoch 19220: total training loss 0.00078\n",
            "2025-06-26 08:49:42,563 Epoch 19220: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19221\n",
            "2025-06-26 08:49:42,566 EPOCH 19221\n",
            "INFO:__main__:Epoch 19221: total training loss 0.00075\n",
            "2025-06-26 08:49:42,646 Epoch 19221: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19222\n",
            "2025-06-26 08:49:42,648 EPOCH 19222\n",
            "INFO:__main__:Epoch 19222: total training loss 0.00079\n",
            "2025-06-26 08:49:42,720 Epoch 19222: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19223\n",
            "2025-06-26 08:49:42,722 EPOCH 19223\n",
            "INFO:__main__:Epoch 19223: total training loss 0.00073\n",
            "2025-06-26 08:49:42,792 Epoch 19223: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19224\n",
            "2025-06-26 08:49:42,795 EPOCH 19224\n",
            "INFO:__main__:Epoch 19224: total training loss 0.00075\n",
            "2025-06-26 08:49:42,869 Epoch 19224: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19225\n",
            "2025-06-26 08:49:42,871 EPOCH 19225\n",
            "INFO:__main__:Epoch 19225: total training loss 0.00079\n",
            "2025-06-26 08:49:42,951 Epoch 19225: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19226\n",
            "2025-06-26 08:49:42,953 EPOCH 19226\n",
            "INFO:__main__:Epoch 19226: total training loss 0.00084\n",
            "2025-06-26 08:49:43,027 Epoch 19226: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19227\n",
            "2025-06-26 08:49:43,029 EPOCH 19227\n",
            "INFO:__main__:Epoch 19227: total training loss 0.00085\n",
            "2025-06-26 08:49:43,111 Epoch 19227: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19228\n",
            "2025-06-26 08:49:43,113 EPOCH 19228\n",
            "INFO:__main__:Epoch 19228: total training loss 0.00083\n",
            "2025-06-26 08:49:43,192 Epoch 19228: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19229\n",
            "2025-06-26 08:49:43,194 EPOCH 19229\n",
            "INFO:__main__:Epoch 19229: total training loss 0.00081\n",
            "2025-06-26 08:49:43,264 Epoch 19229: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19230\n",
            "2025-06-26 08:49:43,266 EPOCH 19230\n",
            "INFO:__main__:Epoch 19230: total training loss 0.00077\n",
            "2025-06-26 08:49:43,352 Epoch 19230: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19231\n",
            "2025-06-26 08:49:43,354 EPOCH 19231\n",
            "INFO:__main__:Epoch 19231: total training loss 0.00079\n",
            "2025-06-26 08:49:43,446 Epoch 19231: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19232\n",
            "2025-06-26 08:49:43,448 EPOCH 19232\n",
            "INFO:__main__:Epoch 19232: total training loss 0.00076\n",
            "2025-06-26 08:49:43,525 Epoch 19232: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19233\n",
            "2025-06-26 08:49:43,527 EPOCH 19233\n",
            "INFO:__main__:Epoch 19233: total training loss 0.00079\n",
            "2025-06-26 08:49:43,616 Epoch 19233: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19234\n",
            "2025-06-26 08:49:43,620 EPOCH 19234\n",
            "INFO:__main__:Epoch 19234: total training loss 0.00082\n",
            "2025-06-26 08:49:43,689 Epoch 19234: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19235\n",
            "2025-06-26 08:49:43,692 EPOCH 19235\n",
            "INFO:__main__:Epoch 19235: total training loss 0.00077\n",
            "2025-06-26 08:49:43,767 Epoch 19235: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19236\n",
            "2025-06-26 08:49:43,769 EPOCH 19236\n",
            "INFO:__main__:Epoch 19236: total training loss 0.00078\n",
            "2025-06-26 08:49:43,841 Epoch 19236: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19237\n",
            "2025-06-26 08:49:43,843 EPOCH 19237\n",
            "INFO:__main__:Epoch 19237: total training loss 0.00077\n",
            "2025-06-26 08:49:43,918 Epoch 19237: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19238\n",
            "2025-06-26 08:49:43,920 EPOCH 19238\n",
            "INFO:__main__:Epoch 19238: total training loss 0.00076\n",
            "2025-06-26 08:49:43,992 Epoch 19238: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19239\n",
            "2025-06-26 08:49:43,994 EPOCH 19239\n",
            "INFO:__main__:Epoch 19239: total training loss 0.00079\n",
            "2025-06-26 08:49:44,064 Epoch 19239: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19240\n",
            "2025-06-26 08:49:44,066 EPOCH 19240\n",
            "INFO:__main__:Epoch 19240: total training loss 0.00080\n",
            "2025-06-26 08:49:44,146 Epoch 19240: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19241\n",
            "2025-06-26 08:49:44,148 EPOCH 19241\n",
            "INFO:__main__:Epoch 19241: total training loss 0.00081\n",
            "2025-06-26 08:49:44,239 Epoch 19241: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19242\n",
            "2025-06-26 08:49:44,241 EPOCH 19242\n",
            "INFO:__main__:Epoch 19242: total training loss 0.00080\n",
            "2025-06-26 08:49:44,315 Epoch 19242: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19243\n",
            "2025-06-26 08:49:44,317 EPOCH 19243\n",
            "INFO:__main__:Epoch 19243: total training loss 0.00084\n",
            "2025-06-26 08:49:44,398 Epoch 19243: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19244\n",
            "2025-06-26 08:49:44,400 EPOCH 19244\n",
            "INFO:__main__:Epoch 19244: total training loss 0.00082\n",
            "2025-06-26 08:49:44,478 Epoch 19244: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19245\n",
            "2025-06-26 08:49:44,481 EPOCH 19245\n",
            "INFO:__main__:Epoch 19245: total training loss 0.00080\n",
            "2025-06-26 08:49:44,554 Epoch 19245: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19246\n",
            "2025-06-26 08:49:44,556 EPOCH 19246\n",
            "INFO:__main__:Epoch 19246: total training loss 0.00081\n",
            "2025-06-26 08:49:44,628 Epoch 19246: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19247\n",
            "2025-06-26 08:49:44,631 EPOCH 19247\n",
            "INFO:__main__:Epoch 19247: total training loss 0.00085\n",
            "2025-06-26 08:49:44,700 Epoch 19247: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19248\n",
            "2025-06-26 08:49:44,702 EPOCH 19248\n",
            "INFO:__main__:Epoch 19248: total training loss 0.00088\n",
            "2025-06-26 08:49:44,774 Epoch 19248: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19249\n",
            "2025-06-26 08:49:44,777 EPOCH 19249\n",
            "INFO:__main__:Epoch 19249: total training loss 0.00086\n",
            "2025-06-26 08:49:44,851 Epoch 19249: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19250\n",
            "2025-06-26 08:49:44,853 EPOCH 19250\n",
            "INFO:__main__:Epoch 19250 Step:    19250 Batch Loss:     0.000782 Tokens per Sec:  1704885, Lr: 0.001000\n",
            "2025-06-26 08:49:44,937 Epoch 19250 Step:    19250 Batch Loss:     0.000782 Tokens per Sec:  1704885, Lr: 0.001000\n",
            "INFO:__main__:Epoch 19250: total training loss 0.00078\n",
            "2025-06-26 08:49:44,939 Epoch 19250: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19251\n",
            "2025-06-26 08:49:44,941 EPOCH 19251\n",
            "INFO:__main__:Epoch 19251: total training loss 0.00081\n",
            "2025-06-26 08:49:45,011 Epoch 19251: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19252\n",
            "2025-06-26 08:49:45,014 EPOCH 19252\n",
            "INFO:__main__:Epoch 19252: total training loss 0.00082\n",
            "2025-06-26 08:49:45,089 Epoch 19252: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19253\n",
            "2025-06-26 08:49:45,091 EPOCH 19253\n",
            "INFO:__main__:Epoch 19253: total training loss 0.00082\n",
            "2025-06-26 08:49:45,173 Epoch 19253: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19254\n",
            "2025-06-26 08:49:45,175 EPOCH 19254\n",
            "INFO:__main__:Epoch 19254: total training loss 0.00086\n",
            "2025-06-26 08:49:45,250 Epoch 19254: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19255\n",
            "2025-06-26 08:49:45,252 EPOCH 19255\n",
            "INFO:__main__:Epoch 19255: total training loss 0.00085\n",
            "2025-06-26 08:49:45,321 Epoch 19255: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19256\n",
            "2025-06-26 08:49:45,323 EPOCH 19256\n",
            "INFO:__main__:Epoch 19256: total training loss 0.00085\n",
            "2025-06-26 08:49:45,404 Epoch 19256: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19257\n",
            "2025-06-26 08:49:45,406 EPOCH 19257\n",
            "INFO:__main__:Epoch 19257: total training loss 0.00087\n",
            "2025-06-26 08:49:45,493 Epoch 19257: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19258\n",
            "2025-06-26 08:49:45,495 EPOCH 19258\n",
            "INFO:__main__:Epoch 19258: total training loss 0.00082\n",
            "2025-06-26 08:49:45,564 Epoch 19258: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19259\n",
            "2025-06-26 08:49:45,567 EPOCH 19259\n",
            "INFO:__main__:Epoch 19259: total training loss 0.00082\n",
            "2025-06-26 08:49:45,636 Epoch 19259: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19260\n",
            "2025-06-26 08:49:45,638 EPOCH 19260\n",
            "INFO:__main__:Epoch 19260: total training loss 0.00083\n",
            "2025-06-26 08:49:45,721 Epoch 19260: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19261\n",
            "2025-06-26 08:49:45,723 EPOCH 19261\n",
            "INFO:__main__:Epoch 19261: total training loss 0.00088\n",
            "2025-06-26 08:49:45,795 Epoch 19261: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19262\n",
            "2025-06-26 08:49:45,797 EPOCH 19262\n",
            "INFO:__main__:Epoch 19262: total training loss 0.00088\n",
            "2025-06-26 08:49:45,867 Epoch 19262: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19263\n",
            "2025-06-26 08:49:45,869 EPOCH 19263\n",
            "INFO:__main__:Epoch 19263: total training loss 0.00082\n",
            "2025-06-26 08:49:45,945 Epoch 19263: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19264\n",
            "2025-06-26 08:49:45,947 EPOCH 19264\n",
            "INFO:__main__:Epoch 19264: total training loss 0.00089\n",
            "2025-06-26 08:49:46,021 Epoch 19264: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19265\n",
            "2025-06-26 08:49:46,023 EPOCH 19265\n",
            "INFO:__main__:Epoch 19265: total training loss 0.00083\n",
            "2025-06-26 08:49:46,097 Epoch 19265: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19266\n",
            "2025-06-26 08:49:46,101 EPOCH 19266\n",
            "INFO:__main__:Epoch 19266: total training loss 0.00081\n",
            "2025-06-26 08:49:46,174 Epoch 19266: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19267\n",
            "2025-06-26 08:49:46,177 EPOCH 19267\n",
            "INFO:__main__:Epoch 19267: total training loss 0.00082\n",
            "2025-06-26 08:49:46,251 Epoch 19267: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19268\n",
            "2025-06-26 08:49:46,254 EPOCH 19268\n",
            "INFO:__main__:Epoch 19268: total training loss 0.00079\n",
            "2025-06-26 08:49:46,337 Epoch 19268: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19269\n",
            "2025-06-26 08:49:46,339 EPOCH 19269\n",
            "INFO:__main__:Epoch 19269: total training loss 0.00077\n",
            "2025-06-26 08:49:46,412 Epoch 19269: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19270\n",
            "2025-06-26 08:49:46,415 EPOCH 19270\n",
            "INFO:__main__:Epoch 19270: total training loss 0.00075\n",
            "2025-06-26 08:49:46,485 Epoch 19270: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19271\n",
            "2025-06-26 08:49:46,489 EPOCH 19271\n",
            "INFO:__main__:Epoch 19271: total training loss 0.00078\n",
            "2025-06-26 08:49:46,585 Epoch 19271: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19272\n",
            "2025-06-26 08:49:46,587 EPOCH 19272\n",
            "INFO:__main__:Epoch 19272: total training loss 0.00078\n",
            "2025-06-26 08:49:46,669 Epoch 19272: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19273\n",
            "2025-06-26 08:49:46,672 EPOCH 19273\n",
            "INFO:__main__:Epoch 19273: total training loss 0.00076\n",
            "2025-06-26 08:49:46,744 Epoch 19273: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19274\n",
            "2025-06-26 08:49:46,746 EPOCH 19274\n",
            "INFO:__main__:Epoch 19274: total training loss 0.00076\n",
            "2025-06-26 08:49:46,819 Epoch 19274: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19275\n",
            "2025-06-26 08:49:46,822 EPOCH 19275\n",
            "INFO:__main__:Epoch 19275: total training loss 0.00075\n",
            "2025-06-26 08:49:46,895 Epoch 19275: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19276\n",
            "2025-06-26 08:49:46,897 EPOCH 19276\n",
            "INFO:__main__:Epoch 19276: total training loss 0.00075\n",
            "2025-06-26 08:49:46,973 Epoch 19276: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19277\n",
            "2025-06-26 08:49:46,975 EPOCH 19277\n",
            "INFO:__main__:Epoch 19277: total training loss 0.00075\n",
            "2025-06-26 08:49:47,068 Epoch 19277: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19278\n",
            "2025-06-26 08:49:47,070 EPOCH 19278\n",
            "INFO:__main__:Epoch 19278: total training loss 0.00075\n",
            "2025-06-26 08:49:47,145 Epoch 19278: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19279\n",
            "2025-06-26 08:49:47,148 EPOCH 19279\n",
            "INFO:__main__:Epoch 19279: total training loss 0.00075\n",
            "2025-06-26 08:49:47,227 Epoch 19279: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19280\n",
            "2025-06-26 08:49:47,229 EPOCH 19280\n",
            "INFO:__main__:Epoch 19280: total training loss 0.00079\n",
            "2025-06-26 08:49:47,305 Epoch 19280: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19281\n",
            "2025-06-26 08:49:47,307 EPOCH 19281\n",
            "INFO:__main__:Epoch 19281: total training loss 0.00078\n",
            "2025-06-26 08:49:47,379 Epoch 19281: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19282\n",
            "2025-06-26 08:49:47,381 EPOCH 19282\n",
            "INFO:__main__:Epoch 19282: total training loss 0.00073\n",
            "2025-06-26 08:49:47,453 Epoch 19282: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19283\n",
            "2025-06-26 08:49:47,455 EPOCH 19283\n",
            "INFO:__main__:Epoch 19283: total training loss 0.00072\n",
            "2025-06-26 08:49:47,528 Epoch 19283: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19284\n",
            "2025-06-26 08:49:47,530 EPOCH 19284\n",
            "INFO:__main__:Epoch 19284: total training loss 0.00072\n",
            "2025-06-26 08:49:47,613 Epoch 19284: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19285\n",
            "2025-06-26 08:49:47,616 EPOCH 19285\n",
            "INFO:__main__:Epoch 19285: total training loss 0.00072\n",
            "2025-06-26 08:49:47,686 Epoch 19285: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19286\n",
            "2025-06-26 08:49:47,688 EPOCH 19286\n",
            "INFO:__main__:Epoch 19286: total training loss 0.00073\n",
            "2025-06-26 08:49:47,757 Epoch 19286: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19287\n",
            "2025-06-26 08:49:47,759 EPOCH 19287\n",
            "INFO:__main__:Epoch 19287: total training loss 0.00072\n",
            "2025-06-26 08:49:47,834 Epoch 19287: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19288\n",
            "2025-06-26 08:49:47,836 EPOCH 19288\n",
            "INFO:__main__:Epoch 19288: total training loss 0.00073\n",
            "2025-06-26 08:49:47,909 Epoch 19288: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19289\n",
            "2025-06-26 08:49:47,910 EPOCH 19289\n",
            "INFO:__main__:Epoch 19289: total training loss 0.00075\n",
            "2025-06-26 08:49:47,980 Epoch 19289: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19290\n",
            "2025-06-26 08:49:47,982 EPOCH 19290\n",
            "INFO:__main__:Epoch 19290: total training loss 0.00078\n",
            "2025-06-26 08:49:48,053 Epoch 19290: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19291\n",
            "2025-06-26 08:49:48,056 EPOCH 19291\n",
            "INFO:__main__:Epoch 19291: total training loss 0.00077\n",
            "2025-06-26 08:49:48,127 Epoch 19291: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19292\n",
            "2025-06-26 08:49:48,129 EPOCH 19292\n",
            "INFO:__main__:Epoch 19292: total training loss 0.00078\n",
            "2025-06-26 08:49:48,208 Epoch 19292: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19293\n",
            "2025-06-26 08:49:48,210 EPOCH 19293\n",
            "INFO:__main__:Epoch 19293: total training loss 0.00102\n",
            "2025-06-26 08:49:48,283 Epoch 19293: total training loss 0.00102\n",
            "INFO:__main__:EPOCH 19294\n",
            "2025-06-26 08:49:48,285 EPOCH 19294\n",
            "INFO:__main__:Epoch 19294: total training loss 0.00088\n",
            "2025-06-26 08:49:48,356 Epoch 19294: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19295\n",
            "2025-06-26 08:49:48,358 EPOCH 19295\n",
            "INFO:__main__:Epoch 19295: total training loss 0.00087\n",
            "2025-06-26 08:49:48,428 Epoch 19295: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19296\n",
            "2025-06-26 08:49:48,430 EPOCH 19296\n",
            "INFO:__main__:Epoch 19296: total training loss 0.00084\n",
            "2025-06-26 08:49:48,501 Epoch 19296: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19297\n",
            "2025-06-26 08:49:48,503 EPOCH 19297\n",
            "INFO:__main__:Epoch 19297: total training loss 0.00085\n",
            "2025-06-26 08:49:48,575 Epoch 19297: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19298\n",
            "2025-06-26 08:49:48,577 EPOCH 19298\n",
            "INFO:__main__:Epoch 19298: total training loss 0.00081\n",
            "2025-06-26 08:49:48,651 Epoch 19298: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19299\n",
            "2025-06-26 08:49:48,653 EPOCH 19299\n",
            "INFO:__main__:Epoch 19299: total training loss 0.00081\n",
            "2025-06-26 08:49:48,730 Epoch 19299: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19300\n",
            "2025-06-26 08:49:48,732 EPOCH 19300\n",
            "INFO:__main__:Epoch 19300: total training loss 0.00087\n",
            "2025-06-26 08:49:48,805 Epoch 19300: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19301\n",
            "2025-06-26 08:49:48,807 EPOCH 19301\n",
            "INFO:__main__:Epoch 19301: total training loss 0.00086\n",
            "2025-06-26 08:49:48,884 Epoch 19301: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19302\n",
            "2025-06-26 08:49:48,886 EPOCH 19302\n",
            "INFO:__main__:Epoch 19302: total training loss 0.00084\n",
            "2025-06-26 08:49:48,958 Epoch 19302: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19303\n",
            "2025-06-26 08:49:48,961 EPOCH 19303\n",
            "INFO:__main__:Epoch 19303: total training loss 0.00080\n",
            "2025-06-26 08:49:49,032 Epoch 19303: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19304\n",
            "2025-06-26 08:49:49,034 EPOCH 19304\n",
            "INFO:__main__:Epoch 19304: total training loss 0.00082\n",
            "2025-06-26 08:49:49,115 Epoch 19304: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19305\n",
            "2025-06-26 08:49:49,117 EPOCH 19305\n",
            "INFO:__main__:Epoch 19305: total training loss 0.00081\n",
            "2025-06-26 08:49:49,189 Epoch 19305: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19306\n",
            "2025-06-26 08:49:49,191 EPOCH 19306\n",
            "INFO:__main__:Epoch 19306: total training loss 0.00078\n",
            "2025-06-26 08:49:49,262 Epoch 19306: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19307\n",
            "2025-06-26 08:49:49,264 EPOCH 19307\n",
            "INFO:__main__:Epoch 19307: total training loss 0.00080\n",
            "2025-06-26 08:49:49,348 Epoch 19307: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19308\n",
            "2025-06-26 08:49:49,350 EPOCH 19308\n",
            "INFO:__main__:Epoch 19308: total training loss 0.00074\n",
            "2025-06-26 08:49:49,434 Epoch 19308: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19309\n",
            "2025-06-26 08:49:49,437 EPOCH 19309\n",
            "INFO:__main__:Epoch 19309: total training loss 0.00079\n",
            "2025-06-26 08:49:49,549 Epoch 19309: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19310\n",
            "2025-06-26 08:49:49,551 EPOCH 19310\n",
            "INFO:__main__:Epoch 19310: total training loss 0.00077\n",
            "2025-06-26 08:49:49,677 Epoch 19310: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19311\n",
            "2025-06-26 08:49:49,679 EPOCH 19311\n",
            "INFO:__main__:Epoch 19311: total training loss 0.00074\n",
            "2025-06-26 08:49:49,808 Epoch 19311: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19312\n",
            "2025-06-26 08:49:49,810 EPOCH 19312\n",
            "INFO:__main__:Epoch 19312: total training loss 0.00076\n",
            "2025-06-26 08:49:49,915 Epoch 19312: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19313\n",
            "2025-06-26 08:49:49,917 EPOCH 19313\n",
            "INFO:__main__:Epoch 19313: total training loss 0.00078\n",
            "2025-06-26 08:49:50,003 Epoch 19313: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19314\n",
            "2025-06-26 08:49:50,005 EPOCH 19314\n",
            "INFO:__main__:Epoch 19314: total training loss 0.00075\n",
            "2025-06-26 08:49:50,086 Epoch 19314: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19315\n",
            "2025-06-26 08:49:50,088 EPOCH 19315\n",
            "INFO:__main__:Epoch 19315: total training loss 0.00078\n",
            "2025-06-26 08:49:50,161 Epoch 19315: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19316\n",
            "2025-06-26 08:49:50,163 EPOCH 19316\n",
            "INFO:__main__:Epoch 19316: total training loss 0.00080\n",
            "2025-06-26 08:49:50,244 Epoch 19316: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19317\n",
            "2025-06-26 08:49:50,249 EPOCH 19317\n",
            "INFO:__main__:Epoch 19317: total training loss 0.00082\n",
            "2025-06-26 08:49:50,352 Epoch 19317: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19318\n",
            "2025-06-26 08:49:50,356 EPOCH 19318\n",
            "INFO:__main__:Epoch 19318: total training loss 0.00081\n",
            "2025-06-26 08:49:50,440 Epoch 19318: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19319\n",
            "2025-06-26 08:49:50,444 EPOCH 19319\n",
            "INFO:__main__:Epoch 19319: total training loss 0.00077\n",
            "2025-06-26 08:49:50,524 Epoch 19319: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19320\n",
            "2025-06-26 08:49:50,525 EPOCH 19320\n",
            "INFO:__main__:Epoch 19320: total training loss 0.00079\n",
            "2025-06-26 08:49:50,624 Epoch 19320: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19321\n",
            "2025-06-26 08:49:50,628 EPOCH 19321\n",
            "INFO:__main__:Epoch 19321: total training loss 0.00084\n",
            "2025-06-26 08:49:50,699 Epoch 19321: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19322\n",
            "2025-06-26 08:49:50,701 EPOCH 19322\n",
            "INFO:__main__:Epoch 19322: total training loss 0.00085\n",
            "2025-06-26 08:49:50,809 Epoch 19322: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19323\n",
            "2025-06-26 08:49:50,812 EPOCH 19323\n",
            "INFO:__main__:Epoch 19323: total training loss 0.00084\n",
            "2025-06-26 08:49:50,933 Epoch 19323: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19324\n",
            "2025-06-26 08:49:50,935 EPOCH 19324\n",
            "INFO:__main__:Epoch 19324: total training loss 0.00081\n",
            "2025-06-26 08:49:51,043 Epoch 19324: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19325\n",
            "2025-06-26 08:49:51,045 EPOCH 19325\n",
            "INFO:__main__:Epoch 19325: total training loss 0.00079\n",
            "2025-06-26 08:49:51,162 Epoch 19325: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19326\n",
            "2025-06-26 08:49:51,167 EPOCH 19326\n",
            "INFO:__main__:Epoch 19326: total training loss 0.00087\n",
            "2025-06-26 08:49:51,272 Epoch 19326: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19327\n",
            "2025-06-26 08:49:51,274 EPOCH 19327\n",
            "INFO:__main__:Epoch 19327: total training loss 0.00083\n",
            "2025-06-26 08:49:51,394 Epoch 19327: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19328\n",
            "2025-06-26 08:49:51,396 EPOCH 19328\n",
            "INFO:__main__:Epoch 19328: total training loss 0.00082\n",
            "2025-06-26 08:49:51,483 Epoch 19328: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19329\n",
            "2025-06-26 08:49:51,484 EPOCH 19329\n",
            "INFO:__main__:Epoch 19329: total training loss 0.00080\n",
            "2025-06-26 08:49:51,588 Epoch 19329: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19330\n",
            "2025-06-26 08:49:51,592 EPOCH 19330\n",
            "INFO:__main__:Epoch 19330: total training loss 0.00082\n",
            "2025-06-26 08:49:51,667 Epoch 19330: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19331\n",
            "2025-06-26 08:49:51,672 EPOCH 19331\n",
            "INFO:__main__:Epoch 19331: total training loss 0.00085\n",
            "2025-06-26 08:49:51,754 Epoch 19331: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19332\n",
            "2025-06-26 08:49:51,760 EPOCH 19332\n",
            "INFO:__main__:Epoch 19332: total training loss 0.00083\n",
            "2025-06-26 08:49:51,852 Epoch 19332: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19333\n",
            "2025-06-26 08:49:51,859 EPOCH 19333\n",
            "INFO:__main__:Epoch 19333: total training loss 0.00075\n",
            "2025-06-26 08:49:51,959 Epoch 19333: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19334\n",
            "2025-06-26 08:49:51,965 EPOCH 19334\n",
            "INFO:__main__:Epoch 19334: total training loss 0.00079\n",
            "2025-06-26 08:49:52,037 Epoch 19334: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19335\n",
            "2025-06-26 08:49:52,043 EPOCH 19335\n",
            "INFO:__main__:Epoch 19335: total training loss 0.00079\n",
            "2025-06-26 08:49:52,150 Epoch 19335: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19336\n",
            "2025-06-26 08:49:52,152 EPOCH 19336\n",
            "INFO:__main__:Epoch 19336: total training loss 0.00080\n",
            "2025-06-26 08:49:52,259 Epoch 19336: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19337\n",
            "2025-06-26 08:49:52,261 EPOCH 19337\n",
            "INFO:__main__:Epoch 19337: total training loss 0.00074\n",
            "2025-06-26 08:49:52,375 Epoch 19337: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19338\n",
            "2025-06-26 08:49:52,377 EPOCH 19338\n",
            "INFO:__main__:Epoch 19338: total training loss 0.00076\n",
            "2025-06-26 08:49:52,494 Epoch 19338: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19339\n",
            "2025-06-26 08:49:52,496 EPOCH 19339\n",
            "INFO:__main__:Epoch 19339: total training loss 0.00074\n",
            "2025-06-26 08:49:52,605 Epoch 19339: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19340\n",
            "2025-06-26 08:49:52,611 EPOCH 19340\n",
            "INFO:__main__:Epoch 19340: total training loss 0.00076\n",
            "2025-06-26 08:49:52,729 Epoch 19340: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19341\n",
            "2025-06-26 08:49:52,731 EPOCH 19341\n",
            "INFO:__main__:Epoch 19341: total training loss 0.00076\n",
            "2025-06-26 08:49:52,831 Epoch 19341: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19342\n",
            "2025-06-26 08:49:52,833 EPOCH 19342\n",
            "INFO:__main__:Epoch 19342: total training loss 0.00075\n",
            "2025-06-26 08:49:52,931 Epoch 19342: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19343\n",
            "2025-06-26 08:49:52,935 EPOCH 19343\n",
            "INFO:__main__:Epoch 19343: total training loss 0.00080\n",
            "2025-06-26 08:49:53,059 Epoch 19343: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19344\n",
            "2025-06-26 08:49:53,062 EPOCH 19344\n",
            "INFO:__main__:Epoch 19344: total training loss 0.00083\n",
            "2025-06-26 08:49:53,152 Epoch 19344: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19345\n",
            "2025-06-26 08:49:53,156 EPOCH 19345\n",
            "INFO:__main__:Epoch 19345: total training loss 0.00085\n",
            "2025-06-26 08:49:53,241 Epoch 19345: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19346\n",
            "2025-06-26 08:49:53,247 EPOCH 19346\n",
            "INFO:__main__:Epoch 19346: total training loss 0.00090\n",
            "2025-06-26 08:49:53,323 Epoch 19346: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19347\n",
            "2025-06-26 08:49:53,327 EPOCH 19347\n",
            "INFO:__main__:Epoch 19347: total training loss 0.00086\n",
            "2025-06-26 08:49:53,416 Epoch 19347: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19348\n",
            "2025-06-26 08:49:53,418 EPOCH 19348\n",
            "INFO:__main__:Epoch 19348: total training loss 0.00077\n",
            "2025-06-26 08:49:53,541 Epoch 19348: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19349\n",
            "2025-06-26 08:49:53,547 EPOCH 19349\n",
            "INFO:__main__:Epoch 19349: total training loss 0.00080\n",
            "2025-06-26 08:49:53,659 Epoch 19349: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19350\n",
            "2025-06-26 08:49:53,661 EPOCH 19350\n",
            "INFO:__main__:Epoch 19350: total training loss 0.00076\n",
            "2025-06-26 08:49:53,740 Epoch 19350: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19351\n",
            "2025-06-26 08:49:53,747 EPOCH 19351\n",
            "INFO:__main__:Epoch 19351: total training loss 0.00075\n",
            "2025-06-26 08:49:53,844 Epoch 19351: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19352\n",
            "2025-06-26 08:49:53,849 EPOCH 19352\n",
            "INFO:__main__:Epoch 19352: total training loss 0.00079\n",
            "2025-06-26 08:49:53,938 Epoch 19352: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19353\n",
            "2025-06-26 08:49:53,943 EPOCH 19353\n",
            "INFO:__main__:Epoch 19353: total training loss 0.00078\n",
            "2025-06-26 08:49:54,021 Epoch 19353: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19354\n",
            "2025-06-26 08:49:54,025 EPOCH 19354\n",
            "INFO:__main__:Epoch 19354: total training loss 0.00076\n",
            "2025-06-26 08:49:54,127 Epoch 19354: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19355\n",
            "2025-06-26 08:49:54,132 EPOCH 19355\n",
            "INFO:__main__:Epoch 19355: total training loss 0.00074\n",
            "2025-06-26 08:49:54,219 Epoch 19355: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19356\n",
            "2025-06-26 08:49:54,226 EPOCH 19356\n",
            "INFO:__main__:Epoch 19356: total training loss 0.00074\n",
            "2025-06-26 08:49:54,329 Epoch 19356: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19357\n",
            "2025-06-26 08:49:54,333 EPOCH 19357\n",
            "INFO:__main__:Epoch 19357: total training loss 0.00078\n",
            "2025-06-26 08:49:54,426 Epoch 19357: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19358\n",
            "2025-06-26 08:49:54,431 EPOCH 19358\n",
            "INFO:__main__:Epoch 19358: total training loss 0.00073\n",
            "2025-06-26 08:49:54,516 Epoch 19358: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19359\n",
            "2025-06-26 08:49:54,521 EPOCH 19359\n",
            "INFO:__main__:Epoch 19359: total training loss 0.00078\n",
            "2025-06-26 08:49:54,638 Epoch 19359: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19360\n",
            "2025-06-26 08:49:54,639 EPOCH 19360\n",
            "INFO:__main__:Epoch 19360: total training loss 0.00076\n",
            "2025-06-26 08:49:54,736 Epoch 19360: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19361\n",
            "2025-06-26 08:49:54,739 EPOCH 19361\n",
            "INFO:__main__:Epoch 19361: total training loss 0.00069\n",
            "2025-06-26 08:49:54,818 Epoch 19361: total training loss 0.00069\n",
            "INFO:__main__:EPOCH 19362\n",
            "2025-06-26 08:49:54,821 EPOCH 19362\n",
            "INFO:__main__:Epoch 19362: total training loss 0.00074\n",
            "2025-06-26 08:49:54,892 Epoch 19362: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19363\n",
            "2025-06-26 08:49:54,894 EPOCH 19363\n",
            "INFO:__main__:Epoch 19363: total training loss 0.00076\n",
            "2025-06-26 08:49:54,996 Epoch 19363: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19364\n",
            "2025-06-26 08:49:55,001 EPOCH 19364\n",
            "INFO:__main__:Epoch 19364: total training loss 0.00074\n",
            "2025-06-26 08:49:55,074 Epoch 19364: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19365\n",
            "2025-06-26 08:49:55,080 EPOCH 19365\n",
            "INFO:__main__:Epoch 19365: total training loss 0.00074\n",
            "2025-06-26 08:49:55,198 Epoch 19365: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19366\n",
            "2025-06-26 08:49:55,203 EPOCH 19366\n",
            "INFO:__main__:Epoch 19366: total training loss 0.00073\n",
            "2025-06-26 08:49:55,276 Epoch 19366: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19367\n",
            "2025-06-26 08:49:55,281 EPOCH 19367\n",
            "INFO:__main__:Epoch 19367: total training loss 0.00076\n",
            "2025-06-26 08:49:55,355 Epoch 19367: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19368\n",
            "2025-06-26 08:49:55,363 EPOCH 19368\n",
            "INFO:__main__:Epoch 19368: total training loss 0.00080\n",
            "2025-06-26 08:49:55,449 Epoch 19368: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19369\n",
            "2025-06-26 08:49:55,452 EPOCH 19369\n",
            "INFO:__main__:Epoch 19369: total training loss 0.00090\n",
            "2025-06-26 08:49:55,526 Epoch 19369: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19370\n",
            "2025-06-26 08:49:55,528 EPOCH 19370\n",
            "INFO:__main__:Epoch 19370: total training loss 0.00098\n",
            "2025-06-26 08:49:55,617 Epoch 19370: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 19371\n",
            "2025-06-26 08:49:55,620 EPOCH 19371\n",
            "INFO:__main__:Epoch 19371: total training loss 0.00100\n",
            "2025-06-26 08:49:55,695 Epoch 19371: total training loss 0.00100\n",
            "INFO:__main__:EPOCH 19372\n",
            "2025-06-26 08:49:55,699 EPOCH 19372\n",
            "INFO:__main__:Epoch 19372: total training loss 0.00096\n",
            "2025-06-26 08:49:55,786 Epoch 19372: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19373\n",
            "2025-06-26 08:49:55,789 EPOCH 19373\n",
            "INFO:__main__:Epoch 19373: total training loss 0.00093\n",
            "2025-06-26 08:49:55,866 Epoch 19373: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19374\n",
            "2025-06-26 08:49:55,870 EPOCH 19374\n",
            "INFO:__main__:Epoch 19374: total training loss 0.00090\n",
            "2025-06-26 08:49:55,943 Epoch 19374: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19375\n",
            "2025-06-26 08:49:55,950 EPOCH 19375\n",
            "INFO:__main__:Epoch 19375: total training loss 0.00090\n",
            "2025-06-26 08:49:56,026 Epoch 19375: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19376\n",
            "2025-06-26 08:49:56,029 EPOCH 19376\n",
            "INFO:__main__:Epoch 19376: total training loss 0.00088\n",
            "2025-06-26 08:49:56,105 Epoch 19376: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19377\n",
            "2025-06-26 08:49:56,107 EPOCH 19377\n",
            "INFO:__main__:Epoch 19377: total training loss 0.00088\n",
            "2025-06-26 08:49:56,185 Epoch 19377: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19378\n",
            "2025-06-26 08:49:56,188 EPOCH 19378\n",
            "INFO:__main__:Epoch 19378: total training loss 0.00083\n",
            "2025-06-26 08:49:56,282 Epoch 19378: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19379\n",
            "2025-06-26 08:49:56,284 EPOCH 19379\n",
            "INFO:__main__:Epoch 19379: total training loss 0.00084\n",
            "2025-06-26 08:49:56,363 Epoch 19379: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19380\n",
            "2025-06-26 08:49:56,365 EPOCH 19380\n",
            "INFO:__main__:Epoch 19380: total training loss 0.00085\n",
            "2025-06-26 08:49:56,440 Epoch 19380: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19381\n",
            "2025-06-26 08:49:56,443 EPOCH 19381\n",
            "INFO:__main__:Epoch 19381: total training loss 0.00083\n",
            "2025-06-26 08:49:56,517 Epoch 19381: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19382\n",
            "2025-06-26 08:49:56,520 EPOCH 19382\n",
            "INFO:__main__:Epoch 19382: total training loss 0.00082\n",
            "2025-06-26 08:49:56,605 Epoch 19382: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19383\n",
            "2025-06-26 08:49:56,607 EPOCH 19383\n",
            "INFO:__main__:Epoch 19383: total training loss 0.00082\n",
            "2025-06-26 08:49:56,678 Epoch 19383: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19384\n",
            "2025-06-26 08:49:56,680 EPOCH 19384\n",
            "INFO:__main__:Epoch 19384: total training loss 0.00091\n",
            "2025-06-26 08:49:56,750 Epoch 19384: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19385\n",
            "2025-06-26 08:49:56,752 EPOCH 19385\n",
            "INFO:__main__:Epoch 19385: total training loss 0.00097\n",
            "2025-06-26 08:49:56,838 Epoch 19385: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 19386\n",
            "2025-06-26 08:49:56,840 EPOCH 19386\n",
            "INFO:__main__:Epoch 19386: total training loss 0.00086\n",
            "2025-06-26 08:49:56,916 Epoch 19386: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19387\n",
            "2025-06-26 08:49:56,919 EPOCH 19387\n",
            "INFO:__main__:Epoch 19387: total training loss 0.00091\n",
            "2025-06-26 08:49:56,991 Epoch 19387: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19388\n",
            "2025-06-26 08:49:56,993 EPOCH 19388\n",
            "INFO:__main__:Epoch 19388: total training loss 0.00090\n",
            "2025-06-26 08:49:57,074 Epoch 19388: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19389\n",
            "2025-06-26 08:49:57,076 EPOCH 19389\n",
            "INFO:__main__:Epoch 19389: total training loss 0.00086\n",
            "2025-06-26 08:49:57,149 Epoch 19389: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19390\n",
            "2025-06-26 08:49:57,151 EPOCH 19390\n",
            "INFO:__main__:Epoch 19390: total training loss 0.00085\n",
            "2025-06-26 08:49:57,236 Epoch 19390: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19391\n",
            "2025-06-26 08:49:57,238 EPOCH 19391\n",
            "INFO:__main__:Epoch 19391: total training loss 0.00083\n",
            "2025-06-26 08:49:57,337 Epoch 19391: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19392\n",
            "2025-06-26 08:49:57,339 EPOCH 19392\n",
            "INFO:__main__:Epoch 19392: total training loss 0.00081\n",
            "2025-06-26 08:49:57,410 Epoch 19392: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19393\n",
            "2025-06-26 08:49:57,412 EPOCH 19393\n",
            "INFO:__main__:Epoch 19393: total training loss 0.00085\n",
            "2025-06-26 08:49:57,494 Epoch 19393: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19394\n",
            "2025-06-26 08:49:57,496 EPOCH 19394\n",
            "INFO:__main__:Epoch 19394: total training loss 0.00083\n",
            "2025-06-26 08:49:57,565 Epoch 19394: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19395\n",
            "2025-06-26 08:49:57,567 EPOCH 19395\n",
            "INFO:__main__:Epoch 19395: total training loss 0.00083\n",
            "2025-06-26 08:49:57,644 Epoch 19395: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19396\n",
            "2025-06-26 08:49:57,646 EPOCH 19396\n",
            "INFO:__main__:Epoch 19396: total training loss 0.00080\n",
            "2025-06-26 08:49:57,726 Epoch 19396: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19397\n",
            "2025-06-26 08:49:57,728 EPOCH 19397\n",
            "INFO:__main__:Epoch 19397: total training loss 0.00080\n",
            "2025-06-26 08:49:57,802 Epoch 19397: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19398\n",
            "2025-06-26 08:49:57,805 EPOCH 19398\n",
            "INFO:__main__:Epoch 19398: total training loss 0.00078\n",
            "2025-06-26 08:49:57,874 Epoch 19398: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19399\n",
            "2025-06-26 08:49:57,876 EPOCH 19399\n",
            "INFO:__main__:Epoch 19399: total training loss 0.00080\n",
            "2025-06-26 08:49:57,946 Epoch 19399: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19400\n",
            "2025-06-26 08:49:57,948 EPOCH 19400\n",
            "INFO:__main__:Epoch 19400: total training loss 0.00080\n",
            "2025-06-26 08:49:58,019 Epoch 19400: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19401\n",
            "2025-06-26 08:49:58,022 EPOCH 19401\n",
            "INFO:__main__:Epoch 19401: total training loss 0.00078\n",
            "2025-06-26 08:49:58,098 Epoch 19401: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19402\n",
            "2025-06-26 08:49:58,103 EPOCH 19402\n",
            "INFO:__main__:Epoch 19402: total training loss 0.00078\n",
            "2025-06-26 08:49:58,185 Epoch 19402: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19403\n",
            "2025-06-26 08:49:58,187 EPOCH 19403\n",
            "INFO:__main__:Epoch 19403: total training loss 0.00076\n",
            "2025-06-26 08:49:58,258 Epoch 19403: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19404\n",
            "2025-06-26 08:49:58,260 EPOCH 19404\n",
            "INFO:__main__:Epoch 19404: total training loss 0.00079\n",
            "2025-06-26 08:49:58,335 Epoch 19404: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19405\n",
            "2025-06-26 08:49:58,339 EPOCH 19405\n",
            "INFO:__main__:Epoch 19405: total training loss 0.00082\n",
            "2025-06-26 08:49:58,437 Epoch 19405: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19406\n",
            "2025-06-26 08:49:58,439 EPOCH 19406\n",
            "INFO:__main__:Epoch 19406: total training loss 0.00079\n",
            "2025-06-26 08:49:58,512 Epoch 19406: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19407\n",
            "2025-06-26 08:49:58,514 EPOCH 19407\n",
            "INFO:__main__:Epoch 19407: total training loss 0.00079\n",
            "2025-06-26 08:49:58,605 Epoch 19407: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19408\n",
            "2025-06-26 08:49:58,607 EPOCH 19408\n",
            "INFO:__main__:Epoch 19408: total training loss 0.00076\n",
            "2025-06-26 08:49:58,678 Epoch 19408: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19409\n",
            "2025-06-26 08:49:58,680 EPOCH 19409\n",
            "INFO:__main__:Epoch 19409: total training loss 0.00079\n",
            "2025-06-26 08:49:58,750 Epoch 19409: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19410\n",
            "2025-06-26 08:49:58,752 EPOCH 19410\n",
            "INFO:__main__:Epoch 19410: total training loss 0.00077\n",
            "2025-06-26 08:49:58,825 Epoch 19410: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19411\n",
            "2025-06-26 08:49:58,827 EPOCH 19411\n",
            "INFO:__main__:Epoch 19411: total training loss 0.00078\n",
            "2025-06-26 08:49:58,899 Epoch 19411: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19412\n",
            "2025-06-26 08:49:58,901 EPOCH 19412\n",
            "INFO:__main__:Epoch 19412: total training loss 0.00120\n",
            "2025-06-26 08:49:58,977 Epoch 19412: total training loss 0.00120\n",
            "INFO:__main__:EPOCH 19413\n",
            "2025-06-26 08:49:58,979 EPOCH 19413\n",
            "INFO:__main__:Epoch 19413: total training loss 0.00136\n",
            "2025-06-26 08:49:59,058 Epoch 19413: total training loss 0.00136\n",
            "INFO:__main__:EPOCH 19414\n",
            "2025-06-26 08:49:59,060 EPOCH 19414\n",
            "INFO:__main__:Epoch 19414: total training loss 0.00144\n",
            "2025-06-26 08:49:59,133 Epoch 19414: total training loss 0.00144\n",
            "INFO:__main__:EPOCH 19415\n",
            "2025-06-26 08:49:59,135 EPOCH 19415\n",
            "INFO:__main__:Epoch 19415: total training loss 0.00143\n",
            "2025-06-26 08:49:59,218 Epoch 19415: total training loss 0.00143\n",
            "INFO:__main__:EPOCH 19416\n",
            "2025-06-26 08:49:59,220 EPOCH 19416\n",
            "INFO:__main__:Epoch 19416: total training loss 0.00150\n",
            "2025-06-26 08:49:59,293 Epoch 19416: total training loss 0.00150\n",
            "INFO:__main__:EPOCH 19417\n",
            "2025-06-26 08:49:59,296 EPOCH 19417\n",
            "INFO:__main__:Epoch 19417: total training loss 0.00160\n",
            "2025-06-26 08:49:59,370 Epoch 19417: total training loss 0.00160\n",
            "INFO:__main__:EPOCH 19418\n",
            "2025-06-26 08:49:59,372 EPOCH 19418\n",
            "INFO:__main__:Epoch 19418: total training loss 0.00160\n",
            "2025-06-26 08:49:59,475 Epoch 19418: total training loss 0.00160\n",
            "INFO:__main__:EPOCH 19419\n",
            "2025-06-26 08:49:59,477 EPOCH 19419\n",
            "INFO:__main__:Epoch 19419: total training loss 0.00144\n",
            "2025-06-26 08:49:59,553 Epoch 19419: total training loss 0.00144\n",
            "INFO:__main__:EPOCH 19420\n",
            "2025-06-26 08:49:59,555 EPOCH 19420\n",
            "INFO:__main__:Epoch 19420: total training loss 0.00134\n",
            "2025-06-26 08:49:59,633 Epoch 19420: total training loss 0.00134\n",
            "INFO:__main__:EPOCH 19421\n",
            "2025-06-26 08:49:59,636 EPOCH 19421\n",
            "INFO:__main__:Epoch 19421: total training loss 0.00129\n",
            "2025-06-26 08:49:59,707 Epoch 19421: total training loss 0.00129\n",
            "INFO:__main__:EPOCH 19422\n",
            "2025-06-26 08:49:59,708 EPOCH 19422\n",
            "INFO:__main__:Epoch 19422: total training loss 0.00125\n",
            "2025-06-26 08:49:59,780 Epoch 19422: total training loss 0.00125\n",
            "INFO:__main__:EPOCH 19423\n",
            "2025-06-26 08:49:59,784 EPOCH 19423\n",
            "INFO:__main__:Epoch 19423: total training loss 0.00129\n",
            "2025-06-26 08:49:59,873 Epoch 19423: total training loss 0.00129\n",
            "INFO:__main__:EPOCH 19424\n",
            "2025-06-26 08:49:59,877 EPOCH 19424\n",
            "INFO:__main__:Epoch 19424: total training loss 0.00126\n",
            "2025-06-26 08:49:59,949 Epoch 19424: total training loss 0.00126\n",
            "INFO:__main__:EPOCH 19425\n",
            "2025-06-26 08:49:59,954 EPOCH 19425\n",
            "INFO:__main__:Epoch 19425: total training loss 0.00119\n",
            "2025-06-26 08:50:00,027 Epoch 19425: total training loss 0.00119\n",
            "INFO:__main__:EPOCH 19426\n",
            "2025-06-26 08:50:00,029 EPOCH 19426\n",
            "INFO:__main__:Epoch 19426: total training loss 0.00118\n",
            "2025-06-26 08:50:00,108 Epoch 19426: total training loss 0.00118\n",
            "INFO:__main__:EPOCH 19427\n",
            "2025-06-26 08:50:00,110 EPOCH 19427\n",
            "INFO:__main__:Epoch 19427: total training loss 0.00109\n",
            "2025-06-26 08:50:00,182 Epoch 19427: total training loss 0.00109\n",
            "INFO:__main__:EPOCH 19428\n",
            "2025-06-26 08:50:00,189 EPOCH 19428\n",
            "INFO:__main__:Epoch 19428: total training loss 0.00111\n",
            "2025-06-26 08:50:00,262 Epoch 19428: total training loss 0.00111\n",
            "INFO:__main__:EPOCH 19429\n",
            "2025-06-26 08:50:00,265 EPOCH 19429\n",
            "INFO:__main__:Epoch 19429: total training loss 0.00111\n",
            "2025-06-26 08:50:00,340 Epoch 19429: total training loss 0.00111\n",
            "INFO:__main__:EPOCH 19430\n",
            "2025-06-26 08:50:00,344 EPOCH 19430\n",
            "INFO:__main__:Epoch 19430: total training loss 0.00104\n",
            "2025-06-26 08:50:00,418 Epoch 19430: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 19431\n",
            "2025-06-26 08:50:00,420 EPOCH 19431\n",
            "INFO:__main__:Epoch 19431: total training loss 0.00103\n",
            "2025-06-26 08:50:00,517 Epoch 19431: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 19432\n",
            "2025-06-26 08:50:00,519 EPOCH 19432\n",
            "INFO:__main__:Epoch 19432: total training loss 0.00098\n",
            "2025-06-26 08:50:00,594 Epoch 19432: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 19433\n",
            "2025-06-26 08:50:00,597 EPOCH 19433\n",
            "INFO:__main__:Epoch 19433: total training loss 0.00094\n",
            "2025-06-26 08:50:00,670 Epoch 19433: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 19434\n",
            "2025-06-26 08:50:00,672 EPOCH 19434\n",
            "INFO:__main__:Epoch 19434: total training loss 0.00096\n",
            "2025-06-26 08:50:00,746 Epoch 19434: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19435\n",
            "2025-06-26 08:50:00,748 EPOCH 19435\n",
            "INFO:__main__:Epoch 19435: total training loss 0.00093\n",
            "2025-06-26 08:50:00,825 Epoch 19435: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19436\n",
            "2025-06-26 08:50:00,827 EPOCH 19436\n",
            "INFO:__main__:Epoch 19436: total training loss 0.00094\n",
            "2025-06-26 08:50:00,900 Epoch 19436: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 19437\n",
            "2025-06-26 08:50:00,903 EPOCH 19437\n",
            "INFO:__main__:Epoch 19437: total training loss 0.00089\n",
            "2025-06-26 08:50:00,973 Epoch 19437: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19438\n",
            "2025-06-26 08:50:00,975 EPOCH 19438\n",
            "INFO:__main__:Epoch 19438: total training loss 0.00089\n",
            "2025-06-26 08:50:01,048 Epoch 19438: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19439\n",
            "2025-06-26 08:50:01,050 EPOCH 19439\n",
            "INFO:__main__:Epoch 19439: total training loss 0.00084\n",
            "2025-06-26 08:50:01,124 Epoch 19439: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19440\n",
            "2025-06-26 08:50:01,126 EPOCH 19440\n",
            "INFO:__main__:Epoch 19440: total training loss 0.00087\n",
            "2025-06-26 08:50:01,225 Epoch 19440: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19441\n",
            "2025-06-26 08:50:01,227 EPOCH 19441\n",
            "INFO:__main__:Epoch 19441: total training loss 0.00088\n",
            "2025-06-26 08:50:01,298 Epoch 19441: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19442\n",
            "2025-06-26 08:50:01,300 EPOCH 19442\n",
            "INFO:__main__:Epoch 19442: total training loss 0.00089\n",
            "2025-06-26 08:50:01,370 Epoch 19442: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19443\n",
            "2025-06-26 08:50:01,372 EPOCH 19443\n",
            "INFO:__main__:Epoch 19443: total training loss 0.00087\n",
            "2025-06-26 08:50:01,447 Epoch 19443: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19444\n",
            "2025-06-26 08:50:01,450 EPOCH 19444\n",
            "INFO:__main__:Epoch 19444: total training loss 0.00089\n",
            "2025-06-26 08:50:01,526 Epoch 19444: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19445\n",
            "2025-06-26 08:50:01,531 EPOCH 19445\n",
            "INFO:__main__:Epoch 19445: total training loss 0.00091\n",
            "2025-06-26 08:50:01,627 Epoch 19445: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19446\n",
            "2025-06-26 08:50:01,629 EPOCH 19446\n",
            "INFO:__main__:Epoch 19446: total training loss 0.00107\n",
            "2025-06-26 08:50:01,706 Epoch 19446: total training loss 0.00107\n",
            "INFO:__main__:EPOCH 19447\n",
            "2025-06-26 08:50:01,708 EPOCH 19447\n",
            "INFO:__main__:Epoch 19447: total training loss 0.00104\n",
            "2025-06-26 08:50:01,799 Epoch 19447: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 19448\n",
            "2025-06-26 08:50:01,801 EPOCH 19448\n",
            "INFO:__main__:Epoch 19448: total training loss 0.00103\n",
            "2025-06-26 08:50:01,871 Epoch 19448: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 19449\n",
            "2025-06-26 08:50:01,874 EPOCH 19449\n",
            "INFO:__main__:Epoch 19449: total training loss 0.00105\n",
            "2025-06-26 08:50:01,945 Epoch 19449: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 19450\n",
            "2025-06-26 08:50:01,947 EPOCH 19450\n",
            "INFO:__main__:Epoch 19450: total training loss 0.00103\n",
            "2025-06-26 08:50:02,019 Epoch 19450: total training loss 0.00103\n",
            "INFO:__main__:EPOCH 19451\n",
            "2025-06-26 08:50:02,021 EPOCH 19451\n",
            "INFO:__main__:Epoch 19451: total training loss 0.00094\n",
            "2025-06-26 08:50:02,099 Epoch 19451: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 19452\n",
            "2025-06-26 08:50:02,101 EPOCH 19452\n",
            "INFO:__main__:Epoch 19452: total training loss 0.00092\n",
            "2025-06-26 08:50:02,194 Epoch 19452: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19453\n",
            "2025-06-26 08:50:02,197 EPOCH 19453\n",
            "INFO:__main__:Epoch 19453: total training loss 0.00089\n",
            "2025-06-26 08:50:02,272 Epoch 19453: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19454\n",
            "2025-06-26 08:50:02,274 EPOCH 19454\n",
            "INFO:__main__:Epoch 19454: total training loss 0.00091\n",
            "2025-06-26 08:50:02,348 Epoch 19454: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19455\n",
            "2025-06-26 08:50:02,354 EPOCH 19455\n",
            "INFO:__main__:Epoch 19455: total training loss 0.00084\n",
            "2025-06-26 08:50:02,440 Epoch 19455: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19456\n",
            "2025-06-26 08:50:02,442 EPOCH 19456\n",
            "INFO:__main__:Epoch 19456: total training loss 0.00087\n",
            "2025-06-26 08:50:02,517 Epoch 19456: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19457\n",
            "2025-06-26 08:50:02,520 EPOCH 19457\n",
            "INFO:__main__:Epoch 19457: total training loss 0.00081\n",
            "2025-06-26 08:50:02,609 Epoch 19457: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19458\n",
            "2025-06-26 08:50:02,611 EPOCH 19458\n",
            "INFO:__main__:Epoch 19458: total training loss 0.00088\n",
            "2025-06-26 08:50:02,699 Epoch 19458: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19459\n",
            "2025-06-26 08:50:02,702 EPOCH 19459\n",
            "INFO:__main__:Epoch 19459: total training loss 0.00086\n",
            "2025-06-26 08:50:02,773 Epoch 19459: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19460\n",
            "2025-06-26 08:50:02,775 EPOCH 19460\n",
            "INFO:__main__:Epoch 19460: total training loss 0.00084\n",
            "2025-06-26 08:50:02,843 Epoch 19460: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19461\n",
            "2025-06-26 08:50:02,845 EPOCH 19461\n",
            "INFO:__main__:Epoch 19461: total training loss 0.00090\n",
            "2025-06-26 08:50:02,921 Epoch 19461: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19462\n",
            "2025-06-26 08:50:02,923 EPOCH 19462\n",
            "INFO:__main__:Epoch 19462: total training loss 0.00093\n",
            "2025-06-26 08:50:03,000 Epoch 19462: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19463\n",
            "2025-06-26 08:50:03,002 EPOCH 19463\n",
            "INFO:__main__:Epoch 19463: total training loss 0.00092\n",
            "2025-06-26 08:50:03,077 Epoch 19463: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19464\n",
            "2025-06-26 08:50:03,082 EPOCH 19464\n",
            "INFO:__main__:Epoch 19464: total training loss 0.00088\n",
            "2025-06-26 08:50:03,159 Epoch 19464: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19465\n",
            "2025-06-26 08:50:03,163 EPOCH 19465\n",
            "INFO:__main__:Epoch 19465: total training loss 0.00080\n",
            "2025-06-26 08:50:03,239 Epoch 19465: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19466\n",
            "2025-06-26 08:50:03,242 EPOCH 19466\n",
            "INFO:__main__:Epoch 19466: total training loss 0.00078\n",
            "2025-06-26 08:50:03,336 Epoch 19466: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19467\n",
            "2025-06-26 08:50:03,338 EPOCH 19467\n",
            "INFO:__main__:Epoch 19467: total training loss 0.00087\n",
            "2025-06-26 08:50:03,411 Epoch 19467: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19468\n",
            "2025-06-26 08:50:03,416 EPOCH 19468\n",
            "INFO:__main__:Epoch 19468: total training loss 0.00086\n",
            "2025-06-26 08:50:03,489 Epoch 19468: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19469\n",
            "2025-06-26 08:50:03,491 EPOCH 19469\n",
            "INFO:__main__:Epoch 19469: total training loss 0.00083\n",
            "2025-06-26 08:50:03,573 Epoch 19469: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19470\n",
            "2025-06-26 08:50:03,576 EPOCH 19470\n",
            "INFO:__main__:Epoch 19470: total training loss 0.00078\n",
            "2025-06-26 08:50:03,650 Epoch 19470: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19471\n",
            "2025-06-26 08:50:03,653 EPOCH 19471\n",
            "INFO:__main__:Epoch 19471: total training loss 0.00082\n",
            "2025-06-26 08:50:03,745 Epoch 19471: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19472\n",
            "2025-06-26 08:50:03,747 EPOCH 19472\n",
            "INFO:__main__:Epoch 19472: total training loss 0.00077\n",
            "2025-06-26 08:50:03,822 Epoch 19472: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19473\n",
            "2025-06-26 08:50:03,825 EPOCH 19473\n",
            "INFO:__main__:Epoch 19473: total training loss 0.00083\n",
            "2025-06-26 08:50:03,896 Epoch 19473: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19474\n",
            "2025-06-26 08:50:03,898 EPOCH 19474\n",
            "INFO:__main__:Epoch 19474: total training loss 0.00082\n",
            "2025-06-26 08:50:03,967 Epoch 19474: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19475\n",
            "2025-06-26 08:50:03,975 EPOCH 19475\n",
            "INFO:__main__:Epoch 19475: total training loss 0.00082\n",
            "2025-06-26 08:50:04,058 Epoch 19475: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19476\n",
            "2025-06-26 08:50:04,060 EPOCH 19476\n",
            "INFO:__main__:Epoch 19476: total training loss 0.00083\n",
            "2025-06-26 08:50:04,132 Epoch 19476: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19477\n",
            "2025-06-26 08:50:04,134 EPOCH 19477\n",
            "INFO:__main__:Epoch 19477: total training loss 0.00082\n",
            "2025-06-26 08:50:04,223 Epoch 19477: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19478\n",
            "2025-06-26 08:50:04,226 EPOCH 19478\n",
            "INFO:__main__:Epoch 19478: total training loss 0.00081\n",
            "2025-06-26 08:50:04,294 Epoch 19478: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19479\n",
            "2025-06-26 08:50:04,296 EPOCH 19479\n",
            "INFO:__main__:Epoch 19479: total training loss 0.00079\n",
            "2025-06-26 08:50:04,365 Epoch 19479: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19480\n",
            "2025-06-26 08:50:04,367 EPOCH 19480\n",
            "INFO:__main__:Epoch 19480: total training loss 0.00083\n",
            "2025-06-26 08:50:04,436 Epoch 19480: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19481\n",
            "2025-06-26 08:50:04,438 EPOCH 19481\n",
            "INFO:__main__:Epoch 19481: total training loss 0.00082\n",
            "2025-06-26 08:50:04,507 Epoch 19481: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19482\n",
            "2025-06-26 08:50:04,509 EPOCH 19482\n",
            "INFO:__main__:Epoch 19482: total training loss 0.00092\n",
            "2025-06-26 08:50:04,578 Epoch 19482: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19483\n",
            "2025-06-26 08:50:04,580 EPOCH 19483\n",
            "INFO:__main__:Epoch 19483: total training loss 0.00105\n",
            "2025-06-26 08:50:04,649 Epoch 19483: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 19484\n",
            "2025-06-26 08:50:04,651 EPOCH 19484\n",
            "INFO:__main__:Epoch 19484: total training loss 0.00104\n",
            "2025-06-26 08:50:04,735 Epoch 19484: total training loss 0.00104\n",
            "INFO:__main__:EPOCH 19485\n",
            "2025-06-26 08:50:04,737 EPOCH 19485\n",
            "INFO:__main__:Epoch 19485: total training loss 0.00087\n",
            "2025-06-26 08:50:04,833 Epoch 19485: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19486\n",
            "2025-06-26 08:50:04,837 EPOCH 19486\n",
            "INFO:__main__:Epoch 19486: total training loss 0.00088\n",
            "2025-06-26 08:50:04,921 Epoch 19486: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19487\n",
            "2025-06-26 08:50:04,923 EPOCH 19487\n",
            "INFO:__main__:Epoch 19487: total training loss 0.00088\n",
            "2025-06-26 08:50:05,003 Epoch 19487: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19488\n",
            "2025-06-26 08:50:05,004 EPOCH 19488\n",
            "INFO:__main__:Epoch 19488: total training loss 0.00097\n",
            "2025-06-26 08:50:05,088 Epoch 19488: total training loss 0.00097\n",
            "INFO:__main__:EPOCH 19489\n",
            "2025-06-26 08:50:05,090 EPOCH 19489\n",
            "INFO:__main__:Epoch 19489: total training loss 0.00092\n",
            "2025-06-26 08:50:05,177 Epoch 19489: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19490\n",
            "2025-06-26 08:50:05,179 EPOCH 19490\n",
            "INFO:__main__:Epoch 19490: total training loss 0.00086\n",
            "2025-06-26 08:50:05,254 Epoch 19490: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19491\n",
            "2025-06-26 08:50:05,259 EPOCH 19491\n",
            "INFO:__main__:Epoch 19491: total training loss 0.00095\n",
            "2025-06-26 08:50:05,346 Epoch 19491: total training loss 0.00095\n",
            "INFO:__main__:EPOCH 19492\n",
            "2025-06-26 08:50:05,348 EPOCH 19492\n",
            "INFO:__main__:Epoch 19492: total training loss 0.00085\n",
            "2025-06-26 08:50:05,432 Epoch 19492: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19493\n",
            "2025-06-26 08:50:05,434 EPOCH 19493\n",
            "INFO:__main__:Epoch 19493: total training loss 0.00086\n",
            "2025-06-26 08:50:05,518 Epoch 19493: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19494\n",
            "2025-06-26 08:50:05,520 EPOCH 19494\n",
            "INFO:__main__:Epoch 19494: total training loss 0.00088\n",
            "2025-06-26 08:50:05,591 Epoch 19494: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19495\n",
            "2025-06-26 08:50:05,593 EPOCH 19495\n",
            "INFO:__main__:Epoch 19495: total training loss 0.00083\n",
            "2025-06-26 08:50:05,670 Epoch 19495: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19496\n",
            "2025-06-26 08:50:05,672 EPOCH 19496\n",
            "INFO:__main__:Epoch 19496: total training loss 0.00084\n",
            "2025-06-26 08:50:05,745 Epoch 19496: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19497\n",
            "2025-06-26 08:50:05,747 EPOCH 19497\n",
            "INFO:__main__:Epoch 19497: total training loss 0.00087\n",
            "2025-06-26 08:50:05,818 Epoch 19497: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19498\n",
            "2025-06-26 08:50:05,820 EPOCH 19498\n",
            "INFO:__main__:Epoch 19498: total training loss 0.00080\n",
            "2025-06-26 08:50:05,896 Epoch 19498: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19499\n",
            "2025-06-26 08:50:05,898 EPOCH 19499\n",
            "INFO:__main__:Epoch 19499: total training loss 0.00083\n",
            "2025-06-26 08:50:06,001 Epoch 19499: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19500\n",
            "2025-06-26 08:50:06,003 EPOCH 19500\n",
            "INFO:__main__:Epoch 19500 Step:    19500 Batch Loss:     0.000823 Tokens per Sec:  1249194, Lr: 0.001000\n",
            "2025-06-26 08:50:06,117 Epoch 19500 Step:    19500 Batch Loss:     0.000823 Tokens per Sec:  1249194, Lr: 0.001000\n",
            "INFO:__main__:Epoch 19500: total training loss 0.00082\n",
            "2025-06-26 08:50:06,120 Epoch 19500: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19501\n",
            "2025-06-26 08:50:06,123 EPOCH 19501\n",
            "INFO:__main__:Epoch 19501: total training loss 0.00079\n",
            "2025-06-26 08:50:06,214 Epoch 19501: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19502\n",
            "2025-06-26 08:50:06,216 EPOCH 19502\n",
            "INFO:__main__:Epoch 19502: total training loss 0.00084\n",
            "2025-06-26 08:50:06,344 Epoch 19502: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19503\n",
            "2025-06-26 08:50:06,346 EPOCH 19503\n",
            "INFO:__main__:Epoch 19503: total training loss 0.00083\n",
            "2025-06-26 08:50:06,445 Epoch 19503: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19504\n",
            "2025-06-26 08:50:06,447 EPOCH 19504\n",
            "INFO:__main__:Epoch 19504: total training loss 0.00082\n",
            "2025-06-26 08:50:06,531 Epoch 19504: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19505\n",
            "2025-06-26 08:50:06,533 EPOCH 19505\n",
            "INFO:__main__:Epoch 19505: total training loss 0.00083\n",
            "2025-06-26 08:50:06,641 Epoch 19505: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19506\n",
            "2025-06-26 08:50:06,643 EPOCH 19506\n",
            "INFO:__main__:Epoch 19506: total training loss 0.00086\n",
            "2025-06-26 08:50:06,741 Epoch 19506: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19507\n",
            "2025-06-26 08:50:06,743 EPOCH 19507\n",
            "INFO:__main__:Epoch 19507: total training loss 0.00085\n",
            "2025-06-26 08:50:06,840 Epoch 19507: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19508\n",
            "2025-06-26 08:50:06,844 EPOCH 19508\n",
            "INFO:__main__:Epoch 19508: total training loss 0.00096\n",
            "2025-06-26 08:50:06,923 Epoch 19508: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19509\n",
            "2025-06-26 08:50:06,928 EPOCH 19509\n",
            "INFO:__main__:Epoch 19509: total training loss 0.00096\n",
            "2025-06-26 08:50:07,031 Epoch 19509: total training loss 0.00096\n",
            "INFO:__main__:EPOCH 19510\n",
            "2025-06-26 08:50:07,034 EPOCH 19510\n",
            "INFO:__main__:Epoch 19510: total training loss 0.00085\n",
            "2025-06-26 08:50:07,129 Epoch 19510: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19511\n",
            "2025-06-26 08:50:07,134 EPOCH 19511\n",
            "INFO:__main__:Epoch 19511: total training loss 0.00087\n",
            "2025-06-26 08:50:07,207 Epoch 19511: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19512\n",
            "2025-06-26 08:50:07,213 EPOCH 19512\n",
            "INFO:__main__:Epoch 19512: total training loss 0.00087\n",
            "2025-06-26 08:50:07,302 Epoch 19512: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19513\n",
            "2025-06-26 08:50:07,305 EPOCH 19513\n",
            "INFO:__main__:Epoch 19513: total training loss 0.00087\n",
            "2025-06-26 08:50:07,395 Epoch 19513: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19514\n",
            "2025-06-26 08:50:07,397 EPOCH 19514\n",
            "INFO:__main__:Epoch 19514: total training loss 0.00085\n",
            "2025-06-26 08:50:07,493 Epoch 19514: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19515\n",
            "2025-06-26 08:50:07,496 EPOCH 19515\n",
            "INFO:__main__:Epoch 19515: total training loss 0.00081\n",
            "2025-06-26 08:50:07,585 Epoch 19515: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19516\n",
            "2025-06-26 08:50:07,587 EPOCH 19516\n",
            "INFO:__main__:Epoch 19516: total training loss 0.00080\n",
            "2025-06-26 08:50:07,676 Epoch 19516: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19517\n",
            "2025-06-26 08:50:07,678 EPOCH 19517\n",
            "INFO:__main__:Epoch 19517: total training loss 0.00081\n",
            "2025-06-26 08:50:07,751 Epoch 19517: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19518\n",
            "2025-06-26 08:50:07,754 EPOCH 19518\n",
            "INFO:__main__:Epoch 19518: total training loss 0.00080\n",
            "2025-06-26 08:50:07,830 Epoch 19518: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19519\n",
            "2025-06-26 08:50:07,832 EPOCH 19519\n",
            "INFO:__main__:Epoch 19519: total training loss 0.00079\n",
            "2025-06-26 08:50:07,908 Epoch 19519: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19520\n",
            "2025-06-26 08:50:07,910 EPOCH 19520\n",
            "INFO:__main__:Epoch 19520: total training loss 0.00076\n",
            "2025-06-26 08:50:08,001 Epoch 19520: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19521\n",
            "2025-06-26 08:50:08,003 EPOCH 19521\n",
            "INFO:__main__:Epoch 19521: total training loss 0.00079\n",
            "2025-06-26 08:50:08,095 Epoch 19521: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19522\n",
            "2025-06-26 08:50:08,098 EPOCH 19522\n",
            "INFO:__main__:Epoch 19522: total training loss 0.00075\n",
            "2025-06-26 08:50:08,187 Epoch 19522: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19523\n",
            "2025-06-26 08:50:08,189 EPOCH 19523\n",
            "INFO:__main__:Epoch 19523: total training loss 0.00076\n",
            "2025-06-26 08:50:08,267 Epoch 19523: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19524\n",
            "2025-06-26 08:50:08,269 EPOCH 19524\n",
            "INFO:__main__:Epoch 19524: total training loss 0.00084\n",
            "2025-06-26 08:50:08,349 Epoch 19524: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19525\n",
            "2025-06-26 08:50:08,351 EPOCH 19525\n",
            "INFO:__main__:Epoch 19525: total training loss 0.00078\n",
            "2025-06-26 08:50:08,439 Epoch 19525: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19526\n",
            "2025-06-26 08:50:08,442 EPOCH 19526\n",
            "INFO:__main__:Epoch 19526: total training loss 0.00077\n",
            "2025-06-26 08:50:08,527 Epoch 19526: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19527\n",
            "2025-06-26 08:50:08,529 EPOCH 19527\n",
            "INFO:__main__:Epoch 19527: total training loss 0.00083\n",
            "2025-06-26 08:50:08,613 Epoch 19527: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19528\n",
            "2025-06-26 08:50:08,615 EPOCH 19528\n",
            "INFO:__main__:Epoch 19528: total training loss 0.00080\n",
            "2025-06-26 08:50:08,682 Epoch 19528: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19529\n",
            "2025-06-26 08:50:08,684 EPOCH 19529\n",
            "INFO:__main__:Epoch 19529: total training loss 0.00078\n",
            "2025-06-26 08:50:08,767 Epoch 19529: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19530\n",
            "2025-06-26 08:50:08,769 EPOCH 19530\n",
            "INFO:__main__:Epoch 19530: total training loss 0.00079\n",
            "2025-06-26 08:50:08,839 Epoch 19530: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19531\n",
            "2025-06-26 08:50:08,841 EPOCH 19531\n",
            "INFO:__main__:Epoch 19531: total training loss 0.00077\n",
            "2025-06-26 08:50:08,918 Epoch 19531: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19532\n",
            "2025-06-26 08:50:08,920 EPOCH 19532\n",
            "INFO:__main__:Epoch 19532: total training loss 0.00078\n",
            "2025-06-26 08:50:08,990 Epoch 19532: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19533\n",
            "2025-06-26 08:50:08,992 EPOCH 19533\n",
            "INFO:__main__:Epoch 19533: total training loss 0.00081\n",
            "2025-06-26 08:50:09,063 Epoch 19533: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19534\n",
            "2025-06-26 08:50:09,064 EPOCH 19534\n",
            "INFO:__main__:Epoch 19534: total training loss 0.00080\n",
            "2025-06-26 08:50:09,138 Epoch 19534: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19535\n",
            "2025-06-26 08:50:09,142 EPOCH 19535\n",
            "INFO:__main__:Epoch 19535: total training loss 0.00083\n",
            "2025-06-26 08:50:09,242 Epoch 19535: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19536\n",
            "2025-06-26 08:50:09,244 EPOCH 19536\n",
            "INFO:__main__:Epoch 19536: total training loss 0.00084\n",
            "2025-06-26 08:50:09,347 Epoch 19536: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19537\n",
            "2025-06-26 08:50:09,350 EPOCH 19537\n",
            "INFO:__main__:Epoch 19537: total training loss 0.00081\n",
            "2025-06-26 08:50:09,444 Epoch 19537: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19538\n",
            "2025-06-26 08:50:09,446 EPOCH 19538\n",
            "INFO:__main__:Epoch 19538: total training loss 0.00086\n",
            "2025-06-26 08:50:09,558 Epoch 19538: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19539\n",
            "2025-06-26 08:50:09,560 EPOCH 19539\n",
            "INFO:__main__:Epoch 19539: total training loss 0.00086\n",
            "2025-06-26 08:50:09,630 Epoch 19539: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19540\n",
            "2025-06-26 08:50:09,632 EPOCH 19540\n",
            "INFO:__main__:Epoch 19540: total training loss 0.00084\n",
            "2025-06-26 08:50:09,725 Epoch 19540: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19541\n",
            "2025-06-26 08:50:09,727 EPOCH 19541\n",
            "INFO:__main__:Epoch 19541: total training loss 0.00081\n",
            "2025-06-26 08:50:09,826 Epoch 19541: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19542\n",
            "2025-06-26 08:50:09,828 EPOCH 19542\n",
            "INFO:__main__:Epoch 19542: total training loss 0.00079\n",
            "2025-06-26 08:50:09,923 Epoch 19542: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19543\n",
            "2025-06-26 08:50:09,925 EPOCH 19543\n",
            "INFO:__main__:Epoch 19543: total training loss 0.00085\n",
            "2025-06-26 08:50:10,038 Epoch 19543: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19544\n",
            "2025-06-26 08:50:10,042 EPOCH 19544\n",
            "INFO:__main__:Epoch 19544: total training loss 0.00079\n",
            "2025-06-26 08:50:10,156 Epoch 19544: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19545\n",
            "2025-06-26 08:50:10,158 EPOCH 19545\n",
            "INFO:__main__:Epoch 19545: total training loss 0.00074\n",
            "2025-06-26 08:50:10,272 Epoch 19545: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19546\n",
            "2025-06-26 08:50:10,274 EPOCH 19546\n",
            "INFO:__main__:Epoch 19546: total training loss 0.00074\n",
            "2025-06-26 08:50:10,373 Epoch 19546: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19547\n",
            "2025-06-26 08:50:10,375 EPOCH 19547\n",
            "INFO:__main__:Epoch 19547: total training loss 0.00077\n",
            "2025-06-26 08:50:10,463 Epoch 19547: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19548\n",
            "2025-06-26 08:50:10,465 EPOCH 19548\n",
            "INFO:__main__:Epoch 19548: total training loss 0.00076\n",
            "2025-06-26 08:50:10,535 Epoch 19548: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19549\n",
            "2025-06-26 08:50:10,537 EPOCH 19549\n",
            "INFO:__main__:Epoch 19549: total training loss 0.00082\n",
            "2025-06-26 08:50:10,608 Epoch 19549: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19550\n",
            "2025-06-26 08:50:10,611 EPOCH 19550\n",
            "INFO:__main__:Epoch 19550: total training loss 0.00087\n",
            "2025-06-26 08:50:10,680 Epoch 19550: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19551\n",
            "2025-06-26 08:50:10,682 EPOCH 19551\n",
            "INFO:__main__:Epoch 19551: total training loss 0.00087\n",
            "2025-06-26 08:50:10,752 Epoch 19551: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19552\n",
            "2025-06-26 08:50:10,754 EPOCH 19552\n",
            "INFO:__main__:Epoch 19552: total training loss 0.00083\n",
            "2025-06-26 08:50:10,826 Epoch 19552: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19553\n",
            "2025-06-26 08:50:10,828 EPOCH 19553\n",
            "INFO:__main__:Epoch 19553: total training loss 0.00082\n",
            "2025-06-26 08:50:10,915 Epoch 19553: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19554\n",
            "2025-06-26 08:50:10,917 EPOCH 19554\n",
            "INFO:__main__:Epoch 19554: total training loss 0.00081\n",
            "2025-06-26 08:50:10,991 Epoch 19554: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19555\n",
            "2025-06-26 08:50:10,994 EPOCH 19555\n",
            "INFO:__main__:Epoch 19555: total training loss 0.00077\n",
            "2025-06-26 08:50:11,070 Epoch 19555: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19556\n",
            "2025-06-26 08:50:11,075 EPOCH 19556\n",
            "INFO:__main__:Epoch 19556: total training loss 0.00082\n",
            "2025-06-26 08:50:11,153 Epoch 19556: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19557\n",
            "2025-06-26 08:50:11,156 EPOCH 19557\n",
            "INFO:__main__:Epoch 19557: total training loss 0.00084\n",
            "2025-06-26 08:50:11,228 Epoch 19557: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19558\n",
            "2025-06-26 08:50:11,230 EPOCH 19558\n",
            "INFO:__main__:Epoch 19558: total training loss 0.00081\n",
            "2025-06-26 08:50:11,312 Epoch 19558: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19559\n",
            "2025-06-26 08:50:11,315 EPOCH 19559\n",
            "INFO:__main__:Epoch 19559: total training loss 0.00075\n",
            "2025-06-26 08:50:11,412 Epoch 19559: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19560\n",
            "2025-06-26 08:50:11,414 EPOCH 19560\n",
            "INFO:__main__:Epoch 19560: total training loss 0.00071\n",
            "2025-06-26 08:50:11,498 Epoch 19560: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19561\n",
            "2025-06-26 08:50:11,503 EPOCH 19561\n",
            "INFO:__main__:Epoch 19561: total training loss 0.00075\n",
            "2025-06-26 08:50:11,588 Epoch 19561: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19562\n",
            "2025-06-26 08:50:11,593 EPOCH 19562\n",
            "INFO:__main__:Epoch 19562: total training loss 0.00078\n",
            "2025-06-26 08:50:11,668 Epoch 19562: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19563\n",
            "2025-06-26 08:50:11,670 EPOCH 19563\n",
            "INFO:__main__:Epoch 19563: total training loss 0.00076\n",
            "2025-06-26 08:50:11,745 Epoch 19563: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19564\n",
            "2025-06-26 08:50:11,747 EPOCH 19564\n",
            "INFO:__main__:Epoch 19564: total training loss 0.00073\n",
            "2025-06-26 08:50:11,822 Epoch 19564: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19565\n",
            "2025-06-26 08:50:11,824 EPOCH 19565\n",
            "INFO:__main__:Epoch 19565: total training loss 0.00073\n",
            "2025-06-26 08:50:11,896 Epoch 19565: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19566\n",
            "2025-06-26 08:50:11,898 EPOCH 19566\n",
            "INFO:__main__:Epoch 19566: total training loss 0.00074\n",
            "2025-06-26 08:50:11,980 Epoch 19566: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19567\n",
            "2025-06-26 08:50:11,981 EPOCH 19567\n",
            "INFO:__main__:Epoch 19567: total training loss 0.00077\n",
            "2025-06-26 08:50:12,065 Epoch 19567: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19568\n",
            "2025-06-26 08:50:12,067 EPOCH 19568\n",
            "INFO:__main__:Epoch 19568: total training loss 0.00072\n",
            "2025-06-26 08:50:12,139 Epoch 19568: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19569\n",
            "2025-06-26 08:50:12,141 EPOCH 19569\n",
            "INFO:__main__:Epoch 19569: total training loss 0.00072\n",
            "2025-06-26 08:50:12,216 Epoch 19569: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19570\n",
            "2025-06-26 08:50:12,218 EPOCH 19570\n",
            "INFO:__main__:Epoch 19570: total training loss 0.00077\n",
            "2025-06-26 08:50:12,305 Epoch 19570: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19571\n",
            "2025-06-26 08:50:12,307 EPOCH 19571\n",
            "INFO:__main__:Epoch 19571: total training loss 0.00074\n",
            "2025-06-26 08:50:12,377 Epoch 19571: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19572\n",
            "2025-06-26 08:50:12,379 EPOCH 19572\n",
            "INFO:__main__:Epoch 19572: total training loss 0.00070\n",
            "2025-06-26 08:50:12,451 Epoch 19572: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19573\n",
            "2025-06-26 08:50:12,453 EPOCH 19573\n",
            "INFO:__main__:Epoch 19573: total training loss 0.00075\n",
            "2025-06-26 08:50:12,546 Epoch 19573: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19574\n",
            "2025-06-26 08:50:12,548 EPOCH 19574\n",
            "INFO:__main__:Epoch 19574: total training loss 0.00077\n",
            "2025-06-26 08:50:12,621 Epoch 19574: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19575\n",
            "2025-06-26 08:50:12,623 EPOCH 19575\n",
            "INFO:__main__:Epoch 19575: total training loss 0.00072\n",
            "2025-06-26 08:50:12,697 Epoch 19575: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19576\n",
            "2025-06-26 08:50:12,699 EPOCH 19576\n",
            "INFO:__main__:Epoch 19576: total training loss 0.00078\n",
            "2025-06-26 08:50:12,770 Epoch 19576: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19577\n",
            "2025-06-26 08:50:12,773 EPOCH 19577\n",
            "INFO:__main__:Epoch 19577: total training loss 0.00077\n",
            "2025-06-26 08:50:12,847 Epoch 19577: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19578\n",
            "2025-06-26 08:50:12,849 EPOCH 19578\n",
            "INFO:__main__:Epoch 19578: total training loss 0.00076\n",
            "2025-06-26 08:50:12,932 Epoch 19578: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19579\n",
            "2025-06-26 08:50:12,935 EPOCH 19579\n",
            "INFO:__main__:Epoch 19579: total training loss 0.00073\n",
            "2025-06-26 08:50:13,013 Epoch 19579: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19580\n",
            "2025-06-26 08:50:13,015 EPOCH 19580\n",
            "INFO:__main__:Epoch 19580: total training loss 0.00073\n",
            "2025-06-26 08:50:13,090 Epoch 19580: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19581\n",
            "2025-06-26 08:50:13,093 EPOCH 19581\n",
            "INFO:__main__:Epoch 19581: total training loss 0.00081\n",
            "2025-06-26 08:50:13,165 Epoch 19581: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19582\n",
            "2025-06-26 08:50:13,167 EPOCH 19582\n",
            "INFO:__main__:Epoch 19582: total training loss 0.00081\n",
            "2025-06-26 08:50:13,260 Epoch 19582: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19583\n",
            "2025-06-26 08:50:13,262 EPOCH 19583\n",
            "INFO:__main__:Epoch 19583: total training loss 0.00079\n",
            "2025-06-26 08:50:13,336 Epoch 19583: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19584\n",
            "2025-06-26 08:50:13,338 EPOCH 19584\n",
            "INFO:__main__:Epoch 19584: total training loss 0.00081\n",
            "2025-06-26 08:50:13,412 Epoch 19584: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19585\n",
            "2025-06-26 08:50:13,414 EPOCH 19585\n",
            "INFO:__main__:Epoch 19585: total training loss 0.00081\n",
            "2025-06-26 08:50:13,503 Epoch 19585: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19586\n",
            "2025-06-26 08:50:13,505 EPOCH 19586\n",
            "INFO:__main__:Epoch 19586: total training loss 0.00075\n",
            "2025-06-26 08:50:13,595 Epoch 19586: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19587\n",
            "2025-06-26 08:50:13,597 EPOCH 19587\n",
            "INFO:__main__:Epoch 19587: total training loss 0.00074\n",
            "2025-06-26 08:50:13,666 Epoch 19587: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19588\n",
            "2025-06-26 08:50:13,667 EPOCH 19588\n",
            "INFO:__main__:Epoch 19588: total training loss 0.00076\n",
            "2025-06-26 08:50:13,745 Epoch 19588: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19589\n",
            "2025-06-26 08:50:13,747 EPOCH 19589\n",
            "INFO:__main__:Epoch 19589: total training loss 0.00074\n",
            "2025-06-26 08:50:13,818 Epoch 19589: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19590\n",
            "2025-06-26 08:50:13,821 EPOCH 19590\n",
            "INFO:__main__:Epoch 19590: total training loss 0.00070\n",
            "2025-06-26 08:50:13,890 Epoch 19590: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19591\n",
            "2025-06-26 08:50:13,892 EPOCH 19591\n",
            "INFO:__main__:Epoch 19591: total training loss 0.00071\n",
            "2025-06-26 08:50:13,962 Epoch 19591: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19592\n",
            "2025-06-26 08:50:13,964 EPOCH 19592\n",
            "INFO:__main__:Epoch 19592: total training loss 0.00076\n",
            "2025-06-26 08:50:14,038 Epoch 19592: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19593\n",
            "2025-06-26 08:50:14,040 EPOCH 19593\n",
            "INFO:__main__:Epoch 19593: total training loss 0.00076\n",
            "2025-06-26 08:50:14,113 Epoch 19593: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19594\n",
            "2025-06-26 08:50:14,115 EPOCH 19594\n",
            "INFO:__main__:Epoch 19594: total training loss 0.00071\n",
            "2025-06-26 08:50:14,201 Epoch 19594: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19595\n",
            "2025-06-26 08:50:14,203 EPOCH 19595\n",
            "INFO:__main__:Epoch 19595: total training loss 0.00072\n",
            "2025-06-26 08:50:14,278 Epoch 19595: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19596\n",
            "2025-06-26 08:50:14,289 EPOCH 19596\n",
            "INFO:__main__:Epoch 19596: total training loss 0.00076\n",
            "2025-06-26 08:50:14,371 Epoch 19596: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19597\n",
            "2025-06-26 08:50:14,373 EPOCH 19597\n",
            "INFO:__main__:Epoch 19597: total training loss 0.00072\n",
            "2025-06-26 08:50:14,445 Epoch 19597: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19598\n",
            "2025-06-26 08:50:14,447 EPOCH 19598\n",
            "INFO:__main__:Epoch 19598: total training loss 0.00070\n",
            "2025-06-26 08:50:14,536 Epoch 19598: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19599\n",
            "2025-06-26 08:50:14,538 EPOCH 19599\n",
            "INFO:__main__:Epoch 19599: total training loss 0.00075\n",
            "2025-06-26 08:50:14,640 Epoch 19599: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19600\n",
            "2025-06-26 08:50:14,642 EPOCH 19600\n",
            "INFO:__main__:Epoch 19600: total training loss 0.00072\n",
            "2025-06-26 08:50:14,730 Epoch 19600: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19601\n",
            "2025-06-26 08:50:14,732 EPOCH 19601\n",
            "INFO:__main__:Epoch 19601: total training loss 0.00070\n",
            "2025-06-26 08:50:14,808 Epoch 19601: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19602\n",
            "2025-06-26 08:50:14,810 EPOCH 19602\n",
            "INFO:__main__:Epoch 19602: total training loss 0.00071\n",
            "2025-06-26 08:50:14,882 Epoch 19602: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19603\n",
            "2025-06-26 08:50:14,884 EPOCH 19603\n",
            "INFO:__main__:Epoch 19603: total training loss 0.00072\n",
            "2025-06-26 08:50:14,961 Epoch 19603: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19604\n",
            "2025-06-26 08:50:14,963 EPOCH 19604\n",
            "INFO:__main__:Epoch 19604: total training loss 0.00073\n",
            "2025-06-26 08:50:15,041 Epoch 19604: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19605\n",
            "2025-06-26 08:50:15,043 EPOCH 19605\n",
            "INFO:__main__:Epoch 19605: total training loss 0.00073\n",
            "2025-06-26 08:50:15,116 Epoch 19605: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19606\n",
            "2025-06-26 08:50:15,118 EPOCH 19606\n",
            "INFO:__main__:Epoch 19606: total training loss 0.00078\n",
            "2025-06-26 08:50:15,202 Epoch 19606: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19607\n",
            "2025-06-26 08:50:15,204 EPOCH 19607\n",
            "INFO:__main__:Epoch 19607: total training loss 0.00083\n",
            "2025-06-26 08:50:15,275 Epoch 19607: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19608\n",
            "2025-06-26 08:50:15,277 EPOCH 19608\n",
            "INFO:__main__:Epoch 19608: total training loss 0.00079\n",
            "2025-06-26 08:50:15,355 Epoch 19608: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19609\n",
            "2025-06-26 08:50:15,358 EPOCH 19609\n",
            "INFO:__main__:Epoch 19609: total training loss 0.00078\n",
            "2025-06-26 08:50:15,427 Epoch 19609: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19610\n",
            "2025-06-26 08:50:15,429 EPOCH 19610\n",
            "INFO:__main__:Epoch 19610: total training loss 0.00079\n",
            "2025-06-26 08:50:15,499 Epoch 19610: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19611\n",
            "2025-06-26 08:50:15,501 EPOCH 19611\n",
            "INFO:__main__:Epoch 19611: total training loss 0.00076\n",
            "2025-06-26 08:50:15,586 Epoch 19611: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19612\n",
            "2025-06-26 08:50:15,588 EPOCH 19612\n",
            "INFO:__main__:Epoch 19612: total training loss 0.00074\n",
            "2025-06-26 08:50:15,677 Epoch 19612: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19613\n",
            "2025-06-26 08:50:15,680 EPOCH 19613\n",
            "INFO:__main__:Epoch 19613: total training loss 0.00075\n",
            "2025-06-26 08:50:15,760 Epoch 19613: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19614\n",
            "2025-06-26 08:50:15,763 EPOCH 19614\n",
            "INFO:__main__:Epoch 19614: total training loss 0.00080\n",
            "2025-06-26 08:50:15,833 Epoch 19614: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19615\n",
            "2025-06-26 08:50:15,835 EPOCH 19615\n",
            "INFO:__main__:Epoch 19615: total training loss 0.00081\n",
            "2025-06-26 08:50:15,908 Epoch 19615: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19616\n",
            "2025-06-26 08:50:15,910 EPOCH 19616\n",
            "INFO:__main__:Epoch 19616: total training loss 0.00077\n",
            "2025-06-26 08:50:15,991 Epoch 19616: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19617\n",
            "2025-06-26 08:50:15,993 EPOCH 19617\n",
            "INFO:__main__:Epoch 19617: total training loss 0.00075\n",
            "2025-06-26 08:50:16,064 Epoch 19617: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19618\n",
            "2025-06-26 08:50:16,067 EPOCH 19618\n",
            "INFO:__main__:Epoch 19618: total training loss 0.00079\n",
            "2025-06-26 08:50:16,137 Epoch 19618: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19619\n",
            "2025-06-26 08:50:16,139 EPOCH 19619\n",
            "INFO:__main__:Epoch 19619: total training loss 0.00078\n",
            "2025-06-26 08:50:16,221 Epoch 19619: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19620\n",
            "2025-06-26 08:50:16,223 EPOCH 19620\n",
            "INFO:__main__:Epoch 19620: total training loss 0.00080\n",
            "2025-06-26 08:50:16,297 Epoch 19620: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19621\n",
            "2025-06-26 08:50:16,299 EPOCH 19621\n",
            "INFO:__main__:Epoch 19621: total training loss 0.00076\n",
            "2025-06-26 08:50:16,370 Epoch 19621: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19622\n",
            "2025-06-26 08:50:16,372 EPOCH 19622\n",
            "INFO:__main__:Epoch 19622: total training loss 0.00077\n",
            "2025-06-26 08:50:16,442 Epoch 19622: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19623\n",
            "2025-06-26 08:50:16,445 EPOCH 19623\n",
            "INFO:__main__:Epoch 19623: total training loss 0.00075\n",
            "2025-06-26 08:50:16,515 Epoch 19623: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19624\n",
            "2025-06-26 08:50:16,518 EPOCH 19624\n",
            "INFO:__main__:Epoch 19624: total training loss 0.00076\n",
            "2025-06-26 08:50:16,590 Epoch 19624: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19625\n",
            "2025-06-26 08:50:16,592 EPOCH 19625\n",
            "INFO:__main__:Epoch 19625: total training loss 0.00075\n",
            "2025-06-26 08:50:16,668 Epoch 19625: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19626\n",
            "2025-06-26 08:50:16,670 EPOCH 19626\n",
            "INFO:__main__:Epoch 19626: total training loss 0.00075\n",
            "2025-06-26 08:50:16,754 Epoch 19626: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19627\n",
            "2025-06-26 08:50:16,757 EPOCH 19627\n",
            "INFO:__main__:Epoch 19627: total training loss 0.00079\n",
            "2025-06-26 08:50:16,836 Epoch 19627: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19628\n",
            "2025-06-26 08:50:16,838 EPOCH 19628\n",
            "INFO:__main__:Epoch 19628: total training loss 0.00076\n",
            "2025-06-26 08:50:16,931 Epoch 19628: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19629\n",
            "2025-06-26 08:50:16,933 EPOCH 19629\n",
            "INFO:__main__:Epoch 19629: total training loss 0.00079\n",
            "2025-06-26 08:50:17,007 Epoch 19629: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19630\n",
            "2025-06-26 08:50:17,009 EPOCH 19630\n",
            "INFO:__main__:Epoch 19630: total training loss 0.00077\n",
            "2025-06-26 08:50:17,089 Epoch 19630: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19631\n",
            "2025-06-26 08:50:17,096 EPOCH 19631\n",
            "INFO:__main__:Epoch 19631: total training loss 0.00080\n",
            "2025-06-26 08:50:17,175 Epoch 19631: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19632\n",
            "2025-06-26 08:50:17,177 EPOCH 19632\n",
            "INFO:__main__:Epoch 19632: total training loss 0.00079\n",
            "2025-06-26 08:50:17,256 Epoch 19632: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19633\n",
            "2025-06-26 08:50:17,258 EPOCH 19633\n",
            "INFO:__main__:Epoch 19633: total training loss 0.00080\n",
            "2025-06-26 08:50:17,332 Epoch 19633: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19634\n",
            "2025-06-26 08:50:17,334 EPOCH 19634\n",
            "INFO:__main__:Epoch 19634: total training loss 0.00074\n",
            "2025-06-26 08:50:17,410 Epoch 19634: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19635\n",
            "2025-06-26 08:50:17,412 EPOCH 19635\n",
            "INFO:__main__:Epoch 19635: total training loss 0.00078\n",
            "2025-06-26 08:50:17,483 Epoch 19635: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19636\n",
            "2025-06-26 08:50:17,485 EPOCH 19636\n",
            "INFO:__main__:Epoch 19636: total training loss 0.00079\n",
            "2025-06-26 08:50:17,577 Epoch 19636: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19637\n",
            "2025-06-26 08:50:17,579 EPOCH 19637\n",
            "INFO:__main__:Epoch 19637: total training loss 0.00078\n",
            "2025-06-26 08:50:17,654 Epoch 19637: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19638\n",
            "2025-06-26 08:50:17,656 EPOCH 19638\n",
            "INFO:__main__:Epoch 19638: total training loss 0.00075\n",
            "2025-06-26 08:50:17,745 Epoch 19638: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19639\n",
            "2025-06-26 08:50:17,748 EPOCH 19639\n",
            "INFO:__main__:Epoch 19639: total training loss 0.00074\n",
            "2025-06-26 08:50:17,829 Epoch 19639: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19640\n",
            "2025-06-26 08:50:17,831 EPOCH 19640\n",
            "INFO:__main__:Epoch 19640: total training loss 0.00076\n",
            "2025-06-26 08:50:17,923 Epoch 19640: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19641\n",
            "2025-06-26 08:50:17,925 EPOCH 19641\n",
            "INFO:__main__:Epoch 19641: total training loss 0.00075\n",
            "2025-06-26 08:50:18,005 Epoch 19641: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19642\n",
            "2025-06-26 08:50:18,007 EPOCH 19642\n",
            "INFO:__main__:Epoch 19642: total training loss 0.00075\n",
            "2025-06-26 08:50:18,079 Epoch 19642: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19643\n",
            "2025-06-26 08:50:18,081 EPOCH 19643\n",
            "INFO:__main__:Epoch 19643: total training loss 0.00074\n",
            "2025-06-26 08:50:18,152 Epoch 19643: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19644\n",
            "2025-06-26 08:50:18,154 EPOCH 19644\n",
            "INFO:__main__:Epoch 19644: total training loss 0.00072\n",
            "2025-06-26 08:50:18,234 Epoch 19644: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19645\n",
            "2025-06-26 08:50:18,236 EPOCH 19645\n",
            "INFO:__main__:Epoch 19645: total training loss 0.00077\n",
            "2025-06-26 08:50:18,309 Epoch 19645: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19646\n",
            "2025-06-26 08:50:18,311 EPOCH 19646\n",
            "INFO:__main__:Epoch 19646: total training loss 0.00077\n",
            "2025-06-26 08:50:18,380 Epoch 19646: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19647\n",
            "2025-06-26 08:50:18,382 EPOCH 19647\n",
            "INFO:__main__:Epoch 19647: total training loss 0.00079\n",
            "2025-06-26 08:50:18,450 Epoch 19647: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19648\n",
            "2025-06-26 08:50:18,452 EPOCH 19648\n",
            "INFO:__main__:Epoch 19648: total training loss 0.00077\n",
            "2025-06-26 08:50:18,521 Epoch 19648: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19649\n",
            "2025-06-26 08:50:18,524 EPOCH 19649\n",
            "INFO:__main__:Epoch 19649: total training loss 0.00075\n",
            "2025-06-26 08:50:18,596 Epoch 19649: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19650\n",
            "2025-06-26 08:50:18,598 EPOCH 19650\n",
            "INFO:__main__:Epoch 19650: total training loss 0.00078\n",
            "2025-06-26 08:50:18,668 Epoch 19650: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19651\n",
            "2025-06-26 08:50:18,670 EPOCH 19651\n",
            "INFO:__main__:Epoch 19651: total training loss 0.00078\n",
            "2025-06-26 08:50:18,741 Epoch 19651: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19652\n",
            "2025-06-26 08:50:18,743 EPOCH 19652\n",
            "INFO:__main__:Epoch 19652: total training loss 0.00076\n",
            "2025-06-26 08:50:18,818 Epoch 19652: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19653\n",
            "2025-06-26 08:50:18,820 EPOCH 19653\n",
            "INFO:__main__:Epoch 19653: total training loss 0.00072\n",
            "2025-06-26 08:50:18,901 Epoch 19653: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19654\n",
            "2025-06-26 08:50:18,905 EPOCH 19654\n",
            "INFO:__main__:Epoch 19654: total training loss 0.00071\n",
            "2025-06-26 08:50:19,011 Epoch 19654: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19655\n",
            "2025-06-26 08:50:19,013 EPOCH 19655\n",
            "INFO:__main__:Epoch 19655: total training loss 0.00079\n",
            "2025-06-26 08:50:19,086 Epoch 19655: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19656\n",
            "2025-06-26 08:50:19,089 EPOCH 19656\n",
            "INFO:__main__:Epoch 19656: total training loss 0.00076\n",
            "2025-06-26 08:50:19,166 Epoch 19656: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19657\n",
            "2025-06-26 08:50:19,168 EPOCH 19657\n",
            "INFO:__main__:Epoch 19657: total training loss 0.00076\n",
            "2025-06-26 08:50:19,258 Epoch 19657: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19658\n",
            "2025-06-26 08:50:19,260 EPOCH 19658\n",
            "INFO:__main__:Epoch 19658: total training loss 0.00076\n",
            "2025-06-26 08:50:19,329 Epoch 19658: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19659\n",
            "2025-06-26 08:50:19,331 EPOCH 19659\n",
            "INFO:__main__:Epoch 19659: total training loss 0.00080\n",
            "2025-06-26 08:50:19,399 Epoch 19659: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19660\n",
            "2025-06-26 08:50:19,401 EPOCH 19660\n",
            "INFO:__main__:Epoch 19660: total training loss 0.00081\n",
            "2025-06-26 08:50:19,472 Epoch 19660: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19661\n",
            "2025-06-26 08:50:19,473 EPOCH 19661\n",
            "INFO:__main__:Epoch 19661: total training loss 0.00076\n",
            "2025-06-26 08:50:19,542 Epoch 19661: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19662\n",
            "2025-06-26 08:50:19,544 EPOCH 19662\n",
            "INFO:__main__:Epoch 19662: total training loss 0.00077\n",
            "2025-06-26 08:50:19,616 Epoch 19662: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19663\n",
            "2025-06-26 08:50:19,618 EPOCH 19663\n",
            "INFO:__main__:Epoch 19663: total training loss 0.00075\n",
            "2025-06-26 08:50:19,686 Epoch 19663: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19664\n",
            "2025-06-26 08:50:19,688 EPOCH 19664\n",
            "INFO:__main__:Epoch 19664: total training loss 0.00073\n",
            "2025-06-26 08:50:19,760 Epoch 19664: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19665\n",
            "2025-06-26 08:50:19,762 EPOCH 19665\n",
            "INFO:__main__:Epoch 19665: total training loss 0.00072\n",
            "2025-06-26 08:50:19,832 Epoch 19665: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19666\n",
            "2025-06-26 08:50:19,834 EPOCH 19666\n",
            "INFO:__main__:Epoch 19666: total training loss 0.00070\n",
            "2025-06-26 08:50:19,903 Epoch 19666: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19667\n",
            "2025-06-26 08:50:19,905 EPOCH 19667\n",
            "INFO:__main__:Epoch 19667: total training loss 0.00072\n",
            "2025-06-26 08:50:19,975 Epoch 19667: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19668\n",
            "2025-06-26 08:50:19,978 EPOCH 19668\n",
            "INFO:__main__:Epoch 19668: total training loss 0.00073\n",
            "2025-06-26 08:50:20,064 Epoch 19668: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19669\n",
            "2025-06-26 08:50:20,066 EPOCH 19669\n",
            "INFO:__main__:Epoch 19669: total training loss 0.00072\n",
            "2025-06-26 08:50:20,139 Epoch 19669: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19670\n",
            "2025-06-26 08:50:20,141 EPOCH 19670\n",
            "INFO:__main__:Epoch 19670: total training loss 0.00071\n",
            "2025-06-26 08:50:20,215 Epoch 19670: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19671\n",
            "2025-06-26 08:50:20,218 EPOCH 19671\n",
            "INFO:__main__:Epoch 19671: total training loss 0.00074\n",
            "2025-06-26 08:50:20,287 Epoch 19671: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19672\n",
            "2025-06-26 08:50:20,289 EPOCH 19672\n",
            "INFO:__main__:Epoch 19672: total training loss 0.00079\n",
            "2025-06-26 08:50:20,361 Epoch 19672: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19673\n",
            "2025-06-26 08:50:20,363 EPOCH 19673\n",
            "INFO:__main__:Epoch 19673: total training loss 0.00076\n",
            "2025-06-26 08:50:20,432 Epoch 19673: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19674\n",
            "2025-06-26 08:50:20,434 EPOCH 19674\n",
            "INFO:__main__:Epoch 19674: total training loss 0.00073\n",
            "2025-06-26 08:50:20,503 Epoch 19674: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19675\n",
            "2025-06-26 08:50:20,505 EPOCH 19675\n",
            "INFO:__main__:Epoch 19675: total training loss 0.00080\n",
            "2025-06-26 08:50:20,590 Epoch 19675: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19676\n",
            "2025-06-26 08:50:20,593 EPOCH 19676\n",
            "INFO:__main__:Epoch 19676: total training loss 0.00078\n",
            "2025-06-26 08:50:20,677 Epoch 19676: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19677\n",
            "2025-06-26 08:50:20,679 EPOCH 19677\n",
            "INFO:__main__:Epoch 19677: total training loss 0.00075\n",
            "2025-06-26 08:50:20,763 Epoch 19677: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19678\n",
            "2025-06-26 08:50:20,765 EPOCH 19678\n",
            "INFO:__main__:Epoch 19678: total training loss 0.00077\n",
            "2025-06-26 08:50:20,853 Epoch 19678: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19679\n",
            "2025-06-26 08:50:20,857 EPOCH 19679\n",
            "INFO:__main__:Epoch 19679: total training loss 0.00074\n",
            "2025-06-26 08:50:20,939 Epoch 19679: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19680\n",
            "2025-06-26 08:50:20,941 EPOCH 19680\n",
            "INFO:__main__:Epoch 19680: total training loss 0.00075\n",
            "2025-06-26 08:50:21,012 Epoch 19680: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19681\n",
            "2025-06-26 08:50:21,015 EPOCH 19681\n",
            "INFO:__main__:Epoch 19681: total training loss 0.00077\n",
            "2025-06-26 08:50:21,112 Epoch 19681: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19682\n",
            "2025-06-26 08:50:21,114 EPOCH 19682\n",
            "INFO:__main__:Epoch 19682: total training loss 0.00083\n",
            "2025-06-26 08:50:21,209 Epoch 19682: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19683\n",
            "2025-06-26 08:50:21,212 EPOCH 19683\n",
            "INFO:__main__:Epoch 19683: total training loss 0.00082\n",
            "2025-06-26 08:50:21,297 Epoch 19683: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19684\n",
            "2025-06-26 08:50:21,300 EPOCH 19684\n",
            "INFO:__main__:Epoch 19684: total training loss 0.00084\n",
            "2025-06-26 08:50:21,371 Epoch 19684: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19685\n",
            "2025-06-26 08:50:21,374 EPOCH 19685\n",
            "INFO:__main__:Epoch 19685: total training loss 0.00082\n",
            "2025-06-26 08:50:21,443 Epoch 19685: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19686\n",
            "2025-06-26 08:50:21,447 EPOCH 19686\n",
            "INFO:__main__:Epoch 19686: total training loss 0.00084\n",
            "2025-06-26 08:50:21,517 Epoch 19686: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19687\n",
            "2025-06-26 08:50:21,519 EPOCH 19687\n",
            "INFO:__main__:Epoch 19687: total training loss 0.00084\n",
            "2025-06-26 08:50:21,596 Epoch 19687: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19688\n",
            "2025-06-26 08:50:21,598 EPOCH 19688\n",
            "INFO:__main__:Epoch 19688: total training loss 0.00088\n",
            "2025-06-26 08:50:21,667 Epoch 19688: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19689\n",
            "2025-06-26 08:50:21,669 EPOCH 19689\n",
            "INFO:__main__:Epoch 19689: total training loss 0.00088\n",
            "2025-06-26 08:50:21,747 Epoch 19689: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19690\n",
            "2025-06-26 08:50:21,749 EPOCH 19690\n",
            "INFO:__main__:Epoch 19690: total training loss 0.00085\n",
            "2025-06-26 08:50:21,832 Epoch 19690: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19691\n",
            "2025-06-26 08:50:21,838 EPOCH 19691\n",
            "INFO:__main__:Epoch 19691: total training loss 0.00085\n",
            "2025-06-26 08:50:21,918 Epoch 19691: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19692\n",
            "2025-06-26 08:50:21,922 EPOCH 19692\n",
            "INFO:__main__:Epoch 19692: total training loss 0.00089\n",
            "2025-06-26 08:50:21,996 Epoch 19692: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19693\n",
            "2025-06-26 08:50:22,001 EPOCH 19693\n",
            "INFO:__main__:Epoch 19693: total training loss 0.00084\n",
            "2025-06-26 08:50:22,073 Epoch 19693: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19694\n",
            "2025-06-26 08:50:22,081 EPOCH 19694\n",
            "INFO:__main__:Epoch 19694: total training loss 0.00087\n",
            "2025-06-26 08:50:22,166 Epoch 19694: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19695\n",
            "2025-06-26 08:50:22,170 EPOCH 19695\n",
            "INFO:__main__:Epoch 19695: total training loss 0.00084\n",
            "2025-06-26 08:50:22,255 Epoch 19695: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19696\n",
            "2025-06-26 08:50:22,259 EPOCH 19696\n",
            "INFO:__main__:Epoch 19696: total training loss 0.00081\n",
            "2025-06-26 08:50:22,331 Epoch 19696: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19697\n",
            "2025-06-26 08:50:22,336 EPOCH 19697\n",
            "INFO:__main__:Epoch 19697: total training loss 0.00081\n",
            "2025-06-26 08:50:22,417 Epoch 19697: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19698\n",
            "2025-06-26 08:50:22,423 EPOCH 19698\n",
            "INFO:__main__:Epoch 19698: total training loss 0.00087\n",
            "2025-06-26 08:50:22,521 Epoch 19698: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19699\n",
            "2025-06-26 08:50:22,525 EPOCH 19699\n",
            "INFO:__main__:Epoch 19699: total training loss 0.00083\n",
            "2025-06-26 08:50:22,614 Epoch 19699: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19700\n",
            "2025-06-26 08:50:22,620 EPOCH 19700\n",
            "INFO:__main__:Epoch 19700: total training loss 0.00080\n",
            "2025-06-26 08:50:22,721 Epoch 19700: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19701\n",
            "2025-06-26 08:50:22,727 EPOCH 19701\n",
            "INFO:__main__:Epoch 19701: total training loss 0.00083\n",
            "2025-06-26 08:50:22,844 Epoch 19701: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19702\n",
            "2025-06-26 08:50:22,850 EPOCH 19702\n",
            "INFO:__main__:Epoch 19702: total training loss 0.00082\n",
            "2025-06-26 08:50:22,946 Epoch 19702: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19703\n",
            "2025-06-26 08:50:22,951 EPOCH 19703\n",
            "INFO:__main__:Epoch 19703: total training loss 0.00076\n",
            "2025-06-26 08:50:23,048 Epoch 19703: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19704\n",
            "2025-06-26 08:50:23,051 EPOCH 19704\n",
            "INFO:__main__:Epoch 19704: total training loss 0.00077\n",
            "2025-06-26 08:50:23,127 Epoch 19704: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19705\n",
            "2025-06-26 08:50:23,133 EPOCH 19705\n",
            "INFO:__main__:Epoch 19705: total training loss 0.00080\n",
            "2025-06-26 08:50:23,226 Epoch 19705: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19706\n",
            "2025-06-26 08:50:23,230 EPOCH 19706\n",
            "INFO:__main__:Epoch 19706: total training loss 0.00073\n",
            "2025-06-26 08:50:23,350 Epoch 19706: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19707\n",
            "2025-06-26 08:50:23,352 EPOCH 19707\n",
            "INFO:__main__:Epoch 19707: total training loss 0.00080\n",
            "2025-06-26 08:50:23,462 Epoch 19707: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19708\n",
            "2025-06-26 08:50:23,464 EPOCH 19708\n",
            "INFO:__main__:Epoch 19708: total training loss 0.00079\n",
            "2025-06-26 08:50:23,552 Epoch 19708: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19709\n",
            "2025-06-26 08:50:23,554 EPOCH 19709\n",
            "INFO:__main__:Epoch 19709: total training loss 0.00078\n",
            "2025-06-26 08:50:23,633 Epoch 19709: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19710\n",
            "2025-06-26 08:50:23,634 EPOCH 19710\n",
            "INFO:__main__:Epoch 19710: total training loss 0.00077\n",
            "2025-06-26 08:50:23,726 Epoch 19710: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19711\n",
            "2025-06-26 08:50:23,728 EPOCH 19711\n",
            "INFO:__main__:Epoch 19711: total training loss 0.00076\n",
            "2025-06-26 08:50:23,819 Epoch 19711: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19712\n",
            "2025-06-26 08:50:23,821 EPOCH 19712\n",
            "INFO:__main__:Epoch 19712: total training loss 0.00079\n",
            "2025-06-26 08:50:23,909 Epoch 19712: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19713\n",
            "2025-06-26 08:50:23,912 EPOCH 19713\n",
            "INFO:__main__:Epoch 19713: total training loss 0.00074\n",
            "2025-06-26 08:50:24,002 Epoch 19713: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19714\n",
            "2025-06-26 08:50:24,009 EPOCH 19714\n",
            "INFO:__main__:Epoch 19714: total training loss 0.00072\n",
            "2025-06-26 08:50:24,102 Epoch 19714: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19715\n",
            "2025-06-26 08:50:24,106 EPOCH 19715\n",
            "INFO:__main__:Epoch 19715: total training loss 0.00075\n",
            "2025-06-26 08:50:24,185 Epoch 19715: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19716\n",
            "2025-06-26 08:50:24,193 EPOCH 19716\n",
            "INFO:__main__:Epoch 19716: total training loss 0.00075\n",
            "2025-06-26 08:50:24,285 Epoch 19716: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19717\n",
            "2025-06-26 08:50:24,288 EPOCH 19717\n",
            "INFO:__main__:Epoch 19717: total training loss 0.00072\n",
            "2025-06-26 08:50:24,384 Epoch 19717: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19718\n",
            "2025-06-26 08:50:24,388 EPOCH 19718\n",
            "INFO:__main__:Epoch 19718: total training loss 0.00073\n",
            "2025-06-26 08:50:24,461 Epoch 19718: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19719\n",
            "2025-06-26 08:50:24,464 EPOCH 19719\n",
            "INFO:__main__:Epoch 19719: total training loss 0.00074\n",
            "2025-06-26 08:50:24,545 Epoch 19719: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19720\n",
            "2025-06-26 08:50:24,549 EPOCH 19720\n",
            "INFO:__main__:Epoch 19720: total training loss 0.00075\n",
            "2025-06-26 08:50:24,645 Epoch 19720: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19721\n",
            "2025-06-26 08:50:24,648 EPOCH 19721\n",
            "INFO:__main__:Epoch 19721: total training loss 0.00075\n",
            "2025-06-26 08:50:24,735 Epoch 19721: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19722\n",
            "2025-06-26 08:50:24,741 EPOCH 19722\n",
            "INFO:__main__:Epoch 19722: total training loss 0.00087\n",
            "2025-06-26 08:50:24,840 Epoch 19722: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19723\n",
            "2025-06-26 08:50:24,844 EPOCH 19723\n",
            "INFO:__main__:Epoch 19723: total training loss 0.00084\n",
            "2025-06-26 08:50:24,926 Epoch 19723: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19724\n",
            "2025-06-26 08:50:24,930 EPOCH 19724\n",
            "INFO:__main__:Epoch 19724: total training loss 0.00085\n",
            "2025-06-26 08:50:25,014 Epoch 19724: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19725\n",
            "2025-06-26 08:50:25,019 EPOCH 19725\n",
            "INFO:__main__:Epoch 19725: total training loss 0.00081\n",
            "2025-06-26 08:50:25,118 Epoch 19725: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19726\n",
            "2025-06-26 08:50:25,121 EPOCH 19726\n",
            "INFO:__main__:Epoch 19726: total training loss 0.00087\n",
            "2025-06-26 08:50:25,212 Epoch 19726: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19727\n",
            "2025-06-26 08:50:25,214 EPOCH 19727\n",
            "INFO:__main__:Epoch 19727: total training loss 0.00087\n",
            "2025-06-26 08:50:25,288 Epoch 19727: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19728\n",
            "2025-06-26 08:50:25,290 EPOCH 19728\n",
            "INFO:__main__:Epoch 19728: total training loss 0.00078\n",
            "2025-06-26 08:50:25,381 Epoch 19728: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19729\n",
            "2025-06-26 08:50:25,383 EPOCH 19729\n",
            "INFO:__main__:Epoch 19729: total training loss 0.00082\n",
            "2025-06-26 08:50:25,471 Epoch 19729: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19730\n",
            "2025-06-26 08:50:25,473 EPOCH 19730\n",
            "INFO:__main__:Epoch 19730: total training loss 0.00076\n",
            "2025-06-26 08:50:25,573 Epoch 19730: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19731\n",
            "2025-06-26 08:50:25,577 EPOCH 19731\n",
            "INFO:__main__:Epoch 19731: total training loss 0.00080\n",
            "2025-06-26 08:50:25,669 Epoch 19731: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19732\n",
            "2025-06-26 08:50:25,671 EPOCH 19732\n",
            "INFO:__main__:Epoch 19732: total training loss 0.00081\n",
            "2025-06-26 08:50:25,762 Epoch 19732: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19733\n",
            "2025-06-26 08:50:25,764 EPOCH 19733\n",
            "INFO:__main__:Epoch 19733: total training loss 0.00079\n",
            "2025-06-26 08:50:25,851 Epoch 19733: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19734\n",
            "2025-06-26 08:50:25,853 EPOCH 19734\n",
            "INFO:__main__:Epoch 19734: total training loss 0.00077\n",
            "2025-06-26 08:50:25,938 Epoch 19734: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19735\n",
            "2025-06-26 08:50:25,941 EPOCH 19735\n",
            "INFO:__main__:Epoch 19735: total training loss 0.00079\n",
            "2025-06-26 08:50:26,019 Epoch 19735: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19736\n",
            "2025-06-26 08:50:26,021 EPOCH 19736\n",
            "INFO:__main__:Epoch 19736: total training loss 0.00077\n",
            "2025-06-26 08:50:26,101 Epoch 19736: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19737\n",
            "2025-06-26 08:50:26,103 EPOCH 19737\n",
            "INFO:__main__:Epoch 19737: total training loss 0.00077\n",
            "2025-06-26 08:50:26,200 Epoch 19737: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19738\n",
            "2025-06-26 08:50:26,204 EPOCH 19738\n",
            "INFO:__main__:Epoch 19738: total training loss 0.00073\n",
            "2025-06-26 08:50:26,318 Epoch 19738: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19739\n",
            "2025-06-26 08:50:26,321 EPOCH 19739\n",
            "INFO:__main__:Epoch 19739: total training loss 0.00076\n",
            "2025-06-26 08:50:26,442 Epoch 19739: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19740\n",
            "2025-06-26 08:50:26,444 EPOCH 19740\n",
            "INFO:__main__:Epoch 19740: total training loss 0.00076\n",
            "2025-06-26 08:50:26,529 Epoch 19740: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19741\n",
            "2025-06-26 08:50:26,531 EPOCH 19741\n",
            "INFO:__main__:Epoch 19741: total training loss 0.00074\n",
            "2025-06-26 08:50:26,623 Epoch 19741: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19742\n",
            "2025-06-26 08:50:26,625 EPOCH 19742\n",
            "INFO:__main__:Epoch 19742: total training loss 0.00077\n",
            "2025-06-26 08:50:26,710 Epoch 19742: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19743\n",
            "2025-06-26 08:50:26,712 EPOCH 19743\n",
            "INFO:__main__:Epoch 19743: total training loss 0.00074\n",
            "2025-06-26 08:50:26,784 Epoch 19743: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19744\n",
            "2025-06-26 08:50:26,787 EPOCH 19744\n",
            "INFO:__main__:Epoch 19744: total training loss 0.00074\n",
            "2025-06-26 08:50:26,855 Epoch 19744: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19745\n",
            "2025-06-26 08:50:26,857 EPOCH 19745\n",
            "INFO:__main__:Epoch 19745: total training loss 0.00077\n",
            "2025-06-26 08:50:26,935 Epoch 19745: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19746\n",
            "2025-06-26 08:50:26,937 EPOCH 19746\n",
            "INFO:__main__:Epoch 19746: total training loss 0.00073\n",
            "2025-06-26 08:50:27,014 Epoch 19746: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19747\n",
            "2025-06-26 08:50:27,016 EPOCH 19747\n",
            "INFO:__main__:Epoch 19747: total training loss 0.00077\n",
            "2025-06-26 08:50:27,099 Epoch 19747: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19748\n",
            "2025-06-26 08:50:27,102 EPOCH 19748\n",
            "INFO:__main__:Epoch 19748: total training loss 0.00076\n",
            "2025-06-26 08:50:27,174 Epoch 19748: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19749\n",
            "2025-06-26 08:50:27,178 EPOCH 19749\n",
            "INFO:__main__:Epoch 19749: total training loss 0.00073\n",
            "2025-06-26 08:50:27,254 Epoch 19749: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19750\n",
            "2025-06-26 08:50:27,259 EPOCH 19750\n",
            "INFO:__main__:Epoch 19750 Step:    19750 Batch Loss:     0.000770 Tokens per Sec:  1811641, Lr: 0.001000\n",
            "2025-06-26 08:50:27,338 Epoch 19750 Step:    19750 Batch Loss:     0.000770 Tokens per Sec:  1811641, Lr: 0.001000\n",
            "INFO:__main__:Epoch 19750: total training loss 0.00077\n",
            "2025-06-26 08:50:27,340 Epoch 19750: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19751\n",
            "2025-06-26 08:50:27,341 EPOCH 19751\n",
            "INFO:__main__:Epoch 19751: total training loss 0.00081\n",
            "2025-06-26 08:50:27,419 Epoch 19751: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19752\n",
            "2025-06-26 08:50:27,423 EPOCH 19752\n",
            "INFO:__main__:Epoch 19752: total training loss 0.00086\n",
            "2025-06-26 08:50:27,494 Epoch 19752: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19753\n",
            "2025-06-26 08:50:27,498 EPOCH 19753\n",
            "INFO:__main__:Epoch 19753: total training loss 0.00087\n",
            "2025-06-26 08:50:27,574 Epoch 19753: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19754\n",
            "2025-06-26 08:50:27,576 EPOCH 19754\n",
            "INFO:__main__:Epoch 19754: total training loss 0.00084\n",
            "2025-06-26 08:50:27,659 Epoch 19754: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19755\n",
            "2025-06-26 08:50:27,661 EPOCH 19755\n",
            "INFO:__main__:Epoch 19755: total training loss 0.00084\n",
            "2025-06-26 08:50:27,740 Epoch 19755: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19756\n",
            "2025-06-26 08:50:27,745 EPOCH 19756\n",
            "INFO:__main__:Epoch 19756: total training loss 0.00087\n",
            "2025-06-26 08:50:27,822 Epoch 19756: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19757\n",
            "2025-06-26 08:50:27,824 EPOCH 19757\n",
            "INFO:__main__:Epoch 19757: total training loss 0.00083\n",
            "2025-06-26 08:50:27,900 Epoch 19757: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19758\n",
            "2025-06-26 08:50:27,904 EPOCH 19758\n",
            "INFO:__main__:Epoch 19758: total training loss 0.00084\n",
            "2025-06-26 08:50:27,999 Epoch 19758: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19759\n",
            "2025-06-26 08:50:28,003 EPOCH 19759\n",
            "INFO:__main__:Epoch 19759: total training loss 0.00084\n",
            "2025-06-26 08:50:28,075 Epoch 19759: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19760\n",
            "2025-06-26 08:50:28,077 EPOCH 19760\n",
            "INFO:__main__:Epoch 19760: total training loss 0.00082\n",
            "2025-06-26 08:50:28,157 Epoch 19760: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19761\n",
            "2025-06-26 08:50:28,159 EPOCH 19761\n",
            "INFO:__main__:Epoch 19761: total training loss 0.00080\n",
            "2025-06-26 08:50:28,244 Epoch 19761: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19762\n",
            "2025-06-26 08:50:28,248 EPOCH 19762\n",
            "INFO:__main__:Epoch 19762: total training loss 0.00079\n",
            "2025-06-26 08:50:28,327 Epoch 19762: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19763\n",
            "2025-06-26 08:50:28,329 EPOCH 19763\n",
            "INFO:__main__:Epoch 19763: total training loss 0.00077\n",
            "2025-06-26 08:50:28,401 Epoch 19763: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19764\n",
            "2025-06-26 08:50:28,403 EPOCH 19764\n",
            "INFO:__main__:Epoch 19764: total training loss 0.00075\n",
            "2025-06-26 08:50:28,482 Epoch 19764: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19765\n",
            "2025-06-26 08:50:28,484 EPOCH 19765\n",
            "INFO:__main__:Epoch 19765: total training loss 0.00077\n",
            "2025-06-26 08:50:28,557 Epoch 19765: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19766\n",
            "2025-06-26 08:50:28,559 EPOCH 19766\n",
            "INFO:__main__:Epoch 19766: total training loss 0.00074\n",
            "2025-06-26 08:50:28,633 Epoch 19766: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19767\n",
            "2025-06-26 08:50:28,636 EPOCH 19767\n",
            "INFO:__main__:Epoch 19767: total training loss 0.00078\n",
            "2025-06-26 08:50:28,717 Epoch 19767: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19768\n",
            "2025-06-26 08:50:28,719 EPOCH 19768\n",
            "INFO:__main__:Epoch 19768: total training loss 0.00077\n",
            "2025-06-26 08:50:28,816 Epoch 19768: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19769\n",
            "2025-06-26 08:50:28,817 EPOCH 19769\n",
            "INFO:__main__:Epoch 19769: total training loss 0.00077\n",
            "2025-06-26 08:50:28,894 Epoch 19769: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19770\n",
            "2025-06-26 08:50:28,896 EPOCH 19770\n",
            "INFO:__main__:Epoch 19770: total training loss 0.00074\n",
            "2025-06-26 08:50:28,967 Epoch 19770: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19771\n",
            "2025-06-26 08:50:28,971 EPOCH 19771\n",
            "INFO:__main__:Epoch 19771: total training loss 0.00076\n",
            "2025-06-26 08:50:29,042 Epoch 19771: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19772\n",
            "2025-06-26 08:50:29,044 EPOCH 19772\n",
            "INFO:__main__:Epoch 19772: total training loss 0.00074\n",
            "2025-06-26 08:50:29,131 Epoch 19772: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19773\n",
            "2025-06-26 08:50:29,133 EPOCH 19773\n",
            "INFO:__main__:Epoch 19773: total training loss 0.00074\n",
            "2025-06-26 08:50:29,213 Epoch 19773: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19774\n",
            "2025-06-26 08:50:29,217 EPOCH 19774\n",
            "INFO:__main__:Epoch 19774: total training loss 0.00078\n",
            "2025-06-26 08:50:29,290 Epoch 19774: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19775\n",
            "2025-06-26 08:50:29,292 EPOCH 19775\n",
            "INFO:__main__:Epoch 19775: total training loss 0.00074\n",
            "2025-06-26 08:50:29,370 Epoch 19775: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19776\n",
            "2025-06-26 08:50:29,372 EPOCH 19776\n",
            "INFO:__main__:Epoch 19776: total training loss 0.00073\n",
            "2025-06-26 08:50:29,445 Epoch 19776: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19777\n",
            "2025-06-26 08:50:29,448 EPOCH 19777\n",
            "INFO:__main__:Epoch 19777: total training loss 0.00070\n",
            "2025-06-26 08:50:29,519 Epoch 19777: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19778\n",
            "2025-06-26 08:50:29,521 EPOCH 19778\n",
            "INFO:__main__:Epoch 19778: total training loss 0.00074\n",
            "2025-06-26 08:50:29,592 Epoch 19778: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19779\n",
            "2025-06-26 08:50:29,594 EPOCH 19779\n",
            "INFO:__main__:Epoch 19779: total training loss 0.00074\n",
            "2025-06-26 08:50:29,665 Epoch 19779: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19780\n",
            "2025-06-26 08:50:29,667 EPOCH 19780\n",
            "INFO:__main__:Epoch 19780: total training loss 0.00075\n",
            "2025-06-26 08:50:29,736 Epoch 19780: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19781\n",
            "2025-06-26 08:50:29,738 EPOCH 19781\n",
            "INFO:__main__:Epoch 19781: total training loss 0.00074\n",
            "2025-06-26 08:50:29,828 Epoch 19781: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19782\n",
            "2025-06-26 08:50:29,831 EPOCH 19782\n",
            "INFO:__main__:Epoch 19782: total training loss 0.00077\n",
            "2025-06-26 08:50:29,898 Epoch 19782: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19783\n",
            "2025-06-26 08:50:29,899 EPOCH 19783\n",
            "INFO:__main__:Epoch 19783: total training loss 0.00086\n",
            "2025-06-26 08:50:29,968 Epoch 19783: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19784\n",
            "2025-06-26 08:50:29,971 EPOCH 19784\n",
            "INFO:__main__:Epoch 19784: total training loss 0.00105\n",
            "2025-06-26 08:50:30,043 Epoch 19784: total training loss 0.00105\n",
            "INFO:__main__:EPOCH 19785\n",
            "2025-06-26 08:50:30,045 EPOCH 19785\n",
            "INFO:__main__:Epoch 19785: total training loss 0.00091\n",
            "2025-06-26 08:50:30,117 Epoch 19785: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19786\n",
            "2025-06-26 08:50:30,119 EPOCH 19786\n",
            "INFO:__main__:Epoch 19786: total training loss 0.00101\n",
            "2025-06-26 08:50:30,192 Epoch 19786: total training loss 0.00101\n",
            "INFO:__main__:EPOCH 19787\n",
            "2025-06-26 08:50:30,194 EPOCH 19787\n",
            "INFO:__main__:Epoch 19787: total training loss 0.00088\n",
            "2025-06-26 08:50:30,268 Epoch 19787: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19788\n",
            "2025-06-26 08:50:30,271 EPOCH 19788\n",
            "INFO:__main__:Epoch 19788: total training loss 0.00087\n",
            "2025-06-26 08:50:30,345 Epoch 19788: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19789\n",
            "2025-06-26 08:50:30,347 EPOCH 19789\n",
            "INFO:__main__:Epoch 19789: total training loss 0.00089\n",
            "2025-06-26 08:50:30,437 Epoch 19789: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19790\n",
            "2025-06-26 08:50:30,440 EPOCH 19790\n",
            "INFO:__main__:Epoch 19790: total training loss 0.00087\n",
            "2025-06-26 08:50:30,510 Epoch 19790: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19791\n",
            "2025-06-26 08:50:30,512 EPOCH 19791\n",
            "INFO:__main__:Epoch 19791: total training loss 0.00083\n",
            "2025-06-26 08:50:30,582 Epoch 19791: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19792\n",
            "2025-06-26 08:50:30,585 EPOCH 19792\n",
            "INFO:__main__:Epoch 19792: total training loss 0.00089\n",
            "2025-06-26 08:50:30,657 Epoch 19792: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19793\n",
            "2025-06-26 08:50:30,660 EPOCH 19793\n",
            "INFO:__main__:Epoch 19793: total training loss 0.00087\n",
            "2025-06-26 08:50:30,735 Epoch 19793: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19794\n",
            "2025-06-26 08:50:30,737 EPOCH 19794\n",
            "INFO:__main__:Epoch 19794: total training loss 0.00091\n",
            "2025-06-26 08:50:30,807 Epoch 19794: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19795\n",
            "2025-06-26 08:50:30,809 EPOCH 19795\n",
            "INFO:__main__:Epoch 19795: total training loss 0.00093\n",
            "2025-06-26 08:50:30,900 Epoch 19795: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19796\n",
            "2025-06-26 08:50:30,902 EPOCH 19796\n",
            "INFO:__main__:Epoch 19796: total training loss 0.00083\n",
            "2025-06-26 08:50:30,974 Epoch 19796: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19797\n",
            "2025-06-26 08:50:30,976 EPOCH 19797\n",
            "INFO:__main__:Epoch 19797: total training loss 0.00088\n",
            "2025-06-26 08:50:31,044 Epoch 19797: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19798\n",
            "2025-06-26 08:50:31,047 EPOCH 19798\n",
            "INFO:__main__:Epoch 19798: total training loss 0.00098\n",
            "2025-06-26 08:50:31,116 Epoch 19798: total training loss 0.00098\n",
            "INFO:__main__:EPOCH 19799\n",
            "2025-06-26 08:50:31,118 EPOCH 19799\n",
            "INFO:__main__:Epoch 19799: total training loss 0.00094\n",
            "2025-06-26 08:50:31,192 Epoch 19799: total training loss 0.00094\n",
            "INFO:__main__:EPOCH 19800\n",
            "2025-06-26 08:50:31,194 EPOCH 19800\n",
            "INFO:__main__:Epoch 19800: total training loss 0.00093\n",
            "2025-06-26 08:50:31,265 Epoch 19800: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19801\n",
            "2025-06-26 08:50:31,268 EPOCH 19801\n",
            "INFO:__main__:Epoch 19801: total training loss 0.00088\n",
            "2025-06-26 08:50:31,337 Epoch 19801: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19802\n",
            "2025-06-26 08:50:31,339 EPOCH 19802\n",
            "INFO:__main__:Epoch 19802: total training loss 0.00087\n",
            "2025-06-26 08:50:31,410 Epoch 19802: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19803\n",
            "2025-06-26 08:50:31,412 EPOCH 19803\n",
            "INFO:__main__:Epoch 19803: total training loss 0.00091\n",
            "2025-06-26 08:50:31,481 Epoch 19803: total training loss 0.00091\n",
            "INFO:__main__:EPOCH 19804\n",
            "2025-06-26 08:50:31,484 EPOCH 19804\n",
            "INFO:__main__:Epoch 19804: total training loss 0.00087\n",
            "2025-06-26 08:50:31,553 Epoch 19804: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19805\n",
            "2025-06-26 08:50:31,554 EPOCH 19805\n",
            "INFO:__main__:Epoch 19805: total training loss 0.00085\n",
            "2025-06-26 08:50:31,625 Epoch 19805: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19806\n",
            "2025-06-26 08:50:31,627 EPOCH 19806\n",
            "INFO:__main__:Epoch 19806: total training loss 0.00085\n",
            "2025-06-26 08:50:31,696 Epoch 19806: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19807\n",
            "2025-06-26 08:50:31,699 EPOCH 19807\n",
            "INFO:__main__:Epoch 19807: total training loss 0.00079\n",
            "2025-06-26 08:50:31,775 Epoch 19807: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19808\n",
            "2025-06-26 08:50:31,777 EPOCH 19808\n",
            "INFO:__main__:Epoch 19808: total training loss 0.00083\n",
            "2025-06-26 08:50:31,849 Epoch 19808: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19809\n",
            "2025-06-26 08:50:31,851 EPOCH 19809\n",
            "INFO:__main__:Epoch 19809: total training loss 0.00081\n",
            "2025-06-26 08:50:31,921 Epoch 19809: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19810\n",
            "2025-06-26 08:50:31,923 EPOCH 19810\n",
            "INFO:__main__:Epoch 19810: total training loss 0.00077\n",
            "2025-06-26 08:50:32,015 Epoch 19810: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19811\n",
            "2025-06-26 08:50:32,017 EPOCH 19811\n",
            "INFO:__main__:Epoch 19811: total training loss 0.00077\n",
            "2025-06-26 08:50:32,090 Epoch 19811: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19812\n",
            "2025-06-26 08:50:32,092 EPOCH 19812\n",
            "INFO:__main__:Epoch 19812: total training loss 0.00074\n",
            "2025-06-26 08:50:32,161 Epoch 19812: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19813\n",
            "2025-06-26 08:50:32,163 EPOCH 19813\n",
            "INFO:__main__:Epoch 19813: total training loss 0.00075\n",
            "2025-06-26 08:50:32,240 Epoch 19813: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19814\n",
            "2025-06-26 08:50:32,243 EPOCH 19814\n",
            "INFO:__main__:Epoch 19814: total training loss 0.00075\n",
            "2025-06-26 08:50:32,315 Epoch 19814: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19815\n",
            "2025-06-26 08:50:32,318 EPOCH 19815\n",
            "INFO:__main__:Epoch 19815: total training loss 0.00079\n",
            "2025-06-26 08:50:32,391 Epoch 19815: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19816\n",
            "2025-06-26 08:50:32,393 EPOCH 19816\n",
            "INFO:__main__:Epoch 19816: total training loss 0.00081\n",
            "2025-06-26 08:50:32,469 Epoch 19816: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19817\n",
            "2025-06-26 08:50:32,472 EPOCH 19817\n",
            "INFO:__main__:Epoch 19817: total training loss 0.00078\n",
            "2025-06-26 08:50:32,543 Epoch 19817: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19818\n",
            "2025-06-26 08:50:32,546 EPOCH 19818\n",
            "INFO:__main__:Epoch 19818: total training loss 0.00076\n",
            "2025-06-26 08:50:32,618 Epoch 19818: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19819\n",
            "2025-06-26 08:50:32,620 EPOCH 19819\n",
            "INFO:__main__:Epoch 19819: total training loss 0.00077\n",
            "2025-06-26 08:50:32,704 Epoch 19819: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19820\n",
            "2025-06-26 08:50:32,706 EPOCH 19820\n",
            "INFO:__main__:Epoch 19820: total training loss 0.00078\n",
            "2025-06-26 08:50:32,780 Epoch 19820: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19821\n",
            "2025-06-26 08:50:32,782 EPOCH 19821\n",
            "INFO:__main__:Epoch 19821: total training loss 0.00080\n",
            "2025-06-26 08:50:32,855 Epoch 19821: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19822\n",
            "2025-06-26 08:50:32,857 EPOCH 19822\n",
            "INFO:__main__:Epoch 19822: total training loss 0.00075\n",
            "2025-06-26 08:50:32,928 Epoch 19822: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19823\n",
            "2025-06-26 08:50:32,931 EPOCH 19823\n",
            "INFO:__main__:Epoch 19823: total training loss 0.00075\n",
            "2025-06-26 08:50:33,006 Epoch 19823: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19824\n",
            "2025-06-26 08:50:33,008 EPOCH 19824\n",
            "INFO:__main__:Epoch 19824: total training loss 0.00079\n",
            "2025-06-26 08:50:33,098 Epoch 19824: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19825\n",
            "2025-06-26 08:50:33,100 EPOCH 19825\n",
            "INFO:__main__:Epoch 19825: total training loss 0.00089\n",
            "2025-06-26 08:50:33,168 Epoch 19825: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19826\n",
            "2025-06-26 08:50:33,170 EPOCH 19826\n",
            "INFO:__main__:Epoch 19826: total training loss 0.00086\n",
            "2025-06-26 08:50:33,244 Epoch 19826: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19827\n",
            "2025-06-26 08:50:33,246 EPOCH 19827\n",
            "INFO:__main__:Epoch 19827: total training loss 0.00085\n",
            "2025-06-26 08:50:33,317 Epoch 19827: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19828\n",
            "2025-06-26 08:50:33,319 EPOCH 19828\n",
            "INFO:__main__:Epoch 19828: total training loss 0.00088\n",
            "2025-06-26 08:50:33,388 Epoch 19828: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19829\n",
            "2025-06-26 08:50:33,390 EPOCH 19829\n",
            "INFO:__main__:Epoch 19829: total training loss 0.00085\n",
            "2025-06-26 08:50:33,461 Epoch 19829: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19830\n",
            "2025-06-26 08:50:33,463 EPOCH 19830\n",
            "INFO:__main__:Epoch 19830: total training loss 0.00089\n",
            "2025-06-26 08:50:33,532 Epoch 19830: total training loss 0.00089\n",
            "INFO:__main__:EPOCH 19831\n",
            "2025-06-26 08:50:33,534 EPOCH 19831\n",
            "INFO:__main__:Epoch 19831: total training loss 0.00082\n",
            "2025-06-26 08:50:33,604 Epoch 19831: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19832\n",
            "2025-06-26 08:50:33,606 EPOCH 19832\n",
            "INFO:__main__:Epoch 19832: total training loss 0.00088\n",
            "2025-06-26 08:50:33,677 Epoch 19832: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19833\n",
            "2025-06-26 08:50:33,679 EPOCH 19833\n",
            "INFO:__main__:Epoch 19833: total training loss 0.00086\n",
            "2025-06-26 08:50:33,747 Epoch 19833: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19834\n",
            "2025-06-26 08:50:33,749 EPOCH 19834\n",
            "INFO:__main__:Epoch 19834: total training loss 0.00081\n",
            "2025-06-26 08:50:33,819 Epoch 19834: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19835\n",
            "2025-06-26 08:50:33,822 EPOCH 19835\n",
            "INFO:__main__:Epoch 19835: total training loss 0.00092\n",
            "2025-06-26 08:50:33,895 Epoch 19835: total training loss 0.00092\n",
            "INFO:__main__:EPOCH 19836\n",
            "2025-06-26 08:50:33,897 EPOCH 19836\n",
            "INFO:__main__:Epoch 19836: total training loss 0.00093\n",
            "2025-06-26 08:50:33,967 Epoch 19836: total training loss 0.00093\n",
            "INFO:__main__:EPOCH 19837\n",
            "2025-06-26 08:50:33,970 EPOCH 19837\n",
            "INFO:__main__:Epoch 19837: total training loss 0.00088\n",
            "2025-06-26 08:50:34,039 Epoch 19837: total training loss 0.00088\n",
            "INFO:__main__:EPOCH 19838\n",
            "2025-06-26 08:50:34,041 EPOCH 19838\n",
            "INFO:__main__:Epoch 19838: total training loss 0.00086\n",
            "2025-06-26 08:50:34,125 Epoch 19838: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19839\n",
            "2025-06-26 08:50:34,127 EPOCH 19839\n",
            "INFO:__main__:Epoch 19839: total training loss 0.00085\n",
            "2025-06-26 08:50:34,200 Epoch 19839: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19840\n",
            "2025-06-26 08:50:34,203 EPOCH 19840\n",
            "INFO:__main__:Epoch 19840: total training loss 0.00086\n",
            "2025-06-26 08:50:34,273 Epoch 19840: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19841\n",
            "2025-06-26 08:50:34,277 EPOCH 19841\n",
            "INFO:__main__:Epoch 19841: total training loss 0.00085\n",
            "2025-06-26 08:50:34,348 Epoch 19841: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19842\n",
            "2025-06-26 08:50:34,351 EPOCH 19842\n",
            "INFO:__main__:Epoch 19842: total training loss 0.00084\n",
            "2025-06-26 08:50:34,423 Epoch 19842: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19843\n",
            "2025-06-26 08:50:34,425 EPOCH 19843\n",
            "INFO:__main__:Epoch 19843: total training loss 0.00085\n",
            "2025-06-26 08:50:34,499 Epoch 19843: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19844\n",
            "2025-06-26 08:50:34,501 EPOCH 19844\n",
            "INFO:__main__:Epoch 19844: total training loss 0.00079\n",
            "2025-06-26 08:50:34,572 Epoch 19844: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19845\n",
            "2025-06-26 08:50:34,574 EPOCH 19845\n",
            "INFO:__main__:Epoch 19845: total training loss 0.00081\n",
            "2025-06-26 08:50:34,643 Epoch 19845: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19846\n",
            "2025-06-26 08:50:34,645 EPOCH 19846\n",
            "INFO:__main__:Epoch 19846: total training loss 0.00083\n",
            "2025-06-26 08:50:34,713 Epoch 19846: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19847\n",
            "2025-06-26 08:50:34,715 EPOCH 19847\n",
            "INFO:__main__:Epoch 19847: total training loss 0.00080\n",
            "2025-06-26 08:50:34,786 Epoch 19847: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19848\n",
            "2025-06-26 08:50:34,788 EPOCH 19848\n",
            "INFO:__main__:Epoch 19848: total training loss 0.00080\n",
            "2025-06-26 08:50:34,858 Epoch 19848: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19849\n",
            "2025-06-26 08:50:34,860 EPOCH 19849\n",
            "INFO:__main__:Epoch 19849: total training loss 0.00075\n",
            "2025-06-26 08:50:34,928 Epoch 19849: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19850\n",
            "2025-06-26 08:50:34,930 EPOCH 19850\n",
            "INFO:__main__:Epoch 19850: total training loss 0.00077\n",
            "2025-06-26 08:50:34,998 Epoch 19850: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19851\n",
            "2025-06-26 08:50:35,000 EPOCH 19851\n",
            "INFO:__main__:Epoch 19851: total training loss 0.00079\n",
            "2025-06-26 08:50:35,069 Epoch 19851: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19852\n",
            "2025-06-26 08:50:35,071 EPOCH 19852\n",
            "INFO:__main__:Epoch 19852: total training loss 0.00073\n",
            "2025-06-26 08:50:35,150 Epoch 19852: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19853\n",
            "2025-06-26 08:50:35,152 EPOCH 19853\n",
            "INFO:__main__:Epoch 19853: total training loss 0.00078\n",
            "2025-06-26 08:50:35,246 Epoch 19853: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19854\n",
            "2025-06-26 08:50:35,248 EPOCH 19854\n",
            "INFO:__main__:Epoch 19854: total training loss 0.00075\n",
            "2025-06-26 08:50:35,317 Epoch 19854: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19855\n",
            "2025-06-26 08:50:35,319 EPOCH 19855\n",
            "INFO:__main__:Epoch 19855: total training loss 0.00075\n",
            "2025-06-26 08:50:35,389 Epoch 19855: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19856\n",
            "2025-06-26 08:50:35,391 EPOCH 19856\n",
            "INFO:__main__:Epoch 19856: total training loss 0.00084\n",
            "2025-06-26 08:50:35,458 Epoch 19856: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19857\n",
            "2025-06-26 08:50:35,461 EPOCH 19857\n",
            "INFO:__main__:Epoch 19857: total training loss 0.00083\n",
            "2025-06-26 08:50:35,536 Epoch 19857: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19858\n",
            "2025-06-26 08:50:35,538 EPOCH 19858\n",
            "INFO:__main__:Epoch 19858: total training loss 0.00086\n",
            "2025-06-26 08:50:35,608 Epoch 19858: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19859\n",
            "2025-06-26 08:50:35,610 EPOCH 19859\n",
            "INFO:__main__:Epoch 19859: total training loss 0.00081\n",
            "2025-06-26 08:50:35,678 Epoch 19859: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19860\n",
            "2025-06-26 08:50:35,680 EPOCH 19860\n",
            "INFO:__main__:Epoch 19860: total training loss 0.00079\n",
            "2025-06-26 08:50:35,751 Epoch 19860: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19861\n",
            "2025-06-26 08:50:35,752 EPOCH 19861\n",
            "INFO:__main__:Epoch 19861: total training loss 0.00081\n",
            "2025-06-26 08:50:35,822 Epoch 19861: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19862\n",
            "2025-06-26 08:50:35,824 EPOCH 19862\n",
            "INFO:__main__:Epoch 19862: total training loss 0.00080\n",
            "2025-06-26 08:50:35,892 Epoch 19862: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19863\n",
            "2025-06-26 08:50:35,894 EPOCH 19863\n",
            "INFO:__main__:Epoch 19863: total training loss 0.00082\n",
            "2025-06-26 08:50:35,965 Epoch 19863: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19864\n",
            "2025-06-26 08:50:35,968 EPOCH 19864\n",
            "INFO:__main__:Epoch 19864: total training loss 0.00087\n",
            "2025-06-26 08:50:36,039 Epoch 19864: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19865\n",
            "2025-06-26 08:50:36,041 EPOCH 19865\n",
            "INFO:__main__:Epoch 19865: total training loss 0.00075\n",
            "2025-06-26 08:50:36,110 Epoch 19865: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19866\n",
            "2025-06-26 08:50:36,113 EPOCH 19866\n",
            "INFO:__main__:Epoch 19866: total training loss 0.00081\n",
            "2025-06-26 08:50:36,181 Epoch 19866: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19867\n",
            "2025-06-26 08:50:36,182 EPOCH 19867\n",
            "INFO:__main__:Epoch 19867: total training loss 0.00079\n",
            "2025-06-26 08:50:36,262 Epoch 19867: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19868\n",
            "2025-06-26 08:50:36,264 EPOCH 19868\n",
            "INFO:__main__:Epoch 19868: total training loss 0.00084\n",
            "2025-06-26 08:50:36,366 Epoch 19868: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19869\n",
            "2025-06-26 08:50:36,368 EPOCH 19869\n",
            "INFO:__main__:Epoch 19869: total training loss 0.00081\n",
            "2025-06-26 08:50:36,439 Epoch 19869: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19870\n",
            "2025-06-26 08:50:36,441 EPOCH 19870\n",
            "INFO:__main__:Epoch 19870: total training loss 0.00083\n",
            "2025-06-26 08:50:36,523 Epoch 19870: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19871\n",
            "2025-06-26 08:50:36,525 EPOCH 19871\n",
            "INFO:__main__:Epoch 19871: total training loss 0.00083\n",
            "2025-06-26 08:50:36,617 Epoch 19871: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19872\n",
            "2025-06-26 08:50:36,620 EPOCH 19872\n",
            "INFO:__main__:Epoch 19872: total training loss 0.00085\n",
            "2025-06-26 08:50:36,705 Epoch 19872: total training loss 0.00085\n",
            "INFO:__main__:EPOCH 19873\n",
            "2025-06-26 08:50:36,707 EPOCH 19873\n",
            "INFO:__main__:Epoch 19873: total training loss 0.00078\n",
            "2025-06-26 08:50:36,790 Epoch 19873: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19874\n",
            "2025-06-26 08:50:36,793 EPOCH 19874\n",
            "INFO:__main__:Epoch 19874: total training loss 0.00077\n",
            "2025-06-26 08:50:36,868 Epoch 19874: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19875\n",
            "2025-06-26 08:50:36,870 EPOCH 19875\n",
            "INFO:__main__:Epoch 19875: total training loss 0.00075\n",
            "2025-06-26 08:50:36,950 Epoch 19875: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19876\n",
            "2025-06-26 08:50:36,952 EPOCH 19876\n",
            "INFO:__main__:Epoch 19876: total training loss 0.00077\n",
            "2025-06-26 08:50:37,033 Epoch 19876: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19877\n",
            "2025-06-26 08:50:37,035 EPOCH 19877\n",
            "INFO:__main__:Epoch 19877: total training loss 0.00073\n",
            "2025-06-26 08:50:37,132 Epoch 19877: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19878\n",
            "2025-06-26 08:50:37,134 EPOCH 19878\n",
            "INFO:__main__:Epoch 19878: total training loss 0.00073\n",
            "2025-06-26 08:50:37,233 Epoch 19878: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19879\n",
            "2025-06-26 08:50:37,235 EPOCH 19879\n",
            "INFO:__main__:Epoch 19879: total training loss 0.00073\n",
            "2025-06-26 08:50:37,325 Epoch 19879: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19880\n",
            "2025-06-26 08:50:37,329 EPOCH 19880\n",
            "INFO:__main__:Epoch 19880: total training loss 0.00078\n",
            "2025-06-26 08:50:37,451 Epoch 19880: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19881\n",
            "2025-06-26 08:50:37,452 EPOCH 19881\n",
            "INFO:__main__:Epoch 19881: total training loss 0.00075\n",
            "2025-06-26 08:50:37,567 Epoch 19881: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19882\n",
            "2025-06-26 08:50:37,569 EPOCH 19882\n",
            "INFO:__main__:Epoch 19882: total training loss 0.00076\n",
            "2025-06-26 08:50:37,686 Epoch 19882: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19883\n",
            "2025-06-26 08:50:37,690 EPOCH 19883\n",
            "INFO:__main__:Epoch 19883: total training loss 0.00077\n",
            "2025-06-26 08:50:37,788 Epoch 19883: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19884\n",
            "2025-06-26 08:50:37,790 EPOCH 19884\n",
            "INFO:__main__:Epoch 19884: total training loss 0.00077\n",
            "2025-06-26 08:50:37,905 Epoch 19884: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19885\n",
            "2025-06-26 08:50:37,909 EPOCH 19885\n",
            "INFO:__main__:Epoch 19885: total training loss 0.00082\n",
            "2025-06-26 08:50:38,028 Epoch 19885: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19886\n",
            "2025-06-26 08:50:38,030 EPOCH 19886\n",
            "INFO:__main__:Epoch 19886: total training loss 0.00077\n",
            "2025-06-26 08:50:38,140 Epoch 19886: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19887\n",
            "2025-06-26 08:50:38,142 EPOCH 19887\n",
            "INFO:__main__:Epoch 19887: total training loss 0.00077\n",
            "2025-06-26 08:50:38,255 Epoch 19887: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19888\n",
            "2025-06-26 08:50:38,257 EPOCH 19888\n",
            "INFO:__main__:Epoch 19888: total training loss 0.00076\n",
            "2025-06-26 08:50:38,376 Epoch 19888: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19889\n",
            "2025-06-26 08:50:38,378 EPOCH 19889\n",
            "INFO:__main__:Epoch 19889: total training loss 0.00077\n",
            "2025-06-26 08:50:38,492 Epoch 19889: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19890\n",
            "2025-06-26 08:50:38,494 EPOCH 19890\n",
            "INFO:__main__:Epoch 19890: total training loss 0.00076\n",
            "2025-06-26 08:50:38,592 Epoch 19890: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19891\n",
            "2025-06-26 08:50:38,594 EPOCH 19891\n",
            "INFO:__main__:Epoch 19891: total training loss 0.00080\n",
            "2025-06-26 08:50:38,687 Epoch 19891: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19892\n",
            "2025-06-26 08:50:38,689 EPOCH 19892\n",
            "INFO:__main__:Epoch 19892: total training loss 0.00078\n",
            "2025-06-26 08:50:38,763 Epoch 19892: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19893\n",
            "2025-06-26 08:50:38,766 EPOCH 19893\n",
            "INFO:__main__:Epoch 19893: total training loss 0.00077\n",
            "2025-06-26 08:50:38,852 Epoch 19893: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19894\n",
            "2025-06-26 08:50:38,854 EPOCH 19894\n",
            "INFO:__main__:Epoch 19894: total training loss 0.00075\n",
            "2025-06-26 08:50:38,939 Epoch 19894: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19895\n",
            "2025-06-26 08:50:38,941 EPOCH 19895\n",
            "INFO:__main__:Epoch 19895: total training loss 0.00080\n",
            "2025-06-26 08:50:39,032 Epoch 19895: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19896\n",
            "2025-06-26 08:50:39,034 EPOCH 19896\n",
            "INFO:__main__:Epoch 19896: total training loss 0.00077\n",
            "2025-06-26 08:50:39,117 Epoch 19896: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19897\n",
            "2025-06-26 08:50:39,119 EPOCH 19897\n",
            "INFO:__main__:Epoch 19897: total training loss 0.00078\n",
            "2025-06-26 08:50:39,214 Epoch 19897: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19898\n",
            "2025-06-26 08:50:39,216 EPOCH 19898\n",
            "INFO:__main__:Epoch 19898: total training loss 0.00073\n",
            "2025-06-26 08:50:39,312 Epoch 19898: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19899\n",
            "2025-06-26 08:50:39,314 EPOCH 19899\n",
            "INFO:__main__:Epoch 19899: total training loss 0.00076\n",
            "2025-06-26 08:50:39,385 Epoch 19899: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19900\n",
            "2025-06-26 08:50:39,387 EPOCH 19900\n",
            "INFO:__main__:Epoch 19900: total training loss 0.00075\n",
            "2025-06-26 08:50:39,470 Epoch 19900: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19901\n",
            "2025-06-26 08:50:39,472 EPOCH 19901\n",
            "INFO:__main__:Epoch 19901: total training loss 0.00075\n",
            "2025-06-26 08:50:39,561 Epoch 19901: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19902\n",
            "2025-06-26 08:50:39,564 EPOCH 19902\n",
            "INFO:__main__:Epoch 19902: total training loss 0.00073\n",
            "2025-06-26 08:50:39,644 Epoch 19902: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19903\n",
            "2025-06-26 08:50:39,646 EPOCH 19903\n",
            "INFO:__main__:Epoch 19903: total training loss 0.00076\n",
            "2025-06-26 08:50:39,719 Epoch 19903: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19904\n",
            "2025-06-26 08:50:39,722 EPOCH 19904\n",
            "INFO:__main__:Epoch 19904: total training loss 0.00074\n",
            "2025-06-26 08:50:39,790 Epoch 19904: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19905\n",
            "2025-06-26 08:50:39,794 EPOCH 19905\n",
            "INFO:__main__:Epoch 19905: total training loss 0.00074\n",
            "2025-06-26 08:50:39,864 Epoch 19905: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19906\n",
            "2025-06-26 08:50:39,868 EPOCH 19906\n",
            "INFO:__main__:Epoch 19906: total training loss 0.00074\n",
            "2025-06-26 08:50:39,942 Epoch 19906: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19907\n",
            "2025-06-26 08:50:39,944 EPOCH 19907\n",
            "INFO:__main__:Epoch 19907: total training loss 0.00074\n",
            "2025-06-26 08:50:40,017 Epoch 19907: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19908\n",
            "2025-06-26 08:50:40,019 EPOCH 19908\n",
            "INFO:__main__:Epoch 19908: total training loss 0.00078\n",
            "2025-06-26 08:50:40,091 Epoch 19908: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19909\n",
            "2025-06-26 08:50:40,094 EPOCH 19909\n",
            "INFO:__main__:Epoch 19909: total training loss 0.00083\n",
            "2025-06-26 08:50:40,166 Epoch 19909: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19910\n",
            "2025-06-26 08:50:40,169 EPOCH 19910\n",
            "INFO:__main__:Epoch 19910: total training loss 0.00084\n",
            "2025-06-26 08:50:40,260 Epoch 19910: total training loss 0.00084\n",
            "INFO:__main__:EPOCH 19911\n",
            "2025-06-26 08:50:40,262 EPOCH 19911\n",
            "INFO:__main__:Epoch 19911: total training loss 0.00079\n",
            "2025-06-26 08:50:40,339 Epoch 19911: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19912\n",
            "2025-06-26 08:50:40,341 EPOCH 19912\n",
            "INFO:__main__:Epoch 19912: total training loss 0.00081\n",
            "2025-06-26 08:50:40,419 Epoch 19912: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19913\n",
            "2025-06-26 08:50:40,421 EPOCH 19913\n",
            "INFO:__main__:Epoch 19913: total training loss 0.00081\n",
            "2025-06-26 08:50:40,507 Epoch 19913: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19914\n",
            "2025-06-26 08:50:40,509 EPOCH 19914\n",
            "INFO:__main__:Epoch 19914: total training loss 0.00086\n",
            "2025-06-26 08:50:40,582 Epoch 19914: total training loss 0.00086\n",
            "INFO:__main__:EPOCH 19915\n",
            "2025-06-26 08:50:40,586 EPOCH 19915\n",
            "INFO:__main__:Epoch 19915: total training loss 0.00077\n",
            "2025-06-26 08:50:40,665 Epoch 19915: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19916\n",
            "2025-06-26 08:50:40,669 EPOCH 19916\n",
            "INFO:__main__:Epoch 19916: total training loss 0.00075\n",
            "2025-06-26 08:50:40,744 Epoch 19916: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19917\n",
            "2025-06-26 08:50:40,746 EPOCH 19917\n",
            "INFO:__main__:Epoch 19917: total training loss 0.00079\n",
            "2025-06-26 08:50:40,823 Epoch 19917: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19918\n",
            "2025-06-26 08:50:40,825 EPOCH 19918\n",
            "INFO:__main__:Epoch 19918: total training loss 0.00078\n",
            "2025-06-26 08:50:40,896 Epoch 19918: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19919\n",
            "2025-06-26 08:50:40,898 EPOCH 19919\n",
            "INFO:__main__:Epoch 19919: total training loss 0.00073\n",
            "2025-06-26 08:50:40,969 Epoch 19919: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19920\n",
            "2025-06-26 08:50:40,972 EPOCH 19920\n",
            "INFO:__main__:Epoch 19920: total training loss 0.00074\n",
            "2025-06-26 08:50:41,042 Epoch 19920: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19921\n",
            "2025-06-26 08:50:41,044 EPOCH 19921\n",
            "INFO:__main__:Epoch 19921: total training loss 0.00075\n",
            "2025-06-26 08:50:41,121 Epoch 19921: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19922\n",
            "2025-06-26 08:50:41,125 EPOCH 19922\n",
            "INFO:__main__:Epoch 19922: total training loss 0.00077\n",
            "2025-06-26 08:50:41,212 Epoch 19922: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19923\n",
            "2025-06-26 08:50:41,214 EPOCH 19923\n",
            "INFO:__main__:Epoch 19923: total training loss 0.00075\n",
            "2025-06-26 08:50:41,322 Epoch 19923: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19924\n",
            "2025-06-26 08:50:41,325 EPOCH 19924\n",
            "INFO:__main__:Epoch 19924: total training loss 0.00072\n",
            "2025-06-26 08:50:41,407 Epoch 19924: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19925\n",
            "2025-06-26 08:50:41,409 EPOCH 19925\n",
            "INFO:__main__:Epoch 19925: total training loss 0.00074\n",
            "2025-06-26 08:50:41,484 Epoch 19925: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19926\n",
            "2025-06-26 08:50:41,486 EPOCH 19926\n",
            "INFO:__main__:Epoch 19926: total training loss 0.00073\n",
            "2025-06-26 08:50:41,576 Epoch 19926: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19927\n",
            "2025-06-26 08:50:41,578 EPOCH 19927\n",
            "INFO:__main__:Epoch 19927: total training loss 0.00075\n",
            "2025-06-26 08:50:41,661 Epoch 19927: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19928\n",
            "2025-06-26 08:50:41,665 EPOCH 19928\n",
            "INFO:__main__:Epoch 19928: total training loss 0.00077\n",
            "2025-06-26 08:50:41,754 Epoch 19928: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19929\n",
            "2025-06-26 08:50:41,756 EPOCH 19929\n",
            "INFO:__main__:Epoch 19929: total training loss 0.00077\n",
            "2025-06-26 08:50:41,861 Epoch 19929: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19930\n",
            "2025-06-26 08:50:41,863 EPOCH 19930\n",
            "INFO:__main__:Epoch 19930: total training loss 0.00076\n",
            "2025-06-26 08:50:41,942 Epoch 19930: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19931\n",
            "2025-06-26 08:50:41,946 EPOCH 19931\n",
            "INFO:__main__:Epoch 19931: total training loss 0.00074\n",
            "2025-06-26 08:50:42,018 Epoch 19931: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19932\n",
            "2025-06-26 08:50:42,023 EPOCH 19932\n",
            "INFO:__main__:Epoch 19932: total training loss 0.00076\n",
            "2025-06-26 08:50:42,117 Epoch 19932: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19933\n",
            "2025-06-26 08:50:42,119 EPOCH 19933\n",
            "INFO:__main__:Epoch 19933: total training loss 0.00077\n",
            "2025-06-26 08:50:42,203 Epoch 19933: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19934\n",
            "2025-06-26 08:50:42,205 EPOCH 19934\n",
            "INFO:__main__:Epoch 19934: total training loss 0.00073\n",
            "2025-06-26 08:50:42,307 Epoch 19934: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19935\n",
            "2025-06-26 08:50:42,310 EPOCH 19935\n",
            "INFO:__main__:Epoch 19935: total training loss 0.00073\n",
            "2025-06-26 08:50:42,406 Epoch 19935: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19936\n",
            "2025-06-26 08:50:42,409 EPOCH 19936\n",
            "INFO:__main__:Epoch 19936: total training loss 0.00073\n",
            "2025-06-26 08:50:42,503 Epoch 19936: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19937\n",
            "2025-06-26 08:50:42,507 EPOCH 19937\n",
            "INFO:__main__:Epoch 19937: total training loss 0.00076\n",
            "2025-06-26 08:50:42,602 Epoch 19937: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19938\n",
            "2025-06-26 08:50:42,604 EPOCH 19938\n",
            "INFO:__main__:Epoch 19938: total training loss 0.00072\n",
            "2025-06-26 08:50:42,684 Epoch 19938: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19939\n",
            "2025-06-26 08:50:42,689 EPOCH 19939\n",
            "INFO:__main__:Epoch 19939: total training loss 0.00076\n",
            "2025-06-26 08:50:42,769 Epoch 19939: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19940\n",
            "2025-06-26 08:50:42,774 EPOCH 19940\n",
            "INFO:__main__:Epoch 19940: total training loss 0.00079\n",
            "2025-06-26 08:50:42,878 Epoch 19940: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19941\n",
            "2025-06-26 08:50:42,882 EPOCH 19941\n",
            "INFO:__main__:Epoch 19941: total training loss 0.00075\n",
            "2025-06-26 08:50:42,964 Epoch 19941: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19942\n",
            "2025-06-26 08:50:42,968 EPOCH 19942\n",
            "INFO:__main__:Epoch 19942: total training loss 0.00076\n",
            "2025-06-26 08:50:43,043 Epoch 19942: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19943\n",
            "2025-06-26 08:50:43,049 EPOCH 19943\n",
            "INFO:__main__:Epoch 19943: total training loss 0.00074\n",
            "2025-06-26 08:50:43,130 Epoch 19943: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19944\n",
            "2025-06-26 08:50:43,134 EPOCH 19944\n",
            "INFO:__main__:Epoch 19944: total training loss 0.00077\n",
            "2025-06-26 08:50:43,211 Epoch 19944: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19945\n",
            "2025-06-26 08:50:43,213 EPOCH 19945\n",
            "INFO:__main__:Epoch 19945: total training loss 0.00075\n",
            "2025-06-26 08:50:43,289 Epoch 19945: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19946\n",
            "2025-06-26 08:50:43,291 EPOCH 19946\n",
            "INFO:__main__:Epoch 19946: total training loss 0.00079\n",
            "2025-06-26 08:50:43,381 Epoch 19946: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19947\n",
            "2025-06-26 08:50:43,383 EPOCH 19947\n",
            "INFO:__main__:Epoch 19947: total training loss 0.00079\n",
            "2025-06-26 08:50:43,463 Epoch 19947: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19948\n",
            "2025-06-26 08:50:43,465 EPOCH 19948\n",
            "INFO:__main__:Epoch 19948: total training loss 0.00077\n",
            "2025-06-26 08:50:43,538 Epoch 19948: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19949\n",
            "2025-06-26 08:50:43,541 EPOCH 19949\n",
            "INFO:__main__:Epoch 19949: total training loss 0.00074\n",
            "2025-06-26 08:50:43,612 Epoch 19949: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19950\n",
            "2025-06-26 08:50:43,614 EPOCH 19950\n",
            "INFO:__main__:Epoch 19950: total training loss 0.00075\n",
            "2025-06-26 08:50:43,687 Epoch 19950: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19951\n",
            "2025-06-26 08:50:43,689 EPOCH 19951\n",
            "INFO:__main__:Epoch 19951: total training loss 0.00073\n",
            "2025-06-26 08:50:43,761 Epoch 19951: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19952\n",
            "2025-06-26 08:50:43,763 EPOCH 19952\n",
            "INFO:__main__:Epoch 19952: total training loss 0.00076\n",
            "2025-06-26 08:50:43,853 Epoch 19952: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19953\n",
            "2025-06-26 08:50:43,855 EPOCH 19953\n",
            "INFO:__main__:Epoch 19953: total training loss 0.00079\n",
            "2025-06-26 08:50:43,939 Epoch 19953: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19954\n",
            "2025-06-26 08:50:43,941 EPOCH 19954\n",
            "INFO:__main__:Epoch 19954: total training loss 0.00074\n",
            "2025-06-26 08:50:44,026 Epoch 19954: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19955\n",
            "2025-06-26 08:50:44,028 EPOCH 19955\n",
            "INFO:__main__:Epoch 19955: total training loss 0.00076\n",
            "2025-06-26 08:50:44,099 Epoch 19955: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19956\n",
            "2025-06-26 08:50:44,101 EPOCH 19956\n",
            "INFO:__main__:Epoch 19956: total training loss 0.00080\n",
            "2025-06-26 08:50:44,170 Epoch 19956: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19957\n",
            "2025-06-26 08:50:44,172 EPOCH 19957\n",
            "INFO:__main__:Epoch 19957: total training loss 0.00083\n",
            "2025-06-26 08:50:44,242 Epoch 19957: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19958\n",
            "2025-06-26 08:50:44,244 EPOCH 19958\n",
            "INFO:__main__:Epoch 19958: total training loss 0.00081\n",
            "2025-06-26 08:50:44,316 Epoch 19958: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19959\n",
            "2025-06-26 08:50:44,318 EPOCH 19959\n",
            "INFO:__main__:Epoch 19959: total training loss 0.00081\n",
            "2025-06-26 08:50:44,388 Epoch 19959: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19960\n",
            "2025-06-26 08:50:44,390 EPOCH 19960\n",
            "INFO:__main__:Epoch 19960: total training loss 0.00078\n",
            "2025-06-26 08:50:44,461 Epoch 19960: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19961\n",
            "2025-06-26 08:50:44,463 EPOCH 19961\n",
            "INFO:__main__:Epoch 19961: total training loss 0.00077\n",
            "2025-06-26 08:50:44,533 Epoch 19961: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19962\n",
            "2025-06-26 08:50:44,535 EPOCH 19962\n",
            "INFO:__main__:Epoch 19962: total training loss 0.00074\n",
            "2025-06-26 08:50:44,605 Epoch 19962: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19963\n",
            "2025-06-26 08:50:44,607 EPOCH 19963\n",
            "INFO:__main__:Epoch 19963: total training loss 0.00076\n",
            "2025-06-26 08:50:44,677 Epoch 19963: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19964\n",
            "2025-06-26 08:50:44,679 EPOCH 19964\n",
            "INFO:__main__:Epoch 19964: total training loss 0.00075\n",
            "2025-06-26 08:50:44,750 Epoch 19964: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19965\n",
            "2025-06-26 08:50:44,752 EPOCH 19965\n",
            "INFO:__main__:Epoch 19965: total training loss 0.00074\n",
            "2025-06-26 08:50:44,823 Epoch 19965: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19966\n",
            "2025-06-26 08:50:44,826 EPOCH 19966\n",
            "INFO:__main__:Epoch 19966: total training loss 0.00074\n",
            "2025-06-26 08:50:44,897 Epoch 19966: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19967\n",
            "2025-06-26 08:50:44,900 EPOCH 19967\n",
            "INFO:__main__:Epoch 19967: total training loss 0.00074\n",
            "2025-06-26 08:50:44,970 Epoch 19967: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19968\n",
            "2025-06-26 08:50:44,972 EPOCH 19968\n",
            "INFO:__main__:Epoch 19968: total training loss 0.00074\n",
            "2025-06-26 08:50:45,062 Epoch 19968: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19969\n",
            "2025-06-26 08:50:45,064 EPOCH 19969\n",
            "INFO:__main__:Epoch 19969: total training loss 0.00072\n",
            "2025-06-26 08:50:45,143 Epoch 19969: total training loss 0.00072\n",
            "INFO:__main__:EPOCH 19970\n",
            "2025-06-26 08:50:45,145 EPOCH 19970\n",
            "INFO:__main__:Epoch 19970: total training loss 0.00074\n",
            "2025-06-26 08:50:45,225 Epoch 19970: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19971\n",
            "2025-06-26 08:50:45,228 EPOCH 19971\n",
            "INFO:__main__:Epoch 19971: total training loss 0.00076\n",
            "2025-06-26 08:50:45,298 Epoch 19971: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19972\n",
            "2025-06-26 08:50:45,300 EPOCH 19972\n",
            "INFO:__main__:Epoch 19972: total training loss 0.00070\n",
            "2025-06-26 08:50:45,371 Epoch 19972: total training loss 0.00070\n",
            "INFO:__main__:EPOCH 19973\n",
            "2025-06-26 08:50:45,373 EPOCH 19973\n",
            "INFO:__main__:Epoch 19973: total training loss 0.00071\n",
            "2025-06-26 08:50:45,443 Epoch 19973: total training loss 0.00071\n",
            "INFO:__main__:EPOCH 19974\n",
            "2025-06-26 08:50:45,445 EPOCH 19974\n",
            "INFO:__main__:Epoch 19974: total training loss 0.00077\n",
            "2025-06-26 08:50:45,517 Epoch 19974: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19975\n",
            "2025-06-26 08:50:45,520 EPOCH 19975\n",
            "INFO:__main__:Epoch 19975: total training loss 0.00077\n",
            "2025-06-26 08:50:45,591 Epoch 19975: total training loss 0.00077\n",
            "INFO:__main__:EPOCH 19976\n",
            "2025-06-26 08:50:45,593 EPOCH 19976\n",
            "INFO:__main__:Epoch 19976: total training loss 0.00073\n",
            "2025-06-26 08:50:45,663 Epoch 19976: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19977\n",
            "2025-06-26 08:50:45,665 EPOCH 19977\n",
            "INFO:__main__:Epoch 19977: total training loss 0.00074\n",
            "2025-06-26 08:50:45,746 Epoch 19977: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19978\n",
            "2025-06-26 08:50:45,748 EPOCH 19978\n",
            "INFO:__main__:Epoch 19978: total training loss 0.00076\n",
            "2025-06-26 08:50:45,825 Epoch 19978: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19979\n",
            "2025-06-26 08:50:45,827 EPOCH 19979\n",
            "INFO:__main__:Epoch 19979: total training loss 0.00075\n",
            "2025-06-26 08:50:45,899 Epoch 19979: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19980\n",
            "2025-06-26 08:50:45,901 EPOCH 19980\n",
            "INFO:__main__:Epoch 19980: total training loss 0.00083\n",
            "2025-06-26 08:50:45,975 Epoch 19980: total training loss 0.00083\n",
            "INFO:__main__:EPOCH 19981\n",
            "2025-06-26 08:50:45,977 EPOCH 19981\n",
            "INFO:__main__:Epoch 19981: total training loss 0.00081\n",
            "2025-06-26 08:50:46,050 Epoch 19981: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19982\n",
            "2025-06-26 08:50:46,053 EPOCH 19982\n",
            "INFO:__main__:Epoch 19982: total training loss 0.00082\n",
            "2025-06-26 08:50:46,147 Epoch 19982: total training loss 0.00082\n",
            "INFO:__main__:EPOCH 19983\n",
            "2025-06-26 08:50:46,154 EPOCH 19983\n",
            "INFO:__main__:Epoch 19983: total training loss 0.00090\n",
            "2025-06-26 08:50:46,230 Epoch 19983: total training loss 0.00090\n",
            "INFO:__main__:EPOCH 19984\n",
            "2025-06-26 08:50:46,232 EPOCH 19984\n",
            "INFO:__main__:Epoch 19984: total training loss 0.00087\n",
            "2025-06-26 08:50:46,309 Epoch 19984: total training loss 0.00087\n",
            "INFO:__main__:EPOCH 19985\n",
            "2025-06-26 08:50:46,313 EPOCH 19985\n",
            "INFO:__main__:Epoch 19985: total training loss 0.00081\n",
            "2025-06-26 08:50:46,406 Epoch 19985: total training loss 0.00081\n",
            "INFO:__main__:EPOCH 19986\n",
            "2025-06-26 08:50:46,409 EPOCH 19986\n",
            "INFO:__main__:Epoch 19986: total training loss 0.00076\n",
            "2025-06-26 08:50:46,483 Epoch 19986: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19987\n",
            "2025-06-26 08:50:46,486 EPOCH 19987\n",
            "INFO:__main__:Epoch 19987: total training loss 0.00076\n",
            "2025-06-26 08:50:46,558 Epoch 19987: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19988\n",
            "2025-06-26 08:50:46,560 EPOCH 19988\n",
            "INFO:__main__:Epoch 19988: total training loss 0.00076\n",
            "2025-06-26 08:50:46,638 Epoch 19988: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19989\n",
            "2025-06-26 08:50:46,640 EPOCH 19989\n",
            "INFO:__main__:Epoch 19989: total training loss 0.00076\n",
            "2025-06-26 08:50:46,713 Epoch 19989: total training loss 0.00076\n",
            "INFO:__main__:EPOCH 19990\n",
            "2025-06-26 08:50:46,715 EPOCH 19990\n",
            "INFO:__main__:Epoch 19990: total training loss 0.00079\n",
            "2025-06-26 08:50:46,787 Epoch 19990: total training loss 0.00079\n",
            "INFO:__main__:EPOCH 19991\n",
            "2025-06-26 08:50:46,789 EPOCH 19991\n",
            "INFO:__main__:Epoch 19991: total training loss 0.00075\n",
            "2025-06-26 08:50:46,865 Epoch 19991: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19992\n",
            "2025-06-26 08:50:46,870 EPOCH 19992\n",
            "INFO:__main__:Epoch 19992: total training loss 0.00078\n",
            "2025-06-26 08:50:46,940 Epoch 19992: total training loss 0.00078\n",
            "INFO:__main__:EPOCH 19993\n",
            "2025-06-26 08:50:46,942 EPOCH 19993\n",
            "INFO:__main__:Epoch 19993: total training loss 0.00080\n",
            "2025-06-26 08:50:47,021 Epoch 19993: total training loss 0.00080\n",
            "INFO:__main__:EPOCH 19994\n",
            "2025-06-26 08:50:47,025 EPOCH 19994\n",
            "INFO:__main__:Epoch 19994: total training loss 0.00074\n",
            "2025-06-26 08:50:47,103 Epoch 19994: total training loss 0.00074\n",
            "INFO:__main__:EPOCH 19995\n",
            "2025-06-26 08:50:47,106 EPOCH 19995\n",
            "INFO:__main__:Epoch 19995: total training loss 0.00073\n",
            "2025-06-26 08:50:47,181 Epoch 19995: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19996\n",
            "2025-06-26 08:50:47,189 EPOCH 19996\n",
            "INFO:__main__:Epoch 19996: total training loss 0.00073\n",
            "2025-06-26 08:50:47,276 Epoch 19996: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19997\n",
            "2025-06-26 08:50:47,280 EPOCH 19997\n",
            "INFO:__main__:Epoch 19997: total training loss 0.00073\n",
            "2025-06-26 08:50:47,350 Epoch 19997: total training loss 0.00073\n",
            "INFO:__main__:EPOCH 19998\n",
            "2025-06-26 08:50:47,353 EPOCH 19998\n",
            "INFO:__main__:Epoch 19998: total training loss 0.00075\n",
            "2025-06-26 08:50:47,427 Epoch 19998: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 19999\n",
            "2025-06-26 08:50:47,429 EPOCH 19999\n",
            "INFO:__main__:Epoch 19999: total training loss 0.00075\n",
            "2025-06-26 08:50:47,501 Epoch 19999: total training loss 0.00075\n",
            "INFO:__main__:EPOCH 20000\n",
            "2025-06-26 08:50:47,503 EPOCH 20000\n",
            "INFO:__main__:Epoch 20000 Step:    20000 Batch Loss:     0.000702 Tokens per Sec:  2015327, Lr: 0.001000\n",
            "2025-06-26 08:50:47,576 Epoch 20000 Step:    20000 Batch Loss:     0.000702 Tokens per Sec:  2015327, Lr: 0.001000\n",
            "INFO:__main__:Validation result at epoch 20000, step    20000: Val DTW Score:  12.97, loss:   0.0948,  duration: 5.6417s\n",
            "2025-06-26 08:50:53,222 Validation result at epoch 20000, step    20000: Val DTW Score:  12.97, loss:   0.0948,  duration: 5.6417s\n",
            "INFO:__main__:Epoch 20000: total training loss 0.00070\n",
            "2025-06-26 08:50:53,225 Epoch 20000: total training loss 0.00070\n",
            "INFO:__main__:Training ended after 20000 epochs.\n",
            "2025-06-26 08:50:53,227 Training ended after 20000 epochs.\n",
            "INFO:__main__:Best validation result at step    18000:  12.93 dtw.\n",
            "2025-06-26 08:50:53,228 Best validation result at step    18000:  12.93 dtw.\n"
          ]
        }
      ]
    }
  ]
}